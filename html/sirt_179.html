<div class="container">

<table style="width: 100%;"><tr>
<td>linking.haberman</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Linking in the 2PL/Generalized Partial Credit Model
</h2>

<h3>Description</h3>

<p>This function does the linking of several studies which are calibrated
using the 2PL or the generalized item response model according to
Haberman (2009). This method is a generalization of log-mean-mean
linking from one study to several studies. The default <code>a_log=TRUE</code>
logarithmizes item slopes for linking while otherwise an additive regression
model is assumed for the original item loadings (see Details; Battauz, 2017)
</p>


<h3>Usage</h3>

<pre><code class="language-R">linking.haberman(itempars, personpars, estimation="OLS", a_trim=Inf, b_trim=Inf,
    lts_prop=.5, a_log=TRUE, conv=1e-05, maxiter=1000, progress=TRUE,
    adjust_main_effects=TRUE, vcov=TRUE)

## S3 method for class 'linking.haberman'
summary(object, digits=3, file=NULL, ...)

linking.haberman.lq(itempars, pow=2, eps=1e-3, a_log=TRUE, use_nu=FALSE,
      est_pow=FALSE, lower_pow=.1, upper_pow=3)

## S3 method for class 'linking.haberman.lq'
summary(object, digits=3, file=NULL, ...)

## prepare 'itempars' argument for linking.haberman()
linking_haberman_itempars_prepare(b, a=NULL, wgt=NULL)

## conversion of different parameterizations of item parameters
linking_haberman_itempars_convert(itempars=NULL, lambda=NULL, nu=NULL, a=NULL, b=NULL)

## L0 polish precedure minimizing number of interactions in two-way table
L0_polish(x, tol, conv=0.01, maxiter=30, type=1, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>itempars</code></td>
<td>

<p>A data frame with four or five columns. The first four columns contain
in the order: study name, item name, <code class="reqn">a</code> parameter, <code class="reqn">b</code> parameter.
The fifth column is an optional weight for every item and every study.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>personpars</code></td>
<td>
<p>A list with vectors (e.g. EAPs or WLEs) or data frames
(e.g. plausible values) containing person parameters which
should be transformed.
If a data frame in each list entry has <code>se</code> or <code>SE</code>
(standard error) in a column name, then the corresponding
column is only multiplied by <code class="reqn">A_t</code>.
If a column is labeled as <code>pid</code> (person ID),
then it is left untransformed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimation</code></td>
<td>
<p>Estimation method. Can be <code>"OLS"</code> (ordinary least squares),
<code>"BSQ"</code> (bisquare weighted regression), <code>"HUB"</code> (regression using Huber
weights), <code>"MED"</code> (median regression), <code>"LTS"</code> (trimmed least squares),
<code>"L1"</code> (median polish), <code>"L0"</code> (minimizing number of interactions)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a_trim</code></td>
<td>
<p>Trimming parameter for item slopes <code class="reqn">a_{it}</code> in
bisquare regression (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b_trim</code></td>
<td>
<p>Trimming parameter for item slopes <code class="reqn">b_{it}</code> in
bisquare regression (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lts_prop</code></td>
<td>
<p>Proportion of retained observations in <code>"LTS"</code>
regression estimation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a_log</code></td>
<td>
<p>Logical indicating whether item slopes should be logarithmized
for linking.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv</code></td>
<td>

<p>Convergence criterion.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>

<p>Maximum number of iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>

<p>An optional logical indicating whether computational progress
should be displayed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjust_main_effects</code></td>
<td>
<p>Logical indicating whether all elements in the vector
of main effects should be simultaneously adjusted</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vcov</code></td>
<td>
<p>Optional indicating whether covariance matrix for linking errors
should be computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pow</code></td>
<td>
<p>Power <code class="reqn">q</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Epsilon value used in differentiable approximating function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_nu</code></td>
<td>
<p>Logical indicating whether item intercepts instead of
item difficulties are used in linking</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est_pow</code></td>
<td>
<p>Logical indicating whether power values should be estimated</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower_pow</code></td>
<td>
<p>Lower bound for estimated power</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper_pow</code></td>
<td>
<p>Upper bound for estimated power</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Matrix containing item loadings</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>Matrix containing item intercepts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object of class <code>linking.haberman</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Number of digits after decimals for rounding in <code>summary</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>Optional file name if <code>summary</code> should be sunk into a file.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments to be passed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>Matrix of item intercepts (items <code class="reqn">times</code> studies)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>Matrix of item slopes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wgt</code></td>
<td>
<p>Matrix of weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Tolerance value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Can be <code>1</code> (using Tukey's median polish) or
<code>2</code> (alternating median regression).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical indicating whether iteration progress should be displayed</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For <code class="reqn">t=1,\ldots,T</code> studies, item difficulties <code class="reqn">b_{it}</code> and
item slopes <code class="reqn">a_{it}</code> are available. For dichotomous responses, these
parameters are defined by the 2PL response equation
</p>
<p style="text-align: center;"><code class="reqn"> logit P(X_{pi}=1| \theta_p )=a_i ( \theta_p - b_i ) </code>
</p>

<p>while for polytomous responses the generalized partial credit model holds
</p>
<p style="text-align: center;"><code class="reqn"> log \frac{P(X_{pi}=k| \theta_p )}{P(X_{pi}=k-1| \theta_p )}
=a_i ( \theta_p - b_i + d_{ik} ) </code>
</p>

<p>The parameters <code class="reqn"> \{ a_{it}, b_{it} \}</code> of all items and studies are
linearly transformed using equations <code class="reqn">a_{it} \approx a_i / A_t</code>
(if <code>a_log=TRUE</code>) or <code class="reqn">a_{it} \approx a_i + A_t</code>
(if <code>a_log=FALSE</code>) and
<code class="reqn">b_{it} \cdot A_t \approx B_t + b_i</code>. For identification reasons,
we define <code class="reqn">A_1=1</code> and <code class="reqn">B_1</code>=0.
</p>
<p>The optimization function (which is a least squares criterion;
see Haberman, 2009) seeks the transformation parameters <code class="reqn">A_t</code> and
<code class="reqn">B_t</code> with an alternating least squares
method (<code>estimation="OLS"</code>). Note that every item <code class="reqn">i</code> and every study <code class="reqn">t</code> can
be weighted (specified in the fifth column of <code>itempars</code>).
Alternatively, a robust regression method based on bisquare weighting (Fox, 2015)
can be employed for linking using the argument <code>estimation="BSQ"</code>.
For example, in the case of item loadings, bisquare weighting is applied to
residuals <code class="reqn">e_{it}=a_{it} - a_i - A_t </code> (where logarithmized or non-logarithmized
item loadings are employed) forming weights
<code class="reqn">w_{it}=[ 1 - ( e_{it} / k )^2 ]^2</code> for <code class="reqn">e_{it} &lt;k</code> and 0 for <code class="reqn">e_{it} \ge k</code>
where <code class="reqn">k</code> is the trimming constant which can be estimated or fixed
during estimation using arguments <code>a_trim</code> or <code>b_trim</code>. Items in studies with
large residuals
(i.e., presence differential item functioning) are effectively set to zero in the
linking procedure. Alternatively, Huber weights (<code>estimation="HUB"</code>) downweight
large residuals by applying <code class="reqn">w_{it}=k / | e_{it} |</code> for residuals
<code class="reqn">|e_{it}|&gt;k</code>.  The method <code>estimation="LTS"</code> employs trimmed least squares
where the proportion
of data retained is specified in <code>lts_prop</code> with default set to .50.
</p>
<p>The method <code>estimation="MED"</code> estimates item parameters and linking constants
based on alternating median regression. A similar approach is the median polish
procedure of Tukey (Tukey, 1977, p. 362ff.; Maronna, Martin &amp; Yohai, 2006, p. 104;
see also <code>stats::medpolish</code>) implemented in
<code>estimation="L1"</code> which aims to minimize <code class="reqn">\sum_{i,t} | e_{it} |</code>.
For a pre-specified tolerance value <code class="reqn">t</code> (in <code>a_trim</code> or <code>b_trim</code>),
the approach <code>estimation="L0"</code> minimizes the number of interactions
(i.e., DIF effects) in the <code class="reqn">e_{it}</code> effects. In more detail, it minimizes
<code class="reqn">\sum_{i,t} \# \{ | e_{it} | &gt; t \} </code> which is computationally conducted
by repeatedly applying the median polish procedure in which one cell is
omitted (Davies, 2012; Terbeck &amp; Davies, 1998).
</p>
<p>Effect sizes of invariance are calculated as R-squared measures
of explained item slopes and intercepts after linking
in comparison to item parameters across groups
(Asparouhov &amp; Muthen, 2014).
</p>
<p>The function <code class="reqn">linking.haberman.lq</code> uses the loss function <code class="reqn">\rho(x)=|x|^q</code>.
The originally proposed Haberman linking can be obtained with <code>pow=2</code> (<code class="reqn">q=2</code>).
The powers can also be estimated (argument <code>est_pow=TRUE</code>).
</p>


<h3>Value</h3>

<p>A list with following entries
</p>
<table>
<tr style="vertical-align: top;">
<td><code>transf.pars</code></td>
<td>
<p>Data frame with transformation parameters
<code class="reqn">A_t</code> and <code class="reqn">B_t</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transf.personpars</code></td>
<td>
<p>Data frame with linear transformation functions
for person parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>joint.itempars</code></td>
<td>
<p>Estimated joint item parameters <code class="reqn">a_i</code> and <code class="reqn">b_i</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a.trans</code></td>
<td>
<p>Transformed <code class="reqn">a_{it}</code> parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.trans</code></td>
<td>
<p>Transformed <code class="reqn">b_{it}</code> parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a.orig</code></td>
<td>
<p>Original <code class="reqn">a_{it}</code> parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.orig</code></td>
<td>
<p>Original <code class="reqn">b_{it}</code> parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a.resid</code></td>
<td>
<p>Residual <code class="reqn">a_{it}</code> parameters (DIF parameters)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.resid</code></td>
<td>
<p>Residual <code class="reqn">b_{it}</code> parameters (DIF parameters)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>personpars</code></td>
<td>
<p>Transformed person parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>es.invariance</code></td>
<td>
<p>Effect size measures of invariance,
separately for item slopes and intercepts.
In the rows, <code class="reqn">R^2</code> and <code class="reqn">\sqrt{1-R^2}</code> are reported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>es.robust</code></td>
<td>
<p>Effect size measures of invariance based on
robust estimation (if used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selitems</code></td>
<td>
<p>Indices of items which are present in more than one
study.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Asparouhov, T., &amp; Muthen, B. (2014). Multiple-group factor analysis alignment.
<em>Structural Equation Modeling, 21</em>(4), 1-14.
<a href="https://doi.org/10.1080/10705511.2014.919210">doi:10.1080/10705511.2014.919210</a>
</p>
<p>Battauz, M. (2017). Multiple equating of separate IRT calibrations.
<em>Psychometrika, 82</em>(3), 610-636.
<a href="https://doi.org/10.1007/s11336-016-9517-x">doi:10.1007/s11336-016-9517-x</a>
</p>
<p>Davies, P. L. (2012). Interactions in the analysis of variance.
<em>Journal of the American Statistical Association, 107</em>(500), 1502-1509.
<a href="https://doi.org/10.1080/01621459.2012.726895">doi:10.1080/01621459.2012.726895</a>
</p>
<p>Fox, J. (2015). <em>Applied regression analysis and generalized linear models</em>.
Thousand Oaks: Sage.
</p>
<p>Haberman, S. J. (2009). <em>Linking parameter estimates derived
from an item response model through separate calibrations</em>.
ETS Research Report ETS RR-09-40. Princeton, ETS.
<a href="https://doi.org/10.1002/j.2333-8504.2009.tb02197.x">doi:10.1002/j.2333-8504.2009.tb02197.x</a>
</p>
<p>Kolen, M. J., &amp; Brennan, R. L. (2014). <em>Test equating, scaling, and linking:
Methods and practices</em>. New York: Springer.
<a href="https://doi.org/10.1007/978-1-4939-0317-7">doi:10.1007/978-1-4939-0317-7</a>
</p>
<p>Magis, D., &amp; De Boeck, P. (2012). A robust outlier approach to prevent type I error
inflation in differential item functioning.
<em>Educational and Psychological Measurement, 72</em>(2), 291-311.
<a href="https://doi.org/10.1177/0013164411416975">doi:10.1177/0013164411416975</a>
</p>
<p>Maronna, R. A., Martin, R. D., &amp; Yohai, V. J. (2006). <em>Robust statistics</em>.
West Sussex: Wiley. <a href="https://doi.org/10.1002/0470010940">doi:10.1002/0470010940</a>
</p>
<p>Terbeck, W., &amp; Davies, P. L. (1998). Interactions and outliers in the two-way
analysis of variance. <em>Annals of Statistics, 26</em>(4), 1279-1305.
doi: 10.1214/aos/1024691243
</p>
<p>Tukey, J. W. (1977). <em>Exploratory data analysis</em>. Addison-Wesley.
</p>
<p>Weeks, J. P. (2010). <span class="pkg">plink</span>: An <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> package for linking mixed-format tests
using IRT-based methods. <code>Journal of Statistical Software, 35</code>(12), 1-33.
<a href="https://doi.org/10.18637/jss.v035.i12">doi:10.18637/jss.v035.i12</a>
</p>


<h3>See Also</h3>

<p>See the <span class="pkg">plink</span> package (Weeks, 2010) for a diversity of linking methods.
</p>
<p>Mean-mean linking, Stocking-Lord and Haebara linking (see Kolen &amp; Brennan, 2014,
for an overview) in the generalized logistic item response model can be conducted with
<code>equating.rasch</code>. See also <code>TAM::tam.linking</code>
in the <span class="pkg">TAM</span> package. Haebara linking and a robustified version of it can be
found in <code>linking.haebara</code>.
</p>
<p>The invariance alignment method employs an optimization function based on
pairwise loss functions of item parameters (Asparouhov &amp; Muthen, 2014),
see <code>invariance.alignment</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#############################################################################
# EXAMPLE 1: Item parameters data.pars1.rasch and data.pars1.2pl
#############################################################################

# Model 1: Linking three studies calibrated by the Rasch model
data(data.pars1.rasch)
mod1 &lt;- sirt::linking.haberman( itempars=data.pars1.rasch )
summary(mod1)

# Model 1b: Linking these studies but weigh these studies by
#     proportion weights 3 : 0.5 : 1 (see below).
#     All weights are the same for each item but they could also
#     be item specific.
itempars &lt;- data.pars1.rasch
itempars$wgt &lt;- 1
itempars[ itempars$study=="study1","wgt"] &lt;- 3
itempars[ itempars$study=="study2","wgt"] &lt;- .5
mod1b &lt;- sirt::linking.haberman( itempars=itempars )
summary(mod1b)

# Model 2: Linking three studies calibrated by the 2PL model
data(data.pars1.2pl)
mod2 &lt;- sirt::linking.haberman( itempars=data.pars1.2pl )
summary(mod2)

# additive model instead of logarithmic model for item slopes
mod2b &lt;- sirt::linking.haberman( itempars=data.pars1.2pl, a_log=FALSE )
summary(mod2b)

## Not run: 
#############################################################################
# EXAMPLE 2: Linking longitudinal data
#############################################################################
data(data.long)

#******
# Model 1: Scaling with the 1PL model

# scaling at T1
dat1 &lt;- data.long[, grep("T1", colnames(data.long) ) ]
resT1 &lt;- sirt::rasch.mml2( dat1 )
itempartable1 &lt;- data.frame( "study"="T1", resT1$item[, c("item", "a", "b" ) ] )
# scaling at T2
dat2 &lt;- data.long[, grep("T2", colnames(data.long) ) ]
resT2 &lt;- sirt::rasch.mml2( dat2 )
summary(resT2)
itempartable2 &lt;- data.frame( "study"="T2", resT2$item[, c("item", "a", "b" ) ] )
itempartable &lt;- rbind( itempartable1, itempartable2 )
itempartable[,2] &lt;- substring( itempartable[,2], 1, 2 )
# estimate linking parameters
mod1 &lt;- sirt::linking.haberman( itempars=itempartable )

#******
# Model 2: Scaling with the 2PL model

# scaling at T1
dat1 &lt;- data.long[, grep("T1", colnames(data.long) ) ]
resT1 &lt;- sirt::rasch.mml2( dat1, est.a=1:6)
itempartable1 &lt;- data.frame( "study"="T1", resT1$item[, c("item", "a", "b" ) ] )

# scaling at T2
dat2 &lt;- data.long[, grep("T2", colnames(data.long) ) ]
resT2 &lt;- sirt::rasch.mml2( dat2, est.a=1:6)
summary(resT2)
itempartable2 &lt;- data.frame( "study"="T2", resT2$item[, c("item", "a", "b" ) ] )
itempartable &lt;- rbind( itempartable1, itempartable2 )
itempartable[,2] &lt;- substring( itempartable[,2], 1, 2 )
# estimate linking parameters
mod2 &lt;- sirt::linking.haberman( itempars=itempartable )

#############################################################################
# EXAMPLE 3: 2 Studies - 1PL and 2PL linking
#############################################################################
set.seed(789)
I &lt;- 20        # number of items
N &lt;- 2000       # number of persons
# define item parameters
b &lt;- seq( -1.5, 1.5, length=I )
# simulate data
dat1 &lt;- sirt::sim.raschtype( stats::rnorm( N, mean=0,sd=1 ), b=b )
dat2 &lt;- sirt::sim.raschtype( stats::rnorm( N, mean=0.5,sd=1.50 ), b=b )

#*** Model 1: 1PL
# 1PL Study 1
mod1 &lt;- sirt::rasch.mml2( dat1, est.a=rep(1,I) )
summary(mod1)
# 1PL Study 2
mod2 &lt;- sirt::rasch.mml2( dat2, est.a=rep(1,I) )
summary(mod2)

# collect item parameters
dfr1 &lt;- data.frame( "study1", mod1$item$item, mod1$item$a, mod1$item$b )
dfr2 &lt;- data.frame( "study2", mod2$item$item, mod2$item$a, mod2$item$b )
colnames(dfr2) &lt;- colnames(dfr1) &lt;- c("study", "item", "a", "b" )
itempars &lt;- rbind( dfr1, dfr2 )

# Haberman linking
linkhab1 &lt;- sirt::linking.haberman(itempars=itempars)
  ## Transformation parameters (Haberman linking)
  ##    study    At     Bt
  ## 1 study1 1.000  0.000
  ## 2 study2 1.465 -0.512
  ##
  ## Linear transformation for item parameters a and b
  ##    study   A_a   A_b    B_b
  ## 1 study1 1.000 1.000  0.000
  ## 2 study2 0.682 1.465 -0.512
  ##
  ## Linear transformation for person parameters theta
  ##    study A_theta B_theta
  ## 1 study1   1.000   0.000
  ## 2 study2   1.465   0.512
  ##
  ## R-Squared Measures of Invariance
  ##        slopes intercepts
  ## R2          1     0.9979
  ## sqrtU2      0     0.0456

#*** Model 2: 2PL
# 2PL Study 1
mod1 &lt;- sirt::rasch.mml2( dat1, est.a=1:I )
summary(mod1)
# 2PL Study 2
mod2 &lt;- sirt::rasch.mml2( dat2, est.a=1:I )
summary(mod2)

# collect item parameters
dfr1 &lt;- data.frame( "study1", mod1$item$item, mod1$item$a, mod1$item$b )
dfr2 &lt;- data.frame( "study2", mod2$item$item, mod2$item$a, mod2$item$b )
colnames(dfr2) &lt;- colnames(dfr1) &lt;- c("study", "item", "a", "b" )
itempars &lt;- rbind( dfr1, dfr2 )

# Haberman linking
linkhab2 &lt;- sirt::linking.haberman(itempars=itempars)
  ## Transformation parameters (Haberman linking)
  ##    study    At     Bt
  ## 1 study1 1.000  0.000
  ## 2 study2 1.468 -0.515
  ##
  ## Linear transformation for item parameters a and b
  ##    study   A_a   A_b    B_b
  ## 1 study1 1.000 1.000  0.000
  ## 2 study2 0.681 1.468 -0.515
  ##
  ## Linear transformation for person parameters theta
  ##    study A_theta B_theta
  ## 1 study1   1.000   0.000
  ## 2 study2   1.468   0.515
  ##
  ## R-Squared Measures of Invariance
  ##        slopes intercepts
  ## R2     0.9984     0.9980
  ## sqrtU2 0.0397     0.0443

#############################################################################
# EXAMPLE 4: 3 Studies - 1PL and 2PL linking
#############################################################################
set.seed(789)
I &lt;- 20         # number of items
N &lt;- 1500       # number of persons
# define item parameters
b &lt;- seq( -1.5, 1.5, length=I )
# simulate data
dat1 &lt;- sirt::sim.raschtype( stats::rnorm( N, mean=0, sd=1), b=b )
dat2 &lt;- sirt::sim.raschtype( stats::rnorm( N, mean=0.5, sd=1.50), b=b )
dat3 &lt;- sirt::sim.raschtype( stats::rnorm( N, mean=-0.2, sd=0.8), b=b )
# set some items to non-administered
dat3 &lt;- dat3[, -c(1,4) ]
dat2 &lt;- dat2[, -c(1,2,3) ]

#*** Model 1: 1PL in sirt
# 1PL Study 1
mod1 &lt;- sirt::rasch.mml2( dat1, est.a=rep(1,ncol(dat1)) )
summary(mod1)
# 1PL Study 2
mod2 &lt;- sirt::rasch.mml2( dat2, est.a=rep(1,ncol(dat2)) )
summary(mod2)
# 1PL Study 3
mod3 &lt;- sirt::rasch.mml2( dat3, est.a=rep(1,ncol(dat3)) )
summary(mod3)

# collect item parameters
dfr1 &lt;- data.frame( "study1", mod1$item$item, mod1$item$a, mod1$item$b )
dfr2 &lt;- data.frame( "study2", mod2$item$item, mod2$item$a, mod2$item$b )
dfr3 &lt;- data.frame( "study3", mod3$item$item, mod3$item$a, mod3$item$b )
colnames(dfr3) &lt;- colnames(dfr2) &lt;- colnames(dfr1) &lt;- c("study", "item", "a", "b" )
itempars &lt;- rbind( dfr1, dfr2, dfr3 )

# use person parameters
personpars &lt;- list( mod1$person[, c("EAP","SE.EAP") ], mod2$person[, c("EAP","SE.EAP") ],
    mod3$person[, c("EAP","SE.EAP") ] )

# Haberman linking
linkhab1 &lt;- sirt::linking.haberman(itempars=itempars, personpars=personpars)
# compare item parameters
round( cbind( linkhab1$joint.itempars[,-1], linkhab1$b.trans )[1:5,], 3 )
  ##            aj     bj study1 study2 study3
  ##   I0001 0.998 -1.427 -1.427     NA     NA
  ##   I0002 0.998 -1.290 -1.324     NA -1.256
  ##   I0003 0.998 -1.140 -1.068     NA -1.212
  ##   I0004 0.998 -0.986 -1.003 -0.969     NA
  ##   I0005 0.998 -0.869 -0.809 -0.872 -0.926

# summary of person parameters of second study
round( psych::describe( linkhab1$personpars[[2]] ), 2 )
  ##   var    n mean   sd median trimmed  mad   min  max range  skew kurtosis
  ## EAP      1 1500 0.45 1.36   0.41    0.47 1.52 -2.61 3.25  5.86 -0.08    -0.62
  ## SE.EAP   2 1500 0.57 0.09   0.53    0.56 0.04  0.49 0.84  0.35  1.47     1.56
  ##          se
  ## EAP    0.04
  ## SE.EAP 0.00

#*** Model 2: 2PL in TAM
library(TAM)
# 2PL Study 1
mod1 &lt;- TAM::tam.mml.2pl( resp=dat1, irtmodel="2PL" )
pvmod1 &lt;- TAM::tam.pv(mod1, ntheta=300, normal.approx=TRUE) # draw plausible values
summary(mod1)
# 2PL Study 2
mod2 &lt;- TAM::tam.mml.2pl( resp=dat2, irtmodel="2PL" )
pvmod2 &lt;- TAM::tam.pv(mod2, ntheta=300, normal.approx=TRUE)
summary(mod2)
# 2PL Study 3
mod3 &lt;- TAM::tam.mml.2pl( resp=dat3, irtmodel="2PL" )
pvmod3 &lt;- TAM::tam.pv(mod3, ntheta=300, normal.approx=TRUE)
summary(mod3)

# collect item parameters
#!!  Note that in TAM the parametrization is a*theta - b while linking.haberman
#!!  needs the parametrization a*(theta-b)
dfr1 &lt;- data.frame( "study1", mod1$item$item, mod1$B[,2,1], mod1$xsi$xsi / mod1$B[,2,1] )
dfr2 &lt;- data.frame( "study2", mod2$item$item, mod2$B[,2,1], mod2$xsi$xsi / mod2$B[,2,1] )
dfr3 &lt;- data.frame( "study3", mod3$item$item, mod3$B[,2,1], mod3$xsi$xsi / mod3$B[,2,1] )
colnames(dfr3) &lt;- colnames(dfr2) &lt;- colnames(dfr1) &lt;- c("study", "item", "a", "b" )
itempars &lt;- rbind( dfr1, dfr2, dfr3 )

# define list containing person parameters
personpars &lt;- list(  pvmod1$pv[,-1], pvmod2$pv[,-1], pvmod3$pv[,-1] )

# Haberman linking
linkhab2 &lt;- sirt::linking.haberman(itempars=itempars,personpars=personpars)
  ##   Linear transformation for person parameters theta
  ##      study A_theta B_theta
  ##   1 study1   1.000   0.000
  ##   2 study2   1.485   0.465
  ##   3 study3   0.786  -0.192

# extract transformed person parameters
personpars.trans &lt;- linkhab2$personpars

#############################################################################
# EXAMPLE 5: Linking with simulated item parameters containing outliers
#############################################################################

# simulate some parameters
I &lt;- 38
set.seed(18785)
b &lt;- stats::rnorm( I, mean=.3, sd=1.4 )
# simulate DIF effects plus some outliers
bdif &lt;- stats::rnorm(I,mean=.4,sd=.09)+( stats::runif(I)&gt;.9 )* rep( 1*c(-1,1)+.4, each=I/2 )
# create item parameter table
itempars &lt;- data.frame( "study"=paste0("study",rep(1:2, each=I)),
                "item"=paste0( "I", 100 + rep(1:I,2) ), "a"=1,
                 "b"=c( b, b + bdif  )  )

#*** Model 1: Haberman linking with least squares regression
mod1 &lt;- sirt::linking.haberman( itempars=itempars )
summary(mod1)

#*** Model 2: Haberman linking with robust bisquare regression with fixed trimming value
mod2 &lt;- sirt::linking.haberman( itempars=itempars, estimation="BSQ", b_trim=.4)
summary(mod2)

#*** Model 2: Haberman linking with robust bisquare regression with estimated trimming value
mod3 &lt;- sirt::linking.haberman( itempars=itempars, estimation="BSQ")
summary(mod3)

## see also Example 3 of ?sirt::robust.linking

#############################################################################
# EXAMPLE 6: Toy example of Magis and De Boeck (2012)
#############################################################################

# define item parameters from Magis &amp; De Boeck (20212, p. 293)
b1 &lt;- c(1,1,1,1)
b2 &lt;- c(1,1,1,2)
itempars &lt;- data.frame(study=rep(1:2, each=4), item=rep(1:4,2), a=1, b=c(b1,b2) )

#- Least squares regression
mod1 &lt;- sirt::linking.haberman( itempars=itempars, estimation="OLS")
summary(mod1)

#- Bisquare regression with estimated and fixed trimming factors
mod2 &lt;- sirt::linking.haberman( itempars=itempars, estimation="BSQ")
mod2a &lt;- sirt::linking.haberman( itempars=itempars, estimation="BSQ", b_trim=.4)
mod2b &lt;- sirt::linking.haberman( itempars=itempars, estimation="BSQ", b_trim=1.2)
summary(mod2)
summary(mod2a)
summary(mod2b)

#- Least squares trimmed regression
mod3 &lt;- sirt::linking.haberman( itempars=itempars, estimation="LTS")
summary(mod3)

#- median regression
mod4 &lt;- sirt::linking.haberman( itempars=itempars, estimation="MED")
summary(mod4)

#############################################################################
# EXAMPLE 7: Simulated example with directional DIF
#############################################################################

set.seed(98)
I &lt;- 8
mu &lt;- c(-.5, 0, .5)
b &lt;- sample(seq(-1.5,1.5, len=I))
sd_dif &lt;- 0.001
pars &lt;- outer(b, mu, "+") + stats::rnorm(I*3, sd=sd_dif)
ind &lt;- c(1,2); pars[ind,1] &lt;- pars[ind,1] + c(.5,.5)
ind &lt;- c(3,4); pars[ind,2] &lt;- pars[ind,2] + (-1)*c(.6,.6)
ind &lt;- c(5,6); pars[ind,3] &lt;- pars[ind,3] + (-1)*c(1,1)

# median polish (=stats::medpolish())
tmod1 &lt;- sirt:::L1_polish(x=pars)
# L0 polish with tolerance criterion of .3
tmod2 &lt;- sirt::L0_polish(x=pars, tol=.3)

#- prepare itempars input
itempars &lt;- sirt::linking_haberman_itempars_prepare(b=pars)

#- compare different estimation functions for Haberman linking
mod01 &lt;- sirt::linking.haberman(itempars, estimation="L1")
mod02 &lt;- sirt::linking.haberman(itempars, estimation="L0", b_trim=.3)
mod1 &lt;- sirt::linking.haberman(itempars, estimation="OLS")
mod2 &lt;- sirt::linking.haberman(itempars, estimation="BSQ")
mod2a &lt;- sirt::linking.haberman(itempars, estimation="BSQ", b_trim=.4)
mod3 &lt;- sirt::linking.haberman(itempars, estimation="MED")
mod4 &lt;- sirt::linking.haberman(itempars, estimation="LTS")
mod5 &lt;- sirt::linking.haberman(itempars, estimation="HUB")
mod01$transf.pars
mod02$transf.pars
mod1$transf.pars
mod2$transf.pars
mod2a$transf.pars
mod3$transf.pars
mod4$transf.pars
mod5$transf.pars

#############################################################################
# EXAMPLE 8: Many studies and directional DIF
#############################################################################

## dataset 2
set.seed(98)
I &lt;- 10 # number of items
S &lt;- 7  # number of studies
mu &lt;- round( seq(0, 1, len=S))
b &lt;- sample(seq(-1.5,1.5, len=I))
sd_dif &lt;- 0.001
pars0 &lt;- pars &lt;- outer(b, mu, "+") + stats::rnorm(I*S, sd=sd_dif)

# select n_dif items at random per group and set it to dif or -dif
n_dif &lt;- 2
dif &lt;- .6
for (ss in 1:S){
    ind &lt;- sample( 1:I, n_dif )
    pars[ind,ss] &lt;- pars[ind,ss] + dif*sign( runif(1) - .5 )
}

# check DIF
pars - pars0

#* estimate models
itempars &lt;- sirt::linking_haberman_itempars_prepare(b=pars)
mod0 &lt;- sirt::linking.haberman(itempars, estimation="L0", b_trim=.2)
mod1 &lt;- sirt::linking.haberman(itempars, estimation="OLS")
mod2 &lt;- sirt::linking.haberman(itempars, estimation="BSQ")
mod2a &lt;- sirt::linking.haberman(itempars, estimation="BSQ", b_trim=.4)
mod3 &lt;- sirt::linking.haberman(itempars, estimation="MED")
mod3a &lt;- sirt::linking.haberman(itempars, estimation="L1")
mod4 &lt;- sirt::linking.haberman(itempars, estimation="LTS")
mod5 &lt;- sirt::linking.haberman(itempars, estimation="HUB")
mod0$transf.pars
mod1$transf.pars
mod2$transf.pars
mod2a$transf.pars
mod3$transf.pars
mod3a$transf.pars
mod4$transf.pars
mod5$transf.pars

#* compare results with Haebara linking
mod11 &lt;- sirt::linking.haebara(itempars, dist="L2")
mod12 &lt;- sirt::linking.haebara(itempars, dist="L1")
summary(mod11)
summary(mod12)

## End(Not run)
</code></pre>


</div>