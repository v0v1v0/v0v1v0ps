<div class="container">

<table style="width: 100%;"><tr>
<td>vc_softbart_regression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SoftBart Varying Coefficient Regression</h2>

<h3>Description</h3>

<p>Fits a semiparametric varying coefficient regression model with the
nonparametric slope and intercept </p>
<p style="text-align: center;"><code class="reqn">Y = \alpha(X) + Z \beta(X) +
\epsilon</code>
</p>
<p> using a soft BART model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vc_softbart_regression(
  formula,
  linear_var_name,
  data,
  test_data,
  num_tree = 20,
  k = 2,
  hypers_intercept = NULL,
  hypers_slope = NULL,
  opts = NULL,
  verbose = TRUE,
  warn = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A model formula with a numeric variable on the left-hand-side and non-linear predictors on the right-hand-side.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>linear_var_name</code></td>
<td>
<p>A string containing the variable in the data that is to be treated linearly.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data frame consisting of the training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_data</code></td>
<td>
<p>A data frame consisting of the testing data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_tree</code></td>
<td>
<p>The number of trees in the ensemble to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Determines the standard deviation of the leaf node parameters, which
is given by <code>3 / k / sqrt(num_tree)</code> (intercept) and defaults to
<code>1/k/sqrt(num_tree)</code> (slope). This can be modified for the slope by
specifying your own hyperparameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hypers_intercept</code></td>
<td>
<p>A list of hyperparameters constructed from the <code>Hypers()</code> function (<code>num_tree</code>, <code>k</code>, and <code>sigma_mu</code> are overridden by this function).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hypers_slope</code></td>
<td>
<p>A list of hyperparameters constructed from the <code>Hypers()</code> function (<code>num_tree</code> is overridden by this function).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opts</code></td>
<td>
<p>A list of options for running the chain constructed from the <code>Opts()</code> function (<code>update_sigma</code> is overridden by this function).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, progress of the chain will be printed to the console.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>
<p>If <code>TRUE</code>, remind the user that they probably don't want the linear term to be included in the formula for the nonlinear part.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a list with the following components
</p>

<ul>
<li> <p><code>sigma_mu_alpha</code>: samples of the standard deviation of the leaf node parameters for the intercept.
</p>
</li>
<li> <p><code>sigma_mu_beta</code>: samples of the standard deviation of the leaf node parameters for the slope.
</p>
</li>
<li> <p><code>sigma</code>: samples of the error standard deviation.
</p>
</li>
<li> <p><code>var_counts_alpha</code>: a matrix with a column for each predictor group containing the number of times each predictor is used in the ensemble at each iteration for the intercept.
</p>
</li>
<li> <p><code>var_counts_beta</code>: a matrix with a column for each predictor group containing the number of times each predictor is used in the ensemble at each iteration for the slope.
</p>
</li>
<li> <p><code>alpha_train</code>: samples of the nonparametric intercept evaluated on the training set.
</p>
</li>
<li> <p><code>alpha_test</code>: samples of the nonparametric intercept evaluated on the test set.
</p>
</li>
<li> <p><code>beta_train</code>: samples of the nonparametric slope evaluated on the training set.
</p>
</li>
<li> <p><code>beta_test</code>: samples of the nonparametric slope evaluated on the test set.
</p>
</li>
<li> <p><code>mu_train</code>: samples of the predictions evaluated on the training set.
</p>
</li>
<li> <p><code>mu_test</code>: samples of the predictions evaluated on the test set.
</p>
</li>
<li> <p><code>formula</code>: the formula specified by the user.
</p>
</li>
<li> <p><code>ecdfs</code>: empirical distribution functions, used by the <code>predict</code> function.
</p>
</li>
<li> <p><code>opts</code>: the options used when running the chain.
</p>
</li>
<li> <p><code>mu_Y, sd_Y</code>: used with the <code>predict</code> function to transform predictions.
</p>
</li>
<li> <p><code>alpha_forest</code>: a forest object for the intercept; see the <code>MakeForest</code> documentation for more details.
</p>
</li>
<li> <p><code>beta_forest</code>: a forest object for the slope; see the <code>MakeForest</code> documentation for more details.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
## NOTE: SET NUMBER OF BURN IN AND SAMPLE ITERATIONS HIGHER IN PRACTICE

num_burn &lt;- 10 ## Should be ~ 5000
num_save &lt;- 10 ## Should be ~ 5000

set.seed(1234)
f_fried &lt;- function(x) 10 * sin(pi * x[,1] * x[,2]) + 20 * (x[,3] - 0.5)^2 +
  10 * x[,4] + 5 * x[,5]

gen_data &lt;- function(n_train, n_test, P, sigma) {
  X &lt;- matrix(runif(n_train * P), nrow = n_train)
  Z &lt;- rnorm(n_train)
  r &lt;- f_fried(X)
  mu &lt;- Z * r
  X_test &lt;- matrix(runif(n_test * P), nrow = n_test)
  Z_test &lt;- rnorm(n_test)
  r_test &lt;- f_fried(X_test)
  mu_test &lt;- Z_test * r_test
  Y &lt;- mu + sigma * rnorm(n_train)
  Y_test &lt;- mu + sigma * rnorm(n_test)

  return(list(X = X, Y = Y, Z = Z, r = r, mu = mu, X_test = X_test, Y_test =
              Y_test, Z_test = Z_test, r_test = r_test, mu_test = mu_test))
}

## Simiulate dataset
sim_data &lt;- gen_data(250, 250, 100, 1)

df &lt;- data.frame(X = sim_data$X, Y = sim_data$Y, Z = sim_data$Z)
df_test &lt;- data.frame(X = sim_data$X_test, Y = sim_data$Y_test, Z = sim_data$Z_test)

## Fit the model

opts &lt;- Opts(num_burn = num_burn, num_save = num_save)
fitted_vc &lt;- vc_softbart_regression(Y ~ . -Z, "Z", df, df_test, opts = opts)

## Plot results

plot(colMeans(fitted_vc$mu_test), sim_data$mu_test)
abline(a = 0, b = 1)

</code></pre>


</div>