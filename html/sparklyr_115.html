<div class="container">

<table style="width: 100%;"><tr>
<td>spark-api</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Access the Spark API</h2>

<h3>Description</h3>

<p>Access the commonly-used Spark objects associated with a Spark instance.
These objects provide access to different facets of the Spark API.
</p>


<h3>Usage</h3>

<pre><code class="language-R">spark_context(sc)

java_context(sc)

hive_context(sc)

spark_session(sc)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>The <a href="https://spark.apache.org/docs/latest/api/scala/">Scala API documentation</a>
is useful for discovering what methods are available for each of these
objects. Use <code>invoke</code> to call methods on these objects.
</p>


<h3>Spark Context</h3>

<p>The main entry point for Spark functionality. The <strong>Spark Context</strong>
represents the connection to a Spark cluster, and can be used to create
<code>RDD</code>s, accumulators and broadcast variables on that cluster.
</p>


<h3>Java Spark Context</h3>

<p>A Java-friendly version of the aforementioned <strong>Spark Context</strong>.
</p>


<h3>Hive Context</h3>

<p>An instance of the Spark SQL execution engine that integrates with data
stored in Hive. Configuration for Hive is read from <code>hive-site.xml</code> on
the classpath.
</p>
<p>Starting with Spark &gt;= 2.0.0, the <strong>Hive Context</strong> class has been
deprecated â€“ it is superceded by the <strong>Spark Session</strong> class, and
<code>hive_context</code> will return a <strong>Spark Session</strong> object instead.
Note that both classes share a SQL interface, and therefore one can invoke
SQL through these objects.
</p>


<h3>Spark Session</h3>

<p>Available since Spark 2.0.0, the <strong>Spark Session</strong> unifies the
<strong>Spark Context</strong> and <strong>Hive Context</strong> classes into a single
interface. Its use is recommended over the older APIs for code
targeting Spark 2.0.0 and above.
</p>


</div>