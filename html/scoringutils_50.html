<div class="container">

<table style="width: 100%;"><tr>
<td>pairwise_comparison</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Do Pairwise Comparisons of Scores</h2>

<h3>Description</h3>

<p>Compute relative scores between different models making pairwise
comparisons. Pairwise comparisons are a sort of pairwise tournament where all
combinations of two models are compared against each other based on the
overlapping set of available forecasts common to both models.
Internally, a ratio of the mean scores of both models is computed.
The relative score of a model is then the geometric mean of all mean score
ratios which involve that model. When a baseline is provided, then that
baseline is excluded from the relative scores for individual models
(which therefore differ slightly from relative scores without a baseline)
and all relative scores are scaled by (i.e. divided by) the relative score of
the baseline model.
Usually, the function input should be unsummarised scores as
produced by <code>score()</code>.
Note that the function internally infers the <em>unit of a single forecast</em> by
determining all columns in the input that do not correspond to metrics
computed by <code>score()</code>. Adding unrelated columns will change results in an
unpredictable way.
</p>
<p>The code for the pairwise comparisons is inspired by an implementation by
Johannes Bracher.
The implementation of the permutation test follows the function
<code>permutationTest</code> from the <code>surveillance</code> package by Michael HÃ¶hle,
Andrea Riebler and Michaela Paul.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pairwise_comparison(
  scores,
  by = "model",
  metric = "auto",
  baseline = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>A data.table of scores as produced by <code>score()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>by</code></td>
<td>
<p>character vector with names of columns present in the input
data.frame. <code>by</code> determines how pairwise comparisons will be computed.
You will get a relative skill score for every grouping level determined in
<code>by</code>. If, for example, <code>by = c("model", "location")</code>. Then you will get a
separate relative skill score for every model in every location. Internally,
the data.frame will be split according <code>by</code> (but removing "model" before
splitting) and the pairwise comparisons will be computed separately for the
split data.frames.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>A character vector of length one with the metric to do the
comparison on. The default is "auto", meaning that either "interval_score",
"crps", or "brier_score" will be selected where available.
See <code>available_metrics()</code> for available metrics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p>character vector of length one that denotes the baseline
model against which to compare other models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments for the comparison between two models. See
<code>compare_two_models()</code> for more information.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A ggplot2 object with a coloured table of summarised scores
</p>


<h3>Author(s)</h3>

<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>
<p>Johannes Bracher, <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">

scores &lt;- score(example_quantile)
pairwise &lt;- pairwise_comparison(scores, by = "target_type")

library(ggplot2)
plot_pairwise_comparison(pairwise, type = "mean_scores_ratio") +
  facet_wrap(~target_type)
</code></pre>


</div>