<div class="container">

<table style="width: 100%;"><tr>
<td>psmMergeSplit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Merge-Split Sampling for a Partition Based on Sequential Allocation Informed
by Pairwise Similarities</h2>

<h3>Description</h3>

<p>Merge-split proposals for conjugate "Chinese Restaurant Process" (CRP)
mixture models using sequentially-allocated elements. Allocation is performed
with weights derived from a previously-calculated pairwise similarity matrix,
and optionally complemented with "restricted Gibbs" scans as discussed in
Jain &amp; Neal (2004).
</p>


<h3>Usage</h3>

<pre><code class="language-R">psmMergeSplit(
  partition,
  psm,
  logPosteriorPredictiveDensity = function(i, subset) 0,
  t = 1,
  mass = 1,
  discount = 0,
  nUpdates = 1L,
  selectionWeights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>partition</code></td>
<td>
<p>A numeric vector of cluster labels representing the current
partition.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psm</code></td>
<td>
<p>A matrix of previously-calculated pairwise similarity
probabilities for each pair of data indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logPosteriorPredictiveDensity</code></td>
<td>
<p>A function taking an index <code class="reqn">i</code> (as a
numeric vector of length one) and a subset of integers <code class="reqn">subset</code>, and
returning the natural logarithm of <code class="reqn">p( y_i | y_subset )</code>, i.e., that
item's contribution to the log integrated likelihood given a subset of the
other items. The default value "turns off" the likelihood, resulting in
prior simulation (rather than posterior simulation).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t</code></td>
<td>
<p>A non-negative integer indicating the number of restricted Gibbs
scans to perform for each merge/split proposal.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mass</code></td>
<td>
<p>A specification of the mass (concentration) parameter in the CRP
prior. Must be greater than the <code>-discount</code> argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discount</code></td>
<td>
<p>A numeric value on the interval [0,1) corresponding to the
discount parameter in the two-parameter CRP prior.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nUpdates</code></td>
<td>
<p>An integer giving the number of merge-split proposals before
returning. This has the effect of thinning the Markov chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectionWeights</code></td>
<td>
<p>A matrix or data frame whose first two columns are
the unique pairs of data indices, along with a column of weights
representing how likely each pair is to be selected at the beginning of
each merge-split update.</p>
</td>
</tr>
</table>
<h3>Value</h3>

 <dl>
<dt>partition</dt>
<dd>
<p>A numeric vector giving the updated
partition encoded using cluster labels.</p>
</dd> <dt>accept</dt>
<dd>
<p>The acceptance rate
of the Metropolis-Hastings proposals, i.e. the number of accepted proposals
divided by <code>nUpdates</code>.</p>
</dd> </dl>
<h3>References</h3>

<p>Jain, S., &amp; Neal, R. M. (2004). A split-merge Markov chain Monte
Carlo procedure for the Dirichlet process mixture model. <em>Journal of
computational and Graphical Statistics</em>, 13(1), 158-182.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Neal (2000) model and data
nealData &lt;- c(-1.48, -1.40, -1.16, -1.08, -1.02, 0.14, 0.51, 0.53, 0.78)
mkLogPosteriorPredictiveDensity &lt;- function(data = nealData,
                                            sigma2 = 0.1^2,
                                            mu0 = 0,
                                            sigma02 = 1) {
  function(i, subset) {
    posteriorVariance &lt;- 1 / ( 1/sigma02 + length(subset)/sigma2 )
    posteriorMean &lt;- posteriorVariance * ( mu0/sigma02 + sum(data[subset])/sigma2 )
    posteriorPredictiveSD &lt;- sqrt(posteriorVariance + sigma2)
    dnorm(data[i], posteriorMean, posteriorPredictiveSD, log=TRUE)
  }
}

logPostPredict &lt;- mkLogPosteriorPredictiveDensity()

nSamples &lt;- 1100L
nBurn &lt;- 100
partitions &lt;- matrix(0, nrow=nSamples, ncol=length(nealData))

# initial draws to inform similarity matrix
for ( i in 2:nBurn ) {
  partitions[i,] &lt;- nealAlgorithm3(partitions[i-1,],
                                   logPostPredict,
                                   mass = 1,
                                   nUpdates = 1)
}

# Generate pairwise similarity matrix from initial draws
psm.mat &lt;- psm(partitions[1:nBurn,])

accept &lt;- 0
for ( i in (nBurn+1):nSamples ) {
  ms &lt;- psmMergeSplit(partitions[i-1,],
                      psm.mat,
                      logPostPredict,
                      t = 1,
                      mass = 1.0,
                      nUpdates = 1)
  partitions[i,] &lt;- ms$partition
  accept &lt;- accept + ms$accept
}

accept / (nSamples - nBurn) # post burn-in M-H acceptance rate
nSubsets &lt;- apply(partitions, 1, function(x) length(unique(x)))
mean(nSubsets)
sum(acf(nSubsets)$acf)-1   # Autocorrelation time

entropy &lt;- apply(partitions, 1, partitionEntropy)
plot.ts(entropy)

</code></pre>


</div>