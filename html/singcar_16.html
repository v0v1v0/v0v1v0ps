<div class="container">

<table style="width: 100%;"><tr>
<td>UDT</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Unstandardised Difference Test</h2>

<h3>Description</h3>

<p>A test on the discrepancy between two tasks in a single case, by comparison
to the mean of discrepancies of the same two tasks in a control sample. Use
<em>only</em> when the two tasks are measured on the same scale with the same
underlying distribution because no standardisation is performed on task
scores. As a rule-of-thumb, the UDT may be applicable to pairs of tasks for
which it would be sensible to perform a paired t-test within the control
group. Calculates however a standardised effect size in the same manner as
<code>RSDT()</code>. This is original behaviour from Crawford and Garthwaite
(2005) but might not be appropriate. So use this standardised effect size
with caution. Calculates a standardised effect size of task discrepancy as
well as a point estimate of the proportion of the control population that
would be expected to show a more extreme discrepancy and respective
confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class="language-R">UDT(
  case_a,
  case_b,
  controls_a,
  controls_b,
  sd_a = NULL,
  sd_b = NULL,
  sample_size = NULL,
  r_ab = NULL,
  alternative = c("two.sided", "greater", "less"),
  conf_int = TRUE,
  conf_level = 0.95,
  conf_int_spec = 0.01,
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>case_a</code></td>
<td>
<p>Case's score on task A.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case_b</code></td>
<td>
<p>Case's score on task B.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>controls_a</code></td>
<td>
<p>Controls' scores on task A. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task A while mean and SD for task B.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>controls_b</code></td>
<td>
<p>Controls' scores on task B. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task B while mean and SD for task A.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd_a</code></td>
<td>
<p>If single value for task A is given as input you must
supply the standard deviation of the sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd_b</code></td>
<td>
<p>If single value for task B is given as input you must
supply the standard deviation of the sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_size</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
sample size. If controls_a is given as vector and controls_b as mean and
SD, sample_size must equal the number of observations in controls_a.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r_ab</code></td>
<td>
<p>If A and/or B is given as mean and SD you must supply the
correlation between the tasks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as A and which is set
as B, be very careful if changing this parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf_int</code></td>
<td>
<p>Initiates a search algorithm for finding confidence
intervals. Defaults to <code>TRUE</code>, set to <code>FALSE</code> for faster
calculation (e.g. for simulations).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf_level</code></td>
<td>
<p>Level of confidence for intervals, defaults to 95%.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf_int_spec</code></td>
<td>
<p>The size of iterative steps for calculating confidence
intervals. Smaller values gives more precise intervals but takes longer to
calculate. Defaults to a specificity of 0.01.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Running  <code>UDT</code> is equivalent to running <code>TD</code> on discrepancy scores
making it possible to run unstandardised tests with covariates by applying
<code>BTD_cov</code> to discrepancy scores.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
<td style="text-align: left;"> <code>statistic</code>   </td>
<td style="text-align: left;"> the t-statistic. </td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">
  <code>parameter</code> </td>
<td style="text-align: left;"> the degrees of freedom for the t-statistic.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">
  <code>p.value</code>    </td>
<td style="text-align: left;"> the p-value of the test.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"> <code>estimate</code> </td>
<td style="text-align: left;">
  unstandardised case scores, task difference and pont estimate of proportion
  control population expected to above or below the observed task difference.
  </td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"> <code>control.desc</code>   </td>
<td style="text-align: left;"> named numerical with descriptive
  statistics of the control samples. </td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"> <code>null.value</code>   </td>
<td style="text-align: left;"> the
  value of the difference under the null hypothesis.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">
  <code>alternative</code>     </td>
<td style="text-align: left;"> a character string describing the alternative
  hypothesis.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"> <code>method</code> </td>
<td style="text-align: left;"> a character string indicating what
  type of test was performed.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;"> <code>data.name</code> </td>
<td style="text-align: left;"> a character string
  giving the name(s) of the data</td>
</tr>
</table>
<h3>References</h3>

<p>Crawford, J. R., &amp; Garthwaite, P. H. (2005). Testing for
Suspected Impairments and Dissociations in Single-Case Studies in
Neuropsychology: Evaluation of Alternatives Using Monte Carlo Simulations and
Revised Tests for Dissociations. <em>Neuropsychology, 19</em>(3), 318 - 331.
<a href="https://doi.org/10.1037/0894-4105.19.3.318">doi:10.1037/0894-4105.19.3.318</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">UDT(-3.857, -1.875, controls_a = 0, controls_b = 0, sd_a = 1,
sd_b = 1, sample_size = 20, r_ab = 0.68)

UDT(case_a = size_weight_illusion[1, "V_SWI"], case_b = size_weight_illusion[1, "K_SWI"],
 controls_a = size_weight_illusion[-1, "V_SWI"], controls_b = size_weight_illusion[-1, "K_SWI"])

</code></pre>


</div>