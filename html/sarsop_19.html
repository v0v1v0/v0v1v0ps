<div class="container">

<table style="width: 100%;"><tr>
<td>sim_pomdp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>simulate a POMDP</h2>

<h3>Description</h3>

<p>Simulate a POMDP given the appropriate matrices.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sim_pomdp(
  transition,
  observation,
  reward,
  discount,
  state_prior = rep(1, dim(observation)[[1]])/dim(observation)[[1]],
  x0,
  a0 = 1,
  Tmax = 20,
  policy = NULL,
  alpha = NULL,
  reps = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>transition</code></td>
<td>
<p>Transition matrix, dimension n_s x n_s x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation</code></td>
<td>
<p>Observation matrix, dimension n_s x n_z x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reward</code></td>
<td>
<p>reward matrix, dimension n_s x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>discount</code></td>
<td>
<p>the discount factor</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>state_prior</code></td>
<td>
<p>initial belief state, optional, defaults to uniform
over states</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x0</code></td>
<td>
<p>initial state</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0</code></td>
<td>
<p>initial action (default is action 1, e.g. can be arbitrary
if the observation process is independent of the action taken)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Tmax</code></td>
<td>
<p>duration of simulation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>policy</code></td>
<td>
<p>Simulate using a pre-computed policy (e.g. MDP policy) instead of POMDP</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the matrix of alpha vectors returned by <code>sarsop</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reps</code></td>
<td>
<p>number of replicate simulations to compute</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to mclapply</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>simulation assumes the following order of updating: For system in state[t] at
time t, an observation of the system obs[t] is made, and then action[t] is based on that
observation and the given policy, returning (discounted) reward[t].
</p>


<h3>Value</h3>

<p>a data frame with columns for time, state, obs, action, and (discounted) value.
</p>


<h3>Examples</h3>

<pre><code class="language-R">m &lt;- fisheries_matrices()
discount &lt;- 0.95
 ## Takes &gt; 5s
if(assert_has_appl()){
alpha &lt;- sarsop(m$transition, m$observation, m$reward, discount, precision = 10)
sim &lt;- sim_pomdp(m$transition, m$observation, m$reward, discount,
                 x0 = 5, Tmax = 20, alpha = alpha)

}

</code></pre>


</div>