<div class="container">

<table style="width: 100%;"><tr>
<td>vcovJK</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>(Clustered) Jackknife Covariance Matrix Estimation</h2>

<h3>Description</h3>

<p>Object-oriented estimation of jackknife covariances, i.e., based on
the centered outer product of leave-on-out estimates of the model
coefficients/parameters.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vcovJK(x, ...)

## Default S3 method:
vcovJK(x, cluster = NULL, center = "mean", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a fitted model object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>a variable indicating the clustering of observations,
a <code>list</code> (or <code>data.frame</code>) thereof, or a formula specifying
which variables from the fitted model should be used (see examples).
By default (<code>cluster = NULL</code>), either <code>attr(x, "cluster")</code> is used
(if any) or otherwise every observation is assumed to be its own cluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>character specifying how to center the coefficients from
all jacknife samples (each dropping one observational unit/cluster).
By default the coefficients are centered by their <code>"mean"</code> across the
sample or, alternatively, by the original full-sample <code>"estimate"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to methods. For the default method, this is
passed to <code>vcovBS</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Jackknife covariance estimation is based on leave-one-out estimates of the
coefficients/parameters of a model. This means that the model is reestimated
after dropping each observational unit once, i.e., each individual observation
in independent observations or each cluster in dependent data. The covariance
matrix is then constructed from the scaled outer product of the centered
jackknife estimates. Centering can either be done by the mean of the jackknife
coefficients (default) or by the original full-sample estimates. Scaling is done
by (N - 1)/N where N is the number of observational units.
</p>
<p>Recent research has shown that the jackknife covariance estimate have particularly
useful properties in practice: they are not downward biased and yield better
coverage rates for confidence intervals compared to other "robust" covariance
estimates. See MacKinnon et al. (2022) and Hansen (2022) for more details.
</p>
<p>As jackknife covariances are also based on reestimation of the coefficients on
subsamples, their computation is very similar to bootstrap covariances. Hence,
the <code>vcovBS</code> methods provided in the package all offer an argument
<code>vcovBS(..., type = "jackknife")</code>. This is called by the default
<code>vcovJK</code> method. Therefore, see the arguments of <code>vcovBS</code> for further
details, e.g., for leveraging multicore computations etc.
</p>
<p>In the linear regression model, the jackknife covariance can actually be computed
without reestimating the coefficients but using only the full-sample estimates and
certain elements of the so-called hat matrix. Namly the diagonal elements or
blocks of elements from the hat matrix are needed for independent observations and
clustered data, respectively. These alternative computations of the jackknife
covariances are available in <code>vcovHC</code> and <code>vcovCL</code>, respectively,
in both cases with argument <code>type = "HC3"</code>. To obtain HC3 covariances that exactly
match the jackknife covariances, the jackknife has to be centered with the full-sample
estimates and the right finite-sample adjustment has to be selected for the HC3.
</p>
<p>In small to moderate sample sizes, the HC3 estimation techniques are typically much
faster than the jackknife. However, in large samples it may become impossible to
compute the HC3 covariances while the jackknife approach is still feasible.
</p>


<h3>Value</h3>

<p>A matrix containing the covariance matrix estimate.
</p>


<h3>References</h3>

<p>Bell RM, McCaffrey DF (2002).
“Bias Reduction in Standard Errors for Linear Regression with Multi-Stage Samples”,
<em>Survey Methodology</em>, <b>28</b>(2), 169–181.
</p>
<p>Hansen BE (2022).
“Jackknife Standard Errors for Clustered Regression”, Working Paper, August 2022.
<a href="https://www.ssc.wisc.edu/~bhansen/papers/tcauchy.html">https://www.ssc.wisc.edu/~bhansen/papers/tcauchy.html</a>
</p>
<p>MacKinnon JG, Nielsen MØ, Webb MD (2022). 
“Cluster-Robust Inference: A Guide to Empirical Practice”, 
<em>Journal of Econometrics</em>, Forthcoming.
<a href="https://doi.org/10.1016/j.jeconom.2022.04.001">doi:10.1016/j.jeconom.2022.04.001</a>
</p>
<p>Zeileis A, Köll S, Graham N (2020).
“Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.”
<em>Journal of Statistical Software</em>, <b>95</b>(1), 1–36.
<a href="https://doi.org/10.18637/jss.v095.i01">doi:10.18637/jss.v095.i01</a>
</p>


<h3>See Also</h3>

<p><code>vcovJK</code>, <code>vcovHC</code>, <code>vcovCL</code></p>


<h3>Examples</h3>

<pre><code class="language-R">## cross-section data
data("PublicSchools", package = "sandwich")
m1 &lt;- lm(Expenditure ~ poly(Income, 2), data = PublicSchools)
vcovJK(m1, center = "estimate")
vcovHC(m1, type = "HC3") * (nobs(m1) - 1)/nobs(m1)

## clustered data
data("PetersenCL", package = "sandwich")
m2 &lt;- lm(y ~ x, data = PetersenCL)

## jackknife estimator coincides with HC3 (aka CV3)
vcovJK(m2, cluster = ~ firm, center = "estimate")
vcovCL(m2, cluster = ~ firm, type = "HC3", cadjust = FALSE)
</code></pre>


</div>