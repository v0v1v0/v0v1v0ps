<div class="container">

<table style="width: 100%;"><tr>
<td>makeSlurmCluster</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Create a Parallel Socket Cluster using Slurm</h2>

<h3>Description</h3>

<p>This function is essentially a wrapper of the function parallel::makePSOCKcluster.
<code>makeSlurmCluster</code> main feature is adding node addresses.
</p>


<h3>Usage</h3>

<pre><code class="language-R">makeSlurmCluster(
  n,
  job_name = random_job_name(),
  tmp_path = opts_slurmR$get_tmp_path(),
  cluster_opt = list(),
  max_wait = 300L,
  verb = TRUE,
  ...
)

## S3 method for class 'slurm_cluster'
stopCluster(cl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Integer scalar. Size of the cluster object (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>job_name</code></td>
<td>
<p>Character. Name of the job to be passed to <code>Slurm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tmp_path</code></td>
<td>
<p>Character. Path to the directory where all the data (including
scripts) will be stored. Notice that this path must be accessible by all the
nodes in the network (See opts_slurmR).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_opt</code></td>
<td>
<p>A list of arguments passed to parallel::makePSOCKcluster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_wait</code></td>
<td>
<p>Integer scalar. Wait time before exiting with error while
trying to read the nodes information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verb</code></td>
<td>
<p>Logical scalar. If <code>TRUE</code>, the function will print messages on
screen reporting on the status of the job submission.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to Slurm_EvalQ via <code>sbatch_opt</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>An object of class <code>slurm_cluster</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>By default, if the <code>time</code> option is not specified via <code>...</code>,
then it is set to the value <code>01:00:00</code>, this is, 1 hour.
</p>
<p>Once a job is submitted via Slurm, the user gets access to the nodes
associated with it, which allows users to star new processes within those.
By means of this, we can create Socket, also known as "PSOCK", clusters across
nodes in a Slurm environment. The name of the hosts are retrieved and passed
later on to parallel::makePSOCKcluster.
</p>
<p>It has been the case that R fails to create the cluster with the following
message in the Slurm log file:
</p>
<div class="sourceCode"><pre>srun: fatal: SLURM_MEM_PER_CPU, SLURM_MEM_PER_GPU, and SLURM_MEM_PER_NODE are mutually exclusive
</pre></div>
<p>In such cases, setting the memory, for example, upfront can solve the problem.
For example:
</p>
<div class="sourceCode"><pre>cl &lt;- makeSlurmCluster(20, mem = 20)
</pre></div>
<p>If the problem persists, i.e., the cluster cannot be created, make sure that
your Slurm cluster allows Socket connections between nodes.
</p>
<p>The method <code>stopCluster</code> for <code>slurm_cluster</code> stops the cluster doing
the following:
</p>

<ol>
<li>
<p> Closes the connection by calling the <code>stopCluster</code> method for <code>PSOCK</code> objects.
</p>
</li>
<li>
<p> Cancel the Slurm job using <code>scancel</code>.
</p>
</li>
</ol>
<h3>Value</h3>

<p>A object of class <code>c("slurm_cluster", "SOCKcluster", "cluster")</code>. It
is the same as what is returned by parallel::makePSOCKcluster with the main
difference that it has two extra attributes:
</p>

<ul><li> <p><code>SLURM_JOBID</code> Which is the id of the Job that initialized that cluster.
</p>
</li></ul>
<h3>Maximum number of connections</h3>

<p>By default, R limits the number of simultaneous connections (see this thread
in R-sig-hpc <a href="https://stat.ethz.ch/pipermail/r-sig-hpc/2012-May/001373.html">https://stat.ethz.ch/pipermail/r-sig-hpc/2012-May/001373.html</a>)
Current maximum is 128 (R version 3.6.1). To modify that limit, you would need
to reinstall R updating the macro <code>NCONNECTIONS</code> in the file <code>src/main/connections.c</code>.
</p>
<p>For now, if the user sets <code>n</code> above 128 it will get an immediate warning
pointing to this issue, in particular, specifying that the cluster object
may not be able to be created.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

# Creating a cluster with 100 workers/offpring/child R sessions
cl &lt;- makeSlurmCluster(100)

# Computing the mean of a 100 random uniforms within each worker
# for this we can use any of the function available in the parallel package.
ans &lt;- parSapply(1:200, function(x) mean(runif(100)))

# We simply call stopCluster as we would do with any other cluster
# object
stopCluster(ans)

# We can also specify SBATCH options directly (...)
cl &lt;- makeSlurmCluster(200, partition = "thomas", time = "02:00:00")
stopCluster(cl)


## End(Not run)

</code></pre>


</div>