<div class="container">

<table style="width: 100%;"><tr>
<td>semtree</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SEM Tree: Recursive Partitioning for Structural Equation Models</h2>

<h3>Description</h3>

<p>Structural equation model (SEM) trees are a combination of SEM and decision
trees (also known as classification and regression trees or recursive
partitioning). SEM trees hierarchically split empirical data into
homogeneous groups sharing similar data patterns with respect to a SEM by
recursively selecting optimal predictors of these differences from a
potentially large set of predictors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">semtree(
  model,
  data = NULL,
  control = NULL,
  constraints = NULL,
  predictors = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A template model specification from <code>OpenMx</code> using
the <code>mxModel</code> function (or a <code>lavaan</code> model
using the <code>lavaan</code> function with option fit=FALSE).
Model must be syntactically correct within the framework chosen, and
converge to a solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Data.frame used in the model creation using
<code>mxModel</code> or <code>lavaan</code> are input here. Order
of modeled variables and predictors is not important when providing a
dataset to <code>semtree</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p><code>semtree</code> model specifications from
<code>semtree.control</code> are input here. Any changes from the default
setting can be specified here.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constraints</code></td>
<td>
<p>A <code>semtree.constraints</code> object setting model
parameters as constrained from the beginning of the <code>semtree</code>
computation. This includes options to globally or locally set equality
constraints and to specify focus parameters (i.e., parameter subsets that
exclusively go into the function evaluating splits). Also, options for
measurement invariance testing in trees are included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predictors</code></td>
<td>
<p>A vector of variable names matching variable names in
dataset. If NULL (default) all variables that are in dataset and not part of
the model are potential predictors. Optional function input to select a
subset of the unmodeled variables to use as predictors in the <code>semtree</code>
function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments passed to the tree growing function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Calling <code>semtree</code> with an <code>OpenMx</code> or
<code>lavaan</code> model creates a tree that recursively
partitions a dataset such that the partitions maximally differ with respect
to the model-predicted distributions. Each resulting subgroup (represented
as a leaf in the tree) is represented by a SEM with a distinct set of
parameter estimates.
</p>
<p>Predictors (yet unmodeled variables) can take on any form for the splitting
algorithm to function (categorical, ordered categories, continuous). Care
must be taken in choosing how many predictors to include in analyses because
as the number of categories grows for unordered categorical variables, the
number of multigroup comparisons increases exponentially for unordered
categories.
</p>
<p>Currently available evaluation methods for assessing partitions:
</p>
<p>1. "naive" selection method compares all possible split values to one
another over all predictors included in the dataset.
</p>
<p>2. "fair" selection uses a two step procedure for analyzing split values on
predictors at each node of the tree. The first phase uses half of the sample
to examine the model improvement for each split value on each predictor, and
retains the the value that presents the largest improvement for each
predictor. The second phase then evaluates these best split points for each
predictor on the second half of the sample. The best improvement for the c
splits tested on c predictors is selected for the node and the dataset is
split from this node for further testing.
</p>
<p>3. "score" uses score-based test statistics. These statistics are much
faster than the classic SEM tree approach while having favorable
statistical properties.
</p>
<p>All other parameters controlling the tree growing process are available
through a separate <code>semtree.control</code> object.
</p>


<h3>Value</h3>

<p>A <code>semtree</code> object is created which can be examined with
<code>summary</code>, <code>plot</code>, and <code>print</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas M. Brandmaier, John J. Prindle, Manuel Arnold
</p>


<h3>References</h3>

<p>Brandmaier, A.M., Oertzen, T. v., McArdle, J.J., &amp; Lindenberger, U. (2013). Structural equation model trees. <em>Psychological Methods</em>, 18(1), 71-86.
</p>
<p>Arnold, M., Voelkle, M. C., &amp; Brandmaier, A. M. (2021). Score-guided structural equation model trees. <em>Frontiers in Psychology</em>, 11, Article 564403. https://doi.org/10.3389/fpsyg.2020.564403
</p>


<h3>See Also</h3>

<p><code>semtree.control</code>, <code>summary.semtree</code>,
<code>parameters</code>, <code>se</code>, <code>prune.semtree</code>,
<code>subtree</code>, <code>OpenMx</code>,
<code>lavaan</code>
</p>


</div>