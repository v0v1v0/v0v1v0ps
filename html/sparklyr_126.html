<div class="container">

<table style="width: 100%;"><tr>
<td>hof_transform_values</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Transforms values of a map</h2>

<h3>Description</h3>

<p>Applies the transformation function specified to all values of a map
(this is essentially a dplyr wrapper to the 'transform_values(expr, func)' higher-
order function, which is supported since Spark 3.0)
</p>


<h3>Usage</h3>

<pre><code class="language-R">hof_transform_values(x, func, expr = NULL, dest_col = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The Spark data frame to be processed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>func</code></td>
<td>
<p>The transformation function to apply (it should take (key, value) as
arguments and return a transformed value)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expr</code></td>
<td>
<p>The map being transformed, could be any SQL expression evaluating to a map
(default: the last column of the Spark data frame)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dest_col</code></td>
<td>
<p>Column to store the transformed result (default: expr)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional params to dplyr::mutate</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

library(sparklyr)
sc &lt;- spark_connect(master = "local", version = "3.0.0")
sdf &lt;- sdf_len(sc, 1) %&gt;% dplyr::mutate(m = map("a", 0L, "b", 2L, "c", -1L))
transformed_sdf &lt;- sdf %&gt;% hof_transform_values(~ CONCAT(.x, " == ", .y))

## End(Not run)

</code></pre>


</div>