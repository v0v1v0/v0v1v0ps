<div class="container">

<table style="width: 100%;"><tr>
<td>klcv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-Validated Kullback-Leibler Divergence</h2>

<h3>Description</h3>

<p>Model selection criterion based on the leave-one-out cross-validated Kullback-Leibler divergence.
</p>


<h3>Usage</h3>

<pre><code class="language-R">klcv(object, X, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>fitted <code>sglasso</code>/<code>fglasso</code> object;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the matrix used to compute the empirical variance/covariance matrix. Its dimension is <code>N</code> <code class="reqn">\times</code> <code>p</code>, where <code>p</code> is the number of random variables and <code>N</code> is the samlpe size;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>scalar value used to scale the estimated degrees-of-freedom. See below for more details.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>klcv</code> function implements the leave-one-out cross-validate Kullback-Leibler divergence criterion proposed in Vujacic et al. (2015). For <code class="reqn">l_1</code>-penalized Gaussian Graphical Models this measure of goodness-of-fit has the following form </p>
<p style="text-align: center;"><code class="reqn">klcv(\rho) = -\frac{\ell(\hat K(\rho))}{N} + \frac{\code{scale}}{2N} gdf(\hat K(\rho)),</code>
</p>
<p> where <code class="reqn">\hat K(\rho)</code> is the glasso estimate of the concentration matrix, <code class="reqn">\ell(\hat K(\rho))</code> is the corresponding value of the log-likelihood function, <code>scale</code> is a scale factor for the complexity part, i.e. <code class="reqn">gdf(\hat K(\rho))</code>, which is defined as </p>
<p style="text-align: center;"><code class="reqn">gdf(\hat K(\rho)) = \frac{1}{N-1}\sum_{k=1}^N vec\{(\hat K(\rho)^{-1} - S_k)\circ 1_\rho\}'vec[\hat K(\rho)\{(S-S_k)\circ 1_\rho\}\hat K(\rho)].</code>
</p>
<p> In the previous expression <code class="reqn">S</code> is the empirical variance/covariance matrix, <code class="reqn">S_k = X_k X_k'</code>, <code class="reqn">1_\rho</code> is a matrix with entries <code class="reqn">I(\hat k_{ij}(\rho)\ne 0)</code> and <code class="reqn">\circ</code> is the Hadamard product operator.
</p>


<h3>Value</h3>

<p><code>klcv</code> returns an S3 object with calls <code>klcv</code>, i.e. a named list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>klcv</code></td>
<td>
<p>the vector with the leave-one-out cross-validated Kullback-Leibler divergence;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p>the rho-values used to compute the leave-one-out cross-validated Kullback-Leibler divergence;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglik</code></td>
<td>
<p>a vector with the log-likelihood computed for the sequence of weighted l1-penalized <em>RCON(V, E);</em></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gdf</code></td>
<td>
<p>a vector returning the generalized degrees-of-freedom;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>the scale value used to define the leave-one-out cross-validated Kullback-Leibler divergence;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.klcv</code></td>
<td>
<p>minimum value of the leave-one-out cross-validated Kullback-Leibler divergence;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho.opt</code></td>
<td>
<p>the rho-value corresponding to minimum leave-one-out cross-validated Kullback-Leibler divergence;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rhoid</code></td>
<td>
<p>the index of the rho-value identified by the leave-one-out cross-validated Kullback-Leibler divergence.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Luigi Augugliaro<br> 
Maintainer: Luigi Augugliaro <a href="mailto:luigi.augugliaro@unipa.it">luigi.augugliaro@unipa.it</a></p>


<h3>References</h3>

<p>Vujacic, I., Abbruzzo, A. and Wit, E. C. (2015) A computationally fast alternative to cross-validation in penalized Gaussian graphical models. <em>J. Stat. Comput. Simul.</em>
</p>


<h3>See Also</h3>

<p><code>sglasso</code>, <code>loglik</code> functions and <code>plot.klcv</code> method.
</p>


<h3>Examples</h3>

<pre><code class="language-R">N &lt;- 100
p &lt;- 5
X &lt;- matrix(rnorm(N * p), N, p)
S &lt;- crossprod(X) / N
mask &lt;- outer(1:p, 1:p, function(i,j) 0.5^abs(i-j))
mask[1,5] &lt;- mask[1,4] &lt;- mask[2,5] &lt;- NA
mask[5,1] &lt;- mask[4,1] &lt;- mask[5,2] &lt;- NA
out.sglasso_path &lt;- sglasso(S, mask, tol = 1.0e-13)
out.klcv &lt;- klcv(out.sglasso_path, X)
out.klcv
</code></pre>


</div>