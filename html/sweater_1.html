<div class="container">

<table style="width: 100%;"><tr>
<td>calculate_es</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate the effect size of a query</h2>

<h3>Description</h3>

<p>This function calculates the effect of a query.
</p>


<h3>Usage</h3>

<pre><code class="language-R">calculate_es(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an S3 object returned from a query, either by the function <code>query()</code> or underlying functions such as <code>mac()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional parameters for the effect size functions
</p>

<ul>
<li> <p><code>r</code> for <code>weat</code>: a boolean to denote whether convert the effect size to biserial correlation coefficient.
</p>
</li>
<li> <p><code>standardize</code> for <code>weat</code>: a boolean to denote whether to correct the difference by the standard division. The standardized version can be interpreted the same way as Cohen's d.
</p>
</li>
</ul>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The following methods are supported.
</p>

<ul>
<li> <p><code>mac</code> mean cosine distance value. The value makes sense only for comparison (e.g. before and after debiasing). But a lower value indicates greater association between the target words and the attribute words.
</p>
</li>
<li> <p><code>rnd</code> sum of all relative norm distances. It equals to zero when there is no bias.
</p>
</li>
<li> <p><code>rnsb</code> Kullback-Leibler divergence of the predicted negative probabilities, P, from the uniform distribution. A lower value indicates less bias.
</p>
</li>
<li> <p><code>ect</code> Spearman Coefficient of an Embedding Coherence Test. The value ranges from -1 to +1 and a larger value indicates less bias.
</p>
</li>
<li> <p><code>weat</code> The standardized effect size (default) can be interpreted the same way as Cohen's D.
</p>
</li>
</ul>
<h3>Value</h3>

<p>effect size
</p>


<h3>References</h3>

<p>Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186. <a href="https://doi.org/10.1126/science.aal4230">doi:10.1126/science.aal4230</a>
</p>
<p>Dev, S., &amp; Phillips, J. (2019, April). <a href="https://proceedings.mlr.press/v89/dev19a.html">Attenuating bias in word vectors.</a> In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 879-887). PMLR.
</p>
<p>Garg, N., Schiebinger, L., Jurafsky, D., &amp; Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences, 115(16), E3635-E3644. <a href="https://doi.org/10.1073/pnas.1720347115">doi:10.1073/pnas.1720347115</a>
</p>
<p>Manzini, T., Lim, Y. C., Tsvetkov, Y., &amp; Black, A. W. (2019). <a href="https://arxiv.org/abs/1904.04047">Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings.</a> arXiv preprint arXiv:1904.04047.
</p>
<p>Sweeney, C., &amp; Najafian, M. (2019, July). <a href="https://aclanthology.org/P19-1162/">A transparent framework for evaluating unintended demographic bias in word embeddings.</a> In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 1662-1667).
</p>


<h3>See Also</h3>

<p><code>weat_es()</code>, <code>mac_es()</code>, <code>rnd_es()</code>, <code>rnsb_es()</code>, <code>ect_es()</code>
</p>


</div>