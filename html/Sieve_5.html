<div class="container">

<table style="width: 100%;"><tr>
<td>Sieve-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Nonparametric Estimation by the Method of Sieves
</h2>

<h3>Description</h3>

<p>Performs multivariate nonparametric regression/classification by the method of sieves (using orthogonal basis). The method is suitable for moderate high-dimensional features (dimension &lt; 100). The l1-penalized sieve estimator, a nonparametric generalization of Lasso, is adaptive to the feature dimension with provable theoretical guarantees. We also include a nonparametric stochastic gradient descent estimator, Sieve-SGD, for online or large scale batch problems. Details of the methods can be found in: &lt;arXiv:2206.02994&gt; &lt;arXiv:2104.00846&gt;&lt;arXiv:2310.12140&gt;.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> Sieve</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Title: </td>
<td style="text-align: left;"> Nonparametric Estimation by the Method of Sieves</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 2.1</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2023-10-19</td>
</tr>
<tr>
<td style="text-align: left;">
Author: </td>
<td style="text-align: left;"> Tianyu Zhang</td>
</tr>
<tr>
<td style="text-align: left;">
Maintainer: </td>
<td style="text-align: left;"> Tianyu Zhang &lt;tianyuz3@andrew.cmu.edu&gt;</td>
</tr>
<tr>
<td style="text-align: left;">
Description: </td>
<td style="text-align: left;"> Performs multivariate nonparametric regression/classification by the method of sieves (using orthogonal basis). The method is suitable for moderate high-dimensional features (dimension &lt; 100). The l1-penalized sieve estimator, a nonparametric generalization of Lasso, is adaptive to the feature dimension with provable theoretical guarantees. We also include a nonparametric stochastic gradient descent estimator, Sieve-SGD, for online or large scale batch problems. Details of the methods can be found in: &lt;arXiv:2206.02994&gt; &lt;arXiv:2104.00846&gt;&lt;arXiv:2310.12140&gt;.</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
<td style="text-align: left;">
Imports: </td>
<td style="text-align: left;"> Rcpp,
combinat,
glmnet,
methods,
MASS</td>
</tr>
<tr>
<td style="text-align: left;">
LinkingTo: </td>
<td style="text-align: left;"> Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td style="text-align: left;">
RoxygenNote: </td>
<td style="text-align: left;"> 7.2.3</td>
</tr>
<tr>
<td style="text-align: left;">
Encoding: </td>
<td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>Index of help topics:
</p>
<pre>
GenSamples              Generate some simulation/testing samples with
                        nonlinear truth.
Sieve-package           Nonparametric Estimation by the Method of
                        Sieves
clean_up_result         Clean up the fitted model
create_index_matrix     Create the index matrix for multivariate
                        regression
sieve.sgd.predict       Sieve-SGD makes prediction with new predictors.
sieve.sgd.preprocess    Preprocess the original data for sieve-SGD
                        estimation.
sieve.sgd.solver        Fit sieve-SGD estimators, using progressive
                        validation for hyperparameter tuning.
sieve_predict           Predict the outcome of interest for new samples
sieve_preprocess        Preprocess the original data for sieve
                        estimation.
sieve_solver            Calculate the coefficients for the basis
                        functions
</pre>
<p>~~ An overview of how to use the ~~
~~ package, including the most ~~
~~ important functions ~~
</p>


<h3>Author(s)</h3>

<p>Tianyu Zhang
</p>
<p>Maintainer: Tianyu Zhang &lt;tianyuz3@andrew.cmu.edu&gt;
</p>


<h3>References</h3>

<p>Tianyu Zhang and Noah Simon (2022) &lt;arXiv:2206.02994&gt;
</p>


<h3>Examples</h3>

<pre><code class="language-R">
xdim &lt;- 5
basisN &lt;- 1000
type &lt;- 'cosine'

#non-linear additive truth. Half of the features are truly associated with the outcome
TrainData &lt;- GenSamples(s.size = 300, xdim = xdim, 
            frho = 'additive', frho.para = xdim/2)

#noise-free testing samples
TestData &lt;- GenSamples(s.size = 1e3, xdim = xdim, noise.para = 0, 
            frho = 'additive', frho.para = xdim/2)

sieve.model &lt;- sieve_preprocess(X = TrainData[,2:(xdim+1)], 
            basisN = basisN, type = type, interaction_order = 2)

sieve.model &lt;- sieve_solver(sieve.model, TrainData$Y, l1 = TRUE)

sieve_model_prediction &lt;- sieve_predict(testX = TestData[,2:(xdim+1)], 
                testY = TestData$Y, sieve.model)

</code></pre>


</div>