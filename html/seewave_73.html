<div class="container">

<table style="width: 100%;"><tr>
<td>kl.dist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kullback-Leibler distance</h2>

<h3>Description</h3>

<p>Compare two distributions (e.g. two frequency spectra) by
computing the Kullback-Leibler distance</p>


<h3>Usage</h3>

<pre><code class="language-R">kl.dist(spec1, spec2, base = 2)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>spec1</code></td>
<td>
<p>any distribution, especially a spectrum obtained with <code>spec</code> or <code>meanspec</code> (not in dB). This can be either a two-column matrix (col1 = frequency, col2 = amplitude) or a vector (amplitude).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spec2</code></td>
<td>
<p>any distribution, especially a spectrum obtained with
<code>spec</code> or <code>meanspec</code> (not in dB). This can be
either a two-column matrix (col1 = frequency, col2 = amplitude) or a
vector (amplitude).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>base</code></td>
<td>
<p>the logarithm base used to compute the distance. See <code>log</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Kullback-Leibler distance or relative entropy is a
non-symmetric measure of the difference between two probability
distributions. It is here adapted for frequency spectra. The distance
is asymmetric, ie computing the K-L distance between spec1 and spec2 is
not the same as computing it between spec2 and spec1. A symmetry can be
obtained by calculating the mean between the two directions.<br>
The distance is obtained following:<br></p>
<p style="text-align: center;"><code class="reqn">D_{K-L}(spec1 \Vert spec2) = \sum{spec1 \times log(\frac{spec1}{spec2})}</code>
</p>



<h3>Value</h3>

<p>The function returns a list of three items:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>D1</code></td>
<td>
<p>The K-L distance of 'spec2' with respect to 'spec1'
(<em>i.e.</em> D(spec1 || spec2))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D2</code></td>
<td>
<p>The K-L distance of 'spec1' with respect to 'spec2'
(<em>i.e.</em> D(spec2 || spec1))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>The symmetric K-L distance (<em>i.e.</em> D = 0.5*(D1+D2))</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>The base of the logarithm can be changed using the argument
<code>base</code>. When sets to base 2, the information is measured in units of
bits. When sets to base <em>e</em>, the information is measured in
nats.<br>
The function works for both Hz and (htk-)mel scales.
</p>


<h3>Author(s)</h3>

<p>Jerome Sueur, improved by Laurent Lellouch</p>


<h3>References</h3>

<p>Kullback, S., Leibler, R.A. (1951). On information and sufficiency. <em>Annals of Mathematical Statistics</em>, 22: 79-86</p>


<h3>See Also</h3>

<p><code>ks.dist</code>, <code>logspec.dist</code>, <code>simspec</code>, <code>diffspec</code></p>


<h3>Examples</h3>

<pre><code class="language-R"># Comparison of two spectra
data(tico)
tico1 &lt;- spec(tico, at=0.65, plot=FALSE)
tico2 &lt;- spec(tico, at=1.1, plot=FALSE)
kl.dist(tico1, tico2)    # log2 (binary logarithm)
kl.dist(tico1, tico2, base=exp(1))  # ln (natural logarithm)
</code></pre>


</div>