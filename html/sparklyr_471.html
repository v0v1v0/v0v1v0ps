<div class="container">

<table style="width: 100%;"><tr>
<td>spark_write_avro</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Serialize a Spark DataFrame into Apache Avro format</h2>

<h3>Description</h3>

<p>Notice this functionality requires the Spark connection <code>sc</code> to be
instantiated with either
an explicitly specified Spark version (i.e.,
<code>spark_connect(..., version = &lt;version&gt;, packages = c("avro", &lt;other package(s)&gt;), ...)</code>)
or a specific version of Spark avro package to use (e.g.,
<code>spark_connect(..., packages =
c("org.apache.spark:spark-avro_2.12:3.0.0", &lt;other package(s)&gt;), ...)</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">spark_write_avro(
  x,
  path,
  avro_schema = NULL,
  record_name = "topLevelRecord",
  record_namespace = "",
  compression = "snappy",
  partition_by = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A Spark DataFrame or dplyr operation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the ‘<span class="samp">⁠"hdfs://"⁠</span>’, ‘<span class="samp">⁠"s3a://"⁠</span>’ and ‘<span class="samp">⁠"file://"⁠</span>’ protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>avro_schema</code></td>
<td>
<p>Optional Avro schema in JSON format</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>record_name</code></td>
<td>
<p>Optional top level record name in write result
(default: "topLevelRecord")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>record_namespace</code></td>
<td>
<p>Record namespace in write result (default: "")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compression</code></td>
<td>
<p>Compression codec to use (default: "snappy")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partition_by</code></td>
<td>
<p>A <code>character</code> vector. Partitions the output by the given columns on the file system.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other Spark serialization routines: 
<code>collect_from_rds()</code>,
<code>spark_insert_table()</code>,
<code>spark_load_table()</code>,
<code>spark_read()</code>,
<code>spark_read_avro()</code>,
<code>spark_read_binary()</code>,
<code>spark_read_csv()</code>,
<code>spark_read_delta()</code>,
<code>spark_read_image()</code>,
<code>spark_read_jdbc()</code>,
<code>spark_read_json()</code>,
<code>spark_read_libsvm()</code>,
<code>spark_read_orc()</code>,
<code>spark_read_parquet()</code>,
<code>spark_read_source()</code>,
<code>spark_read_table()</code>,
<code>spark_read_text()</code>,
<code>spark_save_table()</code>,
<code>spark_write_csv()</code>,
<code>spark_write_delta()</code>,
<code>spark_write_jdbc()</code>,
<code>spark_write_json()</code>,
<code>spark_write_orc()</code>,
<code>spark_write_parquet()</code>,
<code>spark_write_source()</code>,
<code>spark_write_table()</code>,
<code>spark_write_text()</code>
</p>


</div>