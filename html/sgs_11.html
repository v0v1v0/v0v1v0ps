<div class="container">

<table style="width: 100%;"><tr>
<td>fit_sgo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit an SGO model.</h2>

<h3>Description</h3>

<p>Sparse-group OSCAR (SGO) main fitting function. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fit_sgo(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL,
  v_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li>
<p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between OSCAR and gOSCAR. Must be between 0 and 1. Recommended value is 0.95.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/\sqrt{n}</code>.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/n</code>.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"noBaone"</code> no standardisation applied.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>fit_sgo()</code> fits an SGO model (Feser and Evangelou (2024)) using adaptive three operator splitting (ATOS). SGO uses the same model set-up as for SGS, but with different weights (see Bao et. al. (2020) and Feser and Evangelou (2024)).
The penalties are given by (for a group <code class="reqn">g</code> and variable <code class="reqn">i</code>, with <code class="reqn">p</code> variables and <code class="reqn">m</code> groups):
</p>
<p style="text-align: center;"><code class="reqn">
  v_i = \sigma_1 + \sigma_2(p-i), \; w_g = \sigma_1 + \sigma_3(m-g),
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
     \sigma_1 = d_i\|X^\intercal y\|_\infty, \; \sigma_2 = \sigma_1/p, \; \sigma_3 = \sigma_1/m, \; d_i = i \times \exp{(-2)}. 
</code>
</p>



<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>z</code>, which is usually the former. A filter is applied to remove very small values, where ATOS has not been able to shrink exactly to zero. Check this against <code>x</code> and <code>z</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pen_slope</code></td>
<td>
<p>Vector of the variable penalty sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pen_gslope</code></td>
<td>
<p>Vector of the group penalty sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Value(s) of <code class="reqn">\lambda</code> used to fit the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>
<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p>Other SGS-methods: 
<code>as_sgs()</code>,
<code>coef.sgs()</code>,
<code>fit_sgo_cv()</code>,
<code>fit_sgs()</code>,
<code>fit_sgs_cv()</code>,
<code>plot.sgs()</code>,
<code>predict.sgs()</code>,
<code>print.sgs()</code>,
<code>scaled_sgs()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGO
model = fit_sgo(X = data$X, y = data$y, groups = groups, type="linear", path_length = 5, 
alpha=0.95, standardise = "l2", intercept = TRUE, verbose=FALSE)
</code></pre>


</div>