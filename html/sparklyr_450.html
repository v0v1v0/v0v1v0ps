<div class="container">

<table style="width: 100%;"><tr>
<td>spark_read_jdbc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Read from JDBC connection into a Spark DataFrame.</h2>

<h3>Description</h3>

<p>Read from JDBC connection into a Spark DataFrame.
</p>


<h3>Usage</h3>

<pre><code class="language-R">spark_read_jdbc(
  sc,
  name,
  options = list(),
  repartition = 0,
  memory = TRUE,
  overwrite = TRUE,
  columns = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name to assign to the newly generated table.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>A list of strings with additional options.
See <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration">https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>repartition</code></td>
<td>
<p>The number of partitions used to distribute the
generated table. Use 0 (the default) to avoid partitioning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>memory</code></td>
<td>
<p>Boolean; should the data be loaded eagerly into memory? (That
is, should the table be cached?)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overwrite</code></td>
<td>
<p>Boolean; overwrite the table with the given name if it
already exists?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>columns</code></td>
<td>
<p>A vector of column names or a named vector of column types.
If specified, the elements can be <code>"binary"</code> for <code>BinaryType</code>,
<code>"boolean"</code> for <code>BooleanType</code>, <code>"byte"</code> for <code>ByteType</code>,
<code>"integer"</code> for <code>IntegerType</code>, <code>"integer64"</code> for <code>LongType</code>,
<code>"double"</code> for <code>DoubleType</code>, <code>"character"</code> for <code>StringType</code>,
<code>"timestamp"</code> for <code>TimestampType</code> and <code>"date"</code> for <code>DateType</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other Spark serialization routines: 
<code>collect_from_rds()</code>,
<code>spark_insert_table()</code>,
<code>spark_load_table()</code>,
<code>spark_read()</code>,
<code>spark_read_avro()</code>,
<code>spark_read_binary()</code>,
<code>spark_read_csv()</code>,
<code>spark_read_delta()</code>,
<code>spark_read_image()</code>,
<code>spark_read_json()</code>,
<code>spark_read_libsvm()</code>,
<code>spark_read_orc()</code>,
<code>spark_read_parquet()</code>,
<code>spark_read_source()</code>,
<code>spark_read_table()</code>,
<code>spark_read_text()</code>,
<code>spark_save_table()</code>,
<code>spark_write_avro()</code>,
<code>spark_write_csv()</code>,
<code>spark_write_delta()</code>,
<code>spark_write_jdbc()</code>,
<code>spark_write_json()</code>,
<code>spark_write_orc()</code>,
<code>spark_write_parquet()</code>,
<code>spark_write_source()</code>,
<code>spark_write_table()</code>,
<code>spark_write_text()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
sc &lt;- spark_connect(
  master = "local",
  config = list(
    `sparklyr.shell.driver-class-path` = "/usr/share/java/mysql-connector-java-8.0.25.jar"
  )
)
spark_read_jdbc(
  sc,
  name = "my_sql_table",
  options = list(
    url = "jdbc:mysql://localhost:3306/my_sql_schema",
    driver = "com.mysql.jdbc.Driver",
    user = "me",
    password = "******",
    dbtable = "my_sql_table"
  )
)

## End(Not run)

</code></pre>


</div>