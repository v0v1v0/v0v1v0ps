<div class="container">

<table style="width: 100%;"><tr>
<td>elbo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute the evidence lower bound (ELBO)</h2>

<h3>Description</h3>

<p>Compute the evidence lower bound (ELBO)
</p>


<h3>Usage</h3>

<pre><code class="language-R">elbo(Y, delta, X, fit, nrep = 10000, center = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Failure times.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>Censoring indicator, 0: censored, 1: uncensored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Design matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>Fit model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrep</code></td>
<td>
<p>Number of Monte Carlo samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>Should the design matrix be centered.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a list containing: <br></p>
<table>
<tr style="vertical-align: top;">
<td><code>mean</code></td>
<td>
<p>The mean of the ELBO.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd</code></td>
<td>
<p>The standard-deviation of the ELBO.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expected.likelihood</code></td>
<td>
<p>The expectation of the likelihood
under the variational posterior.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kl</code></td>
<td>
<p>The KL between the variational posterior and prior.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The evidence lower bound (ELBO) is a popular goodness of fit measure
used in variational inference. Under the variational posterior the
ELBO is given as
</p>
<p style="text-align: center;"><code class="reqn">ELBO = E_{\tilde{\Pi}}[\log L_p(\beta; Y, X, \delta)] - KL(\tilde{\Pi} \| \Pi)</code>
</p>

<p>where <code class="reqn">\tilde{\Pi}</code> is the variational posterior, <code class="reqn">\Pi</code> is the prior,
<code class="reqn">L_p(\beta; Y, X, \delta)</code> is Cox's partial likelihood. Intuitively,
within the ELBO we incur a trade-off between how well we fit to the data
(through the expectation of the log-partial-likelihood) and how close we
are to our prior (in terms of KL divergence). Ideally we want the ELBO to be 
as small as possible.
</p>


</div>