<div class="container">

<table style="width: 100%;"><tr>
<td>treeEnsemble</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A data generator based on forest</h2>

<h3>Description</h3>

<p>Using given <code>formula</code> and <code>data</code> the method <code>treeEnsemble</code> builds a tree ensemble and turns it into a data generator, which can be used with <code>newdata</code> method to generate 
semi-artificial data. The methods supports classification, regression, and unsupervised data, depending on the input and parameters.
The method <code>indAttrGen</code> generates data from the same distribution as the input data, but 
assuming conditionally independent attributes. 
</p>


<h3>Usage</h3>

<pre><code class="language-R"> treeEnsemble(formula, dataset, noTrees = 100, minNodeWeight=2, noSelectedAttr=0, 
  	problemType=c("byResponse","classification", "regression","density"),
    densityData=c("leaf", "topDown", "bottomUp","no"),
    cdfEstimation = c("ecdf","logspline","kde"), 
	densitySplitMethod=c("balancedSplit","randomSplit","maxVariance"),
    estimator=NULL,...) 

indAttrGen(formula, dataset, cdfEstimation = c("ecdf","logspline","kde"), 
           problemType="byResponse") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p> A formula specifying the response and variables to be modeled. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>
<p> A data frame with training data. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noTrees</code></td>
<td>
<p> The number of trees in the ensemble.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minNodeWeight</code></td>
<td>
<p>The minimal number of instances in a tree leaf.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noSelectedAttr</code></td>
<td>
<p>Number of randomly selected attributes in each node which are considered as possible splits. In general this should be a positive integer, 
but values 0, -1, and -2 are also possible. 
The default value is <code>noSelectedAttr=0</code>, which causes random selection of integer rounded <code class="reqn">\sqrt{a}</code> attributes, where $a$ is the number of all attributes. 
Value -1 means that <code class="reqn">1+\log_2{a}</code> attributes are selected and value -2 means that all attributes are selected.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>problemType</code></td>
<td>
<p>The type of the problem modeled: classification, regression, or unsupervised (density estimation). The default value  <code>"byResponse"</code> indicates that 
the problem type is deducted based on <code>formula</code> and <code>data</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>densityData</code></td>
<td>
<p>The type of generator data and place where new instances are generated: in the leafs, top down from the root of the tree to the leaves, bottom up from
the leaves to root. In case of value <code>"no"</code> the ensemble contains no generator data and can be used as an ordinary ensemble predictor (although 
probably slow, as it is written entirely in R).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cdfEstimation</code></td>
<td>
<p>The manner values are generated and the type of data stored in the generator: <code>"ecdf"</code> indicates values are generated from empirical cumulative 
distributions stored for each variable separately; <code>"logspline"</code> means that value distribution is modeled with logsplines, and <code>"kde"</code> 
indicates that Gaussian kernel density estimation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>densitySplitMethod</code></td>
<td>
<p>In case <code>problemType="density"</code> the parameters determines the criteria for selection of split in the density tree. Possible choices are 
balanced (a split value is chosen in such a way that the split is balanced), random (split value is chosen randomly) and maxVariance (split with 
maximal variance is chosen).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimator</code></td>
<td>
<p>The attribute estimator used to select the node split in classification and regression trees. Function <code>attrEval</code> from <code>CORElearn</code> package is 
used, so the values have to be compatible with that function. The default value <code>NULL</code> chooses Gini index in case of classification problems and MSE 
(mean squared error in resulting splits) in case of regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further parameters to be passed onto probability density estimators.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Parameter <code>formula</code> is used as a mechanism to select features (attributes)
and the prediction variable (response) from the data. Only simple terms can be used and
interaction terms are not supported. The simplest way is
to specify just the response variable using e.g. <code>class ~ .</code>. For unsupervised problems all variables can be selected using formula <code> ~ .</code>.
See examples below.
</p>
<p>A forest of trees is build using R code. The base models of the ensemble are classification, regression or density trees with additional information stored at the 
appropriate nodes. New data can be generated using <code>newdata</code> method.
</p>
<p>The method <code>indAttrGen</code> generates data from the same distribution as the input data (provided in 
<code>dataset</code>), but assumes conditional independence of attributes. This assumption makes the generated data
a simple baseline generator. Internally, the method calls <code>treeEnsemble</code> with parameters 
<code>noTrees=1</code>, <code>minNodeWeight=nrow(dataset)</code>, <code>densityData="leaf"</code>.  
</p>


<h3>Value</h3>

<p>The created model is returned with additional data stored as a list and also in the trees. The model can be used with function <code>newdata</code> to generate new values.
</p>


<h3>Author(s)</h3>

<p> Marko Robnik-Sikonja</p>


<h3>References</h3>

<p>Marko Robnik-Sikonja: Not enough data? Generate it!. <em>Technical Report, University of Ljubljana, Faculty of Computer and Information Science</em>, 2014
</p>
<p>Other references are available from <a href="http://lkm.fri.uni-lj.si/rmarko/papers/">http://lkm.fri.uni-lj.si/rmarko/papers/</a>
</p>


<h3>See Also</h3>

<p><code>newdata</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># use iris data set, split into training and testing, inspect the data
set.seed(12345)
train &lt;- sample(1:nrow(iris),size=nrow(iris)*0.5)
irisTrain &lt;- iris[train,]
irisTest &lt;- iris[-train,]

# inspect properties of the original data
plot(iris[,-5], col=iris$Species)
summary(iris)

# create tree ensemble generator for classification problem
irisGenerator&lt;- treeEnsemble(Species~., irisTrain, noTrees=10)

# use the generator to create new data
irisNew &lt;- newdata(irisGenerator, size=200)

#inspect properties of the new data
plot(irisNew[,-5], col = irisNew$Species) # plot generated data
summary(irisNew)

## Not run: 
# create tree ensemble generator for unsupervised problem
irisUnsupervised&lt;- treeEnsemble(~.,irisTrain[,-5], noTrees=10)
irisNewUn &lt;- newdata(irisUnsupervised, size=200)
plot(irisNewUn) # plot generated data
summary(irisNewUn)

# create tree ensemble generator for regression problem
CO2gen&lt;- treeEnsemble(uptake~.,CO2, noTrees=10)
CO2New &lt;- newdata(CO2gen, size=200)
plot(CO2) # plot original data
plot(CO2New) # plot generated data
summary(CO2)
summary(CO2New)

## End(Not run)

</code></pre>


</div>