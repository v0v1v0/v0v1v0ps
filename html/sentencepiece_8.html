<div class="container">

<table style="width: 100%;"><tr>
<td>sentencepiece_encode</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenise text alongside a Sentencepiece model</h2>

<h3>Description</h3>

<p>Tokenise text alongside a Sentencepiece model
</p>


<h3>Usage</h3>

<pre><code class="language-R">sentencepiece_encode(
  model,
  x,
  type = c("subwords", "ids"),
  nbest = -1L,
  alpha = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>an object of class <code>sentencepiece</code> as returned by <code>sentencepiece_load_model</code> or <code>sentencepiece</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a character vector of text (in UTF-8 Encoding)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>a character string, either 'subwords' or 'ids' to get the subwords or the corresponding ids of these subwords as defined in the vocabulary of the model. 
Defaults to 'subwords'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbest</code></td>
<td>
<p>integer indicating the number of segmentations to extract. See the details. The argument is not used if you do not provide a value for it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>smoothing parameter to perform subword regularisation. Typical values are 0.1, 0.2 or 0.5. See the details. The argument is not used if you do not provide a value for it or do not provide a value for <code>nbest</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If you specify <code>alpha</code> to perform subword regularisation, keep in mind the following. <br>
When alpha is 0.0, one segmentation is uniformly sampled from the <code>nbest</code> or lattice. 
The best Viterbi segmentation is more likely sampled when setting larger <code>alpha</code> values like 0.1. <br></p>

<ul>
<li>
<p> If you provide a positive value for <code>nbest</code>, approximately samples one segmentation from <code>nbest</code> candidates.
</p>
</li>
<li>
<p> If you provide a negative value for <code>nbest</code>, samples one segmentation from the hypotheses (Lattice) according to the generation probabilities using forward-filtering and backward-sampling algorithm.
</p>
</li>
</ul>
<p><code>nbest</code> and <code>alpha</code> correspond respectively to the parameter <code>l</code> and in <code>alpha</code> 
in the paper <a href="https://arxiv.org/abs/1804.10959">https://arxiv.org/abs/1804.10959</a> where (<code>nbest</code> &lt; 0 means l = infinity).<br></p>
<p>If the model is a BPE model, <code>alpha</code> is the merge probability <code>p</code> explained in <a href="https://arxiv.org/abs/1910.13267">https://arxiv.org/abs/1910.13267</a>. 
In a BPE model, nbest-based sampling is not supported so the nbest parameter is ignored although 
it still needs to be provided if you want to make use of <code>alpha</code>.
</p>


<h3>Value</h3>

<p>a list with tokenised text, one for each element of <code>x</code> 
unless you provide <code>nbest</code> without providing <code>alpha</code> in which case the result is a list of list of <code>nbest</code> tokenised texts
</p>


<h3>Examples</h3>

<pre><code class="language-R">model &lt;- system.file(package = "sentencepiece", "models", "nl-fr-dekamer.model")
model &lt;- sentencepiece_load_model(file = model)

txt &lt;- c("De eigendomsoverdracht aan de deelstaten is ingewikkeld.",
         "On est d'accord sur le prix de la biere?")
sentencepiece_encode(model, x = txt, type = "subwords")
sentencepiece_encode(model, x = txt, type = "ids")

## Examples using subword regularisation
model &lt;- system.file(package = "sentencepiece", "models", "nl-fr-dekamer-unigram.model")
model &lt;- sentencepiece_load_model(file = model)

txt &lt;- c("Goed zo",
         "On est d'accord")
sentencepiece_encode(model, x = txt, type = "subwords", nbest = 4)
sentencepiece_encode(model, x = txt, type = "ids", nbest = 4)
sentencepiece_encode(model, x = txt, type = "subwords", nbest = 2)
sentencepiece_encode(model, x = txt, type = "ids", nbest = 2)
sentencepiece_encode(model, x = txt, type = "subwords", nbest = 1)
sentencepiece_encode(model, x = txt, type = "ids", nbest = 1)
sentencepiece_encode(model, x = txt, type = "subwords", nbest = 4, alpha = 0.1)
sentencepiece_encode(model, x = txt, type = "ids", nbest = 4, alpha = 0.1)
sentencepiece_encode(model, x = txt, type = "subwords", nbest = -1, alpha = 0.1)
sentencepiece_encode(model, x = txt, type = "ids", nbest = -1, alpha = 0.1)
sentencepiece_encode(model, x = txt, type = "subwords", nbest = -1, alpha = 0)
sentencepiece_encode(model, x = txt, type = "ids", nbest = -1, alpha = 0)
</code></pre>


</div>