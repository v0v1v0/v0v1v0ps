<div class="container">

<table style="width: 100%;"><tr>
<td>sensitivity-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sensitivity Analysis</h2>

<h3>Description</h3>

<p>Methods and functions for global sensitivity analysis of model outputs, importance measures and machine learning model interpretability</p>


<h3>Details</h3>

<p>The <span class="pkg">sensitivity</span> package implements some global sensitivity analysis
methods and importance measures:
</p>

<ul>
<li>
<p> Linear regression importance measures in regression or classification (logistic regression) contexts (Iooss et al., 2022; Clouvel et al., 2024):
</p>

<ul>
<li>
<p> SRC and SRRC (<code>src</code>), and correlation ratio (<code>correlRatio</code>)
</p>
</li>
<li>
<p> PCC, SPCC, PRCC and SPRCC (<code>pcc</code>),
</p>
</li>
<li>
<p> LMG and LMG on ranks (<code>lmg</code>),
</p>
</li>
<li>
<p> PMVD and PMVD on ranks (<code>pmvd</code>),
</p>
</li>
<li>
<p> Johnson indices (<code>johnson</code>);
</p>
</li>
</ul>
</li>
<li>
<p> Bettonvil's sequential bifurcations (Bettonvil and Kleijnen, 1996) (<code>sb</code>);
</p>
</li>
<li>
<p> Morris's "OAT" elementary effects screening method (<code>morris</code>);
</p>
</li>
<li>
<p> Derivative-based Global Sensitivity Measures:
</p>

<ul>
<li>
<p> Poincare constants for Derivative-based Global Sensitivity Measures (DGSM) (Lamboni et al., 2013; Roustant et al., 2017) (<code>PoincareConstant</code>) and (<code>PoincareOptimal</code>),
</p>
</li>
<li>
<p> Squared coefficients computation in generalized chaos via Poincare differential operators (Roustant et al., 2019) (<code>PoincareChaosSqCoef</code>),
</p>
</li>
<li>
<p> Distributed Evaluation of Local Sensitivity Analysis (DELSA) (Rakovec et al., 2014) (<code>delsa</code>);
</p>
</li>
</ul>
</li>
<li>
<p> Variance-based sensitivity indices (Sobol' indices) for independent inputs:
</p>

<ul>
<li>
<p> Estimation of the Sobol' first order indices with with B-spline Smoothing (Ratto and Pagano, 2010) (<code>sobolSmthSpl</code>),
</p>
</li>
<li>
<p> Monte Carlo estimation of Sobol' indices with independent inputs (also called pick-freeze method): 
</p>

<ul>
<li>
<p> Sobol' scheme (Sobol, 1993) to compute the indices given by the variance decomposition up to a specified order (<code>sobol</code>),
</p>
</li>
<li>
<p> Saltelli's scheme (Saltelli, 2002) to compute first order, second order and total indices  (<code>sobolSalt</code>), 
</p>
</li>
<li>
<p> Saltelli's scheme (Saltelli, 2002) to compute first order and total indices (<code>sobol2002</code>), 
</p>
</li>
<li>
<p> Mauntz-Kucherenko's scheme (Sobol et al., 2007) to compute first order and total indices using improved formulas for small indices (<code>sobol2007</code>),
</p>
</li>
<li>
<p> Jansen-Sobol's scheme (Jansen, 1999) to compute first order and total indices using improved formulas (<code>soboljansen</code>),
</p>
</li>
<li>
<p> Martinez's scheme using correlation coefficient-based formulas (Martinez, 2011; Touati, 2016) to compute first order and total indices, associated with theoretical confidence intervals (<code>sobolmartinez</code> and <code>soboltouati</code>), 
</p>
</li>
<li>
<p> Janon-Monod's scheme (Monod et al., 2006; Janon et al., 2013) to compute first order indices with optimal asymptotic variance (<code>sobolEff</code>),
</p>
</li>
<li>
<p> Mara's scheme (Mara and Joseph, 2008) to compute first order indices with a cost independent of the dimension, via permutations on a single matrix (<code>sobolmara</code>),
</p>
</li>
<li>
<p> Mighty estimator of first-order sensitivity indices based on rank statistics (correlation coefficient of Chatterjee, 2019; Gamboa et al., 2020) (<code>sobolrank</code>),
</p>
</li>
<li>
<p> Owen's scheme (Owen, 2013) to compute first order and total indices using improved formulas (via 3 input independent matrices) for small indices (<code>sobolowen</code>),
</p>
</li>
<li>
<p> Total Interaction Indices using Liu-Owen's scheme (Liu and Owen, 2006) (<code>sobolTIIlo</code>) and pick-freeze scheme (Fruth et al., 2014) (<code>sobolTIIpf</code>),
</p>
</li>
</ul>
</li>
<li>
<p> Replication-based procedures:
</p>

<ul>
<li>
<p> Estimation of the Sobol' first order and closed second order indices using replicated orthogonal array-based Latin hypecube sample (Tissot and Prieur, 2015) (<code>sobolroalhs</code>),
</p>
</li>
<li>
<p> Recursive estimation of the Sobol' first order and closed second order indices using replicated orthogonal array-based Latin hypecube sample (Gilquin et al., 2016) (<code>sobolrec</code>),
</p>
</li>
<li>
<p> Estimation of the Sobol' first order, second order and total indices using the generalized method with replicated orthogonal array-based Latin hypecube sample (Tissot and Prieur, 2015) (<code>sobolrep</code>),
</p>
</li>
<li>
<p> Sobol' indices estimation under inequality constraints (Gilquin et al., 2015) by extension of the replication procedure (Tissot and Prieur, 2015) (<code>sobolroauc</code>),
</p>
</li>
</ul>
</li>
<li>
<p> Estimation of the Sobol' first order and total indices with Saltelli's so-called "extended-FAST" method (Saltelli et al., 1999) (<code>fast99</code>),
</p>
</li>
<li>
<p> Estimation of the Sobol' first order and total indices with kriging-based global sensitivity analysis (Le Gratiet et al., 2014) (<code>sobolGP</code>);
</p>
</li>
</ul>
</li>
<li>
<p> Variance-based sensitivity indices valid for dependent inputs:
</p>

<ul>
<li>
<p> Exact computation of Shapley effects in the linear Gaussian framework (Broto et al., 2019) (<code>shapleyLinearGaussian</code>),
</p>
</li>
<li>
<p> Computation of Shapley effects in the Gaussian linear framework with an unknown block-diagonal covariance matrix (Broto et al., 2020) (<code>shapleyBlockEstimation</code>),
</p>
</li>
<li>
<p> Johnson-Shapley indices (Iooss and Clouvel, 2024) (<code>johnsonshap</code>),
</p>
</li>
<li>
<p> Estimation of Shapley effects by examining all permutations of inputs (Song et al., 2016) (<code>shapleyPermEx</code>),
</p>
</li>
<li>
<p> Estimation of Shapley effects by randomly sampling permutations of inputs (Song et al., 2016) (<code>shapleyPermRand</code>),
</p>
</li>
<li>
<p> Estimation of Shapley effects from data using nearest neighbors method (Broto et al., 2018) (<code>shapleySubsetMc</code>),
</p>
</li>
<li>
<p> Estimation of Shapley effects and all Sobol indices from data using nearest neighbors (Broto et al., 2018) (using a fast approximate algorithm) or ranking (Gamboa et al., 2020) (<code>shapleysobol_knn</code>) and (<code>sobolshap_knn</code>),
</p>
</li>
<li>
<p> Estimation of Shapley effects from data using nearest neighbors method (Broto et al., 2018) with an optimized/parallelized computations and bootstrap confidence intervals estimations  (<code>shapleysobol_knn</code>),
</p>
</li>
<li>
<p> Estimation of Proportional Marginal Effects (PME) (Herin et al., 2024) (<code>pme_knn</code>);
</p>
</li>
</ul>
</li>
<li>
<p> Support index functions (<code>support</code>) of Fruth et al. (2016);
</p>
</li>
<li>
<p> Sensitivity Indices based on Csiszar f-divergence (<code>sensiFdiv</code>) (particular cases: Borgonovo's indices and mutual-information based indices) and Hilbert-Schmidt Independence Criterion (<code>sensiHSIC</code> and <code>testHSIC</code>) (Da Veiga, 2015; De Lozzo and Marrel, 2016; Meynaoui et al., 2019);
</p>
</li>
<li>
<p> Non-parametric variable significance test based on the empirical process (<code>EPtest</code>) of Klein and Rochet (2022);
</p>
</li>
<li>
<p> First-order quantile-oriented sensitivity indices as defined in Fort et al. (2016) via a kernel-based estimator related (Maume-Deschamps and Niang, 2018) (<code>qosa</code>);
</p>
</li>
<li>
<p> Target Sensitivity Analysis via Hilbert-Schmidt Independence Criterion (<code>sensiHSIC</code>) (Spagnol et al., 2019);
</p>
</li>
<li>
<p> Robustness analysis by the Perturbed-Law based Indices (<code>PLI</code>) of Lemaitre et al. (2015), (<code>PLIquantile</code>) of Sueur et al. (2017), (<code>PLIsuperquantile</code>) of Iooss et al. (2021), and extension as (<code>PLIquantile_multivar</code>) and (<code>PLIsuperquantile_multivar</code>) ;
</p>
</li>
<li>
<p> Extensions to multidimensional outputs for:
</p>

<ul>
<li>
<p> Sobol' indices (<code>sobolMultOut</code>): Aggregated Sobol' indices (Lamboni et al., 2011; Gamboa et al., 2014) and functional (1D) Sobol' indices,
</p>
</li>
<li>
<p> Shapley effects and Sobol' indices (<code>shapleysobol_knn</code>) and (<code>sobolshap_knn</code>): Functional (1D) indices,
</p>
</li>
<li>
<p> HSIC indices (<code>sensiHSIC</code>) (Da Veiga, 2015): Aggregated HSIC, potentially via a PCA step (Da Veiga, 2015),
</p>
</li>
<li>
<p> Morris method (<code>morrisMultOut</code>).
</p>
</li>
</ul>
</li>
</ul>
<p>Moreover, some utilities are provided: standard test-cases (<code>testmodels</code>), weight transformation function of the output sample (<code>weightTSA</code>) to perform Target Sensitivity Analysis, normal and Gumbel truncated distributions (<code>truncateddistrib</code>), squared integral estimate (<code>squaredIntEstim</code>), Addelman and Kempthorne construction of orthogonal arrays of strength two (<code>addelman_const</code>), discrepancy criteria (<code>discrepancyCriteria_cplus</code>), maximin criteria (<code>maximin_cplus</code>) and template file generation (<code>template.replace</code>).
</p>


<h3>Model managing</h3>

<p>The <span class="pkg">sensitivity</span> package has been designed to work either models written in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>
than external models such as heavy computational codes. This is achieved with
the input argument <code>model</code> present in all functions of this package.
</p>
<p>The argument <code>model</code> is expected to be either a
funtion or a predictor (i.e. an object with a <code>predict</code> function such as
<code>lm</code>).
</p>

<ul>
<li>
<p> If <code>model = m</code> where <code>m</code> is a function, it will be invoked
once by <code>y &lt;- m(X)</code>.
</p>
</li>
<li>
<p> If <code>model = m</code> where <code>m</code> is a predictor, it will be invoked
once by <code>y &lt;- predict(m, X)</code>.
</p>
</li>
</ul>
<p><code>X</code> is the design of experiments, i.e. a <code>data.frame</code> with
<code>p</code> columns (the input factors) and <code>n</code> lines (each, an
experiment), and <code>y</code> is the vector of length <code>n</code> of the
model responses.
</p>
<p>The model in invoked once for the whole design of experiment.
</p>
<p>The argument <code>model</code> can be left to <code>NULL</code>. This is refered to as 
the decoupled approach and used with external computational codes that rarely
run on the statistician's computer. See <code>decoupling</code>.
</p>


<h3>Author(s)</h3>

<p>Bertrand Iooss, Sebastien Da Veiga, Alexandre Janon and Gilles Pujol with contributions from Paul Lemaitre for <code>PLI</code>, Thibault Delage and Roman Sueur for <code>PLIquantile</code>, Vanessa Verges for <code>PLIquantile</code>, <code>PLIsuperquantile</code>, <code>PLIquantile_multivar</code> and <code>PLIsuperquantile_multivar</code>, Laurent Gilquin for <code>sobolroalhs</code>, <code>sobolroauc</code>, <code>sobolSalt</code>, <code>sobolrep</code>, <code>sobolrec</code>, as well as <code>addelman_const</code>, <code>discrepancyCriteria_cplus</code> and <code>maximin_cplus</code>, Loic le Gratiet for <code>sobolGP</code>, Khalid Boumhaout, Taieb Touati and Bernardo Ramos for <code>sobolowen</code> and <code>soboltouati</code>, Jana Fruth for <code>PoincareConstant</code>, <code>sobolTIIlo</code> and <code>sobolTIIpf</code>, Gabriel Sarazin, Amandine Marrel, Anouar Meynaoui and Reda El Amri for their contributions to <code>sensiHSIC</code> and <code>testHSIC</code>, Joseph Guillaume and Oldrich Rakovec for <code>delsa</code> and <code>parameterSets</code>, Olivier Roustant for <code>PoincareOptimal</code>, <code>PoincareChaosSqCoef</code>, <code>squaredIntEstim</code> and <code>support</code>, Eunhye Song, Barry L. Nelson and Jeremy Staum for <code>shapleyPermEx</code> and <code>shapleyPermRand</code>, Baptiste Broto for <code>shapleySubsetMc</code>, <code>shapleyLinearGaussian</code> and <code>shapleyBlockEstimation</code>, Filippo Monari for (<code>sobolSmthSpl</code>) and (<code>morrisMultOut</code>), Marouane Il Idrissi for <code>lmg</code>, <code>pmvd</code> and <code>shapleysobol_knn</code>, associated to Margot Herin for <code>pme_knn</code>, Laura Clouvel for <code>johnson</code>, Paul Rochet for <code>EPtest</code>, Frank Weber and Roelof Oomen for other contributions.
</p>
<p>(maintainer: Bertrand Iooss <a href="mailto:biooss@yahoo.fr">biooss@yahoo.fr</a>)</p>


<h3>References</h3>

<p>S. Da Veiga, F. Gamboa, B. Iooss and C. Prieur, <em>Basics and trends in sensitivity analysis, Theory and practice in R</em>, SIAM, 2021.
</p>
<p>R. Faivre, B. Iooss, S. Mahevas, D. Makowski, H. Monod, editors, 2013, <em>Analyse de sensibilite et exploration de modeles. Applications aux modeles environnementaux</em>, Editions Quae.
</p>
<p>L. Clouvel, B. Iooss, V. Chabridon, M. Il Idrissi and F. Robin, 2023, <em>An overview of variance-based importance measures in the linear regression context: comparative analyses and numerical tests</em>, Preprint. <a href="https://hal.science/hal-04102053">https://hal.science/hal-04102053</a>
</p>
<p>B. Iooss, V. Chabridon and V. Thouvenot, <em>Variance-based importance measures for machine learning model interpretability</em>, Congres lambda-mu23, Saclay, France, 10-13 octobre 2022. <a href="https://hal.science/hal-03741384">https://hal.science/hal-03741384</a>
</p>
<p>B. Iooss, R. Kennet and P. Secchi, 2022, <em>Different views of interpretability</em>, In: <em>Interpretability for Industry 4.0: Statistical and Machine Learning Approaches</em>, A. Lepore, B. Palumbo and J-M. Poggi (Eds), Springer.
</p>
<p>B. Iooss and A. Saltelli, 2017, <em>Introduction: Sensitivity analysis.</em> In: <em>Springer Handbook on Uncertainty Quantification</em>, R. Ghanem, D. Higdon and H. Owhadi (Eds), Springer.
</p>
<p>A. Saltelli, K. Chan and E. M. Scott eds, 2000, <em>Sensitivity Analysis</em>, Wiley.
</p>


</div>