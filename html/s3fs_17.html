<div class="container">

<table style="width: 100%;"><tr>
<td>S3FileSystem</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Access AWS S3 as if it were a file system.</h2>

<h3>Description</h3>

<p>This creates a file system "like" API based off <code>fs</code>
(e.g. dir_ls, file_copy, etc.) for AWS S3 storage.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>s3_cache</code></dt>
<dd>
<p>Cache AWS S3</p>
</dd>
<dt><code>s3_cache_bucket</code></dt>
<dd>
<p>Cached s3 bucket</p>
</dd>
<dt><code>s3_client</code></dt>
<dd>
<p>paws s3 client</p>
</dd>
<dt><code>region_name</code></dt>
<dd>
<p>AWS region when creating new connections</p>
</dd>
<dt><code>profile_name</code></dt>
<dd>
<p>The name of a profile to use</p>
</dd>
<dt><code>multipart_threshold</code></dt>
<dd>
<p>Threshold to use multipart</p>
</dd>
<dt><code>request_payer</code></dt>
<dd>
<p>Threshold to use multipart</p>
</dd>
<dt><code>pid</code></dt>
<dd>
<p>Get the process ID of the R Session</p>
</dd>
</dl>
</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>retries</code></dt>
<dd>
<p>number of retries</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-S3FileSystem-new"><code>S3FileSystem$new()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_chmod"><code>S3FileSystem$file_chmod()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_copy"><code>S3FileSystem$file_copy()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_create"><code>S3FileSystem$file_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_delete"><code>S3FileSystem$file_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_download"><code>S3FileSystem$file_download()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_exists"><code>S3FileSystem$file_exists()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_info"><code>S3FileSystem$file_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_move"><code>S3FileSystem$file_move()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_size"><code>S3FileSystem$file_size()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_stream_in"><code>S3FileSystem$file_stream_in()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_stream_out"><code>S3FileSystem$file_stream_out()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_temp"><code>S3FileSystem$file_temp()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_delete"><code>S3FileSystem$file_tag_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_info"><code>S3FileSystem$file_tag_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_update"><code>S3FileSystem$file_tag_update()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_touch"><code>S3FileSystem$file_touch()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_upload"><code>S3FileSystem$file_upload()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_url"><code>S3FileSystem$file_url()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_version_info"><code>S3FileSystem$file_version_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_file"><code>S3FileSystem$is_file()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_dir"><code>S3FileSystem$is_dir()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_bucket"><code>S3FileSystem$is_bucket()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_file_empty"><code>S3FileSystem$is_file_empty()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_chmod"><code>S3FileSystem$bucket_chmod()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_create"><code>S3FileSystem$bucket_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_delete"><code>S3FileSystem$bucket_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_copy"><code>S3FileSystem$dir_copy()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_create"><code>S3FileSystem$dir_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_delete"><code>S3FileSystem$dir_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_exists"><code>S3FileSystem$dir_exists()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_download"><code>S3FileSystem$dir_download()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_info"><code>S3FileSystem$dir_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_ls"><code>S3FileSystem$dir_ls()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_ls_url"><code>S3FileSystem$dir_ls_url()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_tree"><code>S3FileSystem$dir_tree()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_upload"><code>S3FileSystem$dir_upload()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path"><code>S3FileSystem$path()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_dir"><code>S3FileSystem$path_dir()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext"><code>S3FileSystem$path_ext()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext_remove"><code>S3FileSystem$path_ext_remove()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext_set"><code>S3FileSystem$path_ext_set()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_file"><code>S3FileSystem$path_file()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_join"><code>S3FileSystem$path_join()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_split"><code>S3FileSystem$path_split()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-clear_cache"><code>S3FileSystem$clear_cache()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-clone"><code>S3FileSystem$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-S3FileSystem-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Initialize S3FileSystem class
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$new(
  aws_access_key_id = NULL,
  aws_secret_access_key = NULL,
  aws_session_token = NULL,
  region_name = NULL,
  profile_name = NULL,
  endpoint = NULL,
  disable_ssl = FALSE,
  multipart_threshold = fs_bytes("2GB"),
  request_payer = FALSE,
  anonymous = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>aws_access_key_id</code></dt>
<dd>
<p>(character): AWS access key ID</p>
</dd>
<dt><code>aws_secret_access_key</code></dt>
<dd>
<p>(character): AWS secret access key</p>
</dd>
<dt><code>aws_session_token</code></dt>
<dd>
<p>(character): AWS temporary session token</p>
</dd>
<dt><code>region_name</code></dt>
<dd>
<p>(character): Default region when creating new connections</p>
</dd>
<dt><code>profile_name</code></dt>
<dd>
<p>(character): The name of a profile to use. If not given,
then the default profile is used.</p>
</dd>
<dt><code>endpoint</code></dt>
<dd>
<p>(character): The complete URL to use for the constructed client.</p>
</dd>
<dt><code>disable_ssl</code></dt>
<dd>
<p>(logical): Whether or not to use SSL. By default, SSL is used.</p>
</dd>
<dt><code>multipart_threshold</code></dt>
<dd>
<p>(fs_bytes): Threshold to use multipart instead of standard
copy and upload methods.</p>
</dd>
<dt><code>request_payer</code></dt>
<dd>
<p>(logical): Confirms that the requester knows that they
will be charged for the request.</p>
</dd>
<dt><code>anonymous</code></dt>
<dd>
<p>(logical): Set up anonymous credentials when connecting to AWS S3.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>Other parameters within <code>paws</code> client.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-S3FileSystem-file_chmod"></a>



<h4>Method <code>file_chmod()</code>
</h4>

<p>Change file permissions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read",
    "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control")
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>mode</code></dt>
<dd>
<p>(character): A character of the mode</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_copy"></a>



<h4>Method <code>file_copy()</code>
</h4>

<p>copy files
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_create"></a>



<h4>Method <code>file_create()</code>
</h4>

<p>Create file on AWS S3, if file already
exists it will be left unchanged.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_create(path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_delete"></a>



<h4>Method <code>file_delete()</code>
</h4>

<p>Delete files in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_delete(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uris.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_delete_objects</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_download"></a>



<h4>Method <code>file_download()</code>
</h4>

<p>Downloads AWS S3 files to local
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_download(path, new_path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): A character vector of paths to the new locations.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_get_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_exists"></a>



<h4>Method <code>file_exists()</code>
</h4>

<p>Check if file exists in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_exists(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character) s3 path to check</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>logical vector if file exists
</p>


<hr>
<a id="method-S3FileSystem-file_info"></a>



<h4>Method <code>file_info()</code>
</h4>

<p>Returns file information within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_info(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>A data.table with metadata for each file. Columns returned are as follows.
</p>

<ul>
<li>
<p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li>
<p>key (character): AWS S3 path key of file
</p>
</li>
<li>
<p>uri (character): S3 uri of file
</p>
</li>
<li>
<p>size (numeric): file size in bytes
</p>
</li>
<li>
<p>type (character): file type (file or directory)
</p>
</li>
<li>
<p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li>
<p>last_modified (POSIXct): Created date of file.
</p>
</li>
<li>
<p>delete_marker (logical): Specifies retrieved a logical marker
</p>
</li>
<li>
<p>accept_ranges (character): Indicates that a range of bytes was specified.
</p>
</li>
<li>
<p>expiration (character): File expiration
</p>
</li>
<li>
<p>restore (character): If file is archived
</p>
</li>
<li>
<p>archive_status (character): Archive status
</p>
</li>
<li>
<p>missing_meta (integer): Number of metadata entries not returned in "x-amz-meta" headers
</p>
</li>
<li>
<p>version_id (character): version id of file
</p>
</li>
<li>
<p>cache_control (character): caching behaviour for the request/reply chain
</p>
</li>
<li>
<p>content_disposition (character): presentational information of file
</p>
</li>
<li>
<p>content_encoding (character): file content encodings
</p>
</li>
<li>
<p>content_language (character): what language the content is in
</p>
</li>
<li>
<p>content_type (character): file MIME type
</p>
</li>
<li>
<p>expires (POSIXct): date and time the file is no longer cacheable
</p>
</li>
<li>
<p>website_redirect_location (character): redirects request for file to another
</p>
</li>
<li>
<p>server_side_encryption (character): File server side encryption
</p>
</li>
<li>
<p>metadata (list): metadata of file
</p>
</li>
<li>
<p>sse_customer_algorithm (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li>
<p>sse_customer_key_md5 (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li>
<p>ssekms_key_id (character): ID of the Amazon Web Services Key Management Service
</p>
</li>
<li>
<p>bucket_key_enabled (logical): s3 bucket key for server-side encryption with
</p>
</li>
<li>
<p>storage_class (character): file storage class information
</p>
</li>
<li>
<p>request_charged (character): indicates successfully charged for request
</p>
</li>
<li>
<p>replication_status (character): return specific header if request
involves a bucket that is either a source or a destination in a replication rule
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object</a>
</p>
</li>
<li>
<p>parts_count (integer): number of count parts the file has
</p>
</li>
<li>
<p>object_lock_mode (character): the file lock mode
</p>
</li>
<li>
<p>object_lock_retain_until_date (POSIXct): date and time of when object_lock_mode expires
</p>
</li>
<li>
<p>object_lock_legal_hold_status (character): file legal holding
</p>
</li>
</ul>
<hr>
<a id="method-S3FileSystem-file_move"></a>



<h4>Method <code>file_move()</code>
</h4>

<p>Move files to another location on AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_move(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of s3 uri</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): A character vector of s3 uri.</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_copy_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_size"></a>



<h4>Method <code>file_size()</code>
</h4>

<p>Return file size in bytes
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_size(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of s3 uri</p>
</dd>
</dl>
</div>


<hr>
<a id="method-S3FileSystem-file_stream_in"></a>



<h4>Method <code>file_stream_in()</code>
</h4>

<p>Streams in AWS S3 file as a raw vector
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_stream_in(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_get_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>list of raw vectors containing the contents of the file
</p>


<hr>
<a id="method-S3FileSystem-file_stream_out"></a>



<h4>Method <code>file_stream_out()</code>
</h4>

<p>Streams out raw vector to AWS S3 file
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_stream_out(
  obj,
  path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>obj</code></dt>
<dd>
<p>(raw|character): A raw vector, rawConnection, url to be streamed up to AWS S3.</p>
</dd>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_temp"></a>



<h4>Method <code>file_temp()</code>
</h4>

<p>return the name which can be used as a temporary file
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_temp(pattern = "file", tmp_dir = "", ext = "")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>pattern</code></dt>
<dd>
<p>(character): A character vector with the non-random portion of the name.</p>
</dd>
<dt><code>tmp_dir</code></dt>
<dd>
<p>(character): The directory the file will be created in.</p>
</dd>
<dt><code>ext</code></dt>
<dd>
<p>(character): A character vector of one or more paths.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_tag_delete"></a>



<h4>Method <code>file_tag_delete()</code>
</h4>

<p>Delete file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_tag_info"></a>



<h4>Method <code>file_tag_info()</code>
</h4>

<p>Get file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_info(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>data.table of file version metadata
</p>

<ul>
<li>
<p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li>
<p>key (character): AWS S3 path key of file
</p>
</li>
<li>
<p>uri (character): S3 uri of file
</p>
</li>
<li>
<p>size (numeric): file size in bytes
</p>
</li>
<li>
<p>version_id (character): version id of file
</p>
</li>
<li>
<p>tag_key (character): name of tag
</p>
</li>
<li>
<p>tag_value (character): tag value
</p>
</li>
</ul>
<hr>
<a id="method-S3FileSystem-file_tag_update"></a>



<h4>Method <code>file_tag_update()</code>
</h4>

<p>Update file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_update(path, tags, overwrite = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>tags</code></dt>
<dd>
<p>(list): Tags to be applied</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): To overwrite tagging or to modify inplace. Default will
modify inplace.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_touch"></a>



<h4>Method <code>file_touch()</code>
</h4>

<p>Similar to <code>fs::file_touch</code> this does not create the file if
it does not exist. Use <code>s3fs$file_create()</code> to do this if needed.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_touch(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_copy_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_upload"></a>



<h4>Method <code>file_upload()</code>
</h4>

<p>Uploads files to AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_upload(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of local file paths to upload to AWS S3</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code>
and <code>s3_create_multipart_upload</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_url"></a>



<h4>Method <code>file_url()</code>
</h4>

<p>Generate presigned url for S3 object
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_url(path, expiration = 3600L, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>expiration</code></dt>
<dd>
<p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters passed to <code>s3_get_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>return character of urls
</p>


<hr>
<a id="method-S3FileSystem-file_version_info"></a>



<h4>Method <code>file_version_info()</code>
</h4>

<p>Get file versions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_version_info(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_list_object_versions</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>return data.table with file version info, columns below:
</p>

<ul>
<li>
<p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li>
<p>key (character): AWS S3 path key of file
</p>
</li>
<li>
<p>uri (character): S3 uri of file
</p>
</li>
<li>
<p>size (numeric): file size in bytes
</p>
</li>
<li>
<p>version_id (character): version id of file
</p>
</li>
<li>
<p>owner (character): file owner
</p>
</li>
<li>
<p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li>
<p>last_modified (POSIXct): Created date of file.
</p>
</li>
</ul>
<hr>
<a id="method-S3FileSystem-is_file"></a>



<h4>Method <code>is_file()</code>
</h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_file(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>logical vector if object is a file
</p>


<hr>
<a id="method-S3FileSystem-is_dir"></a>



<h4>Method <code>is_dir()</code>
</h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_dir(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>logical vector if object is a directory
</p>


<hr>
<a id="method-S3FileSystem-is_bucket"></a>



<h4>Method <code>is_bucket()</code>
</h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_bucket(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_list_objects_v2</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>logical vector if object is a <code style="white-space: pre;">⁠AWS S3⁠</code> bucket
</p>


<hr>
<a id="method-S3FileSystem-is_file_empty"></a>



<h4>Method <code>is_file_empty()</code>
</h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_file_empty(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>logical vector if file is empty
</p>


<hr>
<a id="method-S3FileSystem-bucket_chmod"></a>



<h4>Method <code>bucket_chmod()</code>
</h4>

<p>Change bucket permissions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read")
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>mode</code></dt>
<dd>
<p>(character): A character of the mode</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-bucket_create"></a>



<h4>Method <code>bucket_create()</code>
</h4>

<p>Create bucket
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_create(
  path,
  region_name = NULL,
  mode = c("private", "public-read", "public-read-write", "authenticated-read"),
  versioning = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>region_name</code></dt>
<dd>
<p>(character): aws region</p>
</dd>
<dt><code>mode</code></dt>
<dd>
<p>(character): A character of the mode</p>
</dd>
<dt><code>versioning</code></dt>
<dd>
<p>(logical): Whether to set the bucket to versioning or not.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_create_bucket</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-bucket_delete"></a>



<h4>Method <code>bucket_delete()</code>
</h4>

<p>Delete bucket
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of path or s3 uri.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-S3FileSystem-dir_copy"></a>



<h4>Method <code>dir_copy()</code>
</h4>

<p>Copies the directory recursively to the new location.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code>
and <code>s3_create_multipart_upload</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_create"></a>



<h4>Method <code>dir_create()</code>
</h4>

<p>Create empty directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_create(path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A vector of directory or uri to be created in AWS S3</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_delete"></a>



<h4>Method <code>dir_delete()</code>
</h4>

<p>Delete contents and directory in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A vector of paths or uris to directories to be deleted.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_exists"></a>



<h4>Method <code>dir_exists()</code>
</h4>

<p>Check if path exists in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_exists(path = ".")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character) aws s3 path to be checked</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_download"></a>



<h4>Method <code>dir_download()</code>
</h4>

<p>Downloads AWS S3 files to local
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_download(path, new_path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): A character vector of paths to the new locations.
Please ensure directories end with a <code>/</code>.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_get_object</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_info"></a>



<h4>Method <code>dir_info()</code>
</h4>

<p>Returns file information within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_info(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character):A character vector of one or more paths. Can be path
or s3 uri.</p>
</dd>
<dt><code>type</code></dt>
<dd>
<p>(character): File type(s) to return. Default ("any") returns all
AWS S3 object types.</p>
</dd>
<dt><code>glob</code></dt>
<dd>
<p>(character): A wildcard pattern (e.g. <code>*.csv</code>), passed onto
<code>grep()</code> to filter paths.</p>
</dd>
<dt><code>regexp</code></dt>
<dd>
<p>(character): A regular expression (e.g. <code>[.]csv$</code>),
passed onto <code>grep()</code> to filter paths.</p>
</dd>
<dt><code>invert</code></dt>
<dd>
<p>(logical): If <code>code</code> return files which do not match.</p>
</dd>
<dt><code>recurse</code></dt>
<dd>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>refresh</code></dt>
<dd>
<p>(logical): Refresh cached in <code>s3_cache</code>.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_list_objects_v2</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>data.table with directory metadata
</p>

<ul>
<li>
<p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li>
<p>key (character): AWS S3 path key of file
</p>
</li>
<li>
<p>uri (character): S3 uri of file
</p>
</li>
<li>
<p>size (numeric): file size in bytes
</p>
</li>
<li>
<p>version_id (character): version id of file
</p>
</li>
<li>
<p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li>
<p>last_modified (POSIXct): Created date of file
</p>
</li>
</ul>
<hr>
<a id="method-S3FileSystem-dir_ls"></a>



<h4>Method <code>dir_ls()</code>
</h4>

<p>Returns file name within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_ls(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character):A character vector of one or more paths. Can be path
or s3 uri.</p>
</dd>
<dt><code>type</code></dt>
<dd>
<p>(character): File type(s) to return. Default ("any") returns all
AWS S3 object types.</p>
</dd>
<dt><code>glob</code></dt>
<dd>
<p>(character): A wildcard pattern (e.g. <code>*.csv</code>), passed onto
<code>grep()</code> to filter paths.</p>
</dd>
<dt><code>regexp</code></dt>
<dd>
<p>(character): A regular expression (e.g. <code>[.]csv$</code>),
passed onto <code>grep()</code> to filter paths.</p>
</dd>
<dt><code>invert</code></dt>
<dd>
<p>(logical): If <code>code</code> return files which do not match.</p>
</dd>
<dt><code>recurse</code></dt>
<dd>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>refresh</code></dt>
<dd>
<p>(logical): Refresh cached in <code>s3_cache</code>.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_list_objects_v2</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_ls_url"></a>



<h4>Method <code>dir_ls_url()</code>
</h4>

<p>Generate presigned url to list S3 directories
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_ls_url(path, expiration = 3600L, recurse = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>expiration</code></dt>
<dd>
<p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</dd>
<dt><code>recurse</code></dt>
<dd>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters passed to <code>s3_list_objects_v2</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>return character of urls
</p>


<hr>
<a id="method-S3FileSystem-dir_tree"></a>



<h4>Method <code>dir_tree()</code>
</h4>

<p>Print contents of directories in a tree-like format
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_tree(path, recurse = TRUE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): path A path to print the tree from</p>
</dd>
<dt><code>recurse</code></dt>
<dd>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>Additional arguments passed to s3_dir_ls.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_upload"></a>



<h4>Method <code>dir_upload()</code>
</h4>

<p>Uploads local directory to AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_upload(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of local file paths to upload to AWS S3</p>
</dd>
<dt><code>new_path</code></dt>
<dd>
<p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</dd>
<dt><code>max_batch</code></dt>
<dd>
<p>(fs_bytes): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt>
<dd>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>parameters to be passed to <code>s3_put_object</code>
and <code>s3_create_multipart_upload</code></p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path"></a>



<h4>Method <code>path()</code>
</h4>

<p>Constructs a s3 uri path
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path(..., ext = "")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(character): Character vectors</p>
</dd>
<dt><code>ext</code></dt>
<dd>
<p>(character): An optional extension to append to the generated path</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_dir"></a>



<h4>Method <code>path_dir()</code>
</h4>

<p>Returns the directory portion of s3 uri
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_dir(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_ext"></a>



<h4>Method <code>path_ext()</code>
</h4>

<p>Returns the last extension for a path.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character s3 uri file extension
</p>


<hr>
<a id="method-S3FileSystem-path_ext_remove"></a>



<h4>Method <code>path_ext_remove()</code>
</h4>

<p>Removes the last extension and return the rest of the s3 uri.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext_remove(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_ext_set"></a>



<h4>Method <code>path_ext_set()</code>
</h4>

<p>Replace the extension with a new extension.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext_set(path, ext)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths</p>
</dd>
<dt><code>ext</code></dt>
<dd>
<p>(character): New file extension</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_file"></a>



<h4>Method <code>path_file()</code>
</h4>

<p>Returns the file name portion of the s3 uri path
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_file(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of paths</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of file names
</p>


<hr>
<a id="method-S3FileSystem-path_join"></a>



<h4>Method <code>path_join()</code>
</h4>

<p>Construct an s3 uri path from path vector
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_join(parts)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>parts</code></dt>
<dd>
<p>(character): A character vector of one or more paths</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_split"></a>



<h4>Method <code>path_split()</code>
</h4>

<p>Split s3 uri path to core components bucket, key and version id
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_split(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): A character vector of one or more paths or s3 uri</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>list character vectors splitting the s3 uri path in "Bucket", "Key" and "VersionId"
</p>


<hr>
<a id="method-S3FileSystem-clear_cache"></a>



<h4>Method <code>clear_cache()</code>
</h4>

<p>Clear S3 Cache
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$clear_cache(path = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt>
<dd>
<p>(character): s3 path to be cl</p>
</dd>
</dl>
</div>


<hr>
<a id="method-S3FileSystem-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Note</h3>

<p>This method will only update the modification time of the AWS S3 object.
</p>


</div>