<div class="container">

<table style="width: 100%;"><tr>
<td>ft_regex_tokenizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Transformation â€“ RegexTokenizer (Transformer)</h2>

<h3>Description</h3>

<p>A regex based tokenizer that extracts tokens either by using the provided
regex pattern to split the text (default) or repeatedly matching the regex
(if <code>gaps</code> is false). Optional parameters also allow filtering tokens using a
minimal length. It returns an array of strings that can be empty.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ft_regex_tokenizer(
  x,
  input_col = NULL,
  output_col = NULL,
  gaps = TRUE,
  min_token_length = 1,
  pattern = "\\s+",
  to_lower_case = TRUE,
  uid = random_string("regex_tokenizer_"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_col</code></td>
<td>
<p>The name of the input column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_col</code></td>
<td>
<p>The name of the output column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gaps</code></td>
<td>
<p>Indicates whether regex splits on gaps (TRUE) or matches tokens (FALSE).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_token_length</code></td>
<td>
<p>Minimum token length, greater than or equal to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pattern</code></td>
<td>
<p>The regular expression pattern to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>to_lower_case</code></td>
<td>
<p>Indicates whether to convert all characters to lowercase before tokenizing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the feature transformer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>. If it is a
<code>spark_connection</code>, the function returns a <code>ml_estimator</code> or a
<code>ml_estimator</code> object. If it is a <code>ml_pipeline</code>, it will return
a pipeline with the transformer or estimator appended to it. If a
<code>tbl_spark</code>, it will return a <code>tbl_spark</code> with the transformation
applied to it.
</p>


<h3>See Also</h3>

<p>Other feature transformers: 
<code>ft_binarizer()</code>,
<code>ft_bucketizer()</code>,
<code>ft_chisq_selector()</code>,
<code>ft_count_vectorizer()</code>,
<code>ft_dct()</code>,
<code>ft_elementwise_product()</code>,
<code>ft_feature_hasher()</code>,
<code>ft_hashing_tf()</code>,
<code>ft_idf()</code>,
<code>ft_imputer()</code>,
<code>ft_index_to_string()</code>,
<code>ft_interaction()</code>,
<code>ft_lsh</code>,
<code>ft_max_abs_scaler()</code>,
<code>ft_min_max_scaler()</code>,
<code>ft_ngram()</code>,
<code>ft_normalizer()</code>,
<code>ft_one_hot_encoder()</code>,
<code>ft_one_hot_encoder_estimator()</code>,
<code>ft_pca()</code>,
<code>ft_polynomial_expansion()</code>,
<code>ft_quantile_discretizer()</code>,
<code>ft_r_formula()</code>,
<code>ft_robust_scaler()</code>,
<code>ft_sql_transformer()</code>,
<code>ft_standard_scaler()</code>,
<code>ft_stop_words_remover()</code>,
<code>ft_string_indexer()</code>,
<code>ft_tokenizer()</code>,
<code>ft_vector_assembler()</code>,
<code>ft_vector_indexer()</code>,
<code>ft_vector_slicer()</code>,
<code>ft_word2vec()</code>
</p>


</div>