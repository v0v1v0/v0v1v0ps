<div class="container">

<table style="width: 100%;"><tr>
<td>smoof-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>smoof: Single and Multi-Objective Optimization test functions.</h2>

<h3>Description</h3>

<p>The <span class="pkg">smoof</span> R package provides generators for huge set of single- and
multi-objective test functions, which are frequently used in the literature
to benchmark optimization algorithms. Moreover the package provides methods
to create arbitrary objective functions in an object-orientated manner, extract
their parameters sets and visualize them graphically.
</p>


<h3>Some more details</h3>

<p>Given a set of criteria <code class="reqn">\mathcal{F} = \{f_1, \ldots, f_m\}</code> with each
<code class="reqn">f_i : S \subseteq \mathbf{R}^d \to \mathbf{R} , i = 1, \ldots, m</code> being an
objective-function, the goal in <em>Global Optimization (GO)</em> is to find the best
solution <code class="reqn">\mathbf{x}^* \in S</code>. The set <code class="reqn">S</code> is termed the <em>set of
feasible soluations</em>. In the case of only a single objective function <code class="reqn">f</code>,
- which we want to restrict ourself in this brief description - the goal is to
minimize the objective, i. e., </p>
<p style="text-align: center;"><code class="reqn">\min_{\mathbf{x}} f(\mathbf{x}).</code>
</p>

<p>Sometimes we may be interested in maximizing the objective function value, but
since <code class="reqn">min(f(\mathbf{x})) = -\min(-f(\mathbf{x}))</code>, we do not have to tackle
this separately.
To compare the robustness of optimization algorithms and to investigate their behaviour
in different contexts, a common approach in the literature is to use <em>artificial
benchmarking functions</em>, which are mostly deterministic, easy to evaluate and given
by a closed mathematical formula.
A recent survey by Jamil and Yang lists 175 single-objective benchmarking functions
in total for global optimization [1]. The <span class="pkg">smoof</span> package offers implementations
of a subset of these functions beside some other functions as well as
generators for large benchmarking sets like the noiseless BBOB2009 function set [2]
or functions based on the multiple peaks model 2 [3].
</p>


<h3>References</h3>

<p>[1] Momin Jamil and Xin-She Yang, A literature survey of benchmark
functions for global optimization problems, Int. Journal of Mathematical
Modelling and Numerical Optimisation, Vol. 4, No. 2, pp. 150-194 (2013).
[2] Hansen, N., Finck, S., Ros, R. and Auger, A. Real-Parameter Black-Box
Optimization Benchmarking 2009: Noiseless Functions Definitions. Technical report
RR-6829. INRIA, 2009.
[3] Simon Wessing, The Multiple Peaks Model 2, Algorithm Engineering Report
TR15-2-001, TU Dortmund University, 2015.
</p>


</div>