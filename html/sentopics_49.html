<div class="container">

<table style="width: 100%;"><tr>
<td>topWords</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Extract the most representative words from topics</h2>

<h3>Description</h3>

<p>Extract the top words in each topic/sentiment from a
<code>sentopicmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">topWords(
  x,
  nWords = 10,
  method = c("frequency", "probability", "term-score", "FREX"),
  output = c("data.frame", "plot", "matrix"),
  subset,
  w = 0.5
)

plot_topWords(
  x,
  nWords = 10,
  method = c("frequency", "probability", "term-score", "FREX"),
  subset,
  w = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a <code>sentopicmodel</code> created from the <code>LDA()</code>, <code>JST()</code> or <code>rJST()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nWords</code></td>
<td>
<p>the number of top words to extract</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>specify if a re-ranking function should be applied before
returning the top words. See Details for a description of each method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p>determines the output of the function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>allows to subset using a logical expression, as in <code>subset()</code>.
Particularly useful to limit the number of observation on plot outputs. The
logical expression uses topic and sentiment <em>indices</em> rather than their
label. It is possible to subset on both topic and sentiment but adding a
<code>&amp;</code> operator between two expressions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>only used when <code>method = "FREX"</code>. Determines the weight assigned to
the exclusivity score at the expense of the frequency score.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>"frequency"</code> ranks top words according to their frequency
within a topic. This method also reports the overall frequency of
each word. When returning a plot, the overall frequency is
represented with a grey bar.
</p>
<p><code>"probability"</code> uses the estimated topic-word mixture <code class="reqn">\phi</code> to
rank top words.
</p>
<p><code>"term-score"</code> implements the re-ranking method from Blei and
Lafferty (2009). This method down-weights terms that have high
probability in all topics using the following score:
</p>
<p style="text-align: center;"><code class="reqn">\text{term-score}_{k,v} = \phi_{k, v}\log\left(\frac{\phi_{k,
  v}}{\left(\prod^K_{j=1}\phi_{j,v}\right)^{\frac{1}{K}}}\right),</code>
</p>
<p> for
topic <code class="reqn">k</code>, vocabulary word <code class="reqn">v</code> and number of topics <code class="reqn">K</code>.
</p>
<p><code>"FREX"</code> implements the re-ranking method from Bischof and Airoldi
(2012). This method used the weight <code class="reqn">w</code> to balance between
topic-word probability and topic exclusivity using the following
score:
</p>
<p style="text-align: center;"><code class="reqn">\text{FREX}_{k,v}=\left(\frac{w}{\text{ECDF}\left(
  \frac{\phi_{k,v}}{\sum_{j=1}^K\phi_{k,v}}\right)}
  + \frac{1-w}{\text{ECDF}\left(\phi_{k,v}\right)} \right),</code>
</p>
<p> for
topic <code class="reqn">k</code>, vocabulary word <code class="reqn">v</code>, number of topics <code class="reqn">K</code> and
weight <code class="reqn">w</code>, where <code class="reqn">\text{ECDF}</code> is the empirical cumulative
distribution function.
</p>


<h3>Value</h3>

<p>The top words of the topic model. Depending on the output chosen, can
result in either a long-style data.frame, a <code>ggplot2</code> object or a matrix.
</p>


<h3>Author(s)</h3>

<p>Olivier Delmarcelle
</p>


<h3>References</h3>

<p>Blei, DM. and Lafferty, JD. (2009). <a href="https://www.taylorfrancis.com/chapters/edit/10.1201/9781420059458-12/topic-models-david-blei-john-la%EF%AC%80erty">Topic models.</a>. In <em>Text Mining</em>,
chapter 4, 101–124.
</p>
<p>Bischof JM. and Airoldi, EM. (2012). <a href="https://dl.acm.org/doi/10.5555/3042573.3042578">Summarizing Topical Content with Word Frequency and Exclusivity.</a>. In
<em>Proceedings of the 29th International Conference on International
Conference on Machine Learning</em>, ICML'12, 9–16.
</p>


<h3>See Also</h3>

<p><code>melt.sentopicmodel()</code> for extracting estimated mixtures
</p>


<h3>Examples</h3>

<pre><code class="language-R">model &lt;- LDA(ECB_press_conferences_tokens)
model &lt;- fit(model, 10)
topWords(model)
topWords(model, output = "matrix")
topWords(model, method = "FREX")
plot_topWords(model)
plot_topWords(model, subset = topic %in% 1:2)

jst &lt;- JST(ECB_press_conferences_tokens)
jst &lt;- fit(jst, 10)
plot_topWords(jst)
plot_topWords(jst, subset = topic %in% 1:2 &amp; sentiment == 3)
</code></pre>


</div>