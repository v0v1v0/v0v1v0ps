<div class="container">

<table style="width: 100%;"><tr>
<td>mspeNERjack</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Compute MSPE through Jackknife-based MSPE estimation method for Nested error regression model
</h2>

<h3>Description</h3>

<p>This function returns MSPE estimator with Jackknife-based MSPE estimation method for Nested error regression model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mspeNERjack(ni, X, Y, Xmean, method = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ni</code></td>
<td>

<p>(vector). It represents the sample number for every small area.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>(matrix). Stands for the available auxiliary values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>(vector). It represents the response value for Nested error regression model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xmean</code></td>
<td>

<p>(matrix). Stands for the population mean of auxiliary values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>The MSPE estimation method to be used. See "Details".
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This bias-corrected jackknife MSPE estimator was proposed by J. Jiang and L. S. M. Wan, it covers a fairly general class of mixed models which includes gLMM, mixed logistic model and some of the widely used mixed linear models as special cases.
</p>
<p>Default value for <code>method</code> is 1, <code>method = 1</code> represents the MOM method , <code>method = 2</code> and <code>method = 3</code> represents ML and REML method, respectively.
</p>


<h3>Value</h3>

<p>This function returns a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>MSPE</code></td>
<td>
<p>(vector) MSPE estimates for NER model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bhat</code></td>
<td>
<p>(vector) Estimates of the unknown regression coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigvhat2</code></td>
<td>
<p>(numeric) Estimates of the area-specific variance component.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigehat2</code></td>
<td>
<p>(numeric) Estimates of the random error variance component.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Peiwen Xiao, Xiaohui Liu, Yuzi Liu, Jiming Jiang, and Shaochu Liu
</p>


<h3>References</h3>

<p>M. H. Quenouille. Approximate tests of correlation in time series. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 11(1):68-84, 1949.
</p>
<p>J. W. Tukey. Bias and confidence in not quite large samples. <em>Annals of Mathematical Statistics</em>, 29(2):614, 1958.
</p>
<p>J. Jiang and L. S. M. Wan. A unified jackknife theory for empirical best prediction with m estimation. <em>Annals of Statistics</em>, 30(6):1782-1810, 2002.
</p>


<h3>Examples</h3>

<pre><code class="language-R">### parameter setting 
Ni = 1000; sigmaX = 1.5; m = 5
beta = c(0.5, 1)
sigma_v2 = 0.8; sigma_e2 = 1
ni = sample(seq(1,10), m,replace = TRUE); n = sum(ni)
p = length(beta)
### population function
pop.model = function(Ni, sigmaX, beta, sigma_v2, sigma_e2, m){
  x = rnorm(m * Ni, 1, sqrt(sigmaX)); v = rnorm(m, 0, sqrt(sigma_v2)); y = numeric(m * Ni)
  theta = numeric(m); kk = 1
  for(i in 1 : m){
    sumx = 0
    for(j in 1:Ni){
      sumx = sumx + x[kk]
      y[kk] = beta[1] + beta[2] * x[kk] + v[i] + rnorm(1, 0, sqrt(sigma_e2))
      kk = kk + 1
    }
    meanx = sumx/Ni
    theta[i] = beta[1] + beta[2] * meanx + v[i]
  }
  group = rep(seq(m), each = Ni)
  x = cbind(rep(1, m*Ni), x)
  data = cbind(x, y, group)
  return(list(data = data, theta = theta))
} 
### sample function
sampleXY = function(Ni, ni, m, Population){
  Indx = c()
  for(i in 1:m){
    Indx = c(Indx, sample(c(((i - 1) * Ni + 1) : (i * Ni)), ni[i]))
  }
  Sample = Population[Indx, ]; Nonsample = Population[-Indx, ]
  return(list(Sample, Nonsample))
} 
### data generation process
Population = pop.model(Ni, sigmaX, beta, sigma_v2, sigma_e2, m)$data
XY = sampleXY(Ni, ni, m, Population)[[1]]
X = XY[, 1:p]
Y = XY[, p+1]
Xmean = matrix(NA, m, p)
for(tt in 1: m){
  Xmean[tt, ] = colMeans(Population[which(Population[,p+2] == tt), 1:p])
}
### mspe result
mspeNERjack(ni, X, Y, Xmean, method = 1)
</code></pre>


</div>