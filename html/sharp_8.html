<div class="container">

<table style="width: 100%;"><tr>
<td>BiSelection</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Stability selection of predictors and/or outcomes</h2>

<h3>Description</h3>

<p>Performs stability selection for dimensionality reduction. The underlying
variable selection algorithm (e.g. sparse PLS) is run with different
combinations of parameters controlling the sparsity (e.g. number of selected
variables per component) and thresholds in selection proportions. These
hyper-parameters are jointly calibrated by maximisation of the stability
score.
</p>


<h3>Usage</h3>

<pre><code class="language-R">BiSelection(
  xdata,
  ydata = NULL,
  group_x = NULL,
  group_y = NULL,
  LambdaX = NULL,
  LambdaY = NULL,
  AlphaX = NULL,
  AlphaY = NULL,
  ncomp = 1,
  scale = TRUE,
  pi_list = seq(0.01, 0.99, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  family = "gaussian",
  implementation = SparsePLS,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  beep = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used for
models with group penalisation (e.g. <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group_y</code></td>
<td>
<p>optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.
Only used if <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LambdaX</code></td>
<td>
<p>matrix of parameters controlling the number of selected
variables (for sparse PCA/PLS) or groups (for group and sparse group PLS)
in X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LambdaY</code></td>
<td>
<p>matrix of parameters controlling the number of selected
variables (for sparse PLS) or groups (for group or sparse group PLS) in Y.
Only used if <code>family="gaussian"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AlphaX</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity within
groups in X. Only used if <code>implementation=SparseGroupPLS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AlphaY</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity within
groups in X. Only used if <code>implementation=SparseGroupPLS</code> and
<code>family="gaussian"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>number of components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>number of resampling iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code>set.seed</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>type of PLS model. This parameter must be set to
<code>family="gaussian"</code> for continuous outcomes, or to
<code>family="binomial"</code> for categorical outcomes. Only used if
<code>ydata</code> is provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>implementation</code></td>
<td>
<p>function to use for feature selection. Possible
functions are: <code>SparsePCA</code>, <code>SparsePLS</code>, <code>GroupPLS</code>,
<code>SparseGroupPLS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code>multisession</code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beep</code></td>
<td>
<p>sound indicating the end of the run. Possible values are:
<code>NULL</code> (no sound) or an integer between 1 and 11 (see argument
<code>sound</code> in <code>beep</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In stability selection, a feature selection algorithm is fitted on
<code>K</code> subsamples (or bootstrap samples) of the data with different
parameters controlling the sparsity (<code>LambdaX</code>, <code>LambdaY</code>,
<code>AlphaX</code>, and/or <code>AlphaY</code>). For a given (set of) sparsity
parameter(s), the proportion out of the <code>K</code> models in which each
feature is selected is calculated. Features with selection proportions
above a threshold pi are considered stably selected. The stability
selection model is controlled by the sparsity parameter(s) (denoted by
<code class="reqn">\lambda</code>) for the underlying algorithm, and the threshold in selection
proportion:
</p>
<p><code class="reqn">V_{\lambda, \pi} = \{ j: p_{\lambda}(j) \ge \pi \} </code>
</p>
<p>For sparse and sparse group dimensionality reduction, "feature" refers to
variable (variable selection model). For group PLS, "feature" refers to
group (group selection model). For (sparse) group PLS, groups need to be
defined <em>a priori</em> and specified in arguments <code>group_x</code> and/or
<code>group_y</code>.
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code>ConsensusScore</code> if <code>n_cat=NULL</code> or
<code>StabilityScore</code> otherwise) calculated under the null
hypothesis of equiprobability of selection.
</p>
<p>It is strongly recommended to examine the calibration plot carefully to
check that the grids of parameters <code>Lambda</code> and <code>pi_list</code> do not
restrict the calibration to a region that would not include the global
maximum (see <code>CalibrationPlot</code>). In particular, the grid
<code>Lambda</code> may need to be extended when the maximum stability is
observed on the left or right edges of the calibration heatmap. In some
instances, multiple peaks of stability score can be observed. Simulation
studies suggest that the peak corresponding to the largest number of
selected features tend to give better selection performances. This is not
necessarily the highest peak (which is automatically retained by the
functions in this package). The user can decide to manually choose another
peak.
</p>
<p>To control the expected number of False Positives (Per Family Error Rate)
in the results, a threshold <code>PFER_thr</code> can be specified. The
optimisation problem is then constrained to sets of parameters that
generate models with an upper-bound in PFER below <code>PFER_thr</code> (see
Meinshausen and BÃ¼hlmann (2010) and Shah and Samworth (2013)).
</p>
<p>Possible resampling procedures include defining (i) <code>K</code> subsamples of
a proportion <code>tau</code> of the observations, (ii) <code>K</code> bootstrap samples
with the full sample size (obtained with replacement), and (iii) <code>K/2</code>
splits of the data in half for complementary pair stability selection (see
arguments <code>resampling</code> and <code>cpss</code>). In complementary pair
stability selection, a feature is considered selected at a given resampling
iteration if it is selected in the two complementary subsamples.
</p>
<p>For categorical outcomes (argument <code>family</code> is <code>"binomial"</code> or
<code>"multinomial"</code>), the proportions of observations from each category
in all subsamples or bootstrap samples are the same as in the full sample.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code>multisession</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>bi_selection</code>. A list with: </p>
<table>
<tr style="vertical-align: top;">
<td><code>summary</code></td>
<td>
<p>a
matrix of the best stability scores and corresponding parameters
controlling the level of sparsity in the underlying algorithm for different
numbers of components. Possible columns include: <code>comp</code> (component
index), <code>nx</code> (number of predictors to include, parameter of the
underlying algorithm), <code>alphax</code> (sparsity within the predictor groups,
parameter of the underlying algorithm), <code>pix</code> (threshold in selection
proportion for predictors), <code>ny</code> (number of outcomes to include,
parameter of the underlying algorithm), <code>alphay</code> (sparsity within the
outcome groups, parameter of the underlying algorithm), <code>piy</code>
(threshold in selection proportion for outcomes), <code>S</code> (stability
score). Columns that are not relevant to the model are not reported (e.g.
<code>alpha_x</code> and <code>alpha_y</code> are not returned for sparse PLS models).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>summary_full</code></td>
<td>
<p>a matrix of the best stability scores for different
combinations of parameters controlling the sparsity and components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedX</code></td>
<td>
<p>a binary matrix encoding stably selected predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selpropX</code></td>
<td>
<p>a matrix of calibrated selection proportions for
predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedY</code></td>
<td>
<p>a binary matrix encoding stably selected
outcomes. Only returned for PLS models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selpropY</code></td>
<td>
<p>a matrix of
calibrated selection proportions for outcomes. Only returned for PLS
models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selected</code></td>
<td>
<p>a binary matrix encoding stable relationships
between predictor and outcome variables. Only returned for PLS models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedX_full</code></td>
<td>
<p>a binary matrix encoding stably selected predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selpropX_full</code></td>
<td>
<p>a matrix of selection proportions for predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedY_full</code></td>
<td>
<p>a binary matrix encoding stably selected outcomes.
Only returned for PLS models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selpropY_full</code></td>
<td>
<p>a matrix of selection
proportions for outcomes. Only returned for PLS models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefX</code></td>
<td>
<p>an
array of estimated loadings coefficients for the different components
(rows), for the predictors (columns), as obtained across the <code>K</code>
visited models (along the third dimension).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefY</code></td>
<td>
<p>an array of
estimated loadings coefficients for the different components (rows), for
the outcomes (columns), as obtained across the <code>K</code> visited models
(along the third dimension). Only returned for PLS models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a
list with <code>type="bi_selection"</code> and values used for arguments
<code>implementation</code>, <code>family</code>, <code>scale</code>, <code>resampling</code>,
<code>cpss</code> and <code>PFER_method</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>params</code></td>
<td>
<p>a list with values used
for arguments <code>K</code>, <code>group_x</code>, <code>group_y</code>, <code>LambdaX</code>,
<code>LambdaY</code>, <code>AlphaX</code>, <code>AlphaY</code>, <code>pi_list</code>, <code>tau</code>,
<code>n_cat</code>, <code>pk</code>, <code>n</code> (number of observations),
<code>PFER_thr</code>, <code>FDP_thr</code> and <code>seed</code>. The datasets <code>xdata</code>
and <code>ydata</code> are also included if <code>output_data=TRUE</code>.</p>
</td>
</tr>
</table>
<p> The rows of
<code>summary</code> and columns of <code>selectedX</code>, <code>selectedY</code>,
<code>selpropX</code>, <code>selpropY</code>, <code>selected</code>, <code>coefX</code> and
<code>coefY</code> are ordered in the same way and correspond to components and
parameter values stored in <code>summary</code>. The rows of <code>summary_full</code>
and columns of <code>selectedX_full</code>, <code>selectedY_full</code>,
<code>selpropX_full</code> and <code>selpropY_full</code> are ordered in the same way
and correspond to components and parameter values stored in
<code>summary_full</code>.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
âAutomated calibration for stability selection in penalised regression and graphical models.â
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Shah RD, Samworth RJ (2013).
âVariable selection with error control: another look at stability selection.â
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
âStability selection.â
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Liquet B, de Micheaux PL, Hejblum BP, ThiÃ©baut R (2016).
âGroup and sparse group partial least square approaches applied in genomics context.â
<em>Bioinformatics</em>, <b>32</b>(1), 35-42.
ISSN 1367-4803, <a href="https://doi.org/10.1093/bioinformatics/btv535">doi:10.1093/bioinformatics/btv535</a>.
</p>
<p>KA LC, Rossouw D, Robert-GraniÃ© C, Besse P (2008).
âA sparse PLS for variable selection when integrating omics data.â
<em>Stat Appl Genet Mol Biol</em>, <b>7</b>(1), Article 35.
ISSN 1544-6115, <a href="https://doi.org/10.2202/1544-6115.1390">doi:10.2202/1544-6115.1390</a>.
</p>
<p>Shen H, Huang JZ (2008).
âSparse principal component analysis via regularized low rank matrix approximation.â
<em>Journal of Multivariate Analysis</em>, <b>99</b>(6), 1015-1034.
ISSN 0047-259X, <a href="https://doi.org/10.1016/j.jmva.2007.06.007">doi:10.1016/j.jmva.2007.06.007</a>.
</p>
<p>Zou H, Hastie T, Tibshirani R (2006).
âSparse Principal Component Analysis.â
<em>Journal of Computational and Graphical Statistics</em>, <b>15</b>(2), 265-286.
<a href="https://doi.org/10.1198/106186006X113430">doi:10.1198/106186006X113430</a>.
</p>


<h3>See Also</h3>

<p><code>SparsePCA</code>, <code>SparsePLS</code>,
<code>GroupPLS</code>, <code>SparseGroupPLS</code>,
<code>VariableSelection</code>, <code>Resample</code>,
<code>StabilityScore</code>
</p>
<p>Other stability functions: 
<code>Clustering()</code>,
<code>GraphicalModel()</code>,
<code>StructuralModel()</code>,
<code>VariableSelection()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
if (requireNamespace("sgPLS", quietly = TRUE)) {
  oldpar &lt;- par(no.readonly = TRUE)
  par(mar = c(12, 5, 1, 1))

  ## Sparse Principal Component Analysis

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateComponents(pk = c(5, 3, 4))

  # sPCA: sparsity on X (unsupervised)
  stab &lt;- BiSelection(
    xdata = simul$data,
    ncomp = 2,
    LambdaX = seq_len(ncol(simul$data) - 1),
    implementation = SparsePCA
  )
  print(stab)

  # Calibration plot
  CalibrationPlot(stab)

  # Visualisation of the results
  summary(stab)
  plot(stab)
  SelectedVariables(stab)


  ## Sparse (Group) Partial Least Squares

  # Data simulation (continuous outcomes)
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 15, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # sPLS: sparsity on X
  stab &lt;- BiSelection(
    xdata = x, ydata = y,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    implementation = SparsePLS
  )
  CalibrationPlot(stab)
  summary(stab)
  plot(stab)

  # sPLS: sparsity on both X and Y
  stab &lt;- BiSelection(
    xdata = x, ydata = y,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    LambdaY = seq_len(ncol(y) - 1),
    implementation = SparsePLS,
    n_cat = 2
  )
  CalibrationPlot(stab)
  summary(stab)
  plot(stab)

  # sgPLS: sparsity on X
  stab &lt;- BiSelection(
    xdata = x, ydata = y, K = 10,
    group_x = c(2, 8, 5),
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(2), AlphaX = seq(0.1, 0.9, by = 0.1),
    implementation = SparseGroupPLS
  )
  CalibrationPlot(stab)
  summary(stab)

  par(oldpar)
}

</code></pre>


</div>