<div class="container">

<table style="width: 100%;"><tr>
<td>susie_rss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sum of Single Effects (SuSiE) Regression using Summary Statistics</h2>

<h3>Description</h3>

<p><code>susie_rss</code> performs variable selection under a
sparse Bayesian multiple linear regression of <code class="reqn">Y</code> on <code class="reqn">X</code>
using the z-scores from standard univariate regression
of <code class="reqn">Y</code> on each column of <code class="reqn">X</code>, an estimate, <code class="reqn">R</code>, of
the correlation matrix for the columns of <code class="reqn">X</code>, and optionally,
<em>but strongly recommended</em>, the sample size n. See
“Details” for other ways to call <code>susie_rss</code>
</p>


<h3>Usage</h3>

<pre><code class="language-R">susie_rss(
  z,
  R,
  n,
  bhat,
  shat,
  var_y,
  z_ld_weight = 0,
  estimate_residual_variance = FALSE,
  prior_variance = 50,
  check_prior = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>p-vector of z-scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>p x p correlation matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The sample size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bhat</code></td>
<td>
<p>Alternative summary data giving the estimated effects
(a vector of length p). This, together with <code>shat</code>, may be
provided instead of <code>z</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shat</code></td>
<td>
<p>Alternative summary data giving the standard errors of
the estimated effects (a vector of length p). This, together with
<code>bhat</code>, may be provided instead of <code>z</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var_y</code></td>
<td>
<p>The sample variance of y, defined as <code class="reqn">y'y/(n-1)</code>.
When the sample variance is not provided, the coefficients
(returned from <code>coef</code>) are computed on the
“standardized” X, y scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z_ld_weight</code></td>
<td>
<p>This parameter is included for backwards
compatibility with previous versions of the function, but it is no
longer recommended to set this to a non-zero value. When
<code>z_ld_weight &gt; 0</code>, the matrix <code>R</code> is adjusted to be
<code>cov2cor((1-w)*R + w*tcrossprod(z))</code>, where <code>w =
z_ld_weight</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimate_residual_variance</code></td>
<td>
<p>The default is FALSE, the
residual variance is fixed to 1 or variance of y. If the in-sample
LD matrix is provided, we recommend setting
<code>estimate_residual_variance = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_variance</code></td>
<td>
<p>The prior variance(s) for the non-zero
noncentrality parameterss <code class="reqn">\tilde{b}_l</code>. It is either a scalar,
or a vector of length L. When the <code>susie_suff_stat</code> option
<code>estimate_prior_variance</code> is set to <code>TRUE</code> (which is
highly recommended) this simply provides an initial value for the
prior variance. The default value of 50 is simply intended to be a
large initial value. Note this setting is only relevant when
<code>n</code> is unknown. If <code>n</code> is known, the relevant option is
<code>scaled_prior_variance</code> in <code>susie_suff_stat</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check_prior</code></td>
<td>
<p>When <code>check_prior = TRUE</code>, it checks if the
estimated prior variance becomes unreasonably large (comparing with
100 * max(abs(z))^2).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other parameters to be passed to
<code>susie_suff_stat</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In some applications, particularly genetic applications,
it is desired to fit a regression model (<code class="reqn">Y = Xb + E</code> say,
which we refer to as "the original regression model" or ORM)
without access to the actual values of <code class="reqn">Y</code> and <code class="reqn">X</code>, but
given only some summary statistics. <code>susie_rss</code> assumes
availability of z-scores from standard univariate regression of
<code class="reqn">Y</code> on each column of <code class="reqn">X</code>, and an estimate, <code class="reqn">R</code>, of the
correlation matrix for the columns of <code class="reqn">X</code> (in genetic
applications <code class="reqn">R</code> is sometimes called the “LD matrix”).
</p>
<p>With the inputs <code>z</code>, <code>R</code> and sample size <code>n</code>,
<code>susie_rss</code> computes PVE-adjusted z-scores <code>z_tilde</code>, and
calls <code>susie_suff_stat</code> with <code>XtX = (n-1)R</code>, <code>Xty =
</code> <code class="reqn">\sqrt{n-1} z_tilde</code>, <code>yty = n-1</code>, <code>n = n</code>. The
output effect estimates are on the scale of <code class="reqn">b</code> in the ORM with
<em>standardized</em> <code class="reqn">X</code> and <code class="reqn">y</code>. When the LD matrix
<code>R</code> and the z-scores <code>z</code> are computed using the same
matrix <code class="reqn">X</code>, the results from <code>susie_rss</code> are same as, or
very similar to, <code>susie</code> with <em>standardized</em> <code class="reqn">X</code> and
<code class="reqn">y</code>.
</p>
<p>Alternatively, if the user provides <code>n</code>, <code>bhat</code> (the
univariate OLS estimates from regressing <code class="reqn">y</code> on each column of
<code class="reqn">X</code>), <code>shat</code> (the standard errors from these OLS
regressions), the in-sample correlation matrix <code class="reqn">R =
cov2cor(crossprod(X))</code>, and the variance of <code class="reqn">y</code>, the results
from <code>susie_rss</code> are same as <code>susie</code> with <code class="reqn">X</code> and
<code class="reqn">y</code>. The effect estimates are on the same scale as the
coefficients <code class="reqn">b</code> in the ORM with <code class="reqn">X</code> and <code class="reqn">y</code>.
</p>
<p>In rare cases in which the sample size, <code class="reqn">n</code>, is unknown,
<code>susie_rss</code> calls <code>susie_suff_stat</code> with <code>XtX = R</code>
and <code>Xty = z</code>, and with <code>residual_variance = 1</code>. The
underlying assumption of performing the analysis in this way is
that the sample size is large (<em>i.e.</em>, infinity), and/or the
effects are small. More formally, this combines the log-likelihood
for the noncentrality parameters, <code class="reqn">\tilde{b} = \sqrt{n} b</code>,
</p>
<p style="text-align: center;"><code class="reqn">L(\tilde{b}; z, R) = -(\tilde{b}'R\tilde{b} -
2z'\tilde{b})/2,</code>
</p>
<p> with the “susie prior” on
<code class="reqn">\tilde{b}</code>; see <code>susie</code> and Wang <em>et al</em>
(2020) for details. In this case, the effect estimates returned by
<code>susie_rss</code> are on the noncentrality parameter scale.
</p>
<p>The <code>estimate_residual_variance</code> setting is <code>FALSE</code> by
default, which is recommended when the LD matrix is estimated from
a reference panel. When the LD matrix <code>R</code> and the summary
statistics <code>z</code> (or <code>bhat</code>, <code>shat</code>) are computed
using the same matrix <code class="reqn">X</code>, we recommend setting
<code>estimate_residual_variance = TRUE</code>.
</p>


<h3>Value</h3>

<p>A <code>"susie"</code> object with the following
elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>An L by p matrix of posterior inclusion probabilites.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>An L by p matrix of posterior means, conditional on
inclusion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu2</code></td>
<td>
<p>An L by p matrix of posterior second moments,
conditional on inclusion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbf</code></td>
<td>
<p>log-Bayes Factor for each single effect.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbf_variable</code></td>
<td>
<p>log-Bayes Factor for each variable and single effect.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>Prior variance of the non-zero elements of b.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>elbo</code></td>
<td>
<p>The value of the variational lower bound, or
“ELBO” (objective function to be maximized), achieved at
each iteration of the IBSS fitting procedure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sets</code></td>
<td>
<p>Credible sets estimated from model fit; see
<code>susie_get_cs</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pip</code></td>
<td>
<p>A vector of length p giving the (marginal) posterior
inclusion probabilities for all p covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niter</code></td>
<td>
<p>Number of IBSS iterations that were performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>converged</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether
the IBSS converged to a solution within the chosen tolerance
level.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>G. Wang, A. Sarkar, P. Carbonetto and M. Stephens (2020). A simple
new approach to variable selection in regression, with application
to genetic fine-mapping. <em>Journal of the Royal Statistical
Society, Series B</em> <b>82</b>, 1273-1300 doi: <a href="https://doi.org/10.1101/501114">10.1101/501114</a>.
</p>
<p>Y. Zou, P. Carbonetto, G. Wang, G and M. Stephens
(2022). Fine-mapping from summary data with the “Sum of
Single Effects” model. <em>PLoS Genetics</em> <b>18</b>,
e1010299. doi: <a href="https://doi.org/10.1371/journal.pgen.1010299">10.1371/journal.pgen.1010299</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
n = 1000
p = 1000
beta = rep(0,p)
beta[1:4] = 1
X = matrix(rnorm(n*p),nrow = n,ncol = p)
X = scale(X,center = TRUE,scale = TRUE)
y = drop(X %*% beta + rnorm(n))

input_ss = compute_suff_stat(X,y,standardize = TRUE)
ss   = univariate_regression(X,y)
R    = with(input_ss,cov2cor(XtX))
zhat = with(ss,betahat/sebetahat)
res  = susie_rss(zhat,R, n=n)

# Toy example illustrating behaviour susie_rss when the z-scores
# are mostly consistent with a non-invertible correlation matrix.
# Here the CS should contain both variables, and two PIPs should
# be nearly the same.
z = c(6,6.01)
R = matrix(1,2,2)
fit = susie_rss(z,R)
print(fit$sets$cs)
print(fit$pip)

# In this second toy example, the only difference is that one
# z-score is much larger than the other. Here we expect that the
# second PIP will be much larger than the first.
z = c(6,7)
R = matrix(1,2,2)
fit = susie_rss(z,R)
print(fit$sets$cs)
print(fit$pip)

</code></pre>


</div>