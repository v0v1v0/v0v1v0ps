<div class="container">

<table style="width: 100%;"><tr>
<td>TfIdfVectorizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TfIDF(Term Frequency Inverse Document Frequency) Vectorizer</h2>

<h3>Description</h3>

<p>Creates a tf-idf matrix
</p>


<h3>Details</h3>

<p>Given a list of text, it creates a sparse matrix consisting of tf-idf score for tokens from the text.
</p>


<h3>Super class</h3>

<p><code>superml::CountVectorizer</code> -&gt; <code>TfIdfVectorizer</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>sentences</code></dt>
<dd>
<p>a list containing sentences</p>
</dd>
<dt><code>max_df</code></dt>
<dd>
<p>When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold, value lies between 0 and 1.</p>
</dd>
<dt><code>min_df</code></dt>
<dd>
<p>When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold, value lies between 0 and 1.</p>
</dd>
<dt><code>max_features</code></dt>
<dd>
<p>use top features sorted by count to be used in bag of words matrix.</p>
</dd>
<dt><code>ngram_range</code></dt>
<dd>
<p>The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n &lt;= n &lt;= max_n will be used. For example an ngram_range of c(1, 1) means only unigrams, c(1, 2) means unigrams and bigrams, and c(2, 2) means only bigrams.</p>
</dd>
<dt><code>split</code></dt>
<dd>
<p>splitting criteria for strings, default: " "</p>
</dd>
<dt><code>lowercase</code></dt>
<dd>
<p>convert all characters to lowercase before tokenizing</p>
</dd>
<dt><code>regex</code></dt>
<dd>
<p>regex expression to use for text cleaning.</p>
</dd>
<dt><code>remove_stopwords</code></dt>
<dd>
<p>a list of stopwords to use, by default it uses its inbuilt list of standard stopwords</p>
</dd>
<dt><code>smooth_idf</code></dt>
<dd>
<p>logical, to prevent zero division, adds one to document frequencies, as if an extra document was seen containing every term in the collection exactly once</p>
</dd>
<dt><code>norm</code></dt>
<dd>
<p>logical, if TRUE, each output row will have unit norm ‘l2’: Sum of squares of vector elements is 1. if FALSE returns non-normalized vectors, default: TRUE</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TfIdfVectorizer-new"><code>TfIdfVectorizer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TfIdfVectorizer-fit"><code>TfIdfVectorizer$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-TfIdfVectorizer-fit_transform"><code>TfIdfVectorizer$fit_transform()</code></a>
</p>
</li>
<li> <p><a href="#method-TfIdfVectorizer-transform"><code>TfIdfVectorizer$transform()</code></a>
</p>
</li>
<li> <p><a href="#method-TfIdfVectorizer-clone"><code>TfIdfVectorizer$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-TfIdfVectorizer-new"></a>



<h4>Method <code>new()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>TfIdfVectorizer$new(
  min_df,
  max_df,
  max_features,
  ngram_range,
  regex,
  remove_stopwords,
  split,
  lowercase,
  smooth_idf,
  norm
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>min_df</code></dt>
<dd>
<p>numeric, When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold, value lies between 0 and 1.</p>
</dd>
<dt><code>max_df</code></dt>
<dd>
<p>numeric, When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold, value lies between 0 and 1.</p>
</dd>
<dt><code>max_features</code></dt>
<dd>
<p>integer, Build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.</p>
</dd>
<dt><code>ngram_range</code></dt>
<dd>
<p>vector, The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n &lt;= n &lt;= max_n will be used. For example an ngram_range of c(1, 1) means only unigrams, c(1, 2) means unigrams and bigrams, and c(2, 2) means only bigrams.</p>
</dd>
<dt><code>regex</code></dt>
<dd>
<p>character, regex expression to use for text cleaning.</p>
</dd>
<dt><code>remove_stopwords</code></dt>
<dd>
<p>list, a list of stopwords to use, by default it uses its inbuilt list of standard english stopwords</p>
</dd>
<dt><code>split</code></dt>
<dd>
<p>character, splitting criteria for strings, default: " "</p>
</dd>
<dt><code>lowercase</code></dt>
<dd>
<p>logical, convert all characters to lowercase before tokenizing, default: TRUE</p>
</dd>
<dt><code>smooth_idf</code></dt>
<dd>
<p>logical, to prevent zero division, adds one to document frequencies, as if an extra document was seen containing every term in the collection exactly once</p>
</dd>
<dt><code>norm</code></dt>
<dd>
<p>logical, if TRUE, each output row will have unit norm ‘l2’: Sum of squares of vector elements is 1. if FALSE returns non-normalized vectors, default: TRUE</p>
</dd>
<dt><code>parallel</code></dt>
<dd>
<p>logical,  speeds up ngrams computation using n-1 cores, defaults: TRUE</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Create a new 'TfIdfVectorizer' object.
</p>



<h5>Returns</h5>

<p>A 'TfIdfVectorizer' object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>TfIdfVectorizer$new()
</pre>
</div>


<hr>
<a id="method-TfIdfVectorizer-fit"></a>



<h4>Method <code>fit()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>TfIdfVectorizer$fit(sentences)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>sentences</code></dt>
<dd>
<p>a list of text sentences</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Fits the TfIdfVectorizer model on sentences
</p>



<h5>Returns</h5>

<p>NULL
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>sents = c('i am alone in dark.','mother_mary a lot',
          'alone in the dark?', 'many mothers in the lot....')
tf = TfIdfVectorizer$new(smooth_idf = TRUE, min_df = 0.3)
tf$fit(sents)
</pre>
</div>


<hr>
<a id="method-TfIdfVectorizer-fit_transform"></a>



<h4>Method <code>fit_transform()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>TfIdfVectorizer$fit_transform(sentences)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>sentences</code></dt>
<dd>
<p>a list of text sentences</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Fits the TfIdfVectorizer model and returns a sparse matrix of count of tokens
</p>



<h5>Returns</h5>

<p>a sparse matrix containing tf-idf score for tokens in each given sentence
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>\dontrun{
sents &lt;- c('i am alone in dark.','mother_mary a lot',
         'alone in the dark?', 'many mothers in the lot....')
tf &lt;- TfIdfVectorizer$new(smooth_idf = TRUE, min_df = 0.1)
tf_matrix &lt;- tf$fit_transform(sents)
}
</pre>
</div>


<hr>
<a id="method-TfIdfVectorizer-transform"></a>



<h4>Method <code>transform()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>TfIdfVectorizer$transform(sentences)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>sentences</code></dt>
<dd>
<p>a list of new text sentences</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Returns a matrix of tf-idf score of tokens
</p>



<h5>Returns</h5>

<p>a sparse matrix containing tf-idf score for tokens in each given sentence
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>\dontrun{
sents = c('i am alone in dark.','mother_mary a lot',
          'alone in the dark?', 'many mothers in the lot....')
new_sents &lt;- c("dark at night",'mothers day')
tf = TfIdfVectorizer$new(min_df=0.1)
tf$fit(sents)
tf_matrix &lt;- tf$transform(new_sents)
}
</pre>
</div>


<hr>
<a id="method-TfIdfVectorizer-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TfIdfVectorizer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R">
## ------------------------------------------------
## Method `TfIdfVectorizer$new`
## ------------------------------------------------

TfIdfVectorizer$new()

## ------------------------------------------------
## Method `TfIdfVectorizer$fit`
## ------------------------------------------------

sents = c('i am alone in dark.','mother_mary a lot',
          'alone in the dark?', 'many mothers in the lot....')
tf = TfIdfVectorizer$new(smooth_idf = TRUE, min_df = 0.3)
tf$fit(sents)

## ------------------------------------------------
## Method `TfIdfVectorizer$fit_transform`
## ------------------------------------------------

## Not run: 
sents &lt;- c('i am alone in dark.','mother_mary a lot',
         'alone in the dark?', 'many mothers in the lot....')
tf &lt;- TfIdfVectorizer$new(smooth_idf = TRUE, min_df = 0.1)
tf_matrix &lt;- tf$fit_transform(sents)

## End(Not run)

## ------------------------------------------------
## Method `TfIdfVectorizer$transform`
## ------------------------------------------------

## Not run: 
sents = c('i am alone in dark.','mother_mary a lot',
          'alone in the dark?', 'many mothers in the lot....')
new_sents &lt;- c("dark at night",'mothers day')
tf = TfIdfVectorizer$new(min_df=0.1)
tf$fit(sents)
tf_matrix &lt;- tf$transform(new_sents)

## End(Not run)
</code></pre>


</div>