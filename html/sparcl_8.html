<div class="container">

<table style="width: 100%;"><tr>
<td>HierarchicalSparseCluster</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hierarchical sparse clustering</h2>

<h3>Description</h3>

<p>Performs sparse hierarchical  clustering. If $d_ii'j$ is the
dissimilarity between observations i and i' for feature j, seek a sparse
weight
vector w and then use $(sum_j (d_ii'j w_j))_ii'$ as a nxn dissimilarity
matrix for hierarchical clustering.
</p>


<h3>Usage</h3>

<pre><code class="language-R">HierarchicalSparseCluster(x=NULL, dists=NULL,
method=c("average","complete", "single","centroid"),
wbound=NULL,niter=15,dissimilarity=c("squared.distance","absolute.value"),
 uorth=NULL,
silent=FALSE,cluster.features=FALSE,method.features=c("average", "complete",
"single","centroid"),output.cluster.files=FALSE,
outputfile.prefix="output",genenames=NULL,genedesc=NULL,standardize.arrays=FALSE)
## S3 method for class 'HierarchicalSparseCluster'
print(x,...)
## S3 method for class 'HierarchicalSparseCluster'
plot(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A nxp data matrix; n is the number of observations and p the
number of features. If NULL, then specify dists instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dists</code></td>
<td>
<p>For advanced users, can be entered instead of x. If
HierarchicalSparseCluster has already been run on this data, then
the dists value of the previous output can be entered here. 
Under normal circumstances, leave this argument NULL and
pass in x instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The type of linkage to use in the hierarchical
clustering - "single", "complete", "centroid", or "average".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wbound</code></td>
<td>
<p>The L1 bound on w to use; this is the tuning parameter
for sparse hierarchical clustering. Should be greater than 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niter</code></td>
<td>
<p>The number of iterations to perform in the sparse
hierarchical clustering algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dissimilarity</code></td>
<td>
<p>The type of dissimilarity measure to use. One of
"squared.distance" or "absolute.value". Only use this if x was
passed in (rather than dists).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uorth</code></td>
<td>
<p>If complementary sparse clustering is desired, then this
is the nxn dissimilarity matrix obtained in the original sparse
clustering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize.arrays</code></td>
<td>
<p>Should the arrays be standardized? Default
is FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>Print out progress?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster.features</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method.features</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output.cluster.files</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outputfile.prefix</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>genenames</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>genedesc</code></td>
<td>
<p>Not for use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> not used. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>We seek a p-vector of weights w (one per feature) and a nxn matrix U
that optimize
</p>
<p>$maximize_U,w sum_j w_j sum_ii' d_ii'j U_ii'$ subject to $||w||_2 &lt;= 1,
||w||_1 &lt;= wbound, w_j &gt;= 0, sum_ii' U_ii'^2 &lt;= 1$.
</p>
<p>Here, $d_ii'j$ is the dissimilarity between observations i and i' with
along feature j. The resulting matrix U is used as a dissimilarity
matrix for hierarchical clustering. "wbound" is a tuning parameter for
this method, which controls the L1 bound on w, and as a result the
number of features with non-zero $w_j$ weights.
The non-zero elements of w indicate features that are used in the
sparse clustering.
</p>
<p>We optimize the above criterion with an iterative approach: hold U
fixed and optimize with respect to w. Then, hold w fixed and optimize
with respect to U.
</p>
<p>Note that the arguments described as "Not for use" are included for
the sparcl package to function with GenePattern but should be ignored
by the R user.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>hc</code></td>
<td>
<p>The output of a call to "hclust", giving the results of
hierarchical sparse clustering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ws</code></td>
<td>
<p>The p-vector of feature weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>The nxn dissimilarity matrix passed into hclust, of the form
$(sum_j w_j d_ii'j)_ii'$.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dists</code></td>
<td>
<p>The (n*n)xp dissimilarity matrix for the data matrix
x. This is useful if additional calls to HierarchicalSparseCluster
will be made.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Daniela M. Witten and Robert Tibshirani</p>


<h3>References</h3>

<p>Witten and Tibshirani (2009) A framework for feature
selection in clustering.</p>


<h3>See Also</h3>

<p>HierarchicalSparseCluster.permute,KMeansSparseCluster,KMeansSparseCluster.permute</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Generate 2-class data
  set.seed(1)
  x &lt;- matrix(rnorm(100*50),ncol=50)
  y &lt;- c(rep(1,50),rep(2,50))
  x[y==1,1:25] &lt;- x[y==1,1:25]+2
  # Do tuning parameter selection for sparse hierarchical clustering
  perm.out &lt;- HierarchicalSparseCluster.permute(x, wbounds=c(1.5,2:6),
nperms=5)
  print(perm.out)
  plot(perm.out)
  # Perform sparse hierarchical clustering
  sparsehc &lt;- HierarchicalSparseCluster(dists=perm.out$dists,
wbound=perm.out$bestw, method="complete")
  # faster than   sparsehc &lt;- HierarchicalSparseCluster(x=x,wbound=perm.out$bestw, 
#  method="complete")
  par(mfrow=c(1,2))
  plot(sparsehc)
  plot(sparsehc$hc, labels=rep("", length(y)))
  print(sparsehc)
  # Plot using knowledge of class labels in order to compare true class
  #   labels to clustering obtained
  par(mfrow=c(1,1))
  ColorDendrogram(sparsehc$hc,y=y,main="My Simulated Data",branchlength=.007)
  # Now, what if we want to see if out data contains a *secondary*
  #   clustering after accounting for the first one obtained. We
  #   look for a complementary sparse clustering:
  sparsehc.comp &lt;- HierarchicalSparseCluster(x,wbound=perm.out$bestw,
     method="complete",uorth=sparsehc$u)
  # Redo the analysis, but this time use "absolute value" dissimilarity:
  perm.out &lt;- HierarchicalSparseCluster.permute(x, wbounds=c(1.5,2:6),
    nperms=5, dissimilarity="absolute.value")
  print(perm.out)
  plot(perm.out)
  # Perform sparse hierarchical clustering
  sparsehc &lt;- HierarchicalSparseCluster(dists=perm.out$dists, wbound=perm.out$bestw, 
method="complete",
 dissimilarity="absolute.value")
  par(mfrow=c(1,2))
  plot(sparsehc)
</code></pre>


</div>