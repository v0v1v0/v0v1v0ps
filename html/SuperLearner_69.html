<div class="container">

<table style="width: 100%;"><tr>
<td>SL.biglasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SL wrapper for biglasso</h2>

<h3>Description</h3>

<p>SL wrapper for biglasso
</p>


<h3>Usage</h3>

<pre><code class="language-R">SL.biglasso(Y, X, newX, family, obsWeights, penalty = "lasso",
  alg.logistic = "Newton", screen = "SSR", alpha = 1, nlambda = 100,
  eval.metric = "default", ncores = 1, nfolds = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Outcome variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Training dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newX</code></td>
<td>
<p>Test dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Gaussian or binomial</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obsWeights</code></td>
<td>
<p>Observation-level weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>The penalty to be applied to the model. Either "lasso"
(default), "ridge", or "enet" (elastic net).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alg.logistic</code></td>
<td>
<p>The algorithm used in logistic regression. If "Newton"
then the exact hessian is used (default); if "MM" then a
majorization-minimization algorithm is used to set an upper-bound on the
hessian matrix. This can be faster, particularly in data-larger-than-RAM
case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>screen</code></td>
<td>
<p>"SSR" (default) is the sequential strong rule; "SEDPP" is the
(sequential) EDPP rule. "SSR-BEDPP", "SSR-Dome", and "SSR-Slores" are our
newly proposed screening rules which combine the strong rule with a safe
rule (BEDPP, Dome test, or Slores rule). Among the three, the first two are
for lasso-penalized linear regression, and the last one is for
lasso-penalized logistic regression. "None" is to not apply a screening
rule.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The elastic-net mixing parameter that controls the relative
contribution from the lasso (l1) and the ridge (l2) penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of lambda values to check.  Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eval.metric</code></td>
<td>
<p>The evaluation metric for the cross-validated error and
for choosing optimal <code>lambda</code>. "default" for linear regression is MSE
(mean squared error), for logistic regression is misclassification error.
"MAPE", for linear regression only, is the Mean Absolute Percentage Error.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>The number of cores to use for parallel execution across a
cluster created by the <code>parallel</code> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of cross-validation folds.  Default is 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Any additional arguments, not currently used.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Zeng Y, Breheny P (2017). biglasso: Extending Lasso Model Fitting to Big
Data. https://CRAN.R-project.org/package=biglasso.
</p>


<h3>See Also</h3>

<p><code>predict.SL.biglasso</code> <code>biglasso</code>
<code>cv.biglasso</code>
<code>predict.biglasso</code> <code>SL.glmnet</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Boston, package = "MASS")
Y = Boston$medv
# Remove outcome from covariate dataframe.
X = Boston[, -14]

set.seed(1)

# Sample rows to speed up example.
row_subset = sample(nrow(X), 30)

# Subset rows and columns &amp; use only 2 folds to speed up example.
sl = SuperLearner(Y[row_subset], X[row_subset, 1:2, drop = FALSE],
                  family = gaussian(), cvControl = list(V = 2),
                  SL.library = "SL.biglasso")
sl

pred = predict(sl, X)
summary(pred$pred)

</code></pre>


</div>