<div class="container">

<table style="width: 100%;"><tr>
<td>power_test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Empirical power analysis for single-case data</h2>

<h3>Description</h3>

<p>Conducts a Monte-Carlo study on the test-power and alpha-error probability of
a statistical function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">power_test(
  design,
  method = c("plm_level", "rand", "tauU"),
  effect = "level",
  n_sim = 100,
  design_is_one_study = TRUE,
  alpha_test = TRUE,
  power_test = TRUE,
  binom_test = FALSE,
  binom_test_alpha = FALSE,
  binom_test_power = FALSE,
  binom_test_correct = FALSE,
  ci = FALSE,
  alpha_level = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>design</code></td>
<td>
<p>An object returned from the <code>design</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A (named) list that defines the methods the power analysis is
based on. Each element can contain a function (that takes an scdf file and
returns a p value) or a character string (the name of predefined
functions). default <code>method = list("plm_level", "rand", "tauU")</code> computes a
power analysis based on <code>tau_u()</code>, <code>rand_test()</code> and <code>plm()</code> analyses.
(Further predefined functions are: "plm_slope", "plm_poisson_level",
"plm_poisson_slope", "hplm_level", "hplm_slope", "base_tau".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>effect</code></td>
<td>
<p>Either "level" or "slope". The respective effect of the
provided design is set to 0 when computing the alpha-error proportion.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_sim</code></td>
<td>
<p>Number of sample studies created for the the Monte-Carlo study.
Default is <code>n = 100</code>. Ignored if design_is_one_study = FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>design_is_one_study</code></td>
<td>
<p>If TRUE, the design is assumed to define all cases
of one study that is repeatedly randomly created <code>n_sim</code> times. If false,
the design is assumed to contain all cases from which a random sample is
generated. This is useful for very specific complex simulation studies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha_test</code></td>
<td>
<p>Logical. If TRUE, alpha error is calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power_test</code></td>
<td>
<p>Logical. If TRUE, power is calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binom_test</code></td>
<td>
<p>Shortcut. When set TRUE, binom_test_power is set to 0.80,
binom_test_alpha is set to 0.05, and binom_test_correct is set to 0.875.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binom_test_alpha</code></td>
<td>
<p>Either FALSE or a value. If a value is provided, a
binomial test is calculated testing if the alpha error proportion is less
than the provided value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binom_test_power</code></td>
<td>
<p>Either FALSE or a value. If a value is provided, a
binomial test is calculated testing if the power is greater than the
provided value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binom_test_correct</code></td>
<td>
<p>Either FALSE or a value. If a value is provided, a
binomial test is calculated testing if the correct proportion is greater
than the provided value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>
<p>Either FALSE or a value. If a value is provided, confidence
intervals at the provided level are calculated for power, alpha error, and
correct proportions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha_level</code></td>
<td>
<p>Alpha level used to calculate the proportion of
significant tests. Default is <code>alpha_level = 0.05</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Based on a <code>design()</code> object, a large number of single-cases are generated
and re-analyzed with a provided statistical function. The proportion of
significant analyzes is the test power. In a second step, a specified effect
of the design object is set to 0 and again single-cases are generated and
reanalyzed. The proportion of significant analyzes is the alpha error
probability.
</p>


<h3>Author(s)</h3>

<p>Juergen Wilbert
</p>


<h3>See Also</h3>

<p><code>random_scdf()</code>, <code>design()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Assume you want to conduct a single-case study with 15 measurements
## (phases: A = 6 and B = 9) using a highly reliable test and
## an expected level effect of d = 1.4.
## A (strong) trend effect is trend = 0.05. What is the power?
## (Note: n_sims is set to 10. Set n_sims to 1000 for a serious calculation.)
design &lt;- design(
  n = 1, phase_design = list(A = 6, B = 9),
  rtt = 0.8, level = 1.4, trend = 0.05
)
power_test(design, n_sim = 10)

## Would you achieve higher power by setting up a MBD with three cases?
design &lt;- design(
  n = 3, phase_design = list(A = 6, B = 9),
  rtt = 0.8, level = 1.4, trend = 0.05
)
power_test(design, n_sim=10, method=list("hplm_level", "rand", "tauU_meta"))
</code></pre>


</div>