<div class="container">

<table style="width: 100%;"><tr>
<td>AIC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Extractors for information criteria such as AIC
</h2>

<h3>Description</h3>

<p><code>get_any_IC</code> computes model selection/information criteria such as AIC. See Details for more information about these criteria. The other extractors <code>AIC</code> and <code>extractAIC</code> are methods for <code>HLfit</code> objects of generic functions defined in other packages: <code>AIC</code> is equivalent to <code>get_any_IC</code> (for a single fitted-model object), and <code>extractAIC</code> returns the marginal AIC and the number of degrees of freedom for the fixed effects. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_any_IC(object, nsim=0L, ..., verbose=interactive(),
           also_cAIC=TRUE, short.names=NULL)
## S3 method for class 'HLfit'
AIC(object, ..., nsim=0L, k, verbose=interactive(),
                    also_cAIC=TRUE, short.names=NULL)
## S3 method for class 'HLfit'
extractAIC(fit, scale, k, ..., verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object, fit</code></td>
<td>
<p>A object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale, k</code></td>
<td>
<p>Currently ignored, but are required in the definitions for consistency with the generic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p> Whether to print the model selection criteria or not. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>also_cAIC</code></td>
<td>
<p>Whether to include the plug-in estimate of conditional AIC in the result (its computation may be slow).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>
<p>Controls whether to include the bootstrap estimate of conditional AIC (see Details) in the result. If positive, <code>nsim</code> gives the number of bootstrap replicates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>short.names</code></td>
<td>
<p>NULL, or boolean; controls whether the return value uses short names (<code>mAIC</code>, etc., as shown by screen output if <code>verbose</code> is TRUE), or the descriptive names (<code>"   marginal AIC:"</code>, etc.) also shown in the screen output. Short names are more appropriate for programming but descriptive names may be needed for back-compatibility. The default (NULL) ensures back-compatibility by using descriptive names unless the bootstrap estimate of conditional AIC is reported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For <code>AIC.HLfit</code>: may include more fitted-model objects, consistently with the generic. For this and the other functions: other arguments that may be needed by some method. For example, if <code>nsim</code> is positive, a <code>seed</code> argument may be passed to <code>simulate</code>, and the other “...” may be used to control the optional parallel execution of the bootstrap computations (by providing arguments to <code>dopar</code>).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The AIC is a measure (by Kullback-Leibler directed distance, up to an additive constant) of quality of prediction of new data by a fitted model. 
Comparing information criteria may be viewed as a fast alternative to a comparison of the predictive accuracy of different models by cross-validation. Further procedures for model choice may also be useful (e.g. Williams, 1970; Lewis et al. 2010).
</p>
<p>The <b>conditional AIC</b> (Vaida and Blanchard 2005) applies the AIC concept to new realizations of a mixed model, conditional on the realized values of the random effects. Lee et al. (2006) and Ha et al (2007) defined a corrected AIC [i.e., AIC(D*) in their eq. 7] which is here interpreted as the conditional AIC. 
</p>
<p>Such Kullback-Leibler relative distances cannot generally be evaluated exactly and various estimates have been discussed.
<code>get_any_IC</code> computes, optionally prints, and returns invisibly one or more of the following quantities:<br> 
* Akaike's classical AIC (<b>marginal AIC</b>, <code>mAIC</code>, i.e., minus twice the marginal log-likelihood plus twice the number of fitted parameters);<br> 
* a plug-in estimate (<code>cAIC</code>) and/or a bootstrap estimate (<code>b_cAIC</code>) of the conditional AIC;<br> 
* a focussed AIC for dispersion parameters (<b>dispersion AIC</b>, <code>dAIC</code>). 
</p>
<p>For the <b>conditional AIC</b>, Vaida and Blanchard's plug-in estimator involves the conditional likelihood, and degrees of freedom for (i) estimated residual error parameters and (ii) the overall linear predictor characterized by the <b>Effective degrees of freedom</b> already discussed by previous authors including Lee and Nelder (1996), which gave a plug-in estimator (<code class="reqn">p_D</code>) for it in HGLMs. 
By default, the plug-in estimate of both the conditional AIC and of <code class="reqn">n-p_D</code> (<code>GoFdf</code>, where <code class="reqn">n</code> is the length of the response vector) are returned by <code>get_any_IC</code>. But these are biased estimates of conditional AIC and effective df, and an alternative procedure is available for GLM response families if a non-default positive <code>nsim</code> value is used. In that case, the conditional AIC is estimated by a bootstrap version of Saefken et al. (2014)'s equation 2.5; this involves refitting the model to each bootstrap samples, so it may take time, and a full cross-validation procedure might as well be considered for model selection. 
</p>
<p>The dispersion AIC has been defined from restricted likelihood by Ha et al (2007; eq.10). The present implementation will use restricted likelihood only if made available by an REML fit, otherwise marginal likelihood is used.
</p>


<h3>Value</h3>

<p><code>get_any_IC</code>, a numeric vector whose possible elements are described in the Details, and whose names are controlled by the <code>short.names</code> argument. Note that the bootstrap computation actually makes sense and works also for fixed-effect models (although it is not clear how useful it is in that case). The return value will still refer to its results as conditional AIC.
</p>
<p>For <code>AIC</code>, If just one fit object is provided, the same return value as for <code>get_any_IC</code>. If multiple objects are provided, a data.frame built from such vectors, with rows corresponding to the objects.
</p>
<p>For <code>extractAIC</code>, a numeric vector of length 2, with first and second elements giving
</p>
<table>
<tr style="vertical-align: top;">
<td><code>* edf</code></td>
<td>
<p>the degree of freedom of the fixed-effect terms of the model
for the fitted model <code>fit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>* AIC</code></td>
<td>
<p>the (marginal) Akaike Information Criterion for <code>fit</code>.</p>
</td>
</tr>
</table>
<p>Likelihood is broadly defined up to a constant, which opens the way for inconsistency between different likelihood and AIC computations. In <span class="pkg">spaMM</span>, likelihood is nothing else than the probability or probability density of the data as function of model parameters. No constant is ever added, in contrast to <code>stats::extractAIC</code> output, so there are discrepancies with the latter function (see Examples). 
</p>


<h3>References</h3>


<p>Ha, I. D., Lee, Y. and MacKenzie, G. (2007) Model selection for multi-component frailty models. Statistics in Medicine 26: 4790-4807.
</p>
<p>Lee Y. and Nelder. J. A. 1996. Hierarchical generalized linear models (with discussion). J. R. Statist. Soc. B, 58: 619-678. 
</p>
<p>Lewis, F., Butler, A. and Gilbert, L. (2011), A unified approach to model selection using the likelihood ratio test. Methods in Ecology and Evolution, 2: 155-162. <a href="https://doi.org/10.1111/j.2041-210X.2010.00063.x">doi:10.1111/j.2041-210X.2010.00063.x</a>
</p>

<p>Saefken B., Kneib T., van Waveren C.-S., Greven S. (2014) A unifying approach to the estimation of the conditional Akaike information in generalized linear mixed models. Electron. J. Statist. 8, 201-225. 
</p>
<p>Vaida, F., and Blanchard, S. (2005) Conditional Akaike information for mixed-effects models. Biometrika 92, 351-370.
</p>
<p>Williams D.A. (1970) Discrimination between regression models to determine the pattern of enzyme synthesis in synchronous cell cultures. Biometrics 26: 23-32.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data("wafers")
m1 &lt;- fitme(y ~ X1+X2+X3+X1*X3+X2*X3+I(X2^2)+(1|batch), data=wafers, 
            family=Gamma(log))

get_any_IC(m1) 
# =&gt; The plug-in estimate is stored in the 'm1' object 
#    as a result of the previous computation, and is now returned even by: 
get_any_IC(m1, also_cAIC=FALSE)

if (spaMM.getOption("example_maxtime")&gt;4) {
 get_any_IC(m1, nsim=100L, seed=123) # provides bootstrap estimate of cAIC.
 # (parallelisation options could be used, e.g. nb_cores=detectCores(logical=FALSE)-1L)
}

extractAIC(m1)

## Not run: 
# Checking (in)consistency with glm example from help("stats::extractAIC"):
utils::example(glm) # =&gt; provides 'glm.D93' fit object
logLik(glm.D93) # logL= -23.38066 (df=5)
dataf &lt;- data.frame(counts=counts,outcome=outcome, treatment=treatment)
extractAIC(fitme(counts ~ outcome + treatment, family = poisson(), data=dataf))
# =&gt; 56.76132 = -2 logL + 2* df
extractAIC(glm.D93) # 56.76132 too
#
# But for LM:
lm.D93 &lt;- lm(counts ~ outcome + treatment, data=dataf)
logLik(lm.D93) # logL=-22.78576 (df=6)
extractAIC(fitme(counts ~ outcome + treatment, data=dataf)) # 57.5715 = -2 logL + 2* df
extractAIC(lm.D93) # 30.03062

### Inconsistency also apparent in drop1 output for :
# Toy data from McCullagh &amp; Nelder (1989, pp. 300-2), as in 'glm' doc:
clotting &lt;- data.frame(
    u = c(5,10,15,20,30,40,60,80,100),
    lot1 = c(118,58,42,35,27,25,21,19,18),
    lot2 = c(69,35,26,21,18,16,13,12,12))
#    
drop1( fitme(lot1 ~ log(u), data = clotting), test = "F") # agains reports marginal AIC
# =&gt; this  may differ strongly from those returned by drop1( &lt; glm() fit &gt; ),
# but the latter are not even consistent with those from drop1( &lt; lm() fit &gt; )
# for linear models. Compare
drop1( lm(lot1 ~ log(u), data = clotting), test = "F") # consistent with drop1.HLfit()
drop1( glm(lot1 ~ log(u), data = clotting), test = "F") # inconsistent

## Discrepancies in drop1 output with Gamma() family:

gglm &lt;- glm(lot1 ~ 1, data = clotting, family=Gamma())
logLik(gglm) # -40.34633 (df=2)

spgglm &lt;-  fitme(lot1 ~ 1, data = clotting, family=Gamma())
logLik(spgglm)                      # -40.33777 (slight difference: 
#   see help("method") for difference in estimation method between glm() and fitme()).
# Yet this does not explain the following:

drop1(  fitme(lot1 ~ log(u), data = clotting, family=Gamma()), test = "F") 
# =&gt; second AIC is 84.676 as expected from above logLik(spgglm).
drop1( glm(lot1 ~ log(u), data = clotting, family=Gamma()), test = "F") 
# =&gt; second AIC is 1465.27, quite different from -2*logLik(gglm) + 2*df


## End(Not run)

</code></pre>


</div>