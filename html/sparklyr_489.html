<div class="container">

<table style="width: 100%;"><tr>
<td>stream_read_csv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Read files created by the stream</h2>

<h3>Description</h3>

<p>Read files created by the stream
</p>


<h3>Usage</h3>

<pre><code class="language-R">stream_read_csv(
  sc,
  path,
  name = NULL,
  header = TRUE,
  columns = NULL,
  delimiter = ",",
  quote = "\"",
  escape = "\\",
  charset = "UTF-8",
  null_value = NULL,
  options = list(),
  ...
)

stream_read_text(sc, path, name = NULL, options = list(), ...)

stream_read_json(sc, path, name = NULL, columns = NULL, options = list(), ...)

stream_read_parquet(
  sc,
  path,
  name = NULL,
  columns = NULL,
  options = list(),
  ...
)

stream_read_orc(sc, path, name = NULL, columns = NULL, options = list(), ...)

stream_read_kafka(sc, name = NULL, options = list(), ...)

stream_read_socket(sc, name = NULL, columns = NULL, options = list(), ...)

stream_read_delta(sc, path, name = NULL, options = list(), ...)

stream_read_cloudfiles(sc, path, name = NULL, options = list(), ...)

stream_read_table(sc, path, name = NULL, options = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the ‘<span class="samp">⁠"hdfs://"⁠</span>’, ‘<span class="samp">⁠"s3a://"⁠</span>’ and ‘<span class="samp">⁠"file://"⁠</span>’ protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name to assign to the newly generated stream.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>header</code></td>
<td>
<p>Boolean; should the first row of data be used as a header?
Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>columns</code></td>
<td>
<p>A vector of column names or a named vector of column types.
If specified, the elements can be <code>"binary"</code> for <code>BinaryType</code>,
<code>"boolean"</code> for <code>BooleanType</code>, <code>"byte"</code> for <code>ByteType</code>,
<code>"integer"</code> for <code>IntegerType</code>, <code>"integer64"</code> for <code>LongType</code>,
<code>"double"</code> for <code>DoubleType</code>, <code>"character"</code> for <code>StringType</code>,
<code>"timestamp"</code> for <code>TimestampType</code> and <code>"date"</code> for <code>DateType</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delimiter</code></td>
<td>
<p>The character used to delimit each column. Defaults to ‘<span class="samp">⁠','⁠</span>’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quote</code></td>
<td>
<p>The character used as a quote. Defaults to ‘<span class="samp">⁠'"'⁠</span>’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>escape</code></td>
<td>
<p>The character used to escape other characters. Defaults to ‘<span class="samp">⁠'\'⁠</span>’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>charset</code></td>
<td>
<p>The character set. Defaults to ‘<span class="samp">⁠"UTF-8"⁠</span>’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null_value</code></td>
<td>
<p>The character to use for null, or missing, values. Defaults to <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>A list of strings with additional options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

sc &lt;- spark_connect(master = "local")

dir.create("csv-in")
write.csv(iris, "csv-in/data.csv", row.names = FALSE)

csv_path &lt;- file.path("file://", getwd(), "csv-in")

stream &lt;- stream_read_csv(sc, csv_path) %&gt;% stream_write_csv("csv-out")

stream_stop(stream)

## End(Not run)

</code></pre>


</div>