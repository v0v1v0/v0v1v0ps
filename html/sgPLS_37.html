<div class="container">

<table style="width: 100%;"><tr>
<td>tuning.sPLS.X</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Choice of the tuning parameter (number of variables) related to  predictor matrix for sPLS model (regression mode)</h2>

<h3>Description</h3>

<p>For a grid of tuning parameter, this function computes by leave-one-out or M-fold cross-validation the MSEP (Mean Square Error of Prediction) of a sPLS model. </p>


<h3>Usage</h3>

<pre><code class="language-R">tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), ncomp,
		keepX = NULL, grid.X, setseed, progressBar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times p)</code>, the observations on the <code class="reqn">X</code> variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times q)</code>, the observations on the <code class="reqn">Y</code> variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>Positive integer. Number of folds to use if <code>validation="Mfold"</code>. Defaults to
<code>folds=10</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation</code></td>
<td>
<p>Character string. What kind of (internal) cross-validation method to use, (partially) matching one of <code>"Mfolds"</code> (M-folds) or <code>"loo"</code> (leave-one-out).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>Number of component for investigating the choice of the tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepX</code></td>
<td>
<p>Vector of integer indicating the number of variables to keep in each component. See Details for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grid.X</code></td>
<td>
<p>Vector of integers defining the values of the tuning parameter (corresponding to the number of variables to select) at which cross-validation score should be computed. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>setseed</code></td>
<td>
<p>Integer indicating the random number generation state.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progressBar</code></td>
<td>
<p>By default set to <code>FALSE</code> to output the progress bar of the computation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>validation="Mfolds"</code>, M-fold cross-validation is performed by calling 
<code>Mfold</code>. The folds are generated. The number of cross-validation 
folds is specified with the argument <code>folds</code>. 
</p>
<p>If <code>validation="loo"</code>, 
leave-one-out cross-validation is performed by calling the 
<code>loo</code> function. In this case the arguments <code>folds</code> are ignored.
</p>
<p>if <code>keepX</code> is specified (by default is NULL), each element of <code>keepX</code> indicates the value of the tuning parameter for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-validation score at different values defining by <code>grid.X</code>.
</p>


<h3>Value</h3>

<p>The returned value is a list with components: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>MSEP</code></td>
<td>
<p>Vector containing the cross-validation score computed on the grid</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepX</code></td>
<td>
<p>Value of the tuning parameter on which
the cross-validation method reached it minimum.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 	
## Simulation of Datasets X (with group variables) and Y a multivariate response variable 
n &lt;- 200
sigma.e &lt;- 0.5
p &lt;- 400
q &lt;- 10
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
			rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

set.seed(125)
theta.y1 &lt;- runif(10, 0.5, 2)
theta.y2 &lt;- runif(10, 0.5, 2)
  
temp &lt;-  matrix(c(theta.y1, theta.y2), nrow = 2, byrow = TRUE)

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% t(svd(temp)$v)
     + rmvnorm(n, mean = rep(0, q), sigma = Sigmay, method = "svd")


grid.X &lt;- c(20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300)

## Strategy with same value for both components
tun.sPLS &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
		ncomp = 2, keepX = NULL, grid.X = grid.X, setseed = 1)
tun.sPLS$keepX # for each component

##For a sequential strategy
tun.sPLS.1 &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
		ncomp = 1, keepX = NULL, grid.X = grid.X, setseed = 1)

tun.sPLS.1$keepX # for the first component

tun.sPLS.2 &lt;- tuning.sPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"),
		 ncomp = 2, keepX = tun.sPLS.1$keepX , grid.X = grid.X, setseed = 1)
tun.sPLS.2$keepX # for the second component


## End(Not run)
</code></pre>


</div>