<div class="container">

<table style="width: 100%;"><tr>
<td>fit.twfcta</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TWFCTA model</h2>

<h3>Description</h3>

<p>Implements factorial reduction and then K-means clustering
in a sequential fashion.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fit.twfcta(model, X_i_jk, full_tensor_shape, reduced_tensor_shape)

## S4 method for signature 'tandem'
fit.twfcta(model, X_i_jk, full_tensor_shape, reduced_tensor_shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Initialized tandem model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_i_jk</code></td>
<td>
<p>Matricized tensor along mode-1 (I objects).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>full_tensor_shape</code></td>
<td>
<p>Dimensions of the tensor in full space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reduced_tensor_shape</code></td>
<td>
<p>Dimensions of tensor in the reduced space.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<p>The procedure implements sequential factorial decomposition and clustering.
</p>

<ul>
<li>
<p> The technique performs Tucker2 decomposition on the X_i_jk matrix
to obtain the matrix of component scores Y_i_qr with component weights
matrices B_j_q and C_k_r.
</p>
</li>
<li>
<p> The K-means clustering algorithm is then applied to the component
scores matrix Y_i_qr to obtain the desired core centroids matrix Y_g_qr
and its associated stochastic membership function matrix U_i_g.
</p>
</li>
</ul>
<h3>Value</h3>

<p>Output attributes accessible via the '@' operator.
</p>

<ul>
<li>
<p> U_i_g0 - Initial object membership function matrix.
</p>
</li>
<li>
<p> B_j_q0 - Initial factor/component matrix for the variables.
</p>
</li>
<li>
<p> C_k_r0 - Initial factor/component matrix for the occasions.
</p>
</li>
<li>
<p> U_i_g - Final/updated object membership function matrix.
</p>
</li>
<li>
<p> B_j_q - Final/updated factor/component matrix for the variables.
</p>
</li>
<li>
<p> C_k_r - Final/updated factor/component matrix for the occasions.
</p>
</li>
<li>
<p> Y_g_qr - Derived centroids in the reduced space (data matrix).
</p>
</li>
<li>
<p> X_i_jk_scaled - Standardized dataset matrix.
</p>
</li>
<li>
<p> BestTimeElapsed - Execution time for the best iterate.
</p>
</li>
<li>
<p> BestLoop - Loop that obtained the best iterate.
</p>
</li>
<li>
<p> BestKmIteration - Number of iteration until best iterate for the K-means.
</p>
</li>
<li>
<p> BestFaIteration - Number of iteration until best iterate for the FA.
</p>
</li>
<li>
<p> FaConverged - Flag to check if algorithm converged for the K-means.
</p>
</li>
<li>
<p> KmConverged - Flag to check if algorithm converged for the Factor Decomposition.
</p>
</li>
<li>
<p> nKmConverges - Number of loops that converged for the K-means.
</p>
</li>
<li>
<p> nFaConverges - Number of loops that converged for the Factor decomposition.
</p>
</li>
<li>
<p> TSS_full - Total deviance in the full-space.
</p>
</li>
<li>
<p> BSS_full - Between deviance in the reduced-space.
</p>
</li>
<li>
<p> RSS_full - Residual deviance in the reduced-space.
</p>
</li>
<li>
<p> PF_full - PseudoF in the full-space.
</p>
</li>
<li>
<p> TSS_reduced - Total deviance in the reduced-space.
</p>
</li>
<li>
<p> BSS_reduced - Between deviance in the reduced-space.
</p>
</li>
<li>
<p> RSS_reduced - Residual deviance in the reduced-space.
</p>
</li>
<li>
<p> PF_reduced - PseudoF in the reduced-space.
</p>
</li>
<li>
<p> PF - Actual PseudoF value to obtain best loop.
</p>
</li>
<li>
<p> Labels - Object cluster assignments.
</p>
</li>
<li>
<p> FsKM - Objective function values for the KM best iterate.
</p>
</li>
<li>
<p> FsFA - Objective function values for the FA best iterate.
</p>
</li>
<li>
<p> Enorm - Average l2 norm of the residual norm.
</p>
</li>
</ul>
<h3>Note</h3>



<ul>
<li>
<p> The technique helps interpret the within clusters variability of
the data. The Tucker2 tends to explain most of the total variation in
the dataset. Hence, the variance of variables that do not contribute to
the clustering structure in the dataset is also included.
</p>
</li>
<li>
<p> The Tucker2 dimensions may still mask some essential clustering
structures in the dataset.
</p>
</li>
</ul>
<h3>References</h3>

<p>Arabie P, Hubert L (1996).
“Advances in Cluster Analysis Relevant to Marketing Research.”
In Gaul W, Pfeifer D (eds.), <em>From Data to Knowledge</em>, 3–19.
Tucker L (1966).
“Some mathematical notes on three-mode factor analysis.”
<em>Psychometrika</em>, <b>31</b>(3), 279-311.
<a href="https://doi.org/10.1007/BF02289464">doi:10.1007/BF02289464</a>, <a href="https://ideas.repec.org/a/spr/psycho/v31y1966i3p279-311.html">https://ideas.repec.org/a/spr/psycho/v31y1966i3p279-311.html</a>.
</p>


<h3>See Also</h3>


<p><code>fit.twcfta</code> <code>tandem</code>

</p>


<h3>Examples</h3>

<pre><code class="language-R">X_i_jk = generate_dataset()$X_i_jk
model = tandem()
twfCta = fit.twfcta(model, X_i_jk, c(8,5,4), c(3,3,2))

</code></pre>


</div>