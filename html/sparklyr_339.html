<div class="container">

<table style="width: 100%;"><tr>
<td>sdf_persist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Persist a Spark DataFrame</h2>

<h3>Description</h3>

<p>Persist a Spark DataFrame, forcing any pending computations and (optionally)
serializing the results to disk.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sdf_persist(x, storage.level = "MEMORY_AND_DISK", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>storage.level</code></td>
<td>
<p>The storage level to be used. Please view the
<a href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence">Spark Documentation</a>
for information on what storage levels are accepted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>A name to assign this table. Passed to [sdf_register()].</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Spark DataFrames invoke their operations lazily – pending operations are
deferred until their results are actually needed. Persisting a Spark
DataFrame effectively 'forces' any pending computations, and then persists
the generated Spark DataFrame as requested (to memory, to disk, or
otherwise).
</p>
<p>Users of Spark should be careful to persist the results of any computations
which are non-deterministic – otherwise, one might see that the values
within a column seem to 'change' as new operations are performed on that
data set.
</p>


</div>