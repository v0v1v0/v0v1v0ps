<div class="container">

<table style="width: 100%;"><tr>
<td>logrr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Log ratio of spatial densities</h2>

<h3>Description</h3>

<p><code>logrr</code> computes the estimated log relative risk of
cases relative to controls. The log relative risk at
location s is defined as <code>r(s) = ln(f(s)/g(s))</code>. The
numerator, <code>f(s)</code>, is the spatial density of the
case group. The denominator, <code>g(s)</code>, is the spatial
density of the control group. If <code>nsim &gt; 0</code>, then
pointwise (at each pixel) tolerance envelopes are
estimated under the random labeling hypothesis. The
tolerance envelopes can be used to assess pixels where
the log relative risk differs significantly from zero.
See Details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">logrr(
  x,
  sigma = NULL,
  sigmacon = NULL,
  case = 2,
  nsim = 0,
  level = 0.9,
  alternative = "two.sided",
  envelope = "pixelwise",
  ...,
  bwargs = list(),
  weights = NULL,
  edge = TRUE,
  varcov = NULL,
  at = "pixels",
  leaveoneout = TRUE,
  adjust = 1,
  diggle = FALSE,
  kernel = "gaussian",
  scalekernel = is.character(kernel),
  positive = FALSE,
  verbose = TRUE,
  return_sims = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>ppp</code> object
package with marks for the case and control groups.
<code>x$marks</code> is assumed to be a factor. Automatic
conversion is attempted if it is not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Standard deviation of isotropic smoothing
kernel for cases. Either a numerical value, or a
function that computes an appropriate value of
<code>sigma</code>. If not specified, then
<code>bw.relrisk</code> is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmacon</code></td>
<td>
<p>Standard deviation of isotropic smoothing
kernel for controls.  Default is the same as
<code>sigma</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case</code></td>
<td>
<p>The name of the desired "case" group in
<code>levels(x$marks)</code>. Alternatively, the position of
the name of the "case" group in <code>levels(x$marks)</code>.
Since we don't know the group names, the default is 2,
the second position of <code>levels(x$marks)</code>.
<code>x$marks</code> is assumed to be a factor.  Automatic
conversion is attempted if it is not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>
<p>The number of simulated data sets from which
to construct tolerance envelopes under the random
labeling hypothesis.  The default is 0 (i.e., no
envelopes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>
<p>The level of the tolerance envelopes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>The type of envelopes to construct.
The default is <code>"two.sided"</code> (upper and lower
envelopes).  The values <code>"less"</code> (lower envelope)
and <code>"greater"</code> (upper envelope) are also valid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>envelope</code></td>
<td>
<p>The type of envelope to construct. The
default is <code>"pixelwise"</code>. The other option is
<code>"simulataneous"</code>, which controls the tolerance
level across the entire study area.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Additional arguments passed to <code>pixellate.ppp</code>
and <code>as.mask</code> to determine
the pixel resolution, or passed to <code>sigma</code> if it is a function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bwargs</code></td>
<td>
<p>A list of arguments for the bandwidth
function supplied to <code>sigma</code> and <code>sigmacon</code>,
if applicable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>

<p>Optional weights to be attached to the points.
A numeric vector, numeric matrix, an <code>expression</code>,
or a pixel image.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>edge</code></td>
<td>

<p>Logical value indicating whether to apply edge correction.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varcov</code></td>
<td>

<p>Variance-covariance matrix of anisotropic smoothing kernel.
Incompatible with <code>sigma</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>at</code></td>
<td>

<p>String specifying whether to compute the intensity values
at a grid of pixel locations (<code>at="pixels"</code>) or
only at the points of <code>x</code> (<code>at="points"</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>leaveoneout</code></td>
<td>

<p>Logical value indicating whether to compute a leave-one-out
estimator. Applicable only when <code>at="points"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adjust</code></td>
<td>

<p>Optional. Adjustment factor for the smoothing parameter.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diggle</code></td>
<td>

<p>Logical. If <code>TRUE</code>, use the Jones-Diggle improved edge correction,
which is more accurate but slower to compute than the default
correction.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>

<p>The smoothing kernel.
A character string specifying the smoothing kernel
(current options are <code>"gaussian"</code>, <code>"epanechnikov"</code>,
<code>"quartic"</code> or <code>"disc"</code>),
or a pixel image (object of class <code>"im"</code>)
containing values of the kernel, or a <code>function(x,y)</code> which
yields values of the kernel.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scalekernel</code></td>
<td>

<p>Logical value.
If <code>scalekernel=TRUE</code>, then the kernel will be rescaled
to the bandwidth determined by <code>sigma</code> and <code>varcov</code>:
this is the default behaviour when <code>kernel</code> is a character string.
If <code>scalekernel=FALSE</code>, then <code>sigma</code> and <code>varcov</code>
will be ignored: this is the default behaviour when <code>kernel</code> is a
function or a pixel image.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positive</code></td>
<td>

<p>Logical value indicating whether to force all density values to
be positive numbers. Default is <code>FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>Logical value indicating whether to issue warnings
about numerical problems and conditions.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_sims</code></td>
<td>
<p>A logical value indicating whether
parts of the simulated data shoudl be returned. The
default is <code>FALSE</code>. This is mostly used for
debugging purposes.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>nsim=0</code>, the <code>plot</code> function creates a heat
map of the log relative risk. If <code>nsim &gt; 0</code>, the
<code>plot</code> function colors the pixels where the
estimated log relative risk is outside the tolerance
envelopes created under the random labeling hypothesis
(i.e., pixels with potential clustering of cases or
controls). Colored regions with values above 0 indicate a
cluster of cases relative to controls (without
controlling for multiple comparisons), i.e., a region
where the the density of the cases is greater than the
the density of the controls. Colored regions with values
below 0 indicate a cluster of controls relative to cases
(without controlling for multiple comparisons), i.e., a
region where the density of the controls is greater than
the density of the cases.
</p>
<p>The <code>two.sided</code> alternative test constructs
two-sided tolerance envelopes to assess whether the
estimated <code>r(s)</code> deviates more than what is expected
under the random labeling hypothesis.  The <code>greater</code>
alternative constructs an upper tolerance envelope to
assess whether the estimated <code>r(s)</code> is greater than
what is expected under the random labeling hypothesis,
i.e., where there is clustering of cases relative to
controls. The <code>lower</code> alternative constructs a lower
tolerance envelope to assess whether the estimated
<code>r(s)</code> is lower than what is expected under the
random labeling hypothesis, i.e., where there is
clustering of controls relative to cases.
</p>
<p>If the estimated density of the case or control group
becomes too small, this function may produce warnings due
to numerical underflow. Increasing the bandwidth
(<code>sigma</code>) may help.
</p>


<h3>Value</h3>

<p>The function produces an object of type
<code>logrrenv</code>.  Its components are similar to those
returned by the
<code>density.ppp</code>, with the
intensity values replaced by the log ratio of spatial
densities of f and g.  Includes an array <code>simr</code> of
dimension c(nx, ny, nsim + 1), where nx and ny are the
number of x and y grid points used to estimate the
spatial density. <code>simr[,,1]</code> is the log ratio of
spatial densities for the observed data, and the
remaining <code>nsim</code> elements in the third dimension
of the array are the log ratios of spatial densities
from a new ppp simulated under the random labeling
hypothesis.
</p>


<h3>Author(s)</h3>

<p>Joshua French (and a small chunk by the authors
of the <code>density.ppp</code>)
function for consistency with the default behavior of
that function).
</p>


<h3>References</h3>

<p>Waller, L.A. and Gotway, C.A. (2005). Applied
Spatial Statistics for Public Health Data. Hoboken, NJ:
Wiley.
</p>
<p>Kelsall, Julia E., and Peter J. Diggle. "Kernel
estimation of relative risk." Bernoulli (1995): 3-16.
</p>
<p>Kelsall, Julia E., and Peter J. Diggle. "Non-parametric
estimation of spatial variation in relative risk."
Statistics in Medicine 14.21-22 (1995): 2335-2342.
</p>
<p>Hegg, Alex and French, Joshua P. (2022) "Simultaneous
tolerance bands of log relative risk for 
case-control point data. Technical report.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(grave)
# estimate and plot log relative risk
r = logrr(grave, case = "affected")
plot(r)
# use scott's bandwidth
r2 = logrr(grave, case = 2, sigma = spatstat.explore::bw.scott)
plot(r2)
# construct pointwise tolerance envelopes for log relative risk
## Not run: 
renv = logrr(grave, nsim = 9)
print(renv) # print information about envelopes
plot(renv) # plot results
# plot using a better gradient
grad = gradient.color.scale(min(renv$v, na.rm = TRUE), max(renv$v, na.rm = TRUE))
plot(renv, col = grad$col, breaks = grad$breaks, conlist = list(col = "lightgrey"))
## End(Not run)
</code></pre>


</div>