<div class="container">

<table style="width: 100%;"><tr>
<td>sts</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Variational EM for the Structural Topic and Sentiment-Discourse (STS) Model</h2>

<h3>Description</h3>

<p>Estimation of the STS Model using variational EM.
The function takes sparse representation of a document-term matrix, covariates 
for each document, and an integer number of topics and returns fitted model 
parameters. See an overview of functions in the package here: 
<code>sts-package</code>
</p>


<h3>Usage</h3>

<pre><code class="language-R">sts(
  X,
  X_seed,
  corpus,
  numTopics,
  maxIter = 100,
  initialization = "stm",
  estimation = "lasso",
  verbose = TRUE,
  parallelize = FALSE,
  stmSeed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Data frame of document-specific content covariates affect how much (prevalence) and
the way in which a topic is discussed (sentiment-discourse).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_seed</code></td>
<td>
<p>A vector of length equal to the corpus size. This is the key experimental variable (e.g., review rating or binary indicator of experiment/control group.).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corpus</code></td>
<td>
<p>The document term matrix to be modeled in a sparse term count matrix with one row
per document and one column per term. The object must be a list of with each element 
corresponding to a document. Each document is represented
as an integer matrix with two rows, and columns equal to the number of unique
vocabulary words in the document.  The first row contains the 1-indexed
vocabulary entry and the second row contains the number of times that term
appears. This is the same format in the <code>stm</code> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numTopics</code></td>
<td>
<p>A positive integer (of size 2 or greater) representing
the desired number of topics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxIter</code></td>
<td>
<p>A positive integer representing the max number of VEM iterations allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initialization</code></td>
<td>
<p>Character argument that allows the user to specify an initialization
method. The default choice, <code>"stm"</code>, uses a fitted STM model (Roberts et al. 2014, 2016) 
to initialize coefficients related to prevalence and sentiment-discourse. 
One can also choose <code>"anchor"</code> to initialize prevalence according to anchor words and 
the key experimental covariate identified in argument <code>X_seed</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimation</code></td>
<td>
<p>A character input specifying how kappa should be estimated. <code>"lasso"</code> (default) allows for 
penalties on the L1 norm.  We estimate a regularization path and then select the optimal
shrinkage parameter using AIC. <code>"adjusted"</code> does not utilize the lasso penalty. 
All options use an approximation framework developed in Taddy (2013) called
Distributed Multinomial Regression which utilizes a factorized poisson
approximation to the multinomial.  See Li and Mankad (forthcoming) on the implementation here.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A logical flag indicating whether information should be
printed to the screen.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallelize</code></td>
<td>
<p>A logical flag indicating whether to parallelize the estimation using all but one CPU cores on your local machine.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stmSeed</code></td>
<td>
<p>A prefit STM model object to initialize the STS model. Note this is ignored unless initialization = "stm"</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is the main function for estimating the Structural Topic and 
Sentiment-Discourse (STS) Model. Users provide a corpus of documents and a 
number of topics.  Each word in a document comes from exactly one topic and 
each document is represented by the proportion of its words that come from 
each of the topics. The document-specific content covariates affect how much 
(prevalence) and the way in which a topic is discussed (sentiment-discourse).
</p>


<h3>Value</h3>

<p>An object of class sts 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Estimated prevalence and sentiment-discourse values for each document and topic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>Estimated regression coefficients that determine prevalence and sentiment/discourse for each topic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p>Estimated kappa coefficients that determine sentiment-discourse and the topic-word distributions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma_inv</code></td>
<td>
<p>Inverse of the covariance matrix for the alpha parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Covariance matrix for the alpha parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>elbo</code></td>
<td>
<p>the ELBO at each iteration of the estimation algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mv</code></td>
<td>
<p>the baseline log-transformed occurrence rate of each word in the corpus</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runtime</code></td>
<td>
<p>Time elapsed in seconds</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab</code></td>
<td>
<p>Vocabulary vector used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Mean (fitted) values for alpha based on document-level variables * estimated 
Gamma for each document</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Roberts, M., Stewart, B., Tingley, D., and Airoldi, E. (2013)
"The structural topic model and applied social science." In Advances in
Neural Information Processing Systems Workshop on Topic Models: Computation,
Application, and Evaluation. 
</p>
<p>Roberts M., Stewart, B. and Airoldi, E. (2016) "A model of text for
experimentation in the social sciences" Journal of the American Statistical
Association.
</p>
<p>Chen L. and Mankad, S. (forthcoming) "A Structural Topic and Sentiment-Discourse Model
for Text Analysis" Management Science.
</p>


<h3>See Also</h3>

<p><code>estimateRegnTables</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">#An example using the Gadarian data from the stm package.  From Raw text to 
# fitted model using textProcessor() which leverages the tm Package
library("tm"); library("stm"); library("sts")
temp&lt;-textProcessor(documents=gadarian$open.ended.response,
metadata=gadarian, verbose = FALSE)
out &lt;- prepDocuments(temp$documents, temp$vocab, temp$meta, verbose = FALSE)
X &lt;- model.matrix(~1+out$meta$treatment + out$meta$pid_rep + 
out$meta$treatment * out$meta$pid_rep)[,-1]
X_seed &lt;- as.matrix(out$meta$treatment)
## low max iteration number just for testing
sts_estimate &lt;- sts(X, X_seed, out, numTopics = 3, verbose = FALSE, 
parallelize = FALSE, maxIter = 3, initialization = 'anchor')
</code></pre>


</div>