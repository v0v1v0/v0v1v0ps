<div class="container">

<table style="width: 100%;"><tr>
<td>compare_two_models</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compare Two Models Based on Subset of Common Forecasts</h2>

<h3>Description</h3>

<p>This function compares two models based on the subset of forecasts for which
both models have made a prediction. It gets called
from <code>pairwise_comparison_one_group()</code>, which handles the
comparison of multiple models on a single set of forecasts (there are no
subsets of forecasts to be distinguished). <code>pairwise_comparison_one_group()</code>
in turn gets called from from <code>pairwise_comparison()</code> which can handle
pairwise comparisons for a set of forecasts with multiple subsets, e.g.
pairwise comparisons for one set of forecasts, but done separately for two
different forecast targets.
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare_two_models(
  scores,
  name_model1,
  name_model2,
  metric,
  one_sided = FALSE,
  test_type = c("non_parametric", "permutation"),
  n_permutations = 999
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>A data.table of scores as produced by <code>score()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name_model1</code></td>
<td>
<p>character, name of the first model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name_model2</code></td>
<td>
<p>character, name of the model to compare against</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>A character vector of length one with the metric to do the
comparison on. The default is "auto", meaning that either "interval_score",
"crps", or "brier_score" will be selected where available.
See <code>available_metrics()</code> for available metrics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>one_sided</code></td>
<td>
<p>Boolean, default is <code>FALSE</code>, whether two conduct a one-sided
instead of a two-sided test to determine significance in a pairwise
comparison.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_type</code></td>
<td>
<p>character, either "non_parametric" (the default) or
"permutation". This determines which kind of test shall be conducted to
determine p-values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_permutations</code></td>
<td>
<p>numeric, the number of permutations for a
permutation test. Default is 999.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Johannes Bracher, <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a>
</p>
<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>


</div>