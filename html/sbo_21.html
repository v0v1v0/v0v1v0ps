<div class="container">

<table style="width: 100%;"><tr>
<td>kgram_freqs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k-gram frequency tables</h2>

<h3>Description</h3>

<p>Get k-gram frequency tables from a training corpus.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kgram_freqs(corpus, N, dict, .preprocess = identity, EOS = "")

sbo_kgram_freqs(corpus, N, dict, .preprocess = identity, EOS = "")

kgram_freqs_fast(corpus, N, dict, erase = "", lower_case = FALSE, EOS = "")

sbo_kgram_freqs_fast(corpus, N, dict, erase = "", lower_case = FALSE, EOS = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>corpus</code></td>
<td>
<p>a character vector. The training corpus from which to extract
k-gram frequencies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>a length one integer. The maximum order of k-grams
for which frequencies are to be extracted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dict</code></td>
<td>
<p>either a <code>sbo_dictionary</code> object, a character vector,
or a formula (see details). The language model dictionary.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.preprocess</code></td>
<td>
<p>a function to apply before k-gram
tokenization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EOS</code></td>
<td>
<p>a length one character vector listing all (single character)
end-of-sentence tokens.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>erase</code></td>
<td>
<p>a length one character vector. Regular expression matching
parts  of text to be erased from input. The default removes anything not
alphanumeric, white space, apostrophes or punctuation characters
(i.e. ".?!:;").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower_case</code></td>
<td>
<p>a length one logical vector. If TRUE, puts everything to
lower case.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>These functions extract all k-gram frequency tables from a text
corpus up to a specified k-gram order N. These are
the building blocks to train any N-gram model. The functions
<code>sbo_kgram_freqs()</code> and <code>sbo_kgram_freqs_fast()</code> are aliases for
<code>kgram_freqs()</code> and <code>kgram_freqs_fast()</code>, respectively.
</p>
<p>The optimized version <code>kgram_freqs_fast(erase = x, lower_case = y)</code>
is equivalent to
<code>kgram_freqs(.preprocess = preprocess(erase = x, lower_case = y))</code>,
but more efficient (both from the speed and memory point of view).
</p>
<p>Both <code>kgram_freqs()</code> and <code>kgram_freqs_fast()</code> employ a fixed
(user specified) dictionary: any out-of-vocabulary word gets effectively
replaced by an "unknown word" token. This is specified through the argument
<code>dict</code>, which accepts three types of arguments: a <code>sbo_dictionary</code>
object, a character vector (containing the words of the dictionary) or a
formula. In this last case, valid formulas can be either <code>max_size ~ V</code>
or <code>target ~ f</code>, where <code>V</code> and <code>f</code> represent a dictionary size
and a corpus word coverage fraction (of <code>corpus</code>), respectively. This
usage of the <code>dict</code> argument allows to build the model dictionary
'on the fly'.
</p>
<p>The return value is a "<code>sbo_kgram_freqs</code>" object, i.e. a list of N tibbles,
storing frequency counts for each k-gram observed in the training corpus, for
k = 1, 2, ..., N. In these tables, words are represented by
integer numbers corresponding to their position in the
reference dictionary. The special codes <code>0</code>,
<code>length(dictionary)+1</code> and <code>length(dictionary)+2</code>
correspond to the "Begin-Of-Sentence", "End-Of-Sentence"
and "Unknown word" tokens, respectively.
</p>
<p>Furthermore, the returned objected has the following attributes:
</p>

<ul>
<li> <p><code>N</code>: The highest order of N-grams.
</p>
</li>
<li> <p><code>dict</code>: The reference dictionary, sorted by word frequency.
</p>
</li>
<li> <p><code>.preprocess</code>: The function used for text preprocessing.
</p>
</li>
<li> <p><code>EOS</code>: A length one character vector listing all (single character)
end-of-sentence tokens employed in k-gram tokenization.
</p>
</li>
</ul>
<p>The <code>.preprocess</code> argument of <code>kgram_freqs</code> allows the user to
apply a custom transformation to the training corpus, before kgram
tokenization takes place.
</p>
<p>The algorithm for k-gram tokenization considers anything separated by
(any number of) white spaces (i.e. " ") as a single word. Sentences are split
according to end-of-sentence (single character) tokens, as specified
by the <code>EOS</code> argument. Additionally text belonging to different entries of
the preprocessed input vector which are understood to belong to different
sentences.
</p>
<p><em>Nota Bene</em>: It is useful to keep in mind that the function
passed through the  <code>.preprocess</code> argument also captures its enclosing
environment, which is by default the environment in which the former
was defined.
If, for instance, <code>.preprocess</code> was defined in the global environment,
and the latter binds heavy objects, the resulting <code>sbo_kgram_freqs</code> will
contain bindings to the same objects. If <code>sbo_kgram_freqs</code> is stored out of
memory and recalled in another R session, these objects will also be reloaded
in memory.
For this reason, for non interactive use, it is advisable to avoid using
preprocessing functions defined in the global environment
(for instance, <code>base::identity</code> is preferred to <code>function(x) x</code>).
</p>


<h3>Value</h3>

<p>A <code>sbo_kgram_freqs</code> object, containing the k-gram
frequency tables for k = 1, 2, ..., N.
</p>


<h3>Author(s)</h3>

<p>Valerio Gherardi
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Obtain k-gram frequency table from corpus
## Get k-gram frequencies, for k &lt;= N = 3.
## The dictionary is built on the fly, using the most frequent 1000 words.
freqs &lt;- kgram_freqs(corpus = twitter_train, N = 3, dict = max_size ~ 1000,
                     .preprocess = preprocess, EOS = ".?!:;")
freqs
## Using a predefined dictionary
freqs &lt;- kgram_freqs_fast(twitter_train, N = 3, dict = twitter_dict,
                          erase = "[^.?!:;'\\w\\s]", lower_case = TRUE,
                          EOS = ".?!:;")
freqs
## 2-grams, no preprocessing, use a dictionary covering 50% of corpus
freqs &lt;- kgram_freqs(corpus = twitter_train, N = 2, dict = target ~ 0.5,
                     EOS = ".?!:;")
freqs


# Obtain k-gram frequency table from corpus
freqs &lt;- kgram_freqs_fast(twitter_train, N = 3, dict = twitter_dict)
## Print result
freqs

</code></pre>


</div>