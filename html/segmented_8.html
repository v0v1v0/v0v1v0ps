<div class="container">

<table style="width: 100%;"><tr>
<td>davies.test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Testing for a change in the slope </h2>

<h3>Description</h3>

<p>Given a generalized linear model, the Davies' test can be employed to test for a non-constant regression parameter
in the linear predictor.
</p>


<h3>Usage</h3>

<pre><code class="language-R">davies.test(obj, seg.Z, k = 10, alternative = c("two.sided", "less", "greater"), 
    type=c("lrt","wald"), values=NULL, dispersion=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p> a fitted model typically returned by <code>glm</code> or <code>lm</code>. Even an object returned 
by <code>segmented</code> can be set (e.g. if interest lies in testing for an additional breakpoint).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seg.Z</code></td>
<td>
<p> a formula with no response variable, such as <code>seg.Z=~x1</code>, indicating the 
(continuous) segmented variable being tested. Only a single variable may be tested and an
error is printed when <code>seg.Z</code> includes two or more terms. <code>seg.Z</code> can be omitted if i)<code>obj</code> is a segmented fit with a single segmented covariate (and that variable is taken), or ii)if it is a "lm" or "glm" fit with a single covariate (and that variable is taken)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p> number of points where the test should be evaluated. See Details. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p> a character string specifying the alternative hypothesis (relevant to the slope difference parameter). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p> the test statistic to be used (only for GLM, default to lrt). 
Ignored if <code>obj</code> is a simple linear model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>values</code></td>
<td>
<p> optional. The evaluation points where the Davies approximation is computed. See Details for default values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dispersion</code></td>
<td>
<p> the dispersion parameter for the family to be used to compute the test statistic.
When <code>NULL</code> (the default), it is inferred from <code>obj</code>. Namely it is taken as <code>1</code> for the
Binomial and Poisson families, and otherwise estimated by the residual Chi-squared statistic (calculated from cases with
non-zero weights) divided by the residual degrees of freedom.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>davies.test</code> tests for a non-zero difference-in-slope parameter of a segmented
relationship. Namely, the null hypothesis is <code class="reqn">H_0:\beta=0</code>, where <code class="reqn">\beta</code> is the difference-in-slopes, 
i.e. the coefficient of the segmented function <code class="reqn">\beta(x-\psi)_+</code>. The hypothesis of interest 
<code class="reqn">\beta=0</code> means no breakpoint. 
Roughtly speaking, the procedure computes <code>k</code> ‘naive’ (i.e. assuming
fixed and known the breakpoint) test statistics for the difference-in-slope,
seeks the ‘best’ value and corresponding naive p-value (according to the alternative hypothesis), and then corrects 
the selected (minimum) p-value by means of the <code>k</code> values of the test statistic. 
If <code>obj</code> is a LM, the Davies (2002) test is implemented. This approach works even for small samples. 
If <code>obj</code> represents a GLM fit, relevant methods are described in Davies (1987), and the Wald or the Likelihood ratio 
test statistics can be used, see argument <code>type</code>. This is an asymptotic test.
The <code>k</code> evaluation points are <code>k</code> equally spaced values between the second and the second-last 
values of the variable reported in <code>seg.Z</code>. <code>k</code> should not be small; I find no important difference for <code>k</code> larger than 10, so default 
is <code>k=10</code>. 
</p>


<h3>Value</h3>

<p>A list with class '<code>htest</code>' containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>title (character)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>the regression model and the segmented variable being tested</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>statistic </code></td>
<td>
<p>the point within the range of the covariate in <code>seg.Z</code> at which the maximum 
(or the minimum if <code>alternative="less"</code>) occurs</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter </code></td>
<td>
<p>number of evaluation points</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value </code></td>
<td>
<p>the adjusted p-value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>process</code></td>
<td>
<p>a two-column matrix including the evaluation points and corresponding values of the test statistic</p>
</td>
</tr>
</table>
<h3>Warning </h3>

<p>The Davies test is <em>not</em> aimed at obtaining the estimate of the breakpoint.
The Davies test is based on <code>k</code> evaluation points, thus the value returned in the <code>statistic</code> component
(and printed as "'best' at") is the best among the <code>k</code> points, and typically it will differ from the maximum likelihood estimate
returned by <code>segmented</code>. Use <code>segmented</code> if you are interested in the point estimate. 
</p>
<p>To test for a breakpoint in <em>linear</em> models with small samples, it is suggested to use <code>davies.test()</code> with 
objects of class "lm". If <code>obj</code> is a <code>"glm"</code> object with gaussian family, <code>davies.test()</code> will use 
an approximate test resulting in smaller p-values when the sample is small. 
However if the sample size is large (n&gt;300), the exact Davies (2002) upper bound cannot be computed (as it relies on 
<code>gamma()</code> function) and the <em>approximate</em> upper bound of Davies (1987) is returned.
</p>


<h3>Note</h3>

<p>Strictly speaking,
the Davies test is not confined to the segmented regression; the procedure can be applied when a nuisance parameter
vanishes under the null hypothesis. The test is slightly conservative, as the computed p-value is actually an upper
bound.
</p>
<p>Results should change slightly with respect to previous versions  where the evaluation points were computed 
as <code>k</code> equally spaced values between the second and the second last observed values of the segmented 
variable. 
</p>


<h3>Author(s)</h3>

<p> Vito M.R. Muggeo </p>


<h3>References</h3>

<p>Davies, R.B. (1987) Hypothesis testing when a nuisance parameter is present only under the alternative.
<em>Biometrika</em> <b>74</b>, 33–43. 
</p>
<p>Davies, R.B. (2002) Hypothesis testing when a nuisance parameter is present only under the alternative: 
linear model case. <em>Biometrika</em> <b>89</b>, 484–489. 
</p>


<h3>See Also</h3>

<p>See also <code>pscore.test</code> which is more powerful, especially when the signal-to-noise ratio is low. </p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
set.seed(20)
z&lt;-runif(100)
x&lt;-rnorm(100,2)
y&lt;-2+10*pmax(z-.5,0)+rnorm(100,0,3)

o&lt;-lm(y~z+x)
davies.test(o,~z)
davies.test(o,~x)

o&lt;-glm(y~z+x)
davies.test(o,~z) #it works but the p-value is too small..
  
## End(Not run)
</code></pre>


</div>