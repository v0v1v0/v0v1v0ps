<div class="container">

<table style="width: 100%;"><tr>
<td>exclusivitySTS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Exclusivity</h2>

<h3>Description</h3>

<p>Calculate an exclusivity metric for an STS model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">exclusivitySTS(beta, M = 10, frexw = 0.7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>the beta probability  matrix (topic-word distributions) for a given document or alpha-level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>the number of top words to consider per topic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frexw</code></td>
<td>
<p>the frex weight</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Roberts et al 2014 proposed an exclusivity measure to help with topic model 
selection. 
</p>
<p>The exclusivity measure includes some information on word frequency as well.  
It is based on the FREX
labeling metric (see Roberts et al. 2014) with the weight set to .7 in 
favor of exclusivity by default.
</p>


<h3>Value</h3>

<p>a numeric vector containing exclusivity for each topic
</p>


<h3>References</h3>

<p>Mimno, D., Wallach, H. M., Talley, E., Leenders, M., and 
McCallum, A. (2011, July). "Optimizing semantic coherence in topic models." 
In Proceedings of the Conference on Empirical Methods in 
Natural Language Processing (pp. 262-272). Association for 
Computational Linguistics. Chicago
</p>
<p>Bischof and Airoldi (2012) "Summarizing topical content with word frequency 
and exclusivity" In Proceedings of the International Conference on 
Machine Learning.
</p>
<p>Roberts, M., Stewart, B., Tingley, D., Lucas, C., Leder-Luis, J., 
Gadarian, S., Albertson, B., et al. (2014). 
"Structural topic models for open ended survey responses." American Journal 
of Political Science, 58(4), 1064-1082.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> 
#An example using the Gadarian data from the stm package.  
# From Raw text to fitted model using textProcessor() which leverages the 
# tm Package
library("tm"); library("stm"); library("sts")
temp&lt;-textProcessor(documents=gadarian$open.ended.response,
metadata=gadarian, verbose = FALSE)
out &lt;- prepDocuments(temp$documents, temp$vocab, temp$meta, verbose = FALSE)
X &lt;- model.matrix(~1+out$meta$treatment + out$meta$pid_rep + 
out$meta$treatment * out$meta$pid_rep)[,-1]
X_seed &lt;- as.matrix(out$meta$treatment)
## low max iteration number just for testing
sts_estimate &lt;- sts(X, X_seed, out, numTopics = 3, verbose = FALSE, 
parallelize = FALSE, maxIter = 3, initialization = 'anchor')
full_beta_distn &lt;- exp(sts_estimate$mv + sts_estimate$kappa$kappa_t + 
sts_estimate$kappa$kappa_s %*% diag(apply(sts_estimate$alpha[,3:5], 2, mean)))
full_beta_distn &lt;- t(apply(full_beta_distn, 1, 
function(m) m / colSums(full_beta_distn)))
exclusivitySTS(full_beta_distn)

</code></pre>


</div>