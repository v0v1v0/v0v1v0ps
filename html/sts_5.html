<div class="container">

<table style="width: 100%;"><tr>
<td>heldoutLikelihood</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Heldout Log-Likelihood</h2>

<h3>Description</h3>

<p>Compute the heldout log-likelihood of the STS model
</p>


<h3>Usage</h3>

<pre><code class="language-R">heldoutLikelihood(mv, kappa, alpha, missing)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mv</code></td>
<td>
<p>the baseline log-transformed occurrence rate of each word in the 
corpus</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p>the estimated kappa coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the estimated alpha values for the corpus</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>missing</code></td>
<td>
<p>list of which words and documents are in the heldout set</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>expected.heldout is the average of the held-out log-likelihood values 
for each document.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("tm"); library("stm"); library("sts")
temp&lt;-textProcessor(documents=gadarian$open.ended.response,
metadata=gadarian, verbose = FALSE)
out &lt;- prepDocuments(temp$documents, temp$vocab, temp$meta, verbose = FALSE)
X &lt;- model.matrix(~1+out$meta$treatment + out$meta$pid_rep + 
out$meta$treatment * out$meta$pid_rep)[,-1]
X_seed &lt;- as.matrix(out$meta$treatment)
out &lt;- make.heldout(out$documents, out$vocab)
## low max iteration number just for testing
sts_estimate &lt;- sts(X, X_seed, out, numTopics = 3, verbose = FALSE, 
parallelize = FALSE, maxIter = 3, initialization = 'anchor')
sm &lt;- sample(x=1:length(out$missing$index), 
size = length(out$missing$index)*0.8, replace = TRUE)
d.h &lt;- list(index = out$missing$index[sm], docs = out$missing$docs[sm])
heldoutLikelihood(mv=sts_estimate$mv, kappa=sts_estimate$kappa, 
alpha=sts_estimate$alpha, missing=d.h)$expected.heldout
</code></pre>


</div>