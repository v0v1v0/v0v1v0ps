<div class="container">

<table style="width: 100%;"><tr>
<td>stabsel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Stability Selection
</h2>

<h3>Description</h3>

<p>Selection of influential variables or model components with error control.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## generic stability selection funcion
stabsel(x, ...)

## a method to fit models with stability selection
## S3 method for class 'matrix'
stabsel(x, y, fitfun = lars.lasso,
        args.fitfun = list(), cutoff, q, PFER,
        folds = subsample(rep(1, nrow(x)), B = B),
        B = ifelse(sampling.type == "MB", 100, 50),
        assumption = c("unimodal", "r-concave", "none"),
        sampling.type = c("SS", "MB"),
        papply = mclapply, mc.preschedule = FALSE,
        verbose = TRUE, FWER, eval = TRUE, ...)

## essentially a wrapper for data.frames (see details)
## S3 method for class 'data.frame'
stabsel(x,  y, intercept = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code>
containing the predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector or matrix containing the outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical. If <code>x</code> is a <code>data.frame</code>,
this argument determines if the resulting model matrix should
contain a separate intercept or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitfun</code></td>
<td>
<p>a function that takes the arguments <code>x</code>, <code>y</code>
as above, and additionally the number of variables to include in
each model <code>q</code>. The function then needs to fit the model and to
return a logical vector that indicates which variable was selected
(among the <code>q</code> selected variables).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args.fitfun</code></td>
<td>
<p>a named list containing additional arguments that are
passed to the fitting function; see also argument <code>args</code> in
<code>do.call</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>cutoff between 0.5 and 1. Preferably a value between 0.6
and 0.9 should be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>number of (unique) selected variables (or groups of variables
depending on the model) that are selected on each subsample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PFER</code></td>
<td>
<p>upper bound for the per-family error rate. This
specifies the amount of falsely selected base-learners, which is
tolerated. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p> a weight matrix with number of rows equal to the number
of observations, see <code>subsample</code>. Usually one should not
change the default here as subsampling with a fraction of <code class="reqn">1/2</code>
is needed for the error bounds to hold. One usage scenario where
specifying the folds by hand might be the case when one has
dependent data (e.g. clusters) and thus wants to draw clusters
(i.e., multiple rows together) not individuals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>assumption</code></td>
<td>
<p> Defines the type of assumptions on the
distributions of the selection probabilities and simultaneous
selection probabilities. Only applicable for
<code>sampling.type = "SS"</code>. Per default, <code>"unimodality"</code> is assumed.
For <code>sampling.type = "MB"</code> we always use <code>"none"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sampling.type</code></td>
<td>
<p> use sampling scheme of of Shah &amp; Samworth
(2013), i.e., with complementarty pairs (<code>sampling.type = "SS"</code>),
or the original sampling scheme of Meinshausen &amp; Buehlmann (2010).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p> number of subsampling replicates. Per default, we use 50
complementary pairs for the error bounds of Shah &amp; Samworth (2013)
and 100 for the error bound derived in  Meinshausen &amp; Buehlmann
(2010). As we use <code class="reqn">B</code> complementray pairs in the former case
this leads to <code class="reqn">2B</code> subsamples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>papply</code></td>
<td>
<p> (parallel) apply function, defaults to
<code>mclapply</code>. Alternatively, <code>parLapply</code>
can be used. In the latter case, usually more setup is needed (see
example of <code>cvrisk</code> for some details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mc.preschedule</code></td>
<td>

<p>preschedule tasks if <code>papply = mclapply</code> (default:
<code>mc.preschedule = FALSE</code>)? For details see <code>mclapply</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p> logical (default: <code>TRUE</code>) that determines wether
<code>warnings</code> should be issued. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FWER</code></td>
<td>
<p> deprecated. Only for compatibility with older versions,
use PFER instead.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eval</code></td>
<td>
<p> logical. Determines whether stability selection is
evaluated (<code>eval = TRUE</code>; default) or if only the parameter
combination is returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> additional arguments to parallel apply methods such as
<code>mclapply</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function implements the stability selection procedure by
Meinshausen and Buehlmann (2010) and the improved error bounds by Shah
and Samworth (2013). For details see also Hofner et al. (2014). The
error bounds are implemented in the function
<code>stabsel_parameters</code>. Two of the three arguments
<code>cutoff</code>, <code>q</code> and <code>PFER</code> <em>must</em> be specified. The
per-family error rate (PFER), i.e., the expected number of false
positives <code class="reqn">E(V)</code>, where <code class="reqn">V</code> is the number of false positives,
is bounded by the argument <code>PFER</code>.
</p>
<p>As controlling the PFER is more conservative as controlling the
family-wise error rate (FWER), the procedure also controlls the FWER,
i.e., the probability of selecting at least one non-influential
variable (or model component) is less than <code>PFER</code>.
</p>
<p>Predefined <code>fitfuns</code> functions exist but more can be
easily implemented. Note that stepwise regression methods are usually
not advised as they tend to be relatively unstable. See example below.
</p>
<p>The function <code>stabsel</code> for <code>data.frame</code>s is
essentially just a wrapper to the <code>matrix</code> function with
the same argments. The only difference is that in a pre-processing
step, the data set is converted to a model matrix using the function
<code>model.matrix</code>. The additional argument <code>intercept</code>
determines if an explicit intercept should be added to the model
matrix. This is often not neccessary but depends on the <code>fitfun</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>stabsel</code> with a special <code>print</code> method.
The object has the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>phat</code></td>
<td>
<p>selection probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selected</code></td>
<td>
<p>elements with maximal selection probability greater
<code>cutoff</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max</code></td>
<td>
<p>maximum of selection probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>cutoff used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>average number of selected variables used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PFER</code></td>
<td>
<p>(realized) upper bound for the per-family error rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>specifiedPFER</code></td>
<td>
<p>specified upper bound for the per-family error rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>the number of effects subject to selection.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>the number of subsamples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sampling.type</code></td>
<td>
<p>the sampling type used for stability selection.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>assumption</code></td>
<td>
<p>the assumptions made on the selection
probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the call.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>B. Hofner, L. Boccuto and M. Goeker (2015), Controlling false
discoveries in high-dimensional situations: Boosting with stability
selection. <em>BMC Bioinformatics</em>, 16:144.<br>
doi: <a href="https://doi.org/10.1186/s12859-015-0575-3">10.1186/s12859-015-0575-3</a>.
</p>
<p>N. Meinshausen and P. Buehlmann (2010), Stability selection.
<em>Journal of the Royal Statistical Society, Series B</em>,
<b>72</b>, 417–473.
</p>
<p>R.D. Shah and R.J. Samworth (2013), Variable selection with error
control: another look at stability selection. <em>Journal of the Royal
Statistical Society, Series B</em>, <b>75</b>, 55–80.
</p>


<h3>See Also</h3>

<p><code>stabsel_parameters</code> for the computation of error bounds,
<code>stabsel.stabsel</code> for the fast re-computation of
parameters of a fitted <code>stabsel</code> object,
<code>fitfun</code> for available fitting functions and
<code>plot.stabsel</code> for available plot functions
</p>


<h3>Examples</h3>

<pre><code class="language-R">  
  if (require("TH.data")) {
      ## make data set available
      data("bodyfat", package = "TH.data")
  } else {
      ## simulate some data if TH.data not available. 
      ## Note that results are non-sense with this data.
      bodyfat &lt;- matrix(rnorm(720), nrow = 72, ncol = 10)
  }
  
  ## set seed
  set.seed(1234)
  
  ####################################################################
  ### using stability selection with Lasso methods:

  if (require("lars")) {
      (stab.lasso &lt;- stabsel(x = bodyfat[, -2], y = bodyfat[,2],
                             fitfun = lars.lasso, cutoff = 0.75,
                             PFER = 1))
      (stab.stepwise &lt;- stabsel(x = bodyfat[, -2], y = bodyfat[,2],
                                fitfun = lars.stepwise, cutoff = 0.75,
                                PFER = 1))
      par(mfrow = c(2, 1))
      plot(stab.lasso, main = "Lasso")
      plot(stab.stepwise, main = "Stepwise Selection")
      ## --&gt; stepwise selection seems to be quite unstable even in this low
      ##     dimensional example!
  }

  ## set seed (again to make results comparable)
  set.seed(1234)
  if (require("glmnet")) {
      (stab.glmnet &lt;- stabsel(x = bodyfat[, -2], y = bodyfat[,2],
                              fitfun = glmnet.lasso, cutoff = 0.75,
                              PFER = 1))
      par(mfrow = c(2, 1))
      plot(stab.glmnet, main = "Lasso (glmnet)")
      if (exists("stab.lasso"))
          plot(stab.lasso, main = "Lasso (lars)")    
  }
  
  
  ## Select variables with maximum coefficients based on lasso estimate
  
  set.seed(1234) # reset seed
  if (require("glmnet")) {
      ## use cross-validated lambda 
      lambda.min &lt;- cv.glmnet(x = as.matrix(bodyfat[, -2]), y = bodyfat[,2])$lambda.min
      (stab.maxCoef &lt;- stabsel(x = bodyfat[, -2], y = bodyfat[,2],
                               fitfun = glmnet.lasso_maxCoef, 
                               # specify additional parameters to fitfun
                               args.fitfun = list(lambda = lambda.min),
                               cutoff = 0.75, PFER = 1))
                               
      ## WARNING: Using a fixed penalty (lambda) is usually not permitted and 
      ##          not sensible. See ?fitfun for details.
      
      ## now compare standard lasso with "maximal parameter estimates" from lasso
      par(mfrow = c(2, 1))
      plot(stab.maxCoef, main = "Lasso (glmnet; Maximum Coefficients)")
      plot(stab.glmnet, main = "Lasso (glmnet)")
      ## --&gt; very different results.
  }

  ####################################################################
  ### using stability selection directly on computed boosting models
  ### from mboost


  if (require("mboost")) {
      ### low-dimensional example
      mod &lt;- glmboost(DEXfat ~ ., data = bodyfat)

      ## compute cutoff ahead of running stabsel to see if it is a sensible
      ## parameter choice.
      ##   p = ncol(bodyfat) - 1 (= Outcome) + 1 ( = Intercept)
      stabsel_parameters(q = 3, PFER = 1, p = ncol(bodyfat) - 1 + 1,
                         sampling.type = "MB")
      ## the same:
      stabsel(mod, q = 3, PFER = 1, sampling.type = "MB", eval = FALSE)

      ### Do not test the following code per default on CRAN as it takes some time to run:
      ## now run stability selection
      (sbody &lt;- stabsel(mod, q = 3, PFER = 1, sampling.type = "MB"))
      opar &lt;- par(mai = par("mai") * c(1, 1, 1, 2.7))
      plot(sbody)
      par(opar)
      plot(sbody, type = "maxsel", ymargin = 6)
      
  }
</code></pre>


</div>