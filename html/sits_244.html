<div class="container">

<table style="width: 100%;"><tr>
<td>sits_xgboost</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Train extreme gradient boosting models</h2>

<h3>Description</h3>

<p>This function uses the extreme gradient boosting algorithm.
Boosting iteratively adds basis functions in a greedy fashion
so that each new basis function further reduces the selected loss function.
This function is a front-end to the methods in the "xgboost" package.
Please refer to the documentation in that package for more details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sits_xgboost(
  samples = NULL,
  learning_rate = 0.15,
  min_split_loss = 1,
  max_depth = 5,
  min_child_weight = 1,
  max_delta_step = 1,
  subsample = 0.8,
  nfold = 5,
  nrounds = 100,
  nthread = 6,
  early_stopping_rounds = 20,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learning_rate</code></td>
<td>
<p>Learning rate: scale the contribution
of each tree by a factor of 0 &lt; lr &lt; 1
when it is added to the current approximation.
Used to prevent overfitting. Default: 0.15</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_split_loss</code></td>
<td>
<p>Minimum loss reduction to make a further
partition of a leaf.  Default: 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_depth</code></td>
<td>
<p>Maximum depth of a tree.
Increasing this value makes the model more complex
and more likely to overfit. Default: 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_child_weight</code></td>
<td>
<p>If the leaf node has a minimum sum of instance
weights lower than min_child_weight,
tree splitting stops. The larger min_child_weight is,
the more conservative the algorithm is. Default: 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_delta_step</code></td>
<td>
<p>Maximum delta step we allow each leaf output to be.
If the value is set to 0, there is no constraint.
If it is set to a positive value, it can help making
the update step more conservative. Default: 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subsample</code></td>
<td>
<p>Percentage of samples supplied to a tree.
Default: 0.8.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfold</code></td>
<td>
<p>Number of the subsamples for the cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrounds</code></td>
<td>
<p>Number of rounds to iterate the cross-validation
(default: 100)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nthread</code></td>
<td>
<p>Number of threads (default = 6)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stopping_rounds</code></td>
<td>
<p>Training with a validation set will stop
if the performance doesn't improve for k rounds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Print information on statistics during the process</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Model fitted to input data
(to be passed to <code>sits_classify</code>)
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>Tianqi Chen, Carlos Guestrin,
"XGBoost : Reliable Large-scale Tree Boosting System",
SIG KDD 2016.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train a xgboost model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_xgboost)
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>


</div>