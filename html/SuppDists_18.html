<div class="container">

<table style="width: 100%;"><tr>
<td>invGauss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The inverse Gaussian and Wald distributions</h2>

<h3>Description</h3>

<p>Density, distribution function, quantile function, random generator and summary function for the inverse Gaussian and Wald distributions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dinvGauss(x, nu, lambda, log=FALSE)
pinvGauss(q, nu, lambda, lower.tail=TRUE, log.p=FALSE)
qinvGauss(p, nu, lambda, lower.tail=TRUE, log.p=FALSE)
rinvGauss(n, nu, lambda)
sinvGauss(nu, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x,q</code></td>
<td>
<p>vector of non-negative quantities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>vector of probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>vector of numbers of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>vector real and non-negative parameter – the Wald distribution results when nu=1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>vector real and non-negative parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log, log.p</code></td>
<td>
<p>logical vector; if TRUE, probabilities p are given as log(p)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.tail</code></td>
<td>
<p>logical vector; if TRUE (default), probabilities are <code class="reqn">P[X &lt;= x]</code>, otherwise, <code class="reqn">P[X &gt; x]</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Probability functions:
</p>
<p style="text-align: center;"><code class="reqn">f(x,\nu,\lambda)=\sqrt{\frac{\lambda}{2\pi x^3}}\exp\left[-\lambda\frac{(x-\nu)^2}{2\nu^2 x}\right] \mbox{-- the density}</code>
</p>

<p style="text-align: center;"><code class="reqn">F(x,\nu,\lambda)=\Phi\left[\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\nu}-1\right)\right]+e^{2\lambda/\nu}\Phi\left[\sqrt{\frac{\lambda}{x}}\left(\frac{x}{\nu}+1\right)\right] \mbox{-- the distribution function}</code>
</p>

<p>where <code class="reqn">\Phi[]</code> is the standard normal distribution function.
</p>
<p>The calculations are accurate to at least seven significant figures over
an extended range - much larger than that of any existing tables. We
have tested them for <code class="reqn">\lambda / \nu = 10e-20</code>,
and <code class="reqn">\lambda/\nu=10e4</code>. Accessible tables are
those of Wassan and Roy (1969), which unfortunately, are sometimes good
to only two significant digits. Much better tables are available in an
expensive CRC Handbook (1989), which are accurate to at least 7 significant digits for <code class="reqn">\lambda/\nu \ge 0.02</code> to <code class="reqn">\lambda/\nu \le 4000</code>. 
</p>
<p>These are first passage time distributions of Brownian motion with positive drift. See Whitmore and Seshadri (1987) for a heuristic derivation. The Wald (1947) form represents the average sample number in sequential analysis. The distribution has a non-monotonic failure rate, and is of considerable interest in lifetime studies: Ckhhikara and Folks (1977). A general reference is Seshadri (1993). 
</p>
<p>This is an extremely difficult distribution to treat numerically, and it would not have been possible without some extraordinary contributions. An elegant derivation of the distribution function is to be found in Shuster (1968). The first such derivation seems to be that of Zigangirov (1962), which because of its inaccessibility, the author has not read. The method of generating random numbers is due to Michael, Schucany, and Haas (1976). The approximation of Whitmore and Yalovsky (1978) makes it possible to find starting values for inverting the distribution. All three papers are short, elegant, and non- trivial. 
</p>


<h3>Value</h3>

<p>The output values conform to the output from other such functions in R. <code>dinvGauss()</code> gives the density, <code>pinvGauss()</code> the distribution function and <code>qinvGauss()</code> its inverse. <code>rinvGauss()</code> generates random numbers. <code>sinvGauss()</code> produces a list containing parameters corresponding to the arguments – mean, median, mode, variance, sd, third cental moment, fourth central moment, Pearson's skewness, skewness, and kurtosis.
</p>


<h3>Author(s)</h3>

<p>Bob Wheeler 
</p>


<h3>References</h3>

<p>Ckhhikara, R.S. and Folks, J.L. (1977) The inverse Gaussian distribution as a lifetime model. <em>Technometrics.</em> <b>19-4.</b> 461-468. 
</p>
<p>CRC Handbook. (1989). <em>Percentile points of the inverse Gaussian distribution.</em> J.A. Koziol (ed.) Boca Raton, FL. 
</p>
<p>Michael, J.R., Schucany, W.R. and Haas, R.W. (1976). Generating random variates using transformations with multiple roots. <em>American Statistician.</em> <b>30-2.</b> 88-90. 
</p>
<p>Seshadri, V. (1993). <em>The inverse Gaussian distribution.</em> Clarendon, Oxford 
</p>
<p>Shuster, J. (1968). On the inverse Gaussian distribution function. Jour. <em>Am. Stat. Assoc.</em> <b>63.</b> 1514-1516. 
</p>
<p>Wasan, M.T. and Roy, L.K. (1969). Tables of inverse Gaussian percentage points. <em>Technometrics.</em> <b>11-3.</b> 591-604. 
</p>
<p>Wald, A. (1947). <em>Sequential analysis.</em> Wiley, NY 
</p>
<p>Whitmore, G.A. and Seshadri, V. (1987). A heuristic derivation of the inverse Gaussian distribution. <em>American Statistician.</em> <b>41-4.</b> 280-281. 
</p>
<p>Whitmore, G.A. and Yalovsky, M. (1978). A normalizing logarithmic transformation for inverse Gaussian random variables. <em>Technometrics.</em> <b>20-2.</b> 207-208. 
</p>
<p>Zigangirov, K.S. (1962). Expression for the Wald distribution in terms of normal distribution. <em>Radiotech.Electron.</em> <b>7.</b> 164-166. 
</p>


<h3>Examples</h3>

<pre><code class="language-R">
pinvGauss(1, 1, 16)
pinvGauss(c(.65,1,1.45), 1, 16) ## approximately 5% 50% and 95%
pars&lt;-sinvGauss(1, 16)
plot(function(x)dinvGauss(x,1, 16),pars$Mean-3*pars$SD,pars$Mean+3*pars$SD)
</code></pre>


</div>