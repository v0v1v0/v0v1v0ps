<div class="container">

<table style="width: 100%;"><tr>
<td>ml_kmeans</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Spark ML – K-Means Clustering</h2>

<h3>Description</h3>

<p>K-means clustering with support for k-means|| initialization proposed by Bahmani et al.
Using 'ml_kmeans()' with the formula interface requires Spark 2.0+.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ml_kmeans(
  x,
  formula = NULL,
  k = 2,
  max_iter = 20,
  tol = 1e-04,
  init_steps = 2,
  init_mode = "k-means||",
  seed = NULL,
  features_col = "features",
  prediction_col = "prediction",
  uid = random_string("kmeans_"),
  ...
)

ml_compute_cost(model, dataset)

ml_compute_silhouette_measure(
  model,
  dataset,
  distance_measure = c("squaredEuclidean", "cosine")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>Used when <code>x</code> is a <code>tbl_spark</code>. R formula as a character string or a formula. This is used to transform the input dataframe before fitting, see ft_r_formula for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>The number of clusters to create</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>The maximum number of iterations to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Param for the convergence tolerance for iterative algorithms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init_steps</code></td>
<td>
<p>Number of steps for the k-means|| initialization mode. This is an advanced setting – the default of 2 is almost always enough. Must be &gt; 0. Default: 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init_mode</code></td>
<td>
<p>Initialization algorithm. This can be either "random" to choose random points as initial cluster centers, or "k-means||" to use a parallel variant of k-means++ (Bahmani et al., Scalable K-Means++, VLDB 2012). Default: k-means||.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>A random seed. Set this value if you need your results to be
reproducible across repeated calls.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>features_col</code></td>
<td>
<p>Features column name, as a length-one character vector. The column should be single vector column of numeric values. Usually this column is output by <code>ft_r_formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prediction_col</code></td>
<td>
<p>Prediction column name.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the ML estimator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments, see Details.
#' @return The object returned depends on the class of <code>x</code>. If it is a
<code>spark_connection</code>, the function returns a <code>ml_estimator</code> object. If
it is a <code>ml_pipeline</code>, it will return a pipeline with the predictor
appended to it. If a <code>tbl_spark</code>, it will return a <code>tbl_spark</code> with
the predictions added to it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A fitted K-means model returned by <code>ml_kmeans()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>
<p>Dataset on which to calculate K-means cost</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distance_measure</code></td>
<td>
<p>Distance measure to apply when computing the Silhouette measure.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>ml_compute_cost()</code> returns the K-means cost (sum of
squared distances of points to their nearest center) for the model
on the given data.
</p>
<p><code>ml_compute_silhouette_measure()</code> returns the Silhouette measure
of the clustering on the given data.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
sc &lt;- spark_connect(master = "local")
iris_tbl &lt;- sdf_copy_to(sc, iris, name = "iris_tbl", overwrite = TRUE)
ml_kmeans(iris_tbl, Species ~ .)

## End(Not run)

</code></pre>


</div>