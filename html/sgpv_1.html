<div class="container">

<table style="width: 100%;"><tr>
<td>fdrisk</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>False Discovery Risk for Second-Generation p-Values</h2>

<h3>Description</h3>

<p>This function computes the false discovery risk (sometimes called the "empirical bayes FDR") for a second-generation <em>p</em>-value of 0, or the false confirmation risk for a second-generation <em>p</em>-value of 1.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fdrisk(
  sgpval = 0,
  null.lo,
  null.hi,
  std.err,
  interval.type,
  interval.level,
  pi0 = 0.5,
  null.weights,
  null.space,
  alt.weights,
  alt.space
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sgpval</code></td>
<td>
<p>The observed second-generation <em>p</em>-value. Default is <code class="reqn">0</code>, which gives the false discovery risk.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.lo</code></td>
<td>
<p>The lower bound of the indifference zone (null interval) upon which the second-generation <em>p</em>-value was based</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.hi</code></td>
<td>
<p>The upper bound for the indifference zone (null interval) upon which the second-generation <em>p</em>-value was based</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>std.err</code></td>
<td>
<p>Standard error of the point estimate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interval.type</code></td>
<td>
<p>Class of interval estimate used. This determines the functional form of the power function. Options are <code>confidence</code> for a <code class="reqn">(1-\alpha)100</code>% confidence interval and <code>likelihood</code> for a <code class="reqn">1/k</code> likelihood support interval (<code>credible</code> not yet supported).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interval.level</code></td>
<td>
<p>Level of interval estimate. If <code>interval.type</code> is <code>confidence</code>, the level is <code class="reqn">\alpha</code>. If <code>interval.type</code> is <code>likelihood</code>, the level is <code class="reqn">1/k</code> (not <code class="reqn">k</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi0</code></td>
<td>
<p>Prior probability of the null hypothesis. Default is <code class="reqn">0.5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.weights</code></td>
<td>
<p>Probability distribution for the null parameter space. Options are currently <code>Point</code>, <code>Uniform</code>, and <code>TruncNormal</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.space</code></td>
<td>
<p>Support of the null probability distribution. If <code>null.weights</code> is <code>Point</code>, then <code>null.space</code> is a scalar. If <code>null.weights</code> is <code>Uniform</code>, then <code>null.space</code> is a vector of length two.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alt.weights</code></td>
<td>
<p>Probability distribution for the alternative parameter space. Options are currently <code>Point</code>, <code>Uniform</code>, and <code>TruncNormal</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alt.space</code></td>
<td>
<p>Support for the alternative probability distribution. If <code>alt.weights</code> is <code>Point</code>, then <code>alt.space</code> is a scalar. If <code>alt.weights</code> is <code>Uniform</code>, then <code>alt.space</code> is a vector of length two.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>When possible, one should compute the second-generation <em>p</em>-value and FDR/FCR on a scale that is symmetric about the null hypothesis. For example, if the parameter of interest is an odds ratio, inputs <code>pt.est</code>, <code>std.err</code>, <code>null.lo</code>,  <code>null.hi</code>, <code>null.space</code>, and <code>alt.space</code> are typically on the log scale.
</p>
<p>If <code>TruncNormal</code> is used for <code>null.weights</code>, then the distribution used is a truncated Normal distribution with mean equal to the midpoint of <code>null.space</code>, and standard deviation equal to <code>std.err</code>, truncated to the support of <code>null.space</code>. If <code>TruncNormal</code> is used for <code>alt.weights</code>, then the distribution used is a truncated Normal distribution with mean equal to the midpoint of <code>alt.space</code>, and standard deviation equal to <code>std.err</code>, truncated to the support of <code>alt.space</code>. Further customization of these parameters for the truncated Normal are currently not possible, although they may be implemented in future versions.
</p>


<h3>Value</h3>

<p>Numeric scalar representing the False discovery risk (FDR) or false confirmation risk (FCR) for the observed second-generation <em>p</em>-value. If <code>sgpval</code> = <code class="reqn">0</code>, the function returns false discovery risk (FDR). If <code>sgpval</code> = <code class="reqn">1</code>, the function returns false confirmation risk (FCR).
</p>


<h3>References</h3>

<p>Blume JD, Greevy RA Jr., Welty VF, Smith JR, Dupont WD (2019). An Introduction to Second-generation <em>p</em>-values. <em>The American Statistician</em>. 73:sup1, 157-167, DOI: https://doi.org/10.1080/00031305.2018.1537893
</p>
<p>Blume JD, Dâ€™Agostino McGowan L, Dupont WD, Greevy RA Jr. (2018). Second-generation <em>p</em>-values: Improved rigor, reproducibility, &amp; transparency in statistical analyses. <em>PLoS ONE</em> 13(3): e0188299. https://doi.org/10.1371/journal.pone.0188299
</p>


<h3>See Also</h3>

<p><code>sgpvalue, sgpower, plotsgpv, FDRestimation::p.fdr</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# false discovery risk with 95% confidence level
fdrisk(sgpval = 0,  null.lo = log(1/1.1), null.hi = log(1.1),  std.err = 0.8,
  null.weights = 'Uniform', null.space = c(log(1/1.1), log(1.1)),
  alt.weights = 'Uniform',  alt.space = 2 + c(-1,1)*qnorm(1-0.05/2)*0.8,
  interval.type = 'confidence',  interval.level = 0.05)

# false discovery risk with 1/8 likelihood support level
fdrisk(sgpval = 0,  null.lo = log(1/1.1), null.hi = log(1.1),  std.err = 0.8,
  null.weights = 'Point', null.space = 0,  alt.weights = 'Uniform',
  alt.space = 2 + c(-1,1)*qnorm(1-0.041/2)*0.8,
  interval.type = 'likelihood',  interval.level = 1/8)

## with truncated normal weighting distribution
fdrisk(sgpval = 0,  null.lo = log(1/1.1), null.hi = log(1.1),  std.err = 0.8,
  null.weights = 'Point', null.space = 0,  alt.weights = 'TruncNormal',
  alt.space = 2 + c(-1,1)*qnorm(1-0.041/2)*0.8,
  interval.type = 'likelihood',  interval.level = 1/8)

# false discovery risk with LSI and wider null hypothesis
fdrisk(sgpval = 0,  null.lo = log(1/1.5), null.hi = log(1.5),  std.err = 0.8,
  null.weights = 'Point', null.space = 0,  alt.weights = 'Uniform',
  alt.space = 2.5 + c(-1,1)*qnorm(1-0.041/2)*0.8,
  interval.type = 'likelihood',  interval.level = 1/8)

# false confirmation risk example
fdrisk(sgpval = 1,  null.lo = log(1/1.5), null.hi = log(1.5),  std.err = 0.15,
  null.weights = 'Uniform', null.space = 0.01 + c(-1,1)*qnorm(1-0.041/2)*0.15,
  alt.weights = 'Uniform',  alt.space = c(log(1.5), 1.25*log(1.5)),
  interval.type = 'likelihood',  interval.level = 1/8)


</code></pre>


</div>