<div class="container">

<table style="width: 100%;"><tr>
<td>scout</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Covariance-regularized regression, aka the Scout.</h2>

<h3>Description</h3>

<p>The main function of the "scout" package. Performs
covariance-regularized regression. Required inputs are an x matrix of
features (the columns are the features) and a y vector of
observations. By default, Scout(2,1) is performed; however, $p_1$ and
$p_2$ can be specified (in which case Scout($p_1$, $p_2$) is
performed). Also, by default Scout is performed over a grid of lambda1
and lambda2 values, but a different grid of values (or individual
values, rather than an entire grid) can be specified.
</p>


<h3>Usage</h3>

<pre><code class="language-R">scout(x,y,newx,p1=2,p2=1,lam1s=seq(.001,.2,len=10),lam2s=seq(.001,.2,len=10),
   rescale=TRUE, trace=TRUE,standardize=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A matrix of predictors, where the rows are the samples and
the columns are the predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A matrix of observations, where length(y) should equal
nrow(x)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newx</code></td>
<td>
<p>An *optional* argument, consisting of a matrix with
ncol(x) columns, at which one wishes to make predictions for each
(lam1,lam2) pair.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p1</code></td>
<td>
<p>The $L_p$ penalty for the covariance regularization. Must be
one of 1, 2, or NULL. NULL corresponds to no covariance
regularization.  WARNING: When p1=1, and ncol(x)&gt;500, Scout can be
SLOW. We recommend that for very large data sets, you use Scout with
p1=2. Also, when ncol(x)&gt;nrow(x) and p1=1, then very small values of
lambda1 (lambda1 &lt; 1e-4) will cause problems with graphical lasso,
and so those values will be automatically increased to 1e-4. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p2</code></td>
<td>
<p>The $L_p$ penalty for the estimation of the regression
coefficients based on the regularized covariance matrix. Must be one
of 1 (for $L_1$ regularization) or NULL (for no regularization).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam1s</code></td>
<td>
<p>The (vector of) tuning parameters for regularization of the
covariance matrix. Can be NULL if p1=NULL, since then no covariance
regularization is taking place. If p1=1 and nrow(x)&lt;ncol(x), then the no value in lam1s
should be smaller than 1e-3, because this will cause graphical lasso
to take too long. Also, if ncol(x)&gt;500 then we really do not
recommend using p1=1, as graphical lasso can be uncomfortably slow.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam2s</code></td>
<td>
<p>The (vector of) tuning parameters for the $L_1$ regularization of
the regression coefficients, using the regularized covariance
matrix. Can be NULL if p2=NULL. (If p2=NULL, then non-zero lam2s
have no effect). A value of 0 will result in no
regularization. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rescale</code></td>
<td>
<p>Should coefficients beta obtained by
covariance-regularized regression be re-scaled by a constant, given
by regressing $y$ onto $x beta$? This is done in Witten and
Tibshirani (2008) and is important for good performance. Default is
TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>Print out progress? Prints out each time a lambda1 is
completed. This is a good idea, especially when
ncol(x) is large.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>Should the columns of x be scaled to have standard deviation
1, and should y be scaled to have standard deviation 1, before
covariance-regularized regression is performed? This affects the
meaning of the penalties that are applied. In general,
standardization should be performed. Default is TRUE.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>intercepts</code></td>
<td>
<p>Returns a matrix of intercepts, of dimension length(lam1s)xlength(lam2s)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>Returns an array of coefficients, of dimension
length(lam1s)xlength(lam2s)xncol(x).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p1</code></td>
<td>
<p>p1 value used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p2</code></td>
<td>
<p>p2 value used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam1s</code></td>
<td>
<p>lam1s used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam2s</code></td>
<td>
<p>lam2s used</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>When p1=1 and ncol(x)&gt;500 or so, then Scout can be very slow!!
Please use p1=2 when ncol(x) is large.
</p>


<h3>Author(s)</h3>

<p>Daniela M. Witten and Robert Tibshirani</p>


<h3>References</h3>

<p>Witten, DM and Tibshirani, R (2008) Covariance-regularized
regression and classification for high-dimensional problems. Journal
of the Royal Statistical Society, Series B 71(3): 615-636. &lt;http://www-stat.stanford.edu/~dwitten&gt;</p>


<h3>See Also</h3>

<p>predict.scoutobject, cv.scout</p>


<h3>Examples</h3>

<pre><code class="language-R">library(lars)
data(diabetes)
attach(diabetes)
scout.out &lt;- scout(x2,y,p1=2,p2=1)
print(scout.out)
detach(diabetes)
</code></pre>


</div>