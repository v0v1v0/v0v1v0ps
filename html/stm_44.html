<div class="container">

<table style="width: 100%;"><tr>
<td>prepDocuments</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Prepare documents for analysis with <code>stm</code>
</h2>

<h3>Description</h3>

<p>Performs several corpus manipulations including removing words and
renumbering word indices (to correct for zero-indexing and/or unused words
in the vocab vector).
</p>


<h3>Usage</h3>

<pre><code class="language-R">prepDocuments(
  documents,
  vocab,
  meta = NULL,
  lower.thresh = 1,
  upper.thresh = Inf,
  subsample = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>documents</code></td>
<td>
<p>List of documents. For more on the format see
<code>stm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab</code></td>
<td>
<p>Character vector of words in the vocabulary.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>Document metadata.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.thresh</code></td>
<td>
<p>Words which do not appear in a number of documents
greater than lower.thresh will be dropped and both the documents and vocab
files will be renumbered accordingly.  If this causes all words within a
document to be dropped, a message will print to the screen at it will also
return vector of the documents removed so you can update your meta data as
well. See details below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper.thresh</code></td>
<td>
<p>As with lower.thresh but this provides an upper bound.
Words which appear in at least this number of documents will be dropped.
Defaults to <code>Inf</code> which does no filtering.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subsample</code></td>
<td>
<p>If an integer will randomly subsample (without replacement)
the given number of documents from the total corpus before any processing.
Defaults to <code>NULL</code> which provides no subsampling.  Note that the output
may have fewer than the number of requested documents if additional
processing causes some of those documents to be dropped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A logical indicating whether or not to print details to the
screen.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The default setting <code>lower.thresh=1</code> means that words which appear in
only one document will be dropped.  This is often advantageous as there is
little information about these words but the added cost of including them in
the model can be quite large.  In many cases it will be helpful to set this
threshold considerably higher.  If the vocabulary is in excess of 5000
entries inference can slow quite a bit.
</p>
<p>If words are removed, the function returns a vector of the original indices
for the dropped items.  If it removed documents it returns a vector of doc
indices removed. Users with accompanying metadata or texts may want to drop
those rows from the corresponding objects.
</p>
<p>The behavior is such that when <code>prepDocuments</code> drops documents their
corresponding rows are deleted and the row names are not renumbered.  We however
do not recommend using rownames for joins- instead the best practice is to either
keep a unique identifier in the <code>meta</code> object for doing joins or use something
like <span class="pkg">quanteda</span> which has a more robust interface for manipulating the corpus
itself.
</p>
<p>If you have any documents which are of length 0 in your original object the
function will throw an error. These should be removed before running the
function although please be sure to remove the corresponding rows in the
meta data file if you have one.  You can quickly identify the documents
using the code: <code>which(unlist(lapply(documents, length))==0)</code>.
</p>


<h3>Value</h3>

<p>A list containing a new documents and vocab object.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>documents</code></td>
<td>
<p>The new documents object for use with <code>stm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab</code></td>
<td>
<p>The new vocab object for use with <code>stm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>The
new meta data object for use with <code>stm</code>. Will be the same if no
documents are removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>words.removed</code></td>
<td>
<p>A set of indices corresponding
to the positions in the original vocab object of words which have been
removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>docs.removed</code></td>
<td>
<p>A set of indices corresponding to the
positions in the original documents object of documents which no longer
contained any words after dropping terms from the vocab.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokens.removed</code></td>
<td>
<p>An integer corresponding to the number of unique
tokens removed from the corpus.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wordcounts</code></td>
<td>
<p>A table giving the the
number of documents that each word is found in of the original document set,
prior to any removal. This can be passed through a histogram for visual
inspection.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>plotRemoved</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">temp&lt;-textProcessor(documents=gadarian$open.ended.response,metadata=gadarian)
meta&lt;-temp$meta
vocab&lt;-temp$vocab
docs&lt;-temp$documents
out &lt;- prepDocuments(docs, vocab, meta)
</code></pre>


</div>