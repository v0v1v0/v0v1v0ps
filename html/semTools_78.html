<div class="container">

<table style="width: 100%;"><tr>
<td>moreFitIndices</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate more fit indices</h2>

<h3>Description</h3>

<p>Calculate more fit indices that are not already provided in lavaan.
</p>


<h3>Usage</h3>

<pre><code class="language-R">moreFitIndices(object, fit.measures = "all", nPrior = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>The lavaan model object provided after running the <code>cfa</code>,
<code>sem</code>, <code>growth</code>, or <code>lavaan</code> functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit.measures</code></td>
<td>
<p>Additional fit measures to be calculated. All additional
fit measures are calculated by default</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nPrior</code></td>
<td>
<p>The sample size on which prior is based. This argument is used
to compute <code>bic.priorN</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See <code>nullRMSEA</code> for the further details of the computation of
RMSEA of the null model.
</p>
<p>Gamma-Hat (<code>gammaHat</code>; West, Taylor, &amp; Wu, 2012) is a global
goodness-of-fit index which can be computed (assuming equal number of
indicators across groups) by
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\Gamma} =\frac{p}{p + 2 \times \frac{\chi^{2}_{k} - df_{k}}{N}},</code>
</p>

<p>where <code class="reqn">p</code> is the number of variables in the model, <code class="reqn">\chi^{2}_{k}</code> is
the <code class="reqn">\chi^2</code> test statistic value of the target model, <code class="reqn">df_{k}</code> is
the degree of freedom when fitting the target model, and <code class="reqn">N</code> is the
sample size (or sample size minus the number of groups if <code>mimic</code> is
set to <code>"EQS"</code>).
</p>
<p>Adjusted Gamma-Hat (<code>adjGammaHat</code>; West, Taylor, &amp; Wu, 2012) is a
global fit index which can be computed by
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\Gamma}_\textrm{adj} = \left(1 - \frac{K \times p \times
  (p + 1)}{2 \times df_{k}} \right) \times \left( 1 - \hat{\Gamma} \right),</code>
</p>

<p>where <code class="reqn">K</code> is the number of groups (please refer to Dudgeon, 2004, for
the multiple-group adjustment for <code>adjGammaHat</code>).
</p>
<p>The remaining indices are information criteria calculated using the
<code>object</code>'s <code class="reqn">-2 \times</code> log-likelihood, abbreviated <code class="reqn">-2LL</code>.
</p>
<p>Corrected Akaike Information Criterion (<code>aic.smallN</code>; Burnham &amp;
Anderson, 2003) is a corrected version of AIC for small sample size, often
abbreviated AICc:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{AIC}_{\textrm{small}-N} = AIC + \frac{2q(q + 1)}{N - q - 1},</code>
</p>

<p>where <code class="reqn">AIC</code> is the original AIC: <code class="reqn">-2LL + 2q</code> (where <code class="reqn">q</code>
= the number of estimated parameters in the target model). Note that AICc is
a small-sample correction derived for univariate regression models, so it is
probably <em>not</em> appropriate for comparing SEMs.
</p>
<p>Corrected Bayesian Information Criterion (<code>bic.priorN</code>; Kuha, 2004) is
similar to BIC but explicitly specifying the sample size on which the prior
is based (<code class="reqn">N_{prior}</code>) using the <code>nPrior</code> argument.
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{BIC}_{\textrm{prior}-N} = -2LL + q\log{( 1 + \frac{N}{N_{prior}} )}.</code>
</p>

<p>Bollen et al. (2014) discussed additional BICs that incorporate more terms
from a Taylor series expansion, which the standard BIC drops.  The "Scaled
Unit-Information Prior" BIC is calculated depending on whether the product
of the vector of estimated model parameters (<code class="reqn">\hat{\theta}</code>) and the
observed information matrix (FIM) exceeds the number of estimated model
parameters (Case 1) or not (Case 2), which is checked internally:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{SPBIC}_{\textrm{Case 1}} = -2LL + q(1 - \frac{q}{\hat{\theta}^{'} \textrm{FIM} \hat{\theta}}), or</code>
</p>

<p style="text-align: center;"><code class="reqn"> \textrm{SPBIC}_{\textrm{Case 2}} = -2LL + \hat{\theta}^{'} \textrm{FIM} \hat{\theta},</code>
</p>

<p>Bollen et al. (2014) credit the HBIC to Haughton (1988):
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{HBIC}_{\textrm{Case 1}} = -2LL - q\log{2 \times \pi},</code>
</p>

<p>and proposes the information-matrix-based BIC by adding another term:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{IBIC}_{\textrm{Case 1}} = -2LL - q\log{2 \times \pi} - \log{\det{\textrm{ACOV}}},</code>
</p>

<p>Stochastic information criterion (SIC; see Preacher, 2006, for details) is
similar to IBIC but does not subtract the term <code class="reqn">q\log{2 \times \pi}</code>
that is also in HBIC. SIC and IBIC account for model complexity in a model's
functional form, not merely the number of free parameters.  The SIC can be
computed by
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{SIC} = -2LL + \log{\det{\textrm{FIM}^{-1}}} = -2LL - \log{\det{\textrm{ACOV}}},</code>
</p>

<p>where the inverse of FIM is the asymptotic sampling covariance matrix (ACOV).
</p>
<p>Hannan–Quinn Information Criterion (HQC; Hannan &amp; Quinn, 1979) is used for
model selection, similar to AIC or BIC.
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{HQC} = -2LL + 2k\log{(\log{N})},</code>
</p>

<p>Note that if Satorra–Bentler's or Yuan–Bentler's method is used, the fit
indices using the scaled <code class="reqn">\chi^2</code> values are also provided.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> <code>lavaan.vector</code> including any of the
following requested via <code>fit.measures=</code>
</p>

<ol>
<li> <p><code>gammaHat</code>: Gamma-Hat
</p>
</li>
<li> <p><code>adjGammaHat</code>: Adjusted Gamma-Hat
</p>
</li>
<li> <p><code>baseline.rmsea</code>: RMSEA of the default baseline (i.e., independence) model
</p>
</li>
<li> <p><code>gammaHat.scaled</code>: Gamma-Hat using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>adjGammaHat.scaled</code>: Adjusted Gamma-Hat using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>baseline.rmsea.scaled</code>: RMSEA of the default baseline (i.e.,
independence) model using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>aic.smallN</code>: Corrected (for small sample size) AIC
</p>
</li>
<li> <p><code>bic.priorN</code>: BIC with specified prior sample size
</p>
</li>
<li> <p><code>spbic</code>: Scaled Unit-Information Prior BIC (SPBIC)
</p>
</li>
<li> <p><code>hbic</code>: Haughton's BIC (HBIC)
</p>
</li>
<li> <p><code>ibic</code>: Information-matrix-based BIC (IBIC)
</p>
</li>
<li> <p><code>sic</code>: Stochastic Information Criterion (SIC)
</p>
</li>
<li> <p><code>hqc</code>: Hannan-Quinn Information Criterion (HQC)
</p>
</li>
</ol>
<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Aaron Boulton (University of Delaware)
</p>
<p>Ruben Arslan (Humboldt-University of Berlin, <a href="mailto:rubenarslan@gmail.com">rubenarslan@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>


<h3>References</h3>

<p>Bollen, K. A., Ray, S., Zavisca, J., &amp; Harden, J. J. (2012). A comparison of
Bayes factor approximation methods including two new methods.
<em>Sociological Methods &amp; Research, 41</em>(2), 294–324.
<a href="https://doi.org/10.1177/0049124112452393">doi:10.1177/0049124112452393</a>
</p>
<p>Burnham, K., &amp; Anderson, D. (2003). <em>Model selection and
multimodel inference: A practical–theoretic approach</em>. New York, NY:
Springer–Verlag.
</p>
<p>Dudgeon, P. (2004). A note on extending Steiger's (1998) multiple sample
RMSEA adjustment to other noncentrality parameter-based statistic.
<em>Structural Equation Modeling, 11</em>(3), 305–319.
<a href="https://doi.org/10.1207/s15328007sem1103_1">doi:10.1207/s15328007sem1103_1</a>
</p>
<p>Kuha, J. (2004). AIC and BIC: Comparisons of assumptions and performance.
<em>Sociological Methods Research, 33</em>(2), 188–229.
<a href="https://doi.org/10.1177/0049124103262065">doi:10.1177/0049124103262065</a>
</p>
<p>Preacher, K. J. (2006). Quantifying parsimony in structural equation
modeling. <em>Multivariate Behavioral Research, 43</em>(3), 227-259.
<a href="https://doi.org/10.1207/s15327906mbr4103_1">doi:10.1207/s15327906mbr4103_1</a>
</p>
<p>West, S. G., Taylor, A. B., &amp; Wu, W. (2012). Model fit and model selection
in structural equation modeling. In R. H. Hoyle (Ed.), <em>Handbook of
structural equation modeling</em> (pp. 209–231). New York, NY: Guilford.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code>miPowerFit</code> For the modification indices and their
power approach for model fit evaluation
</p>
</li>
<li> <p><code>nullRMSEA</code> For RMSEA of the default independence model
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit &lt;- cfa(HS.model, data = HolzingerSwineford1939)
moreFitIndices(fit)

fit2 &lt;- cfa(HS.model, data = HolzingerSwineford1939, estimator = "mlr")
moreFitIndices(fit2)

</code></pre>


</div>