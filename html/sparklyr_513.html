<div class="container">

<table style="width: 100%;"><tr>
<td>stream_write_table</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Write Stream to Table</h2>

<h3>Description</h3>

<p>Writes a Spark dataframe stream into a table.
</p>


<h3>Usage</h3>

<pre><code class="language-R">stream_write_table(
  x,
  path,
  format = NULL,
  mode = c("append", "complete", "update"),
  checkpoint = file.path("checkpoints", random_string("")),
  options = list(),
  partition_by = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A Spark DataFrame or dplyr operation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the ‘<span class="samp">⁠"hdfs://"⁠</span>’, ‘<span class="samp">⁠"s3a://"⁠</span>’ and ‘<span class="samp">⁠"file://"⁠</span>’ protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>format</code></td>
<td>
<p>Specifies format of data written to table E.g.
<code>"delta"</code>, <code>"parquet"</code>. Defaults to <code>NULL</code> which will use
system default format.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>Specifies how data is written to a streaming sink. Valid values are
<code>"append"</code>, <code>"complete"</code> or <code>"update"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>checkpoint</code></td>
<td>
<p>The location where the system will write all the checkpoint
information to guarantee end-to-end fault-tolerance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>A list of strings with additional options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partition_by</code></td>
<td>
<p>Partitions the output by the given list of columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other Spark stream serialization: 
<code>stream_write_csv()</code>,
<code>stream_write_memory()</code>
</p>


</div>