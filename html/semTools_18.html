<div class="container">

<table style="width: 100%;"><tr>
<td>compRelSEM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Composite Reliability using SEM</h2>

<h3>Description</h3>

<p>Calculate composite reliability from estimated factor-model parameters
</p>


<h3>Usage</h3>

<pre><code class="language-R">compRelSEM(object, obs.var = TRUE, tau.eq = FALSE, ord.scale = TRUE,
  config = character(0), shared = character(0), higher = character(0),
  return.total = FALSE, dropSingle = TRUE, omit.factors = character(0),
  omit.indicators = character(0), omit.imps = c("no.conv", "no.se"),
  return.df = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A <code>lavaan</code> or
<code>lavaan.mi</code> object, expected to contain only
exogenous common factors (i.e., a CFA model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs.var</code></td>
<td>
<p><code>logical</code> indicating whether to compute AVE using
observed variances in the denominator. Setting <code>FALSE</code> triggers
using model-implied variances in the denominator.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau.eq</code></td>
<td>
<p><code>logical</code> indicating whether to assume (essential)
tau-equivalence, yielding a coefficient analogous to <code class="reqn">\alpha</code>.
Setting <code>FALSE</code> yields an <code class="reqn">\omega</code>-type coefficient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ord.scale</code></td>
<td>
<p><code>logical</code> indicating whether to apply Green and Yang's
(2009, formula 21) correction, so that reliability is calculated for the
actual ordinal response scale (ignored for factors with continuous
indicators).  Setting <code>FALSE</code> yields coefficients that are
only applicable to the continuous latent-response scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>config</code></td>
<td>
<p><code>character</code> vector naming any configural constructs in
a multilevel CFA. For these constructs (and optional total composite),
Lai's (2021) coefficients <code class="reqn">\omega^\textrm{W}</code> and <code class="reqn">\omega^\textrm{2L}</code>
are returned (or corresponding <code class="reqn">\alpha</code> coefficients when
<code>tau.eq=TRUE</code>), rather than Geldhof et al.'s (2014) coefficients for
hypothetical composites of latent components (although the same formula
is used for <code class="reqn">\omega^\textrm{W}</code> in either case). Note that the same name
must be used for the factor component represented at each level of the
model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shared</code></td>
<td>
<p><code>character</code> vector naming any shared constructs in
a multilevel CFA. For these constructs (and optional total composite),
Lai's (2021) coefficient <code class="reqn">\omega^\textrm{B}</code> or <code class="reqn">\alpha^\textrm{B}</code> is
returned, rather than Geldhof et al.'s (2014) between-level coefficient
for hypothetical composites of latent cluster means. Lai's (2021)
coefficient quantifies reliability relative to error associated with both
indicators (measurement error) and subjects (sampling error), like a
generalizability coefficient.  Given that subjects can be considered as
raters of their cluster's shared construct, an interrater reliability
(IRR) coefficient is also returned, quantifying reliability relative to
rater/sampling error alone.  To quantify reliability relative to
indicator/measurement error alone (i.e., <code class="reqn">\omega^\textrm{2L}</code>), the
<code>shared=</code> construct name(s) can additionally be included in
<code>config=</code> argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>higher</code></td>
<td>
<p><code>character</code> vector naming any higher-order constructs in
<code>object</code> for which composite reliability should be calculated.
Ignored when <code>tau.eq=TRUE</code> because alpha is not based on a CFA model;
instead, users must fit a CFA with tau-equivalence constraints.
To obtain Lai's (2021) multilevel composite-reliability indices for a
higher-order factor, do not use this argument; instead, specify the
higher-order factor(s) using the <code>shared=</code> or <code>config=</code> argument
(<code>compRelSEM</code> will automatically check whether it includes latent
indicators and apply the appropriate formula).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.total</code></td>
<td>
<p><code>logical</code> indicating whether to return a final
column containing the reliability of a composite of all indicators (not
listed in <code>omit.indicators</code>) of first-order factors not listed in
<code>omit.factors</code>.  Ignored in 1-factor models, and should only be set
<code>TRUE</code> if all factors represent scale dimensions that could be
meaningfully collapsed to a single composite (scale sum or scale mean).
Setting a negative value (e.g., <code>-1</code> returns <b>only</b> the
total-composite reliability (excluding coefficients per factor), except
when requesting Lai's (2021) coefficients for multilevel <code>config</code>ural
or <code>shared=</code> constructs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dropSingle</code></td>
<td>
<p><code>logical</code> indicating whether to exclude factors
defined by a single indicator from the returned results. If <code>TRUE</code>
(default), single indicators will still be included in the <code>total</code>
column when <code>return.total = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.factors</code></td>
<td>
<p><code>character</code> vector naming any common factors
modeled in <code>object</code> whose composite reliability is not of
interest. For example, higher-order or method factors. Note that
<code>reliabilityL2()</code> should be used to calculate composite
reliability of a higher-order factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.indicators</code></td>
<td>
<p><code>character</code> vector naming any observed variables
that should be ignored when calculating composite reliability. This can
be useful, for example, to estimate reliability when an indicator is
removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any "improper solutions" such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.df</code></td>
<td>
<p><code>logical</code> indicating whether to return reliability
coefficients in a <code>data.frame</code> (one row per group/level), which is
possible when every model block includes the same factors (after excluding
those in <code>omit.factors</code> and applying <code>dropSingle</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Several coefficients for factor-analysis reliability have been termed
"omega", which Cho (2021) argues is a misleading misnomer and argues for
using <code class="reqn">\rho</code> to represent them all, differentiated by descriptive
subscripts.  In our package, we number <code class="reqn">\omega</code> based on commonly
applied calculations.
</p>
<p>Bentler (1968) first introduced factor-analysis reliability for a
unidimensional factor model with congeneric indicators, labeling the
coeficients <code class="reqn">\alpha</code>.  McDonald (1999) later referred to this
<em>and other reliability coefficients</em>, first as <code class="reqn">\theta</code> (in 1970),
then as <code class="reqn">\omega</code>, which is a source of confusion when reporting
coefficients (Cho, 2021).  Coefficients based on factor models were later
generalized to account for multidimenisionality (possibly with
cross-loadings) and correlated errors. The general <code class="reqn">\omega</code> formula
implemented in this function is:
</p>
<p style="text-align: center;"><code class="reqn"> \omega = \frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\hat{\Sigma}</code> can be the model-implied covariance matrix from
either the saturated model (i.e., the "observed" covariance matrix, used by
default) or from the hypothesized CFA model, controlled by the
<code>obs.var</code> argument. A <code class="reqn">k</code>-dimensional vector <code class="reqn">\bold{1}</code> is used
to sum elements in the matrix. Note that if the model includes any directed
effects (latent regression slopes), all coefficients are calculated
from <b>total</b> factor variances:
<code>lavInspect(object, "cov.lv")</code>.
</p>
<p>Assuming (essential) tau-equivalence (<code>tau.eq=TRUE</code>) makes <code class="reqn">\omega</code>
equivalent to coefficient <code class="reqn">\alpha</code> from classical test theory
(Cronbach, 1951):
</p>
<p style="text-align: center;"><code class="reqn"> \alpha = \frac{k}{k - 1}\left[ 1 - \frac{\sum^{k}_{i = 1}
\sigma_{ii}}{\sum^{k}_{i = 1} \sigma_{ii} + 2\sum_{i &lt; j} \sigma_{ij}}
\right],</code>
</p>

<p>where <code class="reqn">k</code> is the number of items in a factor's composite,
<code class="reqn">\sigma_{ii}</code> signifies item <em>i</em>'s variance, and <code class="reqn">\sigma_{ij}</code>
signifies the covariance between items <em>i</em> and <em>j</em>. Again, the
<code>obs.var</code> argument controls whether <code class="reqn">\alpha</code> is calculated using
the observed or model-implied covariance matrix.
</p>
<p>By setting <code>return.total=TRUE</code>, one can estimate reliability for a
single composite calculated using all indicators in a multidimensional
CFA (Bentler, 1972, 2009). Setting <code>return.total = -1</code> will return
<b>only</b> the total-composite reliability (not per factor).
</p>
<p><b>Higher-Order Factors</b>:
The reliability of a composite that represents a higher-order construct
requires partitioning the model-implied factor covariance matrix <code class="reqn">\Phi</code>
in order to isolate the common-factor variance associated only with the
higher-order factor. Using a second-order factor model, the model-implied
covariance matrix of observed indicators <code class="reqn">\hat{\Sigma}</code> can be
partitioned into 3 sources:
</p>

<ol>
<li>
<p> the second-order common-factor (co)variance:
<code class="reqn">\Lambda \bold{B} \Phi_2 \bold{B}^{\prime} \Lambda^{\prime}</code>
</p>
</li>
<li>
<p> the residual variance of the first-order common factors (i.e., not
accounted for by the second-order factor):
<code class="reqn">\Lambda \Psi_{u} \Lambda^{\prime}</code>
</p>
</li>
<li>
<p> the measurement error of observed indicators: <code class="reqn">\Theta</code>
</p>
</li>
</ol>
<p>where <code class="reqn">\Lambda</code> contains first-order factor loadings, <code class="reqn">\bold{B}</code>
contains second-order factor loadings, <code class="reqn">\Phi_2</code> is the model-implied
covariance matrix of the second-order factor(s), and <code class="reqn">\Psi_{u}</code> is the
covariance matrix of first-order factor disturbances. In practice, we can
use the full <code class="reqn">\bold{B}</code> matrix and full model-implied <code class="reqn">\Phi</code> matrix
(i.e., including all latent factors) because the zeros in <code class="reqn">\bold{B}</code>
will cancel out unwanted components of <code class="reqn">\Phi</code>. Thus, we can calculate
the proportion of variance of a composite score calculated from the observed
indicators (e.g., a total score or scale mean) that is attributable to the
second-order factor (i.e., coefficient <code class="reqn">\omega</code>):
</p>
<p style="text-align: center;"><code class="reqn">\omega_{L1}=\frac{\bold{1}^{\prime} \Lambda \bold{B} \Phi \bold{B}^{\prime}
  \Lambda^{\prime} \bold{1} }{ \bold{1}^{\prime} \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\bold{1}</code> is the <em>k</em>-dimensional vector of 1s and <em>k</em>
is the number of observed indicators in the composite. Note that a
higher-order factor can also have observed indicators.
</p>
<p><b>Categorical Indicators</b>:
When all indicators (per composite) are ordinal, the <code>ord.scale</code>
argument controls whether the coefficient is calculated on the
latent-response scale (<code>FALSE</code>) or on the observed ordinal scale
(<code>TRUE</code>, the default).  For <code class="reqn">\omega</code>-type coefficients
(<code>tau.eq=FALSE</code>), Green and Yang's (2009, formula 21) approach is used
to transform factor-model results back to the ordinal response scale.
When <code>ord.scale=TRUE</code>, coefficient <code class="reqn">\alpha</code> is calculated using the
covariance matrix calculated from the integer-valued numeric weights for
ordinal categories, consistent with its definition (Chalmers, 2018) and the
<code>alpha</code> function in the <code>psych</code> package; this implies
<code>obs.var=TRUE</code>, so <code>obs.var=FALSE</code> will be ignored.  When
<code>ord.scale=FALSE</code>, the standard <code class="reqn">\alpha</code> formula is applied to the
polychoric correlation matrix ("ordinal <code class="reqn">\alpha</code>"; Zumbo et al., 2007),
estimated from the saturated or hypothesized model (see <code>obs.var</code>),
and <code class="reqn">\omega</code> is calculated from CFA results without applying Green and
Yang's (2009) correction (see Zumbo &amp; Kroc's, 2019, for a rationalization).
No method has been proposed for calculating reliability with a mixture of
categorical and continuous indicators, so an error is returned if
<code>object</code> includes factors with a mixture of indicator types (unless
omitted using <code>omit.factors</code>). If categorical indicators load on a
different factor(s) than continuous indicators, then reliability will still
be calculated separately for those factors, but <code>return.total</code> must be
<code>FALSE</code> (unless <code>omit.factors</code> is used to isolate factors with
indicators of the same type).
</p>
<p><b>Multilevel Measurement Models</b>:
Under the default settings, <code>compRelSEM()</code> will apply the same formula
in each "block" (group and/or level of analysis). In the case of multilevel
SEMs, this yields "reliability" for latent within- and between-level
components, as proposed by Geldhof et al. (2014).  This is not recommended
because the coefficients do not correspond to actual composites that would
be calculated from the observed data.  Lai (2021) proposed coefficients for
reliability of actual composites, depending on the type of construct, which
requires specifying the names of constructs for which reliability is desired
(or multiple constructs whose indicators would compose a multidimensional
composite). Configural (<code>config=</code>) and/or <code>shared=</code> constructs
can be specified; the same construct can be specified in both arguments, so
that overall scale-reliability can be estimated for a shared construct by
including it in <code>config</code>.  Instead of organizing the output by block
(the default), specifying <code>config=</code> and/or <code>shared=</code> will prompt
organizing the output by <code>$config</code> and/or <code>$shared</code>.
</p>

<ul>
<li>
<p> The overall (<code>_2L</code>) scale reliability for <code>config</code>ural
constructs is returned, along with the reliability of a purely
individual-level composite (<code>_W</code>, calculated by cluster-mean
centering).
</p>
</li>
<li>
<p> The reliability for a <code>shared</code> construct quantifies
generalizability across both indicators and raters (i.e., subjects rating
their cluster's construct).  Lüdtke et al. (2011) refer to these as
measurement error and sampling error, respectively.  An interrater
reliability (IRR) coefficient is also returned, quantifying
generalizability across rater/sampling-error only. To obtain a
scale-reliability coefficient (quantifying a shared construct's
generalizability across indicator/measurement-error only), include the
same factor name in <code>config=</code>.  Jak et al. (2021) recommended
modeling components of the same construct at both levels, but users may
also saturate the within-level model (Lai, 2021).
</p>
</li>
</ul>
<p>Be careful about including Level-2 variables in the model, especially
whether it makes sense to include them in a total composite for a Level-2
construct.  <code>dropSingle=TRUE</code> only prevents estimating reliability for
a single-indicator construct, not from including such an indicator in a
total composite.  It is permissible for <code>shared=</code> constructs to have
indicators at Level-2 only.  If it is necessary to model other Level-2
variables (e.g., to justify the missing-at-random assumption when using
<code>missing = "FIML" estimation</code>), they should be placed in the
<code>omit.indicators=</code> argument to exclude them from total composites.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of composite reliability coefficients per
factor, or a <code>list</code> of vectors per "block" (group and/or level of
analysis), optionally returned as a <code>data.frame</code> when possible (see
<code>return.df=</code> argument description for caveat). If there are multiple
factors, whose multidimensional indicators combine into a single
composite, users can request <code>return.total=TRUE</code> to add a column
including a reliability coefficient for the total composite, or
<code>return.total = -1</code> to return <b>only</b> the total-composite
reliability (ignored when <code>config=</code> or <code>shared=</code> is specified
because each factor's specification must be checked across levels).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Uses hidden functions written by Sunthud Pornprasertmanit
(<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>) for the old <code>reliability()</code> function.
</p>


<h3>References</h3>

<p>Bentler, P. M. (1968). Alpha-maximized factor analysis (alphamax): Its
relation to alpha and canonical factor analysis. <em>Psychometrika, 33</em>(3),
335–345. <a href="https://doi.org/10.1007/BF02289328">doi:10.1007/BF02289328</a>
</p>
<p>Bentler, P. M. (1972). A lower-bound method for the dimension-free
measurement of internal consistency. <em>Social Science Research, 1</em>(4),
343–357. <a href="https://doi.org/10.1016/0049-089X%2872%2990082-8">doi:10.1016/0049-089X(72)90082-8</a>
</p>
<p>Bentler, P. M. (2009). Alpha, dimension-free, and model-based internal
consistency reliability. <em>Psychometrika, 74</em>(1), 137–143.
<a href="https://doi.org/10.1007/s11336-008-9100-1">doi:10.1007/s11336-008-9100-1</a>
</p>
<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of
ordinal alpha. <em>Educational and Psychological Measurement, 78</em>(6),
1056–1071. <a href="https://doi.org/10.1177/0013164417727036">doi:10.1177/0013164417727036</a>
</p>
<p>Cho, E. (2021) Neither Cronbach’s alpha nor McDonald’s omega: A commentary
on Sijtsma and Pfadt. <em>Psychometrika, 86</em>(4), 877–886.
<a href="https://doi.org/10.1007/s11336-021-09801-1">doi:10.1007/s11336-021-09801-1</a>
</p>
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of
tests. <em>Psychometrika, 16</em>(3), 297–334. <a href="https://doi.org/10.1007/BF02310555">doi:10.1007/BF02310555</a>
</p>
<p>Geldhof, G. J., Preacher, K. J., &amp; Zyphur, M. J. (2014). Reliability
estimation in a multilevel confirmatory factor analysis framework.
<em>Psychological Methods, 19</em>(1), 72–91. <a href="https://doi.org/10.1037/a0032138">doi:10.1037/a0032138</a>
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using
structural equation modeling: An alternative to coefficient alpha.
<em>Psychometrika, 74</em>(1), 155–167. <a href="https://doi.org/10.1007/s11336-008-9099-3">doi:10.1007/s11336-008-9099-3</a>
</p>
<p>Jak, S., Jorgensen, T. D., &amp; Rosseel, Y. (2021). Evaluating cluster-level
factor models with <code>lavaan</code> and M<em>plus</em>. <em>Psych, 3</em>(2),
134–152. <a href="https://doi.org/10.3390/psych3020012">doi:10.3390/psych3020012</a>
</p>
<p>Lai, M. H. C. (2021). Composite reliability of multilevel data: It’s about
observed scores and construct meanings. <em>Psychological Methods, 26</em>(1),
90–102. <a href="https://doi.org/10.1037/met0000287">doi:10.1037/met0000287</a>
</p>
<p>Lüdtke, O., Marsh, H. W., Robitzsch, A., &amp; Trautwein, U. (2011).
A 2 <code class="reqn">\times</code> 2 taxonomy of multilevel latent contextual models:
Accuracy–bias trade-offs in full and partial error correction models.
<em>Psychological Methods, 16</em>(4), 444–467. <a href="https://doi.org/10.1037/a0024376">doi:10.1037/a0024376</a>
</p>
<p>McDonald, R. P. (1999). <em>Test theory: A unified treatment</em>. Mahwah, NJ:
Erlbaum.
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of
coefficients alpha and theta for Likert rating scales.
<em>Journal of Modern Applied Statistical Methods, 6</em>(1), 21–29.
<a href="https://doi.org/10.22237/jmasm/1177992180">doi:10.22237/jmasm/1177992180</a>
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens’
scales of measurement do not help make it: A response to Chalmers.
<em>Educational and Psychological Measurement, 79</em>(6), 1184–1197.
<a href="https://doi.org/10.1177/0013164419844305">doi:10.1177/0013164419844305</a>
</p>


<h3>See Also</h3>

<p><code>maximalRelia</code> for the maximal reliability of weighted composite
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(HolzingerSwineford1939)
HS9 &lt;- HolzingerSwineford1939[ , c("x7","x8","x9")]
HSbinary &lt;- as.data.frame( lapply(HS9, cut, 2, labels=FALSE) )
names(HSbinary) &lt;- c("y7","y8","y9")
HS &lt;- cbind(HolzingerSwineford1939, HSbinary)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ y7 + y8 + y9 '

fit &lt;- cfa(HS.model, data = HS, ordered = c("y7","y8","y9"), std.lv = TRUE)

## works for factors with exclusively continuous OR categorical indicators
compRelSEM(fit)

## reliability for ALL indicators only available when they are
## all continuous or all categorical
compRelSEM(fit, omit.factors = "speed", return.total = TRUE)


## loop over visual indicators to calculate alpha if one indicator is removed
for (i in paste0("x", 1:3)) {
  cat("Drop ", i, ":\n", sep = "")
  print(compRelSEM(fit, omit.factors = c("textual","speed"),
                   omit.indicators = i, tau.eq = TRUE))
}


## Reliability of a composite that represents a higher-order factor
mod.hi &lt;- ' visual  =~ x1 + x2 + x3
            textual =~ x4 + x5 + x6
            speed   =~ x7 + x8 + x9
            general =~ visual + textual + speed '

fit.hi &lt;- cfa(mod.hi, data = HolzingerSwineford1939)
compRelSEM(fit.hi, higher = "general")
## reliabilities for lower-order composites also returned


## works for multigroup models and for multilevel models (and both)
data(Demo.twolevel)
## assign clusters to arbitrary groups
Demo.twolevel$g &lt;- ifelse(Demo.twolevel$cluster %% 2L, "type1", "type2")
model2 &lt;- ' group: type1
  level: 1
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
  level: 2
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6

group: type2
  level: 1
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
  level: 2
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
'
fit2 &lt;- sem(model2, data = Demo.twolevel, cluster = "cluster", group = "g")
compRelSEM(fit2) # Geldhof's indices (hypothetical, for latent components)

## Lai's (2021) indices for Level-1 and configural constructs
compRelSEM(fit2, config = c("f1","f2"))
## Lai's (2021) indices for shared (Level-2) constructs
## (also an interrater reliability coefficient)
compRelSEM(fit2, shared = c("f1","f2"))


## Shared construct using saturated within-level model
mod.sat1 &lt;- ' level: 1
  y1 ~~ y1 + y2 + y3 + y4 + y5 + y6
  y2 ~~ y2 + y3 + y4 + y5 + y6
  y3 ~~ y3 + y4 + y5 + y6
  y4 ~~ y4 + y5 + y6
  y5 ~~ y5 + y6
  y6 ~~ y6

  level: 2
  f1 =~ y1 + L2*y2 + L3*y3
  f2 =~ y4 + L5*y5 + L6*y6
'
fit.sat1 &lt;- sem(mod.sat1, data = Demo.twolevel, cluster = "cluster")
compRelSEM(fit.sat1, shared = c("f1","f2"))


## Simultaneous shared-and-configural model (Stapleton et al, 2016, 2019),
## not recommended, but possible by omitting shared or configural factor.
mod.both &lt;- ' level: 1
    fc =~ y1 + L2*y2 + L3*y3 + L4*y4 + L5*y5 + L6*y6
  level: 2
  ## configural construct
    fc =~ y1 + L2*y2 + L3*y3 + L4*y4 + L5*y5 + L6*y6
  ## orthogonal shared construct
    fs =~ NA*y1 + y2 + y3 + y4 + y5 + y6
    fs ~~ 1*fs + 0*fc
'
fit.both &lt;- sem(mod.both, data = Demo.twolevel, cluster = "cluster")
compRelSEM(fit.both, shared = "fs", config = "fc")

</code></pre>


</div>