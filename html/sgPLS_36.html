<div class="container">

<table style="width: 100%;"><tr>
<td>tuning.sgPLS.X</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Choice of the tuning parameters (number of groups and mixing parameter) related to  predictor matrix for sgPLS model (regression mode)</h2>

<h3>Description</h3>

<p>For a grid in two dimension of tuning parameters, this function computes by leave-one-out or M-fold cross-validation the MSEP (Mean Square Error of Prediction) of a sgPLS model. </p>


<h3>Usage</h3>

<pre><code class="language-R">tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), ncomp,
				keepX = NULL, alpha.x = NULL, grid.gX, grid.alpha.X,
				setseed, progressBar = FALSE, ind.block.x = ind.block.x,
				upper.lambda = 10 ^ 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times p)</code>, the observations on the <code class="reqn">X</code> variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Numeric matrix or data frame <code class="reqn">(n \times q)</code>, the observations on the <code class="reqn">Y</code> variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>Positive integer. Number of folds to use if <code>validation="Mfold"</code>. Defaults to
<code>folds=10</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation</code></td>
<td>
<p>Character string. What kind of (internal) cross-validation method to use, 
(partially) matching one of <code>"Mfolds"</code> (M-folds) or <code>"loo"</code> (leave-one-out).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>
<p>Number of component for investigating the choice of the tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepX</code></td>
<td>
<p>Vector of integer indicating the number of group of variables to keep in each component. See Details for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.x</code></td>
<td>
<p>Numeric vector indicating the number of group of variables to keep in each component. See Details for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grid.gX,grid.alpha.X</code></td>
<td>
<p>Vector numeric defining the values of
tuning parameter lambda (number of groups to select) and tuning
parameter alpha (mixing paramter values between 0 and 1) at which cross-validation score should be computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>setseed</code></td>
<td>
<p>Integer indicating the random number generation state.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progressBar</code></td>
<td>
<p>By default set to <code>FALSE</code> to output the progress bar of the computation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.block.x</code></td>
<td>
<p>A vector of integers describing the grouping of the X variables. (see an example in Details section).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper.lambda</code></td>
<td>
<p>By default <code>upper.lambda=10 ^ 9</code>. A large value specifying the upper bound of the intervall of lambda values for searching the value of the tuning parameter (lambda) corresponding to a non-zero group of variables.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>validation = "Mfolds"</code>, M-fold cross-validation is performed by calling 
<code>Mfold</code>. The folds are generated. The number of cross-validation 
folds is specified with the argument <code>folds</code>. 
</p>
<p>If <code>validation = "loo"</code>, 
leave-one-out cross-validation is performed by calling the 
<code>loo</code> function. In this case the arguments <code>folds</code> are ignored.
</p>
<p>if <code>keepX</code> is specified (by default is NULL), each element of <code>keepX</code> indicates the value of the tuning parameter for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-validation score at different values defining by <code>grid.X</code>.
</p>
<p>if <code>alpha.x</code> is specified (by default is NULL), each element of <code>alpha.x</code> indicates the value of the tuning parameter (alpha) for the corresponding component. Only the choice of the tuning parameters corresponding to the remaining components are investigating by evaluating the cross-vlidation score at different values defining by <code>grid.alpha.X</code>.
</p>


<h3>Value</h3>

<p>The returned value is a list with components: 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>MSEP</code></td>
<td>
<p>vector containing the cross-validation score computed on the grid</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keepX</code></td>
<td>
<p>value of the tuning parameter on which
the cross-validation method reached it minimum.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphaX</code></td>
<td>
<p>value of the tuning parameter (alpha) on which
the cross-validation method reached it minimum.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Benoit Liquet and Pierre Lafaye de Micheaux</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 	
## Simulation of datasets X (with group variables) and Y a multivariate response variable 
n &lt;- 200
sigma.e &lt;- 0.5
p &lt;- 400
q &lt;- 10
theta.x1 &lt;- c(rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5), rep(1.5, 15),
			rep(0, 5), rep(-1.5, 15), rep(0, 325))
theta.x2 &lt;- c(rep(0, 320), rep(1, 15), rep(0, 5), rep(-1, 15), rep(0, 5),
			rep(1.5, 15), rep(0, 5), rep(-1.5, 15), rep(0, 5))

set.seed(125)
theta.y1 &lt;- runif(10, 0.5, 2)
theta.y2 &lt;- runif(10, 0.5, 2)
  
temp &lt;-  matrix(c(theta.y1, theta.y2), nrow = 2, byrow = TRUE)

Sigmax &lt;- matrix(0, nrow = p, ncol = p)
diag(Sigmax) &lt;- sigma.e ^ 2
Sigmay &lt;- matrix(0, nrow = q, ncol = q)
diag(Sigmay) &lt;- sigma.e ^ 2

gam1 &lt;- rnorm(n)
gam2 &lt;- rnorm(n)

X &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% matrix(c(theta.x1, theta.x2),
     nrow = 2, byrow = TRUE) + rmvnorm(n, mean = rep(0, p), sigma =
     Sigmax, method = "svd")
Y &lt;- matrix(c(gam1, gam2), ncol = 2, byrow = FALSE) %*% t(svd(temp)$v) 
     + rmvnorm(n, mean = rep(0, q), sigma = Sigmay, method = "svd")

ind.block.x &lt;- seq(20, 380, 20)

grid.X &lt;- 2:16
grid.alpha.X &lt;- c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.95)
## Strategy with same value of each tuning parameter for both components
tun.sgPLS &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
				ncomp = 2,keepX = NULL, alpha.x = NULL,grid.gX = grid.X, 
				grid.alpha.X = grid.alpha.X, setseed = 1, progressBar = FALSE, 
				ind.block.x = ind.block.x) 

tun.sgPLS$keepX # for each component
tun.sgPLS$alphaX # for each component
##For a sequential strategy
tun.sgPLS.1 &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"),
			         ncomp = 1, keepX = NULL,  alpha.x = NULL, grid.gX = grid.X,
				 grid.alpha.X = grid.alpha.X, setseed = 1, 
				 ind.block.x = ind.block.x) 
					 
tun.sgPLS.1$keepX # for the first component
tun.sgPLS.1$alphaX # for the first component

tun.sgPLS.2 &lt;- tuning.sgPLS.X(X, Y, folds = 10, validation = c("Mfold", "loo"), 
					ncomp = 2, keepX = tun.sgPLS.1$keepX,
					alpha.x = tun.sgPLS.1$alphaX,
					grid.gX = grid.X,
					grid.alpha.X = grid.alpha.X,
					setseed = 1,
					ind.block.x = ind.block.x) 

tun.sgPLS.2$keepX # for the second component
tun.sgPLS.2$alphaX # for the second component

## End(Not run)
</code></pre>


</div>