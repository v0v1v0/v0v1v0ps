<div class="container">

<table style="width: 100%;"><tr>
<td>jive.est</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The Jackknife Instrumental Variable Estimator (JIVE).</h2>

<h3>Description</h3>

<p>Compute the JIVE for a multiple regression, as well
as the set of standard errors for the individual vector entries, and
the estimate of the asymptotic variance/covariance matrix.</p>


<h3>Usage</h3>

<pre><code class="language-R">  jive.est(y,X,Z,SE=FALSE,n.bt=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Numeric: A vector of observations, representing the outcome variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Numeric: A matrix of observations, whose number of columns
corresponds to the number of predictors in the model, and the number
of rows should be conformal with the number of entries in <code class="reqn">y</code>. This
matrix may contain both endogenous and exogenous variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>Numeric: A matrix of observations representing the
intrumental variables (IVs) in the first-stage structural equation. The
number of IVs should be at least as large as the number of
endogenous variables in <code class="reqn">X</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE</code></td>
<td>
<p>Logical: If TRUE, then the function also returns the
standard errors of the individual JIVE estimators, and a bootstrap
estimate of its asymptotic variance/covariance matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.bt</code></td>
<td>
<p>Numeric: The number of bootstrap samples performed for
estimating the variance/covariance matrix.
This automatically occurs, whenever the user selects the
SE to be true.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The JIVE was originally introduced by Angrist et al. (1995), in order to reduce the finite-sample
bias of the TSLS estimator, when applied to a large number of
instruments. Indeed, the TSLS estimator tends to behave poorly as the
number of instruments increases. We briefly outline this method. See
Angrist et al. (1999) for an exhaustive description.
</p>
<p>The model is identical to the one used in the rest of this package. That is,
the second-stage equation is modelled as <code class="reqn">y = X\beta + \epsilon,</code>
in which <code class="reqn">y</code> is a vector of <code class="reqn">n</code> observations representing the
outcome variable, <code class="reqn">X</code> is a matrix of order <code class="reqn">n\times k</code>
denoting the predictors of the model, and comprised of both exogenous
and endogenous variables, <code class="reqn">\beta</code> is the <code class="reqn">k</code>-dimensional
vector of parameters of interest; whereas <code class="reqn">\epsilon</code> is an unknown
vector of error terms.
Moreover, the first-stage level of the model is given by a multivariate
multiple regression. That is, this is a linear modle with a
<em>multivariate</em> outcome variable, as well as <em>multiple</em>
predictors. This first-stage model is represented in this manner, 
<code class="reqn">X = Z\Gamma + \Delta</code>,
where <code class="reqn">X</code> is the matrix of predictors from the second-stage
equation, <code class="reqn">Z</code> is a matrix of instrumental variables (IVs) of order
<code class="reqn">n \times l</code>, <code class="reqn">\Gamma</code> is a matrix of unknown parameters of
order <code class="reqn">l\times k</code>; whereas <code class="reqn">\Delta</code> denotes an unknown matrix of order
<code class="reqn">n\times k</code> of error terms. 
</p>
<p>For computing the JIVE, we first consider the estimator of the
regression parameter in the first-stage equation, which is denoted by  
</p>
<p style="text-align: center;"><code class="reqn">\hat\Gamma := ({Z}^{T}{Z})^{-1}({Z}^{T}{X}).</code>
</p>

<p>This matrix is of order <code class="reqn">l\times k</code>. The matrix of predictors, <code class="reqn">{X}</code>, projected
onto the column space of the instruments is then given by
<code class="reqn">\hat{X}={Z}\hat\Gamma</code>. The JIVE proceeds by
estimating each row of <code class="reqn">\hat{X}</code> without using the corresponding data
point. That is, the <code class="reqn">i</code>th row in the jackknife matrix, <code class="reqn">\hat{X}_{J}</code>,
is estimated without using the <code class="reqn">i</code>th row of <code class="reqn">{X}</code>.
This is conducted as follows. For every <code class="reqn">i=1,\ldots,n</code>, we first compute
</p>
<p style="text-align: center;"><code class="reqn">\hat\Gamma_{(i)} :=
    ({Z}_{(i)}^{T}{Z}_{(i)})^{-1}({Z}_{(i)}^{T}{X}_{(i)}),</code>
</p>
  
<p>where <code class="reqn">{Z}_{(i)}</code> and <code class="reqn">{X}_{(i)}</code> denote matrices <code class="reqn">{Z}</code> and <code class="reqn">{X}</code> after
removal of the <code class="reqn">i</code>th row, such that these two matrices are of order
<code class="reqn">(n-1)\times l</code> and <code class="reqn">(n-1)\times k</code>, respectively. Then, the
matrix <code class="reqn">\hat{X}_{J}</code> is constructed by stacking these jackknife
estimates of <code class="reqn">\hat\Gamma</code>, after they have been pre-multiplied by the
corresponding rows of <code class="reqn">{Z}</code>, 
</p>
<p style="text-align: center;"><code class="reqn">\hat{X}_{J} :=
	({z}_{1}\hat\Gamma_{(1)},\ldots,{z}_{n}\hat\Gamma_{(n)})^{T},</code>
</p>
     
<p>where each <code class="reqn">{z}_{i}</code> is an <code class="reqn">l</code>-dimensional row vector. The JIVE
estimator is then obtained by replacing <code class="reqn">\hat{X}</code> with
<code class="reqn">\hat{X}_{J}</code> in the standard formula of the TSLS, such that 
</p>
<p style="text-align: center;"><code class="reqn">\hat\beta_{J} := (\hat{X}_{J}{}^{T}{X})^{-1}(\hat{X}_{J}{}^{T}{y}).</code>
</p>

<p>In this package, we have additionally made use of the computational
formula suggested by Angrist et al. (1999), in which each row of
<code class="reqn">\hat{X}_{J}</code> is calculated using 
</p>
<p style="text-align: center;"><code class="reqn">{z}_{i}\hat\Gamma_{(i)} = \frac{{z}_{i}\hat\Gamma -
    h_{i}{x}_{i}}{1-h_{i}},</code>
</p>

<p>where <code class="reqn">{z}_{i}\hat\Gamma_{(i)}</code>, <code class="reqn">{z}_{i}\hat\Gamma</code> and
<code class="reqn">{x}_{i}</code> are <code class="reqn">k</code>-dimensional row vectors; and with <code class="reqn">h_{i}</code> denoting
the leverage of the corresponding data point in the first-level
equation of our model, such that each <code class="reqn">h_{i}</code> is defined as
<code class="reqn">{z}_{i}({Z}^{T}{Z})^{-1}{z}_{i}^{T}</code>.
</p>


<h3>Value</h3>

<table><tr style="vertical-align: top;">
<td><code>list</code></td>
<td>
<p>A list with one or three arguments, depending on whether
the user has activated the SE flag. The first element (est) in the list
is the TSLS estimate of the model in vector format. The second
element (se) is the vector of standard errors; and the third
element (var) is the sample estimate of the asymptotic
variance/covariance matrix.</p>
</td>
</tr></table>
<h3>Author(s)</h3>

<p>Cedric E. Ginestet &lt;cedric.ginestet@kcl.ac.uk&gt;
</p>


<h3>References</h3>

<p>Angrist, J., Imbens, G., and Krueger, A.B. (1995). Jackknife instrumental variables esti-
mation. Technical Working Paper 172, National Bureau of Economic
Research.
</p>
<p>Angrist, J.D., Imbens, G.W., and Krueger, A.B. (1999). Jackknife instrumental variables
estimation. Journal of Applied Econometrics, 14(1), 57â€“67.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
### Generate a simple example with synthetic data, and no intercept. 
n &lt;- 100; k &lt;- 3; l &lt;- 3;
Ga&lt;- diag(rep(1,l)); be &lt;- rep(1,k);
Z &lt;- matrix(0,n,l); for(j in 1:l) Z[,j] &lt;- rnorm(n); 
X &lt;- matrix(0,n,k); for(j in 1:k) X[,j] &lt;- Z[,j]*Ga[j,j] + rnorm(n); 
y &lt;- X%*%be + rnorm(n);

### Compute JIVE estimator with SEs and variance/covariance matrix.
print(jive.est(y,X,Z))
print(jive.est(y,X,Z,SE=TRUE));

</code></pre>


</div>