<div class="container">

<table style="width: 100%;"><tr>
<td>SPCAvRP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Computes the leading eigenvector using the SPCAvRP algorithm</h2>

<h3>Description</h3>

<p>Computes <code>l</code>-sparse leading eigenvector of the sample covariance matrix, using <code>A x B</code> random axis-aligned projections of dimension <code>d</code>. For the multiple component estimation use <code>SPCAvRP_subspace</code> or <code>SPCAvRP_deflation</code>.</p>


<h3>Usage</h3>

<pre><code class="language-R">SPCAvRP(data, cov = FALSE, l, d = 20, A = 600, B = 200, 
center_data = TRUE, parallel = FALSE, 
cluster_type = "PSOCK", cores = 1, machine_names = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Either the data matrix (<code>p x n</code>) or the sample covariance matrix (<code>p x p</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>
<p><code>TRUE</code> if data is given as a sample covariance matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l</code></td>
<td>
<p>Desired sparsity level in the final estimator (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>The dimension of the random projections (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>Number of projections over which to aggregate (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>Number of projections in a group from which to select (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center_data</code></td>
<td>
<p><code>TRUE</code> if the data matrix should be centered (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p><code>TRUE</code> if the selection step should be computed in parallel by uses package <code>"parallel"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_type</code></td>
<td>
<p>If <code>parallel == TRUE</code>, this can be <code>"PSOCK"</code> or <code>"FORK"</code> (cf. package <code>"parallel"</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>If <code>parallel == TRUE</code> and <code>cluster_type == "FORK"</code>, number of cores to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>machine_names</code></td>
<td>
<p>If <code>parallel == TRUE</code>, the names of the computers on the network.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function implements the SPCAvRP algorithm for the principal component estimation (Algorithm 1 in the reference given below). 
</p>
<p>If the true sparsity level <code>k</code> is known, use <code>l = k</code> and <code>d = k</code>. 
</p>
<p>If the true sparsity level <code>k</code> is unknown, <code>l</code> can take an array of different values and then the estimators of the corresponding sparsity levels are computed. The final choice of <code>l</code> can then be done by the user via inspecting the explained variance computed in the output <code>value</code> or via inspecting the output <code>importance_scores</code>. The default choice for <code>d</code> is <code>20</code>, but we suggest choosing <code>d</code> equal to or slightly larger than <code>l</code>.  
</p>
<p>It is desirable to choose <code>A</code> (and <code>B = ceiling(A/3)</code>) as big as possible subject to the computational budget. In general, we suggest using <code>A = 300</code> and <code>B = 100</code> when the dimension of data is a few hundreds, while <code>A = 600</code> and <code>B = 200</code> when the dimension is on order of <code>1000</code>. 
</p>
<p>If <code>center_data == TRUE</code> and <code>data</code> is given as a data matrix, the first step is to center it by executing <code>scale(data, center_data, FALSE)</code>, which subtracts the column means of <code>data</code> from their corresponding columns.
</p>
<p>If <code>parallel == TRUE</code>, the parallelised SPCAvRP algorithm is used. We recommend to use this option if <code>p</code>, <code>A</code> and <code>B</code> are very large. 
</p>


<h3>Value</h3>

<p>Returns a list of three elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>vector</code></td>
<td>
<p>A matrix of dimension <code>p x length(l)</code> with columns as the estimated eigenvectors of sparsity level <code>l</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value</code></td>
<td>
<p>An array with <code>length(l)</code> eigenvalues corresponding to the estimated eigenvectors returned in <code>vector</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>importance_scores</code></td>
<td>
<p>An array of length p with importance scores for each variable 1 to p.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Milana Gataric, Tengyao Wang and Richard J. Samworth</p>


<h3>References</h3>

<p>Milana Gataric, Tengyao Wang and Richard J. Samworth (2018) Sparse principal component analysis via random projections
<a href="https://arxiv.org/abs/1712.05630">https://arxiv.org/abs/1712.05630</a></p>


<h3>Examples</h3>

<pre><code class="language-R">p &lt;- 100  # data dimension
k &lt;- 10   # true sparsity level
n &lt;- 1000 # number of observations
v1 &lt;- c(rep(1/sqrt(k), k), rep(0,p-k)) # true principal component
Sigma &lt;- 2*tcrossprod(v1) + diag(p)    # population covariance
mu &lt;- rep(0, p)                        # population mean
loss = function(u,v){ 
  # the loss function
  sqrt(abs(1-sum(v*u)^2))
}
set.seed(1)
X &lt;- mvrnorm(n, mu, Sigma) # data matrix

spcavrp &lt;- SPCAvRP(data = X, cov = FALSE, l = k, d = k, A = 200, B = 70)
spcavrp.loss &lt;- loss(v1,spcavrp$vector)
print(paste0("estimation loss when l=d=k=10, A=200, B=70: ", spcavrp.loss))

##choosing sparsity level l if k unknown:
#spcavrp.choosel &lt;- SPCAvRP(data = X, cov = FALSE, l = c(1:30), d = 15, A = 200, B = 70)
#plot(1:p,spcavrp.choosel$importance_scores,xlab='variable',ylab='w',
#     main='choosing l when k unknown: \n importance scores w')
#plot(1:30,spcavrp.choosel$value,xlab='l',ylab='Var_l',
#     main='choosing l when k unknown: \n explained variance Var_l')
</code></pre>


</div>