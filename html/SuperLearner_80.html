<div class="container">

<table style="width: 100%;"><tr>
<td>SL.kernelKnn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SL wrapper for KernelKNN</h2>

<h3>Description</h3>

<p>Wrapper for a configurable implementation of k-nearest
neighbors. Supports both binomial and gaussian outcome distributions.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SL.kernelKnn(Y, X, newX, family, k = 10, method = "euclidean",
  weights_function = NULL, extrema = F, h = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Outcome variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Training dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newX</code></td>
<td>
<p>Test dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Gaussian or binomial</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Number of nearest neighbors to use</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Distance method, can be 'euclidean' (default), 'manhattan',
'chebyshev', 'canberra', 'braycurtis', 'pearson_correlation',
'simple_matching_coefficient', 'minkowski' (by default the order 'p' of the
minkowski parameter equals k), 'hamming', 'mahalanobis',
'jaccard_coefficient', 'Rao_coefficient'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights_function</code></td>
<td>
<p>Weighting method for combining the nearest neighbors.
Can be 'uniform' (default), 'triangular', 'epanechnikov', 'biweight',
'triweight', 'tricube', 'gaussian', 'cosine', 'logistic', 'gaussianSimple',
'silverman', 'inverse', 'exponential'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extrema</code></td>
<td>
<p>if TRUE then the minimum and maximum values from the
k-nearest-neighbors will be removed (can be thought as outlier removal).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>the bandwidth, applicable if the weights_function is not NULL.
Defaults to 1.0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Any additional parameters, not currently passed through.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List with predictions and the original training data &amp;
hyperparameters.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Load a test dataset.
data(PimaIndiansDiabetes2, package = "mlbench")

data = PimaIndiansDiabetes2

# Omit observations with missing data.
data = na.omit(data)

Y_bin = as.numeric(data$diabetes)
X = subset(data, select = -diabetes)

set.seed(1)

sl = SuperLearner(Y_bin, X, family = binomial(),
                 SL.library = c("SL.mean", "SL.kernelKnn"))
sl

</code></pre>


</div>