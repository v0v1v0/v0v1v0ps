<div class="container">

<table style="width: 100%;"><tr>
<td>glmnetcv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross validation, n-fold and leave-one-out, for 'glmnet' in 'glmnet' package</h2>

<h3>Description</h3>

<p>This function is a cross validation function
for 'glmnet' method in 'glmnet' package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">glmnetcv(
  trainx,
  y,
  family = "gaussian",
  alpha = 0.5,
  relax = FALSE,
  type.measure = "mse",
  validation = "CV",
  cv.fold = 10,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>trainx</code></td>
<td>
<p>a matrix contains predictive variables of point samples.
The location information, longitude (long), latitude (lat), need to be included
in the 'trainx' for spatial predictive modelling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector of the response variable in the formula, that is, the left
part of the formula.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. See '?glmnet' for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha, </code></td>
<td>
<p>an elasticnet mixing parameter, with $0 &lt;= alpha &lt;= 1$.
See '?glmnet' for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>relax, </code></td>
<td>
<p>if TRUE then for each active set in the path of solutions,
the model is refit without any regularization. See '?glmnet' for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type.measure, </code></td>
<td>
<p>loss to use for cross-validation. The default is
type.measure="mse". See '?cv.glmnet' for more information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation</code></td>
<td>
<p>validation methods, include 'LOO': leave-one-out, and 'CV':
cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predacc</code></td>
<td>
<p>can be either "VEcv" for vecv or "ALL" for all measures
in function pred.acc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments passed on to 'fields'.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with the following components:
me, rme, mae, rmae, mse, rmse, rrmse, vecv and e1; or vecv only
</p>


<h3>Note</h3>

<p>This function is largely based on 'glmcv' in this 'spm2' package.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>A. Liaw and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(spm)

data(petrel)
x &lt;- as.matrix(petrel[, c(1, 2, 6:9)])
y &lt;- log(petrel[, 5] + 1)
set.seed(1234)
glmnetcv1 &lt;- glmnetcv(x, y, validation = "CV",  predacc = "ALL")
glmnetcv1

data(sponge)
x &lt;- as.matrix(cbind(sponge$easting, sponge$easting^2))
set.seed(1234)
glmnetcv1 &lt;- glmnetcv(x, sponge[, 3], family = poisson, validation = "CV",
predacc = "ALL")
glmnetcv1

# For glmnet with gaussian
x &lt;- as.matrix(petrel[, c(1, 2, 6:9)])
y &lt;- log(petrel[, 5] + 1)
set.seed(1234)
n &lt;- 20 # number of iterations,60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
  glmnetcv1 &lt;- glmnetcv(x, y, validation = "CV", predacc = "VEcv")
  VEcv [i] &lt;- glmnetcv1
 }
plot(VEcv ~ c(1:n), xlab = "Iteration for glmnet", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

# For glmnet with binomial
x &lt;- as.matrix(cbind(petrel[, c(2, 6)], petrel$long^3, petrel$lat^2, petrel$lat^3))
set.seed(1234)
n &lt;- 20 # number of iterations,60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
glmnetcv1 &lt;- glmnetcv(x, petrel[, 5] / 100, family = binomial(link=logit),
validation = "CV", predacc = "VEcv")
VEcv [i] &lt;- glmnetcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for glmnet", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)


</code></pre>


</div>