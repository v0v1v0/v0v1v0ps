<div class="container">

<table style="width: 100%;"><tr>
<td>cv.tune</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Tuning via 5 fold Cross-Validation.
</h2>

<h3>Description</h3>

<p>Implement the tuning procedure for K-nearest neighbor classifier, bagged nearest neighbor classifier, optimal weighted nearest neighbor classifier, and stabilized nearest neighbor classifier.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.tune(train, numgrid = 20, classifier = "snn")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>

<p>Matrix of training data sets. An n by (d+1) matrix, where n is the sample size and d is the dimension. The last column is the class label.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numgrid</code></td>
<td>

<p>Number of grids for search
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier</code></td>
<td>

<p>The classifier for tuning. Possible choices are knn, bnn, ownn, snn.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For the K-nearest neighbor classifier (knn), the grids for search are equal spaced integers in [1, n/2].
</p>
<p>Given the best k for the K-nearest neighbor classifier, the best parameter for the bagged nearest neighbor classifier (bnn) is computed via (3.5) in Samworth (2012).
</p>
<p>Given the best k for the K-nearest neighbor classifier, the best parameter for Samworth's optimal weighted nearest neighbor classifier (ownn) is computed via (2.9) in Samworth (2012).
</p>
<p>For the stabilized nearest neighbor classifier (snn), we first identify a set of lambda's whose corresponding risks are among the lower 10th percentiles, and then choose from them an optimal one which has the minimal estimated classification instability. The grids of lambda's are chosen such that each one is corresponding to an evenly spaced grid of k in [1, n/2]. See Sun et al. (2015) for details.
</p>


<h3>Value</h3>

<p>The returned list contains:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>parameter.opt</code></td>
<td>
<p>The best tuning parameter for the chosen classifier. For example, the best K for knn and ownn, the best ratio for bnn, and the best lambda for snn.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter.list</code></td>
<td>
<p>The list of parameters in the grid search for the chosen classifier.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Wei Sun, Xingye Qiao, and Guang Cheng
</p>


<h3>References</h3>

<p>R.J. Samworth (2012), "Optimal Weighted Nearest Neighbor Classifiers," Annals of Statistics, 40:5, 2733-2763.
</p>
<p>W. Sun, X. Qiao, and G. Cheng (2015) Stabilized Nearest Neighbor Classifier and Its Statistical Properties. Available at arxiv.org/abs/1405.6642. 
</p>


<h3>Examples</h3>

<pre><code class="language-R">	set.seed(1)
	n = 100
	d = 10
	DATA = mydata(n, d)

	## Tuning procedure
	out.tune = cv.tune(DATA, classifier = "knn") 
	out.tune

</code></pre>


</div>