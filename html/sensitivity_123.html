<div class="container">

<table style="width: 100%;"><tr>
<td>pmvd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Proportional Marginal Variance Decomposition indices
for linear and logistic models</h2>

<h3>Description</h3>

<p><code>pmvd</code> computes the PMVD indices derived from Feldman (2005) applied to
the explained variance (<code class="reqn">R^2</code>) as a performance metric. 
They allow for relative importance indices by <code class="reqn">R^2</code> decomposition 
for linear and logistic regression models. These indices allocate a share of
<code class="reqn">R^2</code> to each input based on a Proportional attribution system,
allowing for covariates with null regression coefficients to have indices
equal to 0, despite their potential dependence with other covariates (Exclusion
principle).
</p>


<h3>Usage</h3>

<pre><code class="language-R">pmvd(X, y, logistic = FALSE, tol = NULL, rank = FALSE, nboot = 0, 
    conf = 0.95, max.iter = 1000, parl = NULL)
## S3 method for class 'pmvd'
print(x, ...)
## S3 method for class 'pmvd'
plot(x, ylim = c(0,1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a matrix or data frame containing the observed covariates
(i.e., features, input variables...).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a numeric vector containing the observed outcomes (i.e.,
dependent variable). If <code>logistic=TRUE</code>, can be a numeric vector
of zeros and ones, or a logical vector, or a factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logistic</code></td>
<td>
<p>logical. If <code>TRUE</code>, the analysis is done via a
logistic regression(binomial GLM).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>covariates with absolute marginal contributions less or equal to 
<code>tol</code> are omitted. By default, if <code>tol=NULL</code>, only covariates with no 
marginal contribution are omitted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rank</code></td>
<td>
<p>logical. If <code>TRUE</code>, the analysis is done on the
ranks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nboot</code></td>
<td>
<p>the number of bootstrap replicates for the computation
of confidence intervals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>
<p>the confidence level of the bootstrap confidence intervals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>if <code>logistic=TRUE</code>, the maximum number of iterative 
optimization steps allowed for the logistic regression. Default is <code>1000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parl</code></td>
<td>
<p>number of cores on which to parallelize the computation. If
<code>NULL</code>, then no parallelization is done.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the object returned by <code>lmg</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylim</code></td>
<td>
<p>the y-coordinate limits of the plot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to be passed to methods, such as graphical
parameters (see <code>par</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The computation of the PMVD is done using the recursive method defined in
Feldman (2005), but using the subset procedure defined in Broto, Bachoc
and Depecker (2020), that is computing all the <code class="reqn">R^2</code> for all
possible sub-models first, and then computing <code class="reqn">P(.)</code> recursively for all
subsets of covariates. See Il Idrissi et al. (2021).
</p>
<p>For logistic regression (<code>logistic=TRUE</code>), the <code class="reqn">R^2</code>
value is equal to:
</p>
<p style="text-align: center;"><code class="reqn">R^2 = 1-\frac{\textrm{model deviance}}{\textrm{null deviance}}</code>
</p>

<p>If either a logistic regression model (<code>logistic = TRUE</code>), or any column
of <code>X</code> is categorical (i.e., of class <code>factor</code>), then the rank-based
indices cannot be computed. In both those cases, <code>rank = FALSE</code> is forced
by default (with a <code>warning</code>).
</p>
<p>If too many cores for the machine are passed on to the <code>parl</code> argument,
the chosen number of cores is defaulted to the available cores minus one.
</p>
<p>Spurious covariates are defined by the <code>tol</code> argument. If <code>null</code>,
then covariates with:
</p>
<p style="text-align: center;"><code class="reqn">w(\{i\}) = 0</code>
</p>

<p>are omitted, and their <code>pmvd</code> index is set to zero. In other cases, the 
spurious covariates are detected by:
</p>
<p style="text-align: center;"><code class="reqn">|w(\{i\})| \leq \textrm{tol}</code>
</p>



<h3>Value</h3>

<p><code>pmvd</code> returns a list of class <code>"pmvd"</code>, containing the following
components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pmvd</code></td>
<td>
<p>a data frame containing the estimations of the PMVD indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R2s</code></td>
<td>
<p>the estimations of the <code class="reqn">R^2</code> for all possible sub-models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>indices</code></td>
<td>
<p>list of all subsets corresponding to the structure of R2s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p>the values of <code class="reqn">P(.)</code> of all subsets for recursive computing. Equal to
<code>NULL</code> if bootstrap estimates are made.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf_int</code></td>
<td>
<p>a matrix containing the estimations, biais and confidence
intervals by bootstrap (if <code>nboot&gt;0</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the observed covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>the observed outcomes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logistic</code></td>
<td>
<p>logical. <code>TRUE</code> if the analysis has been made by
logistic regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boot</code></td>
<td>
<p>logical. <code>TRUE</code> if bootstrap estimates have been produced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nboot</code></td>
<td>
<p>number of bootstrap replicates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rank</code></td>
<td>
<p>logical. <code>TRUE</code> if a rank analysis has been made.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parl</code></td>
<td>
<p>number of chosen cores for the computation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>
<p>level for the confidence intervals by bootstrap.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Marouane Il Idrissi
</p>


<h3>References</h3>

<p>Broto B., Bachoc F. and Depecker M. (2020) <em>Variance Reduction for Estimation
of Shapley Effects and Adaptation to Unknown Input Distribution.</em> SIAM/ASA Journal
on Uncertainty Quantification, 8(2).
</p>
<p>D.V. Budescu (1993). <em>Dominance analysis: A new approach to the problem of relative
importance of predictors in multiple regression.</em> Psychological Bulletin, 114:542-551.
</p>
<p>L. Clouvel, B. Iooss, V. Chabridon, M. Il Idrissi and F. Robin, 2024,
<em>An overview of variance-based importance measures in the linear regression context: 
comparative analyses and numerical tests</em>, Preprint.
<a href="https://hal.science/hal-04102053">https://hal.science/hal-04102053</a>
</p>
<p>Feldman, B. (2005) <em>Relative Importance and Value</em> SSRN Electronic Journal.
</p>
<p>U. Gromping (2006). <em>Relative importance for linear regression in R: the Package
relaimpo.</em>  Journal of Statistical Software, 17:1-27.
</p>
<p>M. Il Idrissi, V. Chabridon and B. Iooss (2021). <em>Mesures d'importance relative  
par decompositions de la performance de modeles de regression,</em> Actes des 52emes Journees 
de Statistiques de la Societe Francaise de Statistique (SFdS), pp 497-502,
Nice, France, Juin 2021
</p>
<p>B. Iooss, V. Chabridon and V. Thouvenot, <em>Variance-based importance 
measures for machine learning model interpretability</em>, Congres lambda-mu23,
Saclay, France, 10-13 octobre 2022
<a href="https://hal.science/hal-03741384">https://hal.science/hal-03741384</a>
</p>


<h3>See Also</h3>

<p><code>pcc</code>, <code>src</code>, <code>lmg</code>, <code>pme_knn</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(parallel)
library(gtools)
library(boot)

library(mvtnorm)

set.seed(1234)
n &lt;- 100
beta&lt;-c(1,-2,3)
sigma&lt;-matrix(c(1,0,0,
                0,1,-0.8,
                0,-0.8,1),
              nrow=3,
              ncol=3)

############################
# Gaussian correlated inputs

X &lt;-rmvnorm(n, rep(0,3), sigma)

#############################
# Linear Model

y &lt;- X%*%beta + rnorm(n)

# Without Bootstrap confidence intervals
x&lt;-pmvd(X, y)
print(x)
plot(x)

# With Boostrap confidence intervals
x&lt;-pmvd(X, y, nboot=100, conf=0.95)
print(x)
plot(x)

# Rank-based analysis
x&lt;-pmvd(X, y, rank=TRUE, nboot=100, conf=0.95)
print(x)
plot(x)

############################
# Logistic Regression
y&lt;-as.numeric(X%*%beta + rnorm(n)&gt;0)
x&lt;-pmvd(X,y, logistic = TRUE)
plot(x)
print(x)

# Parallel computing
#x&lt;-pmvd(X,y, logistic = TRUE, parl=2)
#plot(x)
#print(x)

</code></pre>


</div>