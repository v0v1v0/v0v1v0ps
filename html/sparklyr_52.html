<div class="container">

<table style="width: 100%;"><tr>
<td>ft_bucketizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Transformation â€“ Bucketizer (Transformer)</h2>

<h3>Description</h3>

<p>Similar to <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>'s <code>cut</code> function, this transforms a numeric column
into a discretized column, with breaks specified through the <code>splits</code>
parameter.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ft_bucketizer(
  x,
  input_col = NULL,
  output_col = NULL,
  splits = NULL,
  input_cols = NULL,
  output_cols = NULL,
  splits_array = NULL,
  handle_invalid = "error",
  uid = random_string("bucketizer_"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_col</code></td>
<td>
<p>The name of the input column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_col</code></td>
<td>
<p>The name of the output column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splits</code></td>
<td>
<p>A numeric vector of cutpoints, indicating the bucket boundaries.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_cols</code></td>
<td>
<p>Names of input columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_cols</code></td>
<td>
<p>Names of output columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>splits_array</code></td>
<td>
<p>Parameter for specifying multiple splits parameters. Each
element in this array can be used to map continuous features into buckets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>handle_invalid</code></td>
<td>
<p>(Spark 2.1.0+) Param for how to handle invalid entries. Options are
'skip' (filter out rows with invalid values), 'error' (throw an error), or
'keep' (keep invalid values in a special additional bucket). Default: "error"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the feature transformer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>. If it is a
<code>spark_connection</code>, the function returns a <code>ml_estimator</code> or a
<code>ml_estimator</code> object. If it is a <code>ml_pipeline</code>, it will return
a pipeline with the transformer or estimator appended to it. If a
<code>tbl_spark</code>, it will return a <code>tbl_spark</code> with the transformation
applied to it.
</p>


<h3>See Also</h3>

<p>Other feature transformers: 
<code>ft_binarizer()</code>,
<code>ft_chisq_selector()</code>,
<code>ft_count_vectorizer()</code>,
<code>ft_dct()</code>,
<code>ft_elementwise_product()</code>,
<code>ft_feature_hasher()</code>,
<code>ft_hashing_tf()</code>,
<code>ft_idf()</code>,
<code>ft_imputer()</code>,
<code>ft_index_to_string()</code>,
<code>ft_interaction()</code>,
<code>ft_lsh</code>,
<code>ft_max_abs_scaler()</code>,
<code>ft_min_max_scaler()</code>,
<code>ft_ngram()</code>,
<code>ft_normalizer()</code>,
<code>ft_one_hot_encoder()</code>,
<code>ft_one_hot_encoder_estimator()</code>,
<code>ft_pca()</code>,
<code>ft_polynomial_expansion()</code>,
<code>ft_quantile_discretizer()</code>,
<code>ft_r_formula()</code>,
<code>ft_regex_tokenizer()</code>,
<code>ft_robust_scaler()</code>,
<code>ft_sql_transformer()</code>,
<code>ft_standard_scaler()</code>,
<code>ft_stop_words_remover()</code>,
<code>ft_string_indexer()</code>,
<code>ft_tokenizer()</code>,
<code>ft_vector_assembler()</code>,
<code>ft_vector_indexer()</code>,
<code>ft_vector_slicer()</code>,
<code>ft_word2vec()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(dplyr)

sc &lt;- spark_connect(master = "local")
iris_tbl &lt;- sdf_copy_to(sc, iris, name = "iris_tbl", overwrite = TRUE)

iris_tbl %&gt;%
  ft_bucketizer(
    input_col = "Sepal_Length",
    output_col = "Sepal_Length_bucket",
    splits = c(0, 4.5, 5, 8)
  ) %&gt;%
  select(Sepal_Length, Sepal_Length_bucket, Species)

## End(Not run)

</code></pre>


</div>