<div class="container">

<table style="width: 100%;"><tr>
<td>ihess</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Inverse Hessian</h2>

<h3>Description</h3>

<p>Inverse Hessian matrix, useful for obtaining standard errors</p>


<h3>Usage</h3>

<pre><code class="language-R">ihess(f, x, ep = 1e-04, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>Usually a negative log likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Usually maximum likelihood estimates for f</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ep</code></td>
<td>
<p>Step length used to compute numerical second derivatives</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Extra arguments for f, if any</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Matrix of dimension dim(x) times dim(x), containing inverse Hessian
matrix of f at x.
</p>


<h3>Note</h3>

<p>This is not needed in R, where hessian matrices are obtained by setting hessian=T in
calls to optimisation functions.</p>


<h3>Author(s)</h3>

<p>Anthony Davison</p>


<h3>References</h3>

<p>Based on code written by Stuart Coles of Padova University</p>


<h3>Examples</h3>

<pre><code class="language-R"># ML fit of t distribution
nlogL &lt;- function(x, data) # negative log likelihood
{ mu &lt;- x[1]
  sig &lt;- x[2]
  df &lt;- x[3]
  -sum(log( dt((data-mu)/sig, df=df)/sig )) }
y &lt;- rt(n=100, df=10) # generate t data
# this is Splus code.....so remove the #'s for it to work in R
# fit &lt;- nlminb(c(1,1,4), nlogL, upper=c(Inf,Inf,Inf), lower=c(-Inf,0,0),
#               data=y)
# fit$parameters # maximum likelihood estimates
# J &lt;- ihess(nlogL, fit$parameters, data=y)
#  sqrt(diag(J)) # standard errors based on observed information
# 
# In this example the standard error can be a bad measure of
# uncertainty for the df.
</code></pre>


</div>