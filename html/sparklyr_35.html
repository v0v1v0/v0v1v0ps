<div class="container">

<table style="width: 100%;"><tr>
<td>collect_from_rds</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Collect Spark data serialized in RDS format into R</h2>

<h3>Description</h3>

<p>Deserialize Spark data that is serialized using 'spark_write_rds()' into a R
dataframe.
</p>


<h3>Usage</h3>

<pre><code class="language-R">collect_from_rds(path)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>Path to a local RDS file that is produced by 'spark_write_rds()'
(RDS files stored in HDFS will need to be downloaded to local filesystem
first (e.g., by running 'hadoop fs -copyToLocal ...' or similar)</p>
</td>
</tr></table>
<h3>See Also</h3>

<p>Other Spark serialization routines: 
<code>spark_insert_table()</code>,
<code>spark_load_table()</code>,
<code>spark_read()</code>,
<code>spark_read_avro()</code>,
<code>spark_read_binary()</code>,
<code>spark_read_csv()</code>,
<code>spark_read_delta()</code>,
<code>spark_read_image()</code>,
<code>spark_read_jdbc()</code>,
<code>spark_read_json()</code>,
<code>spark_read_libsvm()</code>,
<code>spark_read_orc()</code>,
<code>spark_read_parquet()</code>,
<code>spark_read_source()</code>,
<code>spark_read_table()</code>,
<code>spark_read_text()</code>,
<code>spark_save_table()</code>,
<code>spark_write_avro()</code>,
<code>spark_write_csv()</code>,
<code>spark_write_delta()</code>,
<code>spark_write_jdbc()</code>,
<code>spark_write_json()</code>,
<code>spark_write_orc()</code>,
<code>spark_write_parquet()</code>,
<code>spark_write_source()</code>,
<code>spark_write_table()</code>,
<code>spark_write_text()</code>
</p>


</div>