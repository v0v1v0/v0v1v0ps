<div class="container">

<table style="width: 100%;"><tr>
<td>tune.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Using the <span class="pkg">glmnet</span> and <span class="pkg">ncvreg</span> packages, fits a Generalized Linear
Model or Cox Proportional Hazards Model using various methods for choosing
the regularization parameter <code class="reqn">\lambda</code>
</h2>

<h3>Description</h3>

<p>This function fits a generalized linear model or a Cox proportional hazards
model via penalized maximum likelihood, with available penalties as
indicated in the <span class="pkg">glmnet</span> and <span class="pkg">ncvreg</span> packages. Instead of
providing the whole regularization solution path, the function returns the
solution at a unique value of <code class="reqn">\lambda</code>, the one optimizing the
criterion specified in <code>tune</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tune.fit(
  x,
  y,
  family = c("gaussian", "binomial", "poisson", "cox"),
  penalty = c("SCAD", "MCP", "lasso"),
  concavity.parameter = switch(penalty, SCAD = 3.7, 3),
  tune = c("cv", "aic", "bic", "ebic"),
  nfolds = 10,
  type.measure = c("deviance", "class", "auc", "mse", "mae"),
  gamma.ebic = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The design matrix, of dimensions n * p, without an intercept. Each
row is an observation vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>The response vector of dimension n * 1. Quantitative for
<code>family='gaussian'</code>, non-negative counts for <code>family='poisson'</code>,
binary (0-1) for <code>family='binomial'</code>. For <code>family='cox'</code>, <code>y</code>
should be an object of class <code>Surv</code>, as provided by the function
<code>Surv()</code> in the package <span class="pkg">survival</span>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Response type (see above).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>The penalty to be applied in the regularized likelihood
subproblems. 'SCAD' (the default), 'MCP', or 'lasso' are provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>concavity.parameter</code></td>
<td>
<p>The tuning parameter used to adjust the concavity
of the SCAD/MCP penalty. Default is 3.7 for SCAD and 3 for MCP.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune</code></td>
<td>
<p>Method for selecting the regularization parameter along the
solution path of the penalized likelihood problem. Options to provide a
final model include <code>tune='cv'</code>, <code>tune='aic'</code>, <code>tune='bic'</code>,
and <code>tune='ebic'</code>. See references at the end for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>Number of folds used in cross-validation. The default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type.measure</code></td>
<td>
<p>Loss to use for cross-validation. Currently five
options, not all available for all models. The default is
<code>type.measure='deviance'</code>, which uses squared-error for gaussian models
(also equivalent to <code>type.measure='mse'</code> in this case), deviance for
logistic and poisson regression, and partial-likelihood for the Cox model.
Both <code>type.measure='class'</code> and <code>type.measure='auc'</code> apply only to
logistic regression and give misclassification error and area under the ROC
curve, respectively. <code>type.measure='mse'</code> or <code>type.measure='mae'</code>
(mean absolute error) can be used by all models except the <code>'cox'</code>;
they measure the deviation from the fitted mean to the response. For
<code>penalty='SCAD'</code> and <code>penalty='MCP'</code>, only
<code>type.measure='deviance'</code> is available.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma.ebic</code></td>
<td>
<p>Specifies the parameter in the Extended BIC criterion
penalizing the size of the corresponding model space. The default is
<code>gamma.ebic=1</code>. See references at the end for details.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns an object with </p>
<table>
<tr style="vertical-align: top;">
<td><code>ix</code></td>
<td>
<p> The vector of indices of the
nonzero coefficients selected by the maximum penalized likelihood procedure
with <code>tune</code> as the method for choosing the regularization parameter.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0</code></td>
<td>
<p>The intercept of the final model selected by <code>tune</code>.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>The vector of coefficients of the final model selected by
<code>tune</code>.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>The fitted penalized regression object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The corresponding lambda in the final model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.ind</code></td>
<td>
<p>The index on the solution path for the final model.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Jianqing Fan, Yang Feng, Diego Franco Saldana, Richard Samworth, and
Yichao Wu
</p>


<h3>References</h3>

<p>Jerome Friedman and Trevor Hastie and Rob Tibshirani (2010)
Regularization Paths for Generalized Linear Models Via Coordinate Descent.
<em>Journal of Statistical Software</em>, <b>33</b>(1), 1-22.
</p>
<p>Noah Simon and Jerome Friedman and Trevor Hastie and Rob Tibshirani (2011)
Regularization Paths for Cox's Proportional Hazards Model Via Coordinate
Descent. <em>Journal of Statistical Software</em>, <b>39</b>(5), 1-13.
</p>
<p>Patrick Breheny and Jian Huang (2011) Coordiante Descent Algorithms for
Nonconvex Penalized Regression, with Applications to Biological Feature
Selection. <em>The Annals of Applied Statistics</em>, <b>5</b>, 232-253.
</p>
<p>Hirotogu Akaike (1973) Information Theory and an Extension of the Maximum
Likelihood Principle. In <em>Proceedings of the 2nd International
Symposium on Information Theory</em>, BN Petrov and F Csaki (eds.), 267-281.
</p>
<p>Gideon Schwarz (1978) Estimating the Dimension of a Model. <em>The Annals
of Statistics</em>, <b>6</b>, 461-464.
</p>
<p>Jiahua Chen and Zehua Chen (2008) Extended Bayesian Information Criteria for
Model Selection with Large Model Spaces. <em>Biometrika</em>, <b>95</b>,
759-771.
</p>


<h3>Examples</h3>

<pre><code class="language-R">

set.seed(0)
data('leukemia.train', package = 'SIS')
y.train = leukemia.train[,dim(leukemia.train)[2]]
x.train = as.matrix(leukemia.train[,-dim(leukemia.train)[2]])
x.train = standardize(x.train)
model = tune.fit(x.train[,1:3500], y.train, family='binomial', tune='bic')
model$ix
model$a0
model$beta


</code></pre>


</div>