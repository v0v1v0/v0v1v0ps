<div class="container">

<table style="width: 100%;"><tr>
<td>rda_high_dim</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>High-Dimensional Regularized Discriminant Analysis (HDRDA)</h2>

<h3>Description</h3>

<p>Given a set of training data, this function builds the HDRDA classifier from
Ramey, Stein, and Young (2017). Specially designed for small-sample,
high-dimensional data, the HDRDA classifier incorporates dimension reduction
and covariance-matrix shrinkage to enable a computationally efficient
classifier.
</p>
<p>For a given <code>rda_high_dim</code> object, we predict the class of each observation
(row) of the the matrix given in <code>newdata</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rda_high_dim(x, ...)

## Default S3 method:
rda_high_dim(
  x,
  y,
  lambda = 1,
  gamma = 0,
  shrinkage_type = c("ridge", "convex"),
  prior = NULL,
  tol = 1e-06,
  ...
)

## S3 method for class 'formula'
rda_high_dim(formula, data, ...)

## S3 method for class 'rda_high_dim'
predict(
  object,
  newdata,
  projected = FALSE,
  type = c("class", "prob", "score"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Matrix or data frame containing the training data. The rows are the
sample observations, and the columns are the features. Only complete data are
retained.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments (not currently used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of class labels for each training observation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the HDRDA pooling parameter. Must be between 0 and 1,
inclusively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>a numeric values used for the shrinkage parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shrinkage_type</code></td>
<td>
<p>the type of covariance-matrix shrinkage to apply. By
default, a ridge-like shrinkage is applied. If <code>convex</code> is given, then
shrinkage similar to Friedman (1989) is applied. See Ramey et al. (2017) for
details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>vector with prior probabilities for each class. If <code>NULL</code>
(default), then the sample proportion of observations belonging to each class
equal probabilities are used. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>a threshold for determining nonzero eigenvalues.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A formula of the form <code>groups ~ x1 + x2 + ...</code> That is,
the response is the grouping factor and the right hand side specifies the
(non-factor) discriminators.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame from which variables specified in <code>formula</code> are
preferentially to be taken.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object of type <code>rda_high_dim</code> that contains the trained HDRDA
classifier</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>Matrix or data frame of observations to predict. Each row
corresponds to a new observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>projected</code></td>
<td>
<p>logical indicating whether <code>newdata</code> have already been
projected to a q-dimensional subspace. This argument can yield large gains in
speed when the linear transformation has already been performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Prediction type: either <code>"class"</code>, <code>"prob"</code>, or <code>"score"</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The HDRDA classifier utilizes a covariance-matrix estimator that is a convex
combination of the covariance-matrix estimators used in the Linear
Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA)
classifiers. For each of the <code>K</code> classes given in <code>y</code>,
<code class="reqn">(k = 1, \ldots, K)</code>, we first define this convex combination as
</p>
<p style="text-align: center;"><code class="reqn">\hat{\Sigma}_k(\lambda) = (1 - \lambda) \hat{\Sigma}_k
+ \lambda \hat{\Sigma},</code>
</p>

<p>where <code class="reqn">\lambda \in [0, 1]</code> is the <em>pooling</em> parameter. We then
calculate the covariance-matrix estimator
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_k = \alpha_k \hat{\Sigma}_k(\lambda) + \gamma I_p,</code>
</p>

<p>where <code class="reqn">I_p</code> is the <code class="reqn">p \times p</code> identity matrix. The matrix
<code class="reqn">\tilde{\Sigma}_k</code> is substituted into the HDRDA classifier. See Ramey et
al. (2017) for more details.
</p>
<p>The matrix of training observations are given in <code>x</code>. The rows of
<code>x</code> contain the sample observations, and the columns contain the features
for each training observation. The vector of class labels given in <code>y</code>
are coerced to a <code>factor</code>. The length of <code>y</code> should match the number
of rows in <code>x</code>.
</p>
<p>The vector <code>prior</code> contains the <em>a priori</em> class membership for
each class. If <code>prior</code> is <code>NULL</code> (default), the class membership
probabilities are estimated as the sample proportion of observations
belonging to each class. Otherwise, <code>prior</code> should be a vector with the
same length as the number of classes in <code>y</code>. The <code>prior</code>
probabilities should be nonnegative and sum to one. The order of the prior
probabilities is assumed to match the levels of <code>factor(y)</code>.
</p>


<h3>Value</h3>

<p><code>rda_high_dim</code> object that contains the trained HDRDA classifier
</p>
<p>list with predicted class and discriminant scores for each of the K
classes
</p>


<h3>References</h3>

<p>Ramey, J. A., Stein, C. K., and Young, D. M. (2017),
"High-Dimensional Regularized Discriminant Analysis."
<a href="https://arxiv.org/abs/1602.01182">https://arxiv.org/abs/1602.01182</a>.
</p>
<p>Friedman, J. H. (1989), "Regularized Discriminant Analysis,"
Journal of American Statistical Association, 84, 405, 165-175.
<a href="http://www.jstor.org/stable/2289860">http://www.jstor.org/stable/2289860</a> (Requires full-text access).
</p>


</div>