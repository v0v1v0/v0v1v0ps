<div class="container">

<table style="width: 100%;"><tr>
<td>spark_read_tfrecord</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Read a TFRecord File</h2>

<h3>Description</h3>

<p>Read a TFRecord file as a Spark DataFrame.
</p>


<h3>Usage</h3>

<pre><code class="language-R">spark_read_tfrecord(sc, name = NULL, path = name, schema = NULL,
  record_type = c("Example", "SequenceExample"), overwrite = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sc</code></td>
<td>
<p>A spark conneciton.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name to assign to the newly generated table or the path to the file. Note that if a path is provided for the 'name' argument
then one cannot specify a name.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster. Supports the "hdfs://", "s3a://" and "file://" protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>schema</code></td>
<td>
<p>(Currently unsupported.) Schema of TensorFlow records.  If not provided, the schema is inferred from TensorFlow records.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>record_type</code></td>
<td>
<p>Input format of TensorFlow records. By default it is Example.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overwrite</code></td>
<td>
<p>Boolean; overwrite the table with the given name if it already exists?</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
iris_tbl &lt;- copy_to(sc, iris)
data_path &lt;- file.path(tempdir(), "iris")
df1 &lt;- iris_tbl %&gt;%
ft_string_indexer_model(
  "Species", "label",
  labels = c("setosa", "versicolor", "virginica")
)

df1 %&gt;%
spark_write_tfrecord(
  path = data_path,
  write_locality = "local"
)

spark_read_tfrecord(sc, data_path)

## End(Not run)

</code></pre>


</div>