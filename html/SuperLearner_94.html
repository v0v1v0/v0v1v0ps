<div class="container">

<table style="width: 100%;"><tr>
<td>SL.ranger</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>SL wrapper for ranger</h2>

<h3>Description</h3>

<p>Ranger is a fast implementation of Random Forest (Breiman 2001)
or recursive partitioning, particularly suited for high dimensional data.
</p>
<p>Extending code by Eric Polley from the SuperLearnerExtra package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SL.ranger(Y, X, newX, family, obsWeights, num.trees = 500,
  mtry = floor(sqrt(ncol(X))), write.forest = TRUE,
  probability = family$family == "binomial",
  min.node.size = ifelse(family$family == "gaussian", 5, 1), replace = TRUE,
  sample.fraction = ifelse(replace, 1, 0.632), num.threads = 1,
  verbose = T, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Outcome variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Training dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newX</code></td>
<td>
<p>Test dataframe</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Gaussian or binomial</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obsWeights</code></td>
<td>
<p>Observation-level weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.trees</code></td>
<td>
<p>Number of trees.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p>Number of variables to possibly split at in each node. Default is
the (rounded down) square root of the number variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>write.forest</code></td>
<td>
<p>Save ranger.forest object, required for prediction. Set
to FALSE to reduce memory usage if no prediction intended.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probability</code></td>
<td>
<p>Grow a probability forest as in Malley et al. (2012).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.node.size</code></td>
<td>
<p>Minimal node size. Default 1 for classification, 5 for
regression, 3 for survival, and 10 for probability.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replace</code></td>
<td>
<p>Sample with replacement.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample.fraction</code></td>
<td>
<p>Fraction of observations to sample. Default is 1 for
sampling with replacement and 0.632 for sampling without replacement.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.threads</code></td>
<td>
<p>Number of threads to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If TRUE, display additional output during execution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Any additional arguments, not currently used.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Breiman, L. (2001). Random forests. Machine learning 45:5-32.
</p>
<p>Wright, M. N. &amp; Ziegler, A. (2016). ranger: A Fast Implementation of Random
Forests for High Dimensional Data in C++ and R. Journal of Statistical
Software, in press. http://arxiv.org/abs/1508.04409.
</p>


<h3>See Also</h3>

<p><code>SL.ranger</code> <code>ranger</code>
<code>predict.ranger</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(Boston, package = "MASS")
Y = Boston$medv
# Remove outcome from covariate dataframe.
X = Boston[, -14]

set.seed(1)

# Use only 2 CV folds to speed up example.
sl = SuperLearner(Y, X, family = gaussian(), cvControl = list(V = 2),
                 SL.library = c("SL.mean", "SL.ranger"))
sl

pred = predict(sl, X)
summary(pred$pred)

</code></pre>


</div>