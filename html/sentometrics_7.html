<div class="container">

<table style="width: 100%;"><tr>
<td>as.sentiment</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Convert a sentiment table to a sentiment object</h2>

<h3>Description</h3>

<p>Converts a properly structured sentiment table into a <code>sentiment</code> object, that can be used
for further aggregation with the <code>aggregate.sentiment</code> function. This allows to start from
sentiment scores not necessarily computed with <code>compute_sentiment</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">as.sentiment(s)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>a <code>data.table</code> or <code>data.frame</code> that can be converted into a <code>sentiment</code> object. It
should have at least an <code>"id"</code>, a <code>"date"</code>, a <code>"word_count"</code> and one sentiment scores column.
If other column names are provided with a separating <code>"--"</code>, the first part is considered the lexicon
(or more generally, the sentiment computation method), and the second part the feature. For sentiment column
names without any <code>"--"</code>, a <code>"dummyFeature"</code> component is added.</p>
</td>
</tr></table>
<h3>Value</h3>

<p>A <code>sentiment</code> object.
</p>


<h3>Author(s)</h3>

<p>Samuel Borms
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(505)

data("usnews", package = "sentometrics")
data("list_lexicons", package = "sentometrics")

ids &lt;- paste0("id", 1:200)
dates &lt;- sample(seq(as.Date("2015-01-01"), as.Date("2018-01-01"), by = "day"), 200, TRUE)
word_count &lt;- sample(150:850, 200, replace = TRUE)
sent &lt;- matrix(rnorm(200 * 8), nrow =  200)
s1 &lt;- s2 &lt;- data.table::data.table(id = ids, date = dates, word_count = word_count, sent)
s3 &lt;- data.frame(id = ids, date = dates, word_count = word_count, sent,
                 stringsAsFactors = FALSE)
s4 &lt;- compute_sentiment(usnews$texts[201:400],
                        sento_lexicons(list_lexicons["GI_en"]),
                        "counts", do.sentence = TRUE)
m &lt;- "method"

colnames(s1)[-c(1:3)] &lt;- paste0(m, 1:8)
sent1 &lt;- as.sentiment(s1)

colnames(s2)[-c(1:3)] &lt;- c(paste0(m, 1:4, "--", "feat1"), paste0(m, 1:4, "--", "feat2"))
sent2 &lt;- as.sentiment(s2)

colnames(s3)[-c(1:3)] &lt;- c(paste0(m, 1:3, "--", "feat1"), paste0(m, 1:3, "--", "feat2"),
                           paste0(m, 4:5))
sent3 &lt;- as.sentiment(s3)

s4[, "date" := rep(dates, s4[, max(sentence_id), by = id][[2]])]
sent4 &lt;- as.sentiment(s4)

# further aggregation from then on is easy...
sentMeas1 &lt;- aggregate(sent1, ctr_agg(lag = 10))
sent5 &lt;- aggregate(sent4, ctr_agg(howDocs = "proportional"), do.full = FALSE)

</code></pre>


</div>