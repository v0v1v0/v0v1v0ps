<div class="container">

<table style="width: 100%;"><tr>
<td>ft_quantile_discretizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Transformation â€“ QuantileDiscretizer (Estimator)</h2>

<h3>Description</h3>

<p><code>ft_quantile_discretizer</code> takes a column with continuous features and outputs
a column with binned categorical features. The number of bins can be
set using the <code>num_buckets</code> parameter. It is possible that the number
of buckets used will be smaller than this value, for example, if there
are too few distinct values of the input to create enough distinct
quantiles.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ft_quantile_discretizer(
  x,
  input_col = NULL,
  output_col = NULL,
  num_buckets = 2,
  input_cols = NULL,
  output_cols = NULL,
  num_buckets_array = NULL,
  handle_invalid = "error",
  relative_error = 0.001,
  uid = random_string("quantile_discretizer_"),
  weight_column = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_col</code></td>
<td>
<p>The name of the input column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_col</code></td>
<td>
<p>The name of the output column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_buckets</code></td>
<td>
<p>Number of buckets (quantiles, or categories) into which data
points are grouped. Must be greater than or equal to 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_cols</code></td>
<td>
<p>Names of input columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_cols</code></td>
<td>
<p>Names of output columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_buckets_array</code></td>
<td>
<p>Array of number of buckets (quantiles, or categories)
into which data points are grouped. Each value must be greater than or equal to 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>handle_invalid</code></td>
<td>
<p>(Spark 2.1.0+) Param for how to handle invalid entries. Options are
'skip' (filter out rows with invalid values), 'error' (throw an error), or
'keep' (keep invalid values in a special additional bucket). Default: "error"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>relative_error</code></td>
<td>
<p>(Spark 2.0.0+) Relative error (see documentation for
org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">here</a>
for description). Must be in the range [0, 1]. default: 0.001</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the feature transformer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight_column</code></td>
<td>
<p>If not NULL, then a generalized version of the Greenwald-Khanna algorithm will be run to compute
weighted percentiles, with each input having a relative weight specified by the corresponding value in 'weight_column'.
The weights can be considered as relative frequencies of sample inputs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>NaN handling: null and NaN values will be ignored from the column
during <code>QuantileDiscretizer</code> fitting. This will produce a <code>Bucketizer</code>
model for making predictions. During the transformation, <code>Bucketizer</code>
will raise an error when it finds NaN values in the dataset, but the
user can also choose to either keep or remove NaN values within the
dataset by setting <code>handle_invalid</code> If the user chooses to keep NaN values,
they will be handled specially and placed into their own bucket,
for example, if 4 buckets are used, then non-NaN data will be put
into buckets[0-3], but NaNs will be counted in a special bucket[4].
</p>
<p>Algorithm: The bin ranges are chosen using an approximate algorithm (see
the documentation for org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">here</a> for a detailed description). The precision of the approximation can be
controlled with the <code>relative_error</code> parameter. The lower and upper bin
bounds will be -Infinity and +Infinity, covering all real values.
</p>
<p>Note that the result may be different every time you run it, since the sample
strategy behind it is non-deterministic.
</p>
<p>In the case where <code>x</code> is a <code>tbl_spark</code>, the estimator
fits against <code>x</code> to obtain a transformer, returning a <code>tbl_spark</code>.
</p>


<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>. If it is a
<code>spark_connection</code>, the function returns a <code>ml_estimator</code> or a
<code>ml_estimator</code> object. If it is a <code>ml_pipeline</code>, it will return
a pipeline with the transformer or estimator appended to it. If a
<code>tbl_spark</code>, it will return a <code>tbl_spark</code> with the transformation
applied to it.
</p>


<h3>See Also</h3>

<p><code>ft_bucketizer</code>
</p>
<p>Other feature transformers: 
<code>ft_binarizer()</code>,
<code>ft_bucketizer()</code>,
<code>ft_chisq_selector()</code>,
<code>ft_count_vectorizer()</code>,
<code>ft_dct()</code>,
<code>ft_elementwise_product()</code>,
<code>ft_feature_hasher()</code>,
<code>ft_hashing_tf()</code>,
<code>ft_idf()</code>,
<code>ft_imputer()</code>,
<code>ft_index_to_string()</code>,
<code>ft_interaction()</code>,
<code>ft_lsh</code>,
<code>ft_max_abs_scaler()</code>,
<code>ft_min_max_scaler()</code>,
<code>ft_ngram()</code>,
<code>ft_normalizer()</code>,
<code>ft_one_hot_encoder()</code>,
<code>ft_one_hot_encoder_estimator()</code>,
<code>ft_pca()</code>,
<code>ft_polynomial_expansion()</code>,
<code>ft_r_formula()</code>,
<code>ft_regex_tokenizer()</code>,
<code>ft_robust_scaler()</code>,
<code>ft_sql_transformer()</code>,
<code>ft_standard_scaler()</code>,
<code>ft_stop_words_remover()</code>,
<code>ft_string_indexer()</code>,
<code>ft_tokenizer()</code>,
<code>ft_vector_assembler()</code>,
<code>ft_vector_indexer()</code>,
<code>ft_vector_slicer()</code>,
<code>ft_word2vec()</code>
</p>


</div>