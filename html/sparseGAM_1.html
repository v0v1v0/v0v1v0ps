<div class="container">

<table style="width: 100%;"><tr>
<td>cv.grpreg.gamma</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation for Group-regularized Gamma Regression</h2>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized gamma regression with a known shape parameter <code class="reqn">\nu</code> and the log link. For a description of group-regularized gamma regression, see the description for the <code>grpreg.gamma</code> function.
</p>
<p>Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.grpreg.gamma(y, X, groups, gamma.shape=1, penalty=c("gLASSO","gSCAD","gMCP"),
                nfolds=10, weights, taper, nlambda=100, lambda, max.iter=10000, 
                tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses. Default is <code>gamma.shape=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>group regularization method to use on the groups of coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement cross-validation for gamma regression with the SSGL penalty, use the <code>cv.SSGL</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=10</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). "Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors." <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). "Unified LASSO estimation by least squares approximation." <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate data
set.seed(12345)
X = matrix(runif(100*11), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,3,3,4,5,5)
true.beta = c(-1,1,1,0,0,0,0,0,0,1.5,-1.5)

## Generate responses from gamma regression with known shape parameter 1
eta = crossprod(t(X), true.beta)
shape = 1
y = rgamma(n, rate=shape/exp(eta), shape=shape)

## 10-fold cross-validation for group-regularized gamma regression
## with the group LASSO penalty
gamma.cv = cv.grpreg.gamma(y, X, groups, penalty="gLASSO")

## Plot cross-validation curve
plot(gamma.cv$lambda, gamma.cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
gamma.cv$lambda.min
</code></pre>


</div>