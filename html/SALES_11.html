<div class="container">

<table style="width: 100%;"><tr>
<td>ernet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Regularization paths for the sparse asymmetric least squares (SALES)
regression (or the sparse expectile regression)</h2>

<h3>Description</h3>

<p>Fits regularization paths for the Lasso or elastic net penalized asymmetric
least squares regression at a sequence of regularization parameters.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ernet(
  x,
  y,
  nlambda = 100L,
  method = "er",
  lambda.factor = ifelse(nobs &lt; nvars, 0.01, 1e-04),
  lambda = NULL,
  lambda2 = 0,
  pf = rep(1, nvars),
  pf2 = rep(1, nvars),
  exclude,
  dfmax = nvars + 1,
  pmax = min(dfmax * 1.2, nvars),
  standardize = TRUE,
  intercept = TRUE,
  eps = 1e-08,
  maxit = 1000000L,
  tau = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix of predictors, of dimension (nobs * nvars); each row is an
observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>the number of <code>lambda</code> values (default is 100).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character string specifying the loss function to use. only
<code>er</code> is available now.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.factor</code></td>
<td>
<p>The factor for getting the minimal lambda in the
<code>lambda</code> sequence, where we set <code>min(lambda)</code> =
<code>lambda.factor</code> * <code>max(lambda)</code> with <code>max(lambda)</code> being the
smallest value of <code>lambda</code> that penalizes all coefficients to zero.
The default depends on the relationship between <code class="reqn">N</code> (the number of rows
in the matrix of predictors) and <code class="reqn">p</code> (the number of predictors). If
<code class="reqn">N &lt; p</code>, the default is <code>0.01</code>. If <code class="reqn">N &gt; p</code>, the default is
<code>0.0001</code>, closer to zero. A very small value of <code>lambda.factor</code>
will lead to a saturated fit. It takes no effect if there is a
user-supplied <code>lambda</code> sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>a user-supplied <code>lambda</code> sequence. Typically, by leaving
this option unspecified users can have the program compute its own
<code>lambda</code> sequence based on <code>nlambda</code> and <code>lambda.factor</code>. It
is better to supply, if necessary, a decreasing sequence of <code>lambda</code>
values than a single (small) value. The program will ensure that the
user-supplied <code>lambda</code> sequence is sorted in decreasing order before
fitting the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda2</code></td>
<td>
<p>regularization parameter <code>lambda2</code> for the quadratic
penalty of the coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pf</code></td>
<td>
<p>L1 penalty factor of length <code class="reqn">p</code> used for the adaptive LASSO or
adaptive elastic net. Separate L1 penalty weights can be applied to each
coefficient to allow different L1 shrinkage. Can be 0 for some variables,
which imposes no shrinkage, and results in that variable always be included
in the model. Default is 1 for all variables (and implicitly infinity for
variables listed in <code>exclude</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pf2</code></td>
<td>
<p>L2 penalty factor of length <code class="reqn">p</code> used for adaptive elastic net.
Separate L2 penalty weights can be applied to each coefficient to allow
different L2 shrinkage. Can be 0 for some variables, which imposes no
shrinkage. Default is 1 for all variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exclude</code></td>
<td>
<p>indices of variables to be excluded from the model. Default is
none. Equivalent to an infinite penalty factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dfmax</code></td>
<td>
<p>the maximum number of variables allowed in the model. Useful for
very large <code class="reqn">p</code> when a partial path is desired. Default is <code class="reqn">p+1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pmax</code></td>
<td>
<p>the maximum number of coefficients allowed ever to be nonzero.
For example once <code class="reqn">\beta</code> enters the model, no matter how many times it
exits or re-enters the model through the path, it will be counted only
once. Default is <code>min(dfmax*1.2, p)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>logical flag for variable standardization, prior to
fitting the model sequence. The coefficients are always returned to the
original scale. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Should intercept(s) be fitted (default is <code>TRUE</code>) or
set to zero (<code>FALSE</code>)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>convergence threshold for coordinate descent. Each inner
coordinate descent loop continues until the maximum change in any
coefficient is less than <code>eps</code>. Defaults value is <code>1e-8</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>maximum number of outer-loop iterations allowed at fixed lambda
values. Default is 1e7. If the algorithm does not converge, consider
increasing <code>maxit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>the parameter <code class="reqn">\tau</code> in the ALS regression model. The value
must be in (0,1). Default is 0.5.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Note that the objective function in <code>ernet</code> is
</p>
<p style="text-align: center;"><code class="reqn">1'\Psi_{\tau}(y-X\beta)/N + \lambda_{1}*\Vert\beta\Vert_1 +
  0.5\lambda_{2}*\Vert\beta\Vert_2^2,</code>
</p>
<p> where
<code class="reqn">\Psi_{\tau}</code> denotes the asymmetric squared error loss and
the penalty is a combination of weighted L1 and L2 terms.
</p>
<p>For faster computation, if the algorithm is not converging or running slow,
consider increasing <code>eps</code>, decreasing <code>nlambda</code>, or increasing
<code>lambda.factor</code> before increasing <code>maxit</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>ernet</code>.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b0</code></td>
<td>
<p>intercept sequence of length <code>length(lambda)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>a <code>p*length(lambda)</code> matrix of coefficients, stored as a
sparse matrix (<code>dgCMatrix</code> class, the standard class for sparse
numeric matrices in the <code>Matrix</code> package.). To convert it into normal
type matrix use <code>as.matrix()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the actual sequence of <code>lambda</code> values used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>the number of nonzero coefficients for each value of
<code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>dimension of coefficient matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npasses</code></td>
<td>
<p>total number of iterations summed over all lambda values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jerr</code></td>
<td>
<p>error flag, for warnings and errors, 0 if no error.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yuwen Gu and Hui Zou<br></p>
<p>Maintainer: Yuwen Gu &lt;yuwen.gu@uconn.edu&gt;
</p>


<h3>References</h3>

<p>Gu, Y., and Zou, H. (2016).
"High-dimensional generalizations of asymmetric least squares regression and their applications."
<em>The Annals of Statistics</em>, 44(6), 2661â€“2694.<br></p>


<h3>See Also</h3>

<p><code>plot.ernet</code>, <code>coef.ernet</code>,
<code>predict.ernet</code>, <code>print.ernet</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(1)
n &lt;- 100
p &lt;- 400
x &lt;- matrix(rnorm(n * p), n, p)
y &lt;- rnorm(n)
tau &lt;- 0.90
pf &lt;- abs(rnorm(p))
pf2 &lt;- abs(rnorm(p))
lambda2 &lt;- 1
m1 &lt;- ernet(y = y, x = x, tau = tau, eps = 1e-8, pf = pf,
            pf2 = pf2, standardize = FALSE, intercept = FALSE,
            lambda2 = lambda2)

</code></pre>


</div>