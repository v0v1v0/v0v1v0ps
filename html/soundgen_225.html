<div class="container">

<table style="width: 100%;"><tr>
<td>shiftPitch</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Shift pitch</h2>

<h3>Description</h3>

<p>Raises or lowers pitch with or without also shifting the formants (resonance
frequencies) and performing a time-stretch. The three operations (pitch
shift, formant shift, and time stretch) are independent and can be performed
in any combination, statically or dynamically. <code>shiftPitch</code> can also be
used to shift formants without changing pitch or duration, but the dedicated
<code>shiftFormants</code> is faster for that task.
</p>


<h3>Usage</h3>

<pre><code class="language-R">shiftPitch(
  x,
  multPitch = 1,
  multFormants = multPitch,
  timeStretch = 1,
  samplingRate = NULL,
  freqWindow = NULL,
  dynamicRange = 80,
  windowLength = 40,
  step = 2,
  overlap = NULL,
  wn = "gaussian",
  interpol = c("approx", "spline")[1],
  propagation = c("time", "adaptive")[1],
  preserveEnv = NULL,
  transplantEnv_pars = list(windowLength = 10),
  normalize = c("max", "orig", "none")[2],
  play = FALSE,
  saveAudio = NULL,
  reportEvery = NULL,
  cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>path to a folder, one or more wav or mp3 files c('file1.wav',
'file2.mp3'), Wave object, numeric vector, or a list of Wave objects or
numeric vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multPitch</code></td>
<td>
<p>1 = no change, &gt;1 = raise pitch (eg 1.1 = 10% up, 2 = one
octave up), &lt;1 = lower pitch. Anchor format accepted for multPitch /
multFormant / timeStretch (see <code>soundgen</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multFormants</code></td>
<td>
<p>1 = no change, &gt;1 = raise formants (eg 1.1 = 10% up, 2 =
one octave up), &lt;1 = lower formants</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>timeStretch</code></td>
<td>
<p>1 = no change, &gt;1 = longer, &lt;1 = shorter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samplingRate</code></td>
<td>
<p>sampling rate of <code>x</code> (only needed if <code>x</code> is a
numeric vector)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>freqWindow</code></td>
<td>
<p>the width of spectral smoothing window, Hz. Defaults to
detected f0 prior to pitch shifting - see <code>shiftFormants</code> for
discussion and examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dynamicRange</code></td>
<td>
<p>dynamic range, dB. All values more than one dynamicRange
under maximum are treated as zero</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>windowLength</code></td>
<td>
<p>length of FFT window, ms</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>
<p>you can override <code>overlap</code> by specifying FFT step, ms (NB:
because digital audio is sampled at discrete time intervals of
1/samplingRate, the actual step and thus the time stamps of STFT frames
may be slightly different, eg 24.98866 instead of 25.0 ms)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overlap</code></td>
<td>
<p>overlap between successive FFT frames, %</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wn</code></td>
<td>
<p>window type accepted by <code>ftwindow</code>, currently
gaussian, hanning, hamming, bartlett, blackman, flattop, rectangle</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpol</code></td>
<td>
<p>the method for interpolating scaled spectra and anchors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>propagation</code></td>
<td>
<p>the method for propagating phase: "time" = horizontal
propagation (default), "adaptive" = an experimental implementation of
"vocoder done right" (Prusa &amp; Holighaus 2017)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>preserveEnv</code></td>
<td>
<p>if TRUE, transplants the amplitude envelope from the
original to the modified sound with <code>transplantEnv</code>. Defaults
to TRUE if no time stretching is performed and FALSE otherwise</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transplantEnv_pars</code></td>
<td>
<p>a list of parameters passed on to
<code>transplantEnv</code> if <code>preserveEnv = TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>"orig" = same as input (default), "max" = maximum possible
peak amplitude, "none" = no normalization</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>play</code></td>
<td>
<p>if TRUE, plays the synthesized sound using the default player on
your system. If character, passed to <code>play</code> as the name
of player to use, eg "aplay", "play", "vlc", etc. In case of errors, try
setting another default player for <code>play</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>saveAudio</code></td>
<td>
<p>full path to the folder in which to save audio files (one
per detected syllable)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reportEvery</code></td>
<td>
<p>when processing multiple inputs, report estimated time
left every ... iterations (NULL = default, NA = don't report)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>number of cores for parallel processing</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Algorithm: phase vocoder. Pitch shifting is accomplished by performing a time
stretch (at present, with horizontal or adaptive phase propagation) followed
by resampling. This shifts both pitch and formants; to preserve the original
formant frequencies or modify them independently of pitch, a variant of
<code>link{transplantFormants}</code> is performed to "transplant" the original or
scaled formants onto the time-stretched new sound.
</p>


<h3>See Also</h3>

<p><code>shiftFormants</code> <code>transplantFormants</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">s = soundgen(sylLen = 200, ampl = c(0,-10),
             pitch = c(250, 350), rolloff = c(-9, -15),
             noise = -40,
             formants = 'aii', addSilence = 50)
# playme(s)
s1 = shiftPitch(s, samplingRate = 16000, freqWindow = 400,
                multPitch = 1.25, multFormants = .8)
# playme(s1)

## Not run: 
## Dynamic manipulations
# Add a chevron-shaped pitch contour
s2 = shiftPitch(s, samplingRate = 16000, multPitch = c(1.1, 1.3, .8))
playme(s2)

# Time-stretch only the middle
s3 = shiftPitch(s, samplingRate = 16000, timeStretch = list(
  time = c(0, .25, .31, .5, .55, 1),
  value = c(1, 1, 3, 3, 1, 1))
)
playme(s3)


## Various combinations of 3 manipulations
data(sheep, package = 'seewave')  # import a recording from seewave
playme(sheep)
spectrogram(sheep)

# Raise pitch and formants by 3 semitones, shorten by half
sheep1 = shiftPitch(sheep, multPitch = 2 ^ (3 / 12), timeStretch = 0.5)
playme(sheep1, sheep@samp.rate)
spectrogram(sheep1, sheep@samp.rate)

# Just shorten
shiftPitch(sheep, multPitch = 1, timeStretch = 0.25, play = TRUE)

# Raise pitch preserving formants
sheep2 = shiftPitch(sheep, multPitch = 1.2, multFormants = 1, freqWindow = 150)
playme(sheep2, sheep@samp.rate)
spectrogram(sheep2, sheep@samp.rate)

## End(Not run)
</code></pre>


</div>