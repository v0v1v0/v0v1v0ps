<div class="container">

<table style="width: 100%;"><tr>
<td>valid_corr2</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Determine Correlation Bounds for Ordinal, Continuous, Poisson, and/or Negative Binomial Variables: Correlation Method 2</h2>

<h3>Description</h3>

<p>This function calculates the lower and upper correlation bounds for the given distributions and
checks if a given target correlation matrix rho is within the bounds.  It should be used before simulation with
<code>rcorrvar2</code>.  However, even if all pairwise correlations fall within the bounds, it is still possible
that the desired correlation matrix is not feasible.  This is particularly true when ordinal variables (r &gt;= 2 categories) are
generated or negative correlations are desired.  Therefore, this function should be used as a general check to eliminate pairwise correlations that are obviously
not reproducible.  It will help prevent errors when executing the simulation.
</p>
<p>Note: Some pieces of the function code have been adapted from Demirtas, Hu, &amp; Allozi's (2017) <code>validation_specs</code>.
This function (<code>valid_corr2</code>) extends the methods to:
</p>
<p>1) non-normal continuous variables generated by Fleishman's third-order or Headrick's fifth-order polynomial transformation method,
</p>
<p>2) Negative Binomial variables (including all pairwise correlations involving them), and
</p>
<p>3) Count variables are treated as ordinal when calculating the bounds since that is the intermediate correlation calculation method.
</p>
<p>Please see the <b>Comparison of Method 1 and Method 2</b> vignette for more information regarding method 2.
</p>


<h3>Usage</h3>

<pre><code class="language-R">valid_corr2(k_cat = 0, k_cont = 0, k_pois = 0, k_nb = 0,
  method = c("Fleishman", "Polynomial"), means = NULL, vars = NULL,
  skews = NULL, skurts = NULL, fifths = NULL, sixths = NULL,
  Six = list(), marginal = list(), lam = NULL, pois_eps = NULL,
  size = NULL, prob = NULL, mu = NULL, nb_eps = NULL, rho = NULL,
  n = 100000, seed = 1234)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>k_cat</code></td>
<td>
<p>the number of ordinal (r &gt;= 2 categories) variables (default = 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k_cont</code></td>
<td>
<p>the number of continuous variables (default = 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k_pois</code></td>
<td>
<p>the number of Poisson variables (default = 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k_nb</code></td>
<td>
<p>the number of Negative Binomial variables (default = 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the method used to generate the k_cont continuous variables.  "Fleishman" uses a third-order polynomial transformation
and "Polynomial" uses Headrick's fifth-order transformation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>means</code></td>
<td>
<p>a vector of means for the k_cont continuous variables (i.e. = rep(0, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vars</code></td>
<td>
<p>a vector of variances (i.e. = rep(1, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skews</code></td>
<td>
<p>a vector of skewness values (i.e. = rep(0, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skurts</code></td>
<td>
<p>a vector of standardized kurtoses (kurtosis - 3, so that normal variables have a value of 0; i.e. = rep(0, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fifths</code></td>
<td>
<p>a vector of standardized fifth cumulants (not necessary for <code>method</code> = "Fleishman"; i.e. = rep(0, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sixths</code></td>
<td>
<p>a vector of standardized sixth cumulants (not necessary for <code>method</code> = "Fleishman"; i.e. = rep(0, k_cont))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Six</code></td>
<td>
<p>a list of vectors of correction values to add to the sixth cumulants if no valid pdf constants are found,
ex: <code>Six = list(seq(0.01, 2,by = 0.01), seq(1, 10,by = 0.5))</code>; if no correction is desired for variable Y_i, set the i-th list
component equal to NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>marginal</code></td>
<td>
<p>a list of length equal to <code>k_cat</code>; the i-th element is a vector of the cumulative
probabilities defining the marginal distribution of the i-th variable;
if the variable can take r values, the vector will contain r - 1 probabilities (the r-th is assumed to be 1; default = list())</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam</code></td>
<td>
<p>a vector of lambda (&gt; 0) constants for the Poisson variables (see <code>Poisson</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pois_eps</code></td>
<td>
<p>a vector of length <code>k_pois</code> containing the truncation values (i.e. = rep(0.0001, k_pois); default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>a vector of size parameters for the Negative Binomial variables (see <code>NegBinomial</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>a vector of success probability parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>a vector of mean parameters (*Note: either <code>prob</code> or <code>mu</code> should be supplied for all Negative Binomial variables,
not a mixture; default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nb_eps</code></td>
<td>
<p>a vector of length <code>k_nb</code> containing the truncation values (i.e. = rep(0.0001, k_nb); default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p>the target correlation matrix (<em>must be ordered ordinal, continuous, Poisson, Negative Binomial</em>; default = NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>the sample size (i.e. the length of each simulated variable; default = 100000)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>the seed value for random number generation (default = 1234)</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with components:
</p>
<p><code>L_rho</code> the lower correlation bound
</p>
<p><code>U_rho</code> the upper correlation bound
</p>
<p>If continuous variables are desired, additional components are:
</p>
<p><code>constants</code> the calculated constants
</p>
<p><code>sixth_correction</code> a vector of the sixth cumulant correction values
</p>
<p><code>valid.pdf</code> a vector with i-th component equal to "TRUE" if variable Y_i has a valid power method pdf, else "FALSE"
</p>
<p>If a target correlation matrix rho is provided, each pairwise correlation is checked to see if it is within the lower and upper
bounds.  If the correlation is outside the bounds, the indices of the variable pair are given.
</p>


<h3>Reasons for Function Errors</h3>

<p>1) The most likely cause for function errors is that no solutions to <code>fleish</code> or
<code>poly</code> converged when using <code>find_constants</code>.  If this happens,
the simulation will stop.  It may help to first use <code>find_constants</code> for each continuous variable to
determine if a vector of sixth cumulant correction values is needed.  If the standardized cumulants are obtained from <code>calc_theory</code>,
the user may need to use rounded values as inputs (i.e.
<code>skews = round(skews, 8)</code>).  Due to the nature of the integration involved in <code>calc_theory</code>, the results are
approximations.  Greater accuracy can be achieved by increasing the number of subdivisions (<code>sub</code>) used in the integration
process.  For example, in order to ensure that skew is exactly 0 for symmetric distributions.
</p>
<p>2) In addition, the kurtosis may be outside the region of possible values.  There is an associated lower boundary for kurtosis associated
with a given skew (for Fleishman's method) or skew and fifth and sixth cumulants (for Headrick's method).  Use
<code>calc_lower_skurt</code> to determine the boundary for a given set of cumulants.
</p>


<h3>The Generate, Sort, and Correlate (GSC, Demirtas &amp; Hedeker, 2011, doi: <a href="http://doi.org/10.1198/tast.2011.10090">10.1198/tast.2011.10090</a>) Algorithm</h3>

<p>The GSC algorithm is a flexible method for determining empirical correlation bounds when the theoretical bounds are unknown.
The steps are as follows:
</p>
<p>1) Generate independent random samples from the desired distributions using a large number of observations (i.e. N = 100,000).
</p>
<p>2) Lower Bound: Sort the two variables in opposite directions (i.e., one increasing and one decreasing) and find the sample correlation.
</p>
<p>3) Upper Bound: Sort the two variables in the same direction and find the sample correlation.
</p>
<p>Demirtas &amp; Hedeker showed that the empirical bounds computed from the GSC method are similar to the theoretical bounds (when they are known).
</p>
<p>The processes used to find the correlation bounds for each variable type are described below:
</p>


<h3>Ordinal Variables</h3>

<p>Binary pairs: The correlation bounds are determined as in Demirtas et al. (2012, doi: <a href="http://doi.org/10.1002/sim.5362">10.1002/sim.5362</a>), who used the method of Emrich &amp;
Piedmonte (1991, doi: <a href="http://doi.org/10.1080/00031305.1991.10475828">10.1080/00031305.1991.10475828</a>).  The joint distribution is determined by "borrowing" the moments of a multivariate normal
distribution.  For two binary variables <code class="reqn">Y_{i}</code> and <code class="reqn">Y_{j}</code>, with success probabilities <code class="reqn">p_{i}</code> and <code class="reqn">p_{j}</code>, the lower
correlation bound is given by
</p>
<p style="text-align: center;"><code class="reqn">max(-\sqrt{(p_{i}p_{j})/(q_{i}q_{j})},\ -\sqrt{(q_{i}q_{j})/(p_{i}p_{j})})</code>
</p>

<p>and the upper bound by
</p>
<p style="text-align: center;"><code class="reqn">min(\sqrt{(p_{i}q_{j})/(q_{i}p_{j})},\ \sqrt{(q_{i}p_{j})/(p_{i}q_{j})})</code>
</p>

<p>Here, <code class="reqn">q_{i} = 1 - p_{i}</code> and <code class="reqn">q_{j} = 1 - p_{j}</code>.
</p>
<p>Binary-Ordinal or Ordinal-Ordinal pairs: Randomly generated variables with the given marginal distributions are used in the
GSC algorithm to find the correlation bounds.
</p>


<h3>Continuous Variables</h3>

<p>Continuous variables are randomly generated using constants from <code>find_constants</code> and a vector of sixth
cumulant correction values (if provided.)  The GSC algorithm is used to find the lower and upper bounds.
</p>


<h3>Poisson Variables</h3>

<p>The maximum support values, given the vector of cumulative probability truncation values (pois_eps) and vector of means (lam), are calculated using
<code>max_count_support</code>.  The finite supports are used to determine marginal distributions for each Poisson variable.
Randomly generated variables with the given marginal distributions are used in the GSC algorithm to find the correlation bounds.
</p>


<h3>Negative Binomial Variables</h3>

<p>The maximum support values, given the vector of cumulative probability truncation values (nb_eps) and vectors of
sizes and success probabilities (prob) or means (mu), are calculated using <code>max_count_support</code>.
The finite supports are used to determine marginal distributions for each Negative Binomial variable.
Randomly generated variables with the given marginal distributions are used in the GSC algorithm to find the correlation bounds.
</p>


<h3>Continuous - Ordinal Pairs</h3>

<p>Randomly generated ordinal variables with the given marginal distributions and the previously generated continuous variables are used in the
GSC algorithm to find the correlation bounds.
</p>


<h3>Ordinal - Poisson Pairs</h3>

<p>Randomly generated ordinal and Poisson variables with the given marginal distributions are used in the GSC algorithm to find
the correlation bounds.
</p>


<h3>Ordinal - Negative Binomial Pairs</h3>

<p>Randomly generated ordinal and Negative Binomial variables with the given marginal distributions are used in the GSC algorithm to find
the correlation bounds.
</p>


<h3>Continuous - Poisson Pairs</h3>

<p>The previously generated continuous variables and randomly generated Poisson variables with the given marginal distributions are used
in the GSC algorithm to find the correlation bounds.
</p>


<h3>Continuous - Negative Binomial Pairs</h3>

<p>The previously generated continuous variables and randomly generated Negative Binomial variables with the given marginal distributions are used
in the GSC algorithm to find the correlation bounds.
</p>


<h3>Poisson - Negative Binomial Pairs</h3>

<p>Randomly generated variables with the given marginal distributions are used in the GSC algorithm to find the correlation bounds.
</p>


<h3>References</h3>

<p>Please see <code>rcorrvar2</code> for additional references.
</p>
<p>Demirtas H &amp; Hedeker D (2011). A practical way for computing approximate lower and upper correlation bounds.
American Statistician, 65(2): 104-109. doi: <a href="http://doi.org/10.1198/tast.2011.10090">10.1198/tast.2011.10090</a>.
</p>
<p>Demirtas H, Hedeker D, &amp; Mermelstein RJ (2012). Simulation of massive public health data by power polynomials.
Statistics in Medicine, 31(27): 3337-3346. doi: <a href="http://doi.org/10.1002/sim.5362">10.1002/sim.5362</a>.
</p>
<p>Emrich LJ &amp; Piedmonte MR (1991). A Method for Generating High-Dimensional Multivariate Binary Variables. The American Statistician, 45(4): 302-4.
doi: <a href="http://doi.org/10.1080/00031305.1991.10475828">10.1080/00031305.1991.10475828</a>.
</p>
<p>Frechet M.  Sur les tableaux de correlation dont les marges sont donnees.  Ann. l'Univ. Lyon SectA.  1951;14:53-77.
</p>
<p>Hoeffding W. Scale-invariant correlation theory. In: Fisher NI, Sen PK, editors. The collected works of Wassily Hoeffding.
New York: Springer-Verlag; 1994. p. 57-107.
</p>
<p>Hakan Demirtas, Yiran Hu and Rawan Allozi (2017). PoisBinOrdNor: Data Generation with Poisson, Binary, Ordinal and Normal Components.
R package version 1.4. <a href="https://CRAN.R-project.org/package=PoisBinOrdNor">https://CRAN.R-project.org/package=PoisBinOrdNor</a>
</p>


<h3>See Also</h3>

<p><code>find_constants</code>, <code>rcorrvar2</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">valid_corr2(n = 1000, k_cat = 1, k_cont = 1, method = "Polynomial",
  means = 0, vars = 1, skews = 0, skurts = 0, fifths = 0, sixths = 0,
  marginal = list(c(1/3, 2/3)), rho = matrix(c(1, 0.4, 0.4, 1), 2, 2))

## Not run: 

# Binary, Ordinal, Continuous, Poisson, and Negative Binomial Variables

options(scipen = 999)
seed &lt;- 1234
n &lt;- 10000

# Continuous Distributions: Normal, t (df = 10), Chisq (df = 4),
#                           Beta (a = 4, b = 2), Gamma (a = 4, b = 4)
Dist &lt;- c("Gaussian", "t", "Chisq", "Beta", "Gamma")

# calculate standardized cumulants
# those for the normal and t distributions are rounded to ensure the
# correct values (i.e. skew = 0)

M1 &lt;- round(calc_theory(Dist = "Gaussian", params = c(0, 1)), 8)
M2 &lt;- round(calc_theory(Dist = "t", params = 10), 8)
M3 &lt;- calc_theory(Dist = "Chisq", params = 4)
M4 &lt;- calc_theory(Dist = "Beta", params = c(4, 2))
M5 &lt;- calc_theory(Dist = "Gamma", params = c(4, 4))
M &lt;- cbind(M1, M2, M3, M4, M5)
M &lt;- round(M[-c(1:2),], digits = 6)
colnames(M) &lt;- Dist
rownames(M) &lt;- c("skew", "skurtosis", "fifth", "sixth")
means &lt;- rep(0, length(Dist))
vars &lt;- rep(1, length(Dist))

# Binary and Ordinal Distributions
marginal &lt;- list(0.3, 0.4, c(0.1, 0.5), c(0.3, 0.6, 0.9),
                 c(0.2, 0.4, 0.7, 0.8))
support &lt;- list()

# Poisson Distributions
lam &lt;- c(1, 5, 10)

# Negative Binomial Distributions
size &lt;- c(3, 6)
prob &lt;- c(0.2, 0.8)

ncat &lt;- length(marginal)
ncont &lt;- ncol(M)
npois &lt;- length(lam)
nnb &lt;- length(size)

# Create correlation matrix from a uniform distribution (-0.8, 0.8)
set.seed(seed)
Rey &lt;- diag(1, nrow = (ncat + ncont + npois + nnb))
for (i in 1:nrow(Rey)) {
  for (j in 1:ncol(Rey)) {
    if (i &gt; j) Rey[i, j] &lt;- runif(1, -0.8, 0.8)
    Rey[j, i] &lt;- Rey[i, j]
  }
}

# Test for positive-definiteness
library(Matrix)
if(min(eigen(Rey, symmetric = TRUE)$values) &lt; 0) {
  Rey &lt;- as.matrix(nearPD(Rey, corr = T, keepDiag = T)$mat)
}

# Make sure Rey is within upper and lower correlation limits
valid &lt;- valid_corr2(k_cat = ncat, k_cont = ncont, k_pois = npois,
                     k_nb = nnb, method = "Polynomial", means = means,
                     vars = vars, skews = M[1, ], skurts = M[2, ],
                     fifths = M[3, ], sixths = M[4, ], marginal = marginal,
                     lam = lam, pois_eps = rep(0.0001, npois),
                     size = size, prob = prob, nb_eps = rep(0.0001, nnb),
                     rho = Rey, seed = seed)


## End(Not run)
</code></pre>


</div>