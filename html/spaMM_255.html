<div class="container">

<table style="width: 100%;"><tr>
<td>method</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fitting methods (objective functions maximized)
</h2>

<h3>Description</h3>

<p>The <code>method</code> argument of the fitting functions, with possible values <code>"ML"</code>, <code>"REML"</code>,<code>"PQL"</code>, <code>"PQL/L"</code>, and so on, controls whether restricted likelihood techniques are used to estimate residual variance and random-effect parameters, and the way likelihood functions are approximated.
</p>
<p>By default, Laplace approximations are used, as selected by <code>"ML"</code> and <code>"REML"</code> methods. The Laplace approximation to (log-)marginal likelihood can be expressed in terms of the joint log-likelihood of the data and the random effects (or the <em>h</em>-likelihood in works of Lee and Nelder). The Laplace approximation is the joint likelihood minus half the log-determinant of the matrix of second derivatives (Hessian matrix) of the negative joint likelihood with respect to the random effects (observed information matrix). The Laplace approximation to restricted likelihood (for REML estimation) is similarly defined from the Hessian matrix with respect to random effects <b>and</b> fixed effects (for the adventurous, <span class="pkg">spaMM</span> allows some non-standard specification of the fixed effects included in the definition of he Hessian).
</p>
<p>Various additional approximations have been considered. Penalized quasi-likelihood (PQL), as originally defined for GLMMs by Breslow and Clayton (1993), uses a Laplace approximation of restricted likelihood to estimate dispersion parameters, and estimates fixed effects by maximizing the joint likelihood (h-likelihood). Although PQL has been criticized as an approximation of likelihood (and actual implementations may diverge from the original version), it has some interesting inferential properties. <span class="pkg">spaMM</span> allows one to use an ML variant of PQL, named PQL/L.  
</p>
<p>Further approximations defined by Lee, Nelder and collaborators (e.g., Noh and Lee, 2007, for some overview) may mostly be seen as laying between PQL and the full Laplace method in terms of approximation of the likelihood, and as extending them to models with non-gaussian random effects (“HGLMs”). 
In practice the ML, REML, PQL and PQL/L methods should cover most (all?) needs for GLMMs, and EQL extends the PQL concept to HGLMs. <code>method="EQL+"</code> stands for the EQL method of Lee and Nelder (2001). The '+' signals that it includes the d v/ d tau correction described p. 997 of that paper, while <code>method="EQL-"</code> ignores it. <code>"PQL"</code> is equivalent to <code>EQL-</code> for GLMMs. <code>"PQL/L"</code> is PQL without the leverage corrections that characterize REML estimation of random-effect parameters. 
</p>
<p><b><span class="pkg">spaMM</span> uses the observed information matrix by default since version 4.0.0</b>. By contrast, in Laplace approximations of likelihood described in the work of Lee &amp; Nelder, i.e. for mixed-effect models with GLM response families, the information matrix is written in terms of the GLM weights (e.g., Lee &amp; Nelder 2001, p.1004), and is thus effectively the expected information matrix, which differs from the observed information matrix in the case of GLM families with non-canonical link (McCullagh &amp; Nelder 1989, p.42). Therefore, the likelihood approximation based on the expected information matrix differs from the one based on the observed information matrix in the same conditions. 
</p>
<p>For non-GLM response families (currently, the <code>negbin1</code>, <code>beta_resp</code> and <code>betabin</code>), only observed information is available (expected information would at best be quite difficult to evaluate, with no benefits). For GLM response families, use of expected information matrix can be required at a global level by setting <code>spaMM.options(obsInfo=FALSE)</code> or in a specific fit by adding <code>"exp"</code> as a second specifier in the method (e.g., <code>method=c("ML","exp")</code>). This can be distinctly useful (in terms of speed) for fitting models with <code>Gamma(log)</code> response family. Conversely, the <code>"obs"</code> specifier will enforce use of observed information matrix when the alternative is set at a global level.
</p>


<h3>Details</h3>

<p>The <code>method</code> (or <code>HLmethod</code>) argument of fitting functions also accepts values of the form <code>"HL(&lt;...&gt;)"</code>, <code>"ML(&lt;...&gt;)"</code> and <code>"RE(&lt;...&gt;)"</code>, e.g. <code>method="RE(1,1)"</code>, which allow one to experiment with further combinations of approximations. HL and RE are equivalent (both imply an REML correction). The first '1' means that a Laplace approximation to the likelihood is used to estimate fixed effects 
(a '0' would instead mean that the h likelihood is used as the objective function). The second  '1' means that a Laplace approximation to the likelihood or restricted likelihood is used to estimate dispersion parameters, this approximation including the dv/d tau term specifically discussed by Lee &amp; Nelder 2001, p. 997 (a '0' would instead mean that these terms are ignored). It is possible to enforce the EQL approximation for estimation of dispersion parameter (i.e., Lee and Nelder's (2001) method) by adding a third index with value 0. <code>"EQL+"</code> is thus <code>"HL(0,1,0)"</code>, while <code>"EQL-"</code> is <code>"HL(0,0,0)"</code>. <code>"PQL"</code> is <code>EQL-</code> for GLMMs. <code>"REML"</code> is <code>"HL(1,1)"</code>. <code>"ML"</code> is <code>"ML(1,1)"</code>. 
</p>
<p>Some of these distinctions make sense for <b>GLMs</b>, and may help in understanding idiosyncrasies of <code>stats::glm</code> for Gamma GLMs. In particular (as stated in the <code>stats::logLik</code> documentation) the logLik of a Gamma GLM fit by <code>glm</code> differs from the exact likelihood. An <code>"ML(0,0,0)"</code> approximation of true ML provides the same log likelihood as <code>stats::logLik</code>. Further, the dispersion estimate returned by <code>summary.glm</code> differs from the one implied by <code>logLik</code>, because <code>summary.glm</code> uses Pearson residuals instead of deviance residuals. This may be confusing, and no <code>method</code> in <span class="pkg">spaMM</span> tries to reproduce simultaneously these distinct features (however, <code>spaMM_glm</code> may do so). The dispersion estimate returned by an <code>"HL(.,.,0)"</code> fit matches what can be computed from residual deviance and residual degrees of freedom of a <code>glm</code> fit, but this is not the estimate displayed by <code>summary.glm</code>. The fixed effect estimates are not affected by these tinkerings.     
</p>


<h3>References</h3>

<p>Breslow, NE, Clayton, DG. (1993). Approximate Inference in Generalized Linear Mixed Models.
Journal of the American Statistical Association 88, 9-25.
</p>
<p>Lee, Y., Nelder, J. A. (2001)  Hierarchical generalised linear models: A
synthesis of generalised linear models, random-effect models and structured
dispersions. Biometrika 88, 987-1006.
</p>
<p>McCullagh, P. and Nelder, J.A. (1989) Generalized Linear Models, 2nd edition. London: Chapman &amp; Hall.
</p>
<p>Noh, M., and Lee, Y. (2007). REML estimation for binary data in GLMMs, J.
Multivariate Anal. 98, 896-915.
</p>


</div>