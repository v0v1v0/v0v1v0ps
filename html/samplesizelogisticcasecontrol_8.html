<div class="container">

<table style="width: 100%;"><tr>
<td>sampleSize_binary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sample size for a binary exposure</h2>

<h3>Description</h3>

<p>Calculates the required sample size of as case-control study with a binary exposure variable
</p>


<h3>Usage</h3>

<pre><code class="language-R">sampleSize_binary(prev, logOR, probXeq1=NULL, distF=NULL, data=NULL, 
      size.2sided=0.05, power=0.9, cc.ratio=0.5, interval=c(-100, 100), tol=0.0001,
      n.samples=10000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probXeq1</code></td>
<td>
<p>NULL or a number between 0 and 1 giving the probability that the exposure
variable is 1. If set to NULL, the the <code>data</code> option must be specified so 
that <code>probXeq1</code> can be estimated. The default is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distF</code></td>
<td>
<p>NULL, a function or a character string giving the function to generate random
vectors from the distribution of the confounders and exposure. The order of the returned
vector must match the order of <code>logOR</code>.
User defined functions are also allowed, provided the user-defined function has only
one integer valued argument that inputs the number of random vectors to generate. 
For instance the header of a user-defined function called "userF" would be 
userF &lt;- function(n). 
The default depends on other options (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code>file.list</code> that gives
a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power</code></td>
<td>
<p>Number between 0 and 1 for the desired power of the test. The default is 0.9.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.samples</code></td>
<td>
<p>Integer giving the number of random vectors to generate when the option <code>distF</code>
is specified.
The default is 10000.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If there are no confounders (length(logOR) = 1), then either <code>probXeq1</code> or <code>data</code> must
be specified, where <code>probXeq1</code> takes precedance. If there are confounders (length(logOR) &gt; 1), then
either <code>data</code> or <code>distF</code> must be specified, where <code>data</code> takes precedance.
</p>


<h3>Value</h3>

<p>A list containing four sample sizes, where two of them are for a Wald test and two for a score test.
The two sample sizes for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code>sampleSize_continuous</code>, <code>sampleSize_ordinal</code>, <code>sampleSize_data</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, Prob(X=1)=0.2
  sampleSize_binary(prev, logOR, probXeq1=0.2) 

  # Generate data for a N(0,1) confounder and binary exposure
  data &lt;- cbind(rnorm(1000), rbinom(1000, 1, 0.4))
  beta &lt;- c(0.1, 0.2)
  sampleSize_binary(prev, beta, data=data) 

  # Define a function to generate random vectors for two confounders and the binary exposure
  f &lt;- function(n) {cbind(rnorm(n), rbinom(n, 3, 0.5), rbinom(n, 1, 0.3))}
  logOR &lt;- c(0.2, 0.3, 0.25)
  sampleSize_binary(prev, logOR, distF=f) 

</code></pre>


</div>