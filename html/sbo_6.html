<div class="container">

<table style="width: 100%;"><tr>
<td>eval_sbo_predictor</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Evaluate Stupid Back-off next-word predictions</h2>

<h3>Description</h3>

<p>Evaluate next-word predictions based on Stupid Back-off N-gram
model on a test corpus.
</p>


<h3>Usage</h3>

<pre><code class="language-R">eval_sbo_predictor(model, test, L = attr(model, "L"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a <code>sbo_predictor</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>a character vector. Perform a single prediction on each entry of
this vector (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L</code></td>
<td>
<p>Maximum number of predictions for each input sentence
(maximum allowed is <code>attr(model, "L")</code>)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function allows to obtain information on the quality of
Stupid Back-off model predictions, such as next-word prediction accuracy,
or the word-rank distribution of correct prediction, by direct test against
a test set corpus. For a reasonable estimate of prediction accuracy, the
different entries of the <code>test</code> vector should be uncorrelated
documents (e.g. separate tweets, as in the <code>twitter_test</code>
example dataset).
</p>
<p>More in detail, <code>eval_sbo_predictor</code> performs the following operations:
</p>

<ol>
<li>
<p> Sample a single sentence from each entry of the character vector
<code>test</code>.
</p>
</li>
<li>
<p> Sample a single $N$-gram from each sentence obtained in the previous step.
</p>
</li>
<li>
<p> Predict next words from the $(N-1)$-gram prefix.
</p>
</li>
<li>
<p> Return all predictions, together with the true word completions.
</p>
</li>
</ol>
<h3>Value</h3>

<p>A tibble, containing the input $(N-1)$-grams, the true completions,
the predicted completions and a column indicating whether one of the
predictions were correct or not.
</p>


<h3>Author(s)</h3>

<p>Valerio Gherardi
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Evaluating next-word predictions from a Stupid Back-off N-gram model
if (suppressMessages(require(dplyr) &amp;&amp; require(ggplot2))) {
        p &lt;- sbo_predictor(twitter_predtable)
        set.seed(840) # Set seed for reproducibility
        test &lt;- sample(twitter_test, 500)
        eval &lt;- eval_sbo_predictor(p, test)
        
        ## Compute three-word accuracies
        eval %&gt;% summarise(accuracy = sum(correct)/n()) # Overall accuracy
        eval %&gt;% # Accuracy for in-sentence predictions
                filter(true != "&lt;EOS&gt;") %&gt;%
                summarise(accuracy = sum(correct) / n())
        
        ## Make histogram of word-rank distribution for correct predictions
        dict &lt;- attr(twitter_predtable, "dict")
        eval %&gt;%
                filter(correct, true != "&lt;EOS&gt;") %&gt;%
                transmute(rank = match(true, table = dict)) %&gt;%
                ggplot(aes(x = rank)) + geom_histogram(binwidth = 30)
}

</code></pre>


</div>