<div class="container">

<table style="width: 100%;"><tr>
<td>StatMHMMR-class</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A Reference Class which contains statistics of a MHMMR model.</h2>

<h3>Description</h3>

<p>StatMHMMR contains all the statistics associated to a MHMMR
model. It mainly includes the E-Step of the EM algorithm calculating the
posterior distribution of the hidden variables (ie the smoothing
probabilities), as well as the calculation of the prediction and filtering
probabilities, the log-likelhood at each step of the algorithm and the
obtained values of model selection criteria..
</p>


<h3>Fields</h3>


<dl>
<dt><code>tau_tk</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the posterior probability
that the observation <code class="reqn">Y_{i}</code> originates from the <code class="reqn">k</code>-th regression
model.</p>
</dd>
<dt><code>alpha_tk</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the forwards
probabilities: <code class="reqn">P(Y_{1},\dots,Y_{t}, z_{t} = k)</code>.</p>
</dd>
<dt><code>beta_tk</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code>, giving the backwards
probabilities: <code class="reqn">P(Y_{t+1},\dots,Y_{m} | z_{t} =
  k)</code>.</p>
</dd>
<dt><code>xi_tkl</code></dt>
<dd>
<p>Array of size <code class="reqn">(m - 1, K, K)</code> giving the joint post
probabilities: <code class="reqn">xi_tk[t, k, l] = P(z_{t} = k, z_{t-1} = l |
  \boldsymbol{Y})</code> for <code class="reqn">t
  = 2,\dots,m</code>.</p>
</dd>
<dt><code>f_tk</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the cumulative distribution
function <code class="reqn">f(y_{t} | z{_t} = k)</code>.</p>
</dd>
<dt><code>log_f_tk</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the logarithm of the
cumulative distribution <code>f_tk</code>.</p>
</dd>
<dt><code>loglik</code></dt>
<dd>
<p>Numeric. Log-likelihood of the MHMMR model.</p>
</dd>
<dt><code>stored_loglik</code></dt>
<dd>
<p>Numeric vector. Stored values of the log-likelihood at
each iteration of the EM algorithm.</p>
</dd>
<dt><code>klas</code></dt>
<dd>
<p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>z_ik</code></dt>
<dd>
<p>Hard segmentation logical matrix of dimension <code class="reqn">(m, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ P(z_{i} = s |
  \boldsymbol{Y})  = tau\_tk;\ 0 \ \textrm{otherwise}</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>state_probs</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the distribution of the
Markov chain.
<code class="reqn">P(z_{1},\dots,z_{m};\pi,\boldsymbol{A})</code>
with <code class="reqn">\pi</code> the prior probabilities (field <code>prior</code> of the class
ParamMHMMR) and <code class="reqn">\boldsymbol{A}</code> the transition matrix
(field <code>trans_mat</code> of the class ParamMHMMR) of the Markov
chain.</p>
</dd>
<dt><code>BIC</code></dt>
<dd>
<p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>AIC</code></dt>
<dd>
<p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>regressors</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the values of the
estimated polynomial regression components.</p>
</dd>
<dt><code>predict_prob</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the prediction
probabilities: <code class="reqn">P(z_{t} = k | y_{1},\dots,y_{t-1})</code>.</p>
</dd>
<dt><code>predicted</code></dt>
<dd>
<p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the prediction probabilities
<code>predict_prob</code>.</p>
</dd>
<dt><code>filter_prob</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the filtering
probabilities <code class="reqn">Pr(z_{t} = k | y_{1},\dots,y_{t})</code>.</p>
</dd>
<dt><code>filtered</code></dt>
<dd>
<p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the filtering probabilities.</p>
</dd>
<dt><code>smoothed_regressors</code></dt>
<dd>
<p>Matrix of size <code class="reqn">(m, K)</code> giving the polynomial
components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
<dt><code>smoothed</code></dt>
<dd>
<p>Row matrix of size <code class="reqn">(m, 1)</code> giving the sum of the
polynomial components weighted by the posterior probability <code>tau_tk</code>.</p>
</dd>
</dl>
<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(paramMHMMR)</code></dt>
<dd>
<p>Method to compute the log-likelihood based on some parameters given by
the object <code>paramMHMMR</code> of class ParamMHMMR.</p>
</dd>
<dt><code>computeStats(paramMHMMR)</code></dt>
<dd>
<p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramMHMMR</code> of class
ParamMHMMR.</p>
</dd>
<dt><code>EStep(paramMHMMR)</code></dt>
<dd>
<p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramMHMMR</code> of class ParamMHMMR
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt>
<dd>
<p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z\_ik = 1 \ \textrm{if} \ z\_ik = \textrm{arg} \
      \textrm{max}_{s} \ P(z_{i} = s | \boldsymbol{Y})  = tau\_tk;\ 0 \
      \textrm{otherwise}</code></p>
</dd>
</dl>
<h3>See Also</h3>

<p>ParamMHMMR
</p>


</div>