<div class="container">

<table style="width: 100%;"><tr>
<td>minimizeSmoothedSequence</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Minimize the objective function of a smoothed regression operator with respect to <code class="reqn">betavector</code> using the progressive smoothing algorithm.</h2>

<h3>Description</h3>

<p>Minimize the objective function of a smoothed regression operator with respect to <code class="reqn">betavector</code> using the progressive smoothing algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">minimizeSmoothedSequence(p, obj, objgrad, muSeq = 2^seq(3, -6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>The dimension of the unknown parameters (regression coefficients).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p>The objective function of the regression operator. Note that in the case of the progressive smoothing algorithm, the objective function must be a function of both <code class="reqn">betavector</code> and <code class="reqn">mu</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objgrad</code></td>
<td>
<p>The gradient function of the regression operator. Note that in the case of the progressive smoothing algorithm, the gradient must be a function of both <code class="reqn">betavector</code> and <code class="reqn">mu</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>muSeq</code></td>
<td>
<p>The sequence of Nesterov smoothing parameters. The default is <code class="reqn">2^{-n}</code> for <code class="reqn">n \in \{-3,\ldots,6\}</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The estimator <code class="reqn">betavector</code> (minimizer) of the regression operator.
</p>


<h3>References</h3>

<p>Hahn, G., Lutz, S., Laha, N., and Lange, C. (2020). A framework to efficiently smooth L1 penalties for linear regression. bioRxiv:2020.09.17.301788.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(smoothedLasso)
n &lt;- 100
p &lt;- 500
betavector &lt;- runif(p)
X &lt;- matrix(runif(n*p),nrow=n,ncol=p)
y &lt;- X %*% betavector
lambda &lt;- 1
temp &lt;- standardLasso(X,y,lambda)
obj &lt;- function(z,m) objFunctionSmooth(z,temp$u,temp$v,temp$w,mu=m)
objgrad &lt;- function(z,m) objFunctionSmoothGradient(z,temp$w,temp$du,temp$dv,temp$dw,mu=m)
print(minimizeSmoothedSequence(p,obj,objgrad))

</code></pre>


</div>