<div class="container">

<table style="width: 100%;"><tr>
<td>sits_tae</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Train a model using  Temporal Self-Attention Encoder</h2>

<h3>Description</h3>

<p>Implementation of Temporal Attention Encoder (TAE)
for satellite image time series classification.
</p>
<p>This function is based on the paper by Vivien Garnot referenced below
and code available on github at
https://github.com/VSainteuf/pytorch-psetae.
</p>
<p>We also used the code made available by Maja Schneider in her work with
Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.
</p>
<p>If you use this method, please cite Garnot's and Schneider's work.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sits_tae(
  samples = NULL,
  samples_validation = NULL,
  epochs = 150,
  batch_size = 64,
  validation_split = 0.2,
  optimizer = torch::optim_adamw,
  opt_hparams = list(lr = 0.001, eps = 1e-08, weight_decay = 1e-06),
  lr_decay_epochs = 1,
  lr_decay_rate = 0.95,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples_validation</code></td>
<td>
<p>Time series with the validation samples. if the
<code>samples_validation</code> parameter is provided,
the <code>validation_split</code> parameter is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epochs</code></td>
<td>
<p>Number of iterations to train the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Number of samples per gradient update.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation_split</code></td>
<td>
<p>Number between 0 and 1. Fraction of training data
to be used as validation data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
lr : Learning rate of the optimizer
eps: Term added to the denominator
to improve numerical stability.
weight_decay:       L2 regularization</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lr_decay_epochs</code></td>
<td>
<p>Number of epochs to reduce learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lr_decay_rate</code></td>
<td>
<p>Decay factor for reducing learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_delta</code></td>
<td>
<p>Minimum improvement to reset the patience counter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A fitted model to be used for classification.
</p>


<h3>Author(s)</h3>

<p>Charlotte Pelletier, <a href="mailto:charlotte.pelletier@univ-ubs.fr">charlotte.pelletier@univ-ubs.fr</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>References</h3>

<p>Vivien Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata,
"Satellite Image Time Series Classification with Pixel-Set Encoders
and Temporal Self-Attention",
2020 Conference on Computer Vision and Pattern Recognition.
pages 12322-12331.
DOI: 10.1109/CVPR42600.2020.01234
</p>
<p>Schneider, Maja; Körner, Marco,
"[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention."
ReScience C 7 (2), 2021.
DOI: 10.5281/zenodo.4835356
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (sits_run_examples()) {
    # create a TAE model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_tae())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6.1",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>


</div>