<div class="container">

<table style="width: 100%;"><tr>
<td>predict.scoutobject</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Prediction function for covariance-regularized regression, aka the Scout.</h2>

<h3>Description</h3>

<p>A function to perform prediction, using an x matrix and the output of
the "scout" function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'scoutobject'
predict(object, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>The results of a call to the "scout" function. The
coefficients that are part of this object will be used for
making predictions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newx</code></td>
<td>
<p>The new x at which predictions should be made. Can be a
vector of length ncol(x), where x is the data on which scout.obj was
created, or a matrix with ncol(x) columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to predict</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table><tr style="vertical-align: top;">
<td><code>yhat</code></td>
<td>
<p>If newx was a vector, then a  matrix will be returned,
with dimension length(lam1s)xlength(lam2s) (where lam1s and lam2s
are attributes of scout.obj). The (i,j) element of this matrix will
correspond to tuning parameter values (lam1s[i], lam2s[j]). If newx
is a matrix, then an array of dimension
nrow(newx)xlength(lam1s)xlength(lam2s) will be returned.</p>
</td>
</tr></table>
<h3>Author(s)</h3>

<p>Daniela M. Witten and Robert Tibshirani</p>


<h3>References</h3>

<p>Witten, DM and Tibshirani, R (2008) Covariance-regularized
regression and classification for high-dimensional problems.  Journal
of the Royal Statistical Society, Series B 71(3): 615-636. &lt;http://www-stat.stanford.edu/~dwitten&gt;</p>


<h3>See Also</h3>

<p>scout, cv.scout </p>


<h3>Examples</h3>

<pre><code class="language-R">library(lars)
data(diabetes)
attach(diabetes)
# Split data into training and test set
training &lt;- sample(nrow(x2),floor(nrow(x2)/2))
xtrain &lt;- x2[training,]
ytrain &lt;- y[training]
xtest &lt;- x2[-training,]
ytest &lt;- y[-training]
# Done splitting data into training and test set
# Do cross-validation to determine best tuning parameter values for Scout(1,1)
## Not run: cv.out &lt;- cv.scout(xtrain,ytrain,p1=1,p2=1, lam1s=seq(0.001,.15,len=5),K=4)
## Not run: print(cv.out)
# Done cross-validation
## Fit Model
#scout.object &lt;- scout(xtrain,ytrain,p1=1,p2=1,lam1s=cv.out$bestlam1,lam2s=cv.out$bestlam2)
#print(scout.object)
## Done Fitting Model
## Predict on test data, and report MSE
#yhats &lt;- predict(scout.object,xtest)
#print(mean((yhats-ytest)^2))
detach(diabetes)
</code></pre>


</div>