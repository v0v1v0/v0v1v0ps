<div class="container">

<table style="width: 100%;"><tr>
<td>spark_read_avro</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Reads a Avro File into Apache Spark</h2>

<h3>Description</h3>

<p>Reads a Avro file into Apache Spark using sparklyr.
</p>


<h3>Usage</h3>

<pre><code class="language-R">spark_read_avro(
  sc,
  name,
  path,
  readOptions = list(),
  repartition = 0L,
  memory = TRUE,
  overwrite = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>sc</code></td>
<td>
<p>An active <code>spark_connection</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name to assign to the newly generated table.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>The path to the file. Needs to be accessible from the cluster.
Supports the ‘<span class="samp">⁠"hdfs://"⁠</span>’, ‘<span class="samp">⁠"s3n://"⁠</span>’ and ‘<span class="samp">⁠"file://"⁠</span>’ protocols.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>readOptions</code></td>
<td>
<p>A list of strings with additional options.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>repartition</code></td>
<td>
<p>The number of partitions used to distribute the
generated table. Use 0 (the default) to avoid partitioning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>memory</code></td>
<td>
<p>Boolean; should the data be loaded eagerly into memory? (That
is, should the table be cached?)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overwrite</code></td>
<td>
<p>Boolean; overwrite the table with the given name if it
already exists?</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
## If you haven't got a Spark cluster, you can install Spark locally like this
library(sparklyr)
spark_install(version = "2.0.1")

sc &lt;- spark_connect(master = "local")
df &lt;- spark_read_avro(
  sc,
  "twitter",
  system.file("extdata/twitter.avro", package = "sparkavro"),
  repartition = FALSE,
  memory = FALSE,
  overwrite = FALSE
)

spark_disconnect(sc)

## End(Not run)
</code></pre>


</div>