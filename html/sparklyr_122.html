<div class="container">

<table style="width: 100%;"><tr>
<td>hof_map_filter</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Filters a map</h2>

<h3>Description</h3>

<p>Filters entries in a map using the function specified
(this is essentially a dplyr wrapper to the 'map_filter(expr, func)' higher-
order function, which is supported since Spark 3.0)
</p>


<h3>Usage</h3>

<pre><code class="language-R">hof_map_filter(x, func, expr = NULL, dest_col = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The Spark data frame to be processed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>func</code></td>
<td>
<p>The filter function to apply (it should take (key, value) as arguments
and return a boolean value, with FALSE indicating the key-value pair should be discarded
and TRUE otherwise)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expr</code></td>
<td>
<p>The map being filtered, could be any SQL expression evaluating to a map
(default: the last column of the Spark data frame)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dest_col</code></td>
<td>
<p>Column to store the filtered result (default: expr)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional params to dplyr::mutate</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

library(sparklyr)
sc &lt;- spark_connect(master = "local", version = "3.0.0")
sdf &lt;- sdf_len(sc, 1) %&gt;% dplyr::mutate(m = map(1, 0, 2, 2, 3, -1))
filtered_sdf &lt;- sdf %&gt;% hof_map_filter(~ .x &gt; .y)

## End(Not run)

</code></pre>


</div>