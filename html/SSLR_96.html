<div class="container">

<table style="width: 100%;"><tr>
<td>seeded_kmeans</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>General Interface Seeded KMeans</h2>

<h3>Description</h3>

<p>The difference with traditional Kmeans is that in this method implemented,
at initialization, there are as many clusters as the number of classes that exist of the labelled data,
the average of the labelled data of a given class
</p>


<h3>Usage</h3>

<pre><code class="language-R">seeded_kmeans(max_iter = 10, method = "euclidean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>maximum iterations in KMeans. Default is 10</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>distance method in KMeans: "euclidean", "maximum", "manhattan", "canberra", "binary" or "minkowski"</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Sugato Basu, Arindam Banerjee, Raymond Mooney<br><em>Semi-supervised clustering by seeding</em><br>
July 2002
In Proceedings of 19th International Conference on Machine Learning
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(tidyverse)
library(caret)
library(SSLR)
library(tidymodels)

data &lt;- iris

set.seed(1)
#% LABELED
cls &lt;- which(colnames(iris) == "Species")

labeled.index &lt;- createDataPartition(data$Species, p = .2, list = FALSE)
data[-labeled.index,cls] &lt;- NA



m &lt;- seeded_kmeans() %&gt;% fit(Species ~ ., data)

#Get labels (assing clusters), type = "raw" return factor
labels &lt;- m %&gt;% cluster_labels()

print(labels)


#Get centers
centers &lt;- m %&gt;% get_centers()

print(centers)
</code></pre>


</div>