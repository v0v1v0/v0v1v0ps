<div class="container">

<table style="width: 100%;"><tr>
<td>mspeFHjack</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Compute MSPE through Jackknife-based MSPE estimation method for Fay Herriot model
</h2>

<h3>Description</h3>

<p>This function returns MSPE estimator with jackknife method for Fay Herriot model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mspeFHjack(Y, X, D, method = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>(vector). It represents the response value for Fay Herriot model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>(matrix). It stands for the available auxiliary values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>

<p>(vector). Stands for the known sampling variances of each small area levels.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>The variance component estimation method to be used. See "Details".
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This bias-corrected jackknife MSPE estimator was proposed by J. Jiang and L. S. M. Wan, it covers a fairly general class of mixed models which includes gLMM, mixed logistic model and some of the widely used mixed linear models as special cases.
</p>
<p>Default value for <code>method</code> is 1, <code>method = 1</code> represents the MOM method , <code>method = 2</code> and <code>method = 3</code> represents ML and REML method, respectively.
</p>


<h3>Value</h3>

<p>This function returns a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>MSPE</code></td>
<td>
<p>(vector) MSPE estimates for Fay Herriot model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bhat</code></td>
<td>
<p>(vector) Estimates of the unknown regression coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ahat</code></td>
<td>
<p>(numeric) Estimates of the variance component.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Peiwen Xiao, Xiaohui Liu, Yuzi Liu, Jiming Jiang, and Shaochu Liu
</p>


<h3>References</h3>

<p>M. H. Quenouille. Approximate tests of correlation in time series. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 11(1):68-84, 1949.
</p>
<p>J. W. Tukey. Bias and confidence in not quite large samples. <em>Annals of Mathematical Statistics</em>, 29(2):614, 1958.
</p>
<p>J. Jiang and L. S. M. Wan. A unified jackknife theory for empirical best prediction with m estimation. <em>Annals of Statistics</em>, 30(6):1782-1810, 2002.
</p>


<h3>Examples</h3>

<pre><code class="language-R">X = matrix(runif(10 * 3), 10, 3)
X[,1] = rep(1, 10) 
D = (1:10) / 10 + 0.5
Y = X %*% c(0.5,1,1.5) + rnorm(10, 0, sqrt(2)) + rnorm(10, 0, sqrt(D))
mspeFHjack(Y, X, D, method = 1)
</code></pre>


</div>