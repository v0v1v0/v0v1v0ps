<div class="container">

<table style="width: 100%;"><tr>
<td>Fbwidths.by.x</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Computes the Frechet bounds of cells in a contingency table by considering all the possible subsets of the common variables.</h2>

<h3>Description</h3>

<p>This function permits to compute the bounds for cell probabilities in the contingency table Y vs. Z starting from the marginal tables (<b>X</b> vs. Y), (<b>X</b> vs. Z) and the joint distribution of the <b>X</b> variables, by considering all the possible subsets of the <b>X</b> variables.  In this manner it is possible to identify which subset of the <b>X</b> variables produces the major reduction of the average width of conditional bounds.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Fbwidths.by.x(tab.x, tab.xy, tab.xz, deal.sparse="discard", 
          nA=NULL, nB=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tab.x</code></td>
<td>

<p>A <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> table crossing the <b>X</b> variables.  This table must be obtained by using the function <code>xtabs</code> or <code>table</code>, e.g. <br><code>tab.x &lt;- xtabs(~x1+x2+x3, data=data.all)</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tab.xy</code></td>
<td>

<p>A <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> table of <b>X</b> vs. Y variable.  This table must be obtained by using the function <code>xtabs</code> or <code>table</code>, e.g. <br><code>table.xy &lt;- xtabs(~x1+x2+x3+y, data=data.A)</code>.
</p>
<p>A single categorical Y variables is allowed.  One or more categorical variables can be considered as <b>X</b> variables (common variables).  The same <b>X</b> variables in <code>tab.x</code> must be available in <code>tab.xy</code>.  Moreover, it is assumed that the joint distribution of the <b>X</b> variables computed from <code>tab.xy</code> is equal to <code>tab.x</code>; a warning is produced if this is not true.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tab.xz</code></td>
<td>

<p>A <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> table of <b>X</b> vs. Z variable.  This table must be obtained by using the function <code>xtabs</code> or <code>table</code>, e.g. <br><code>tab.xz &lt;- xtabs(~x1+x2+x3+z, data=data.B)</code>.
</p>
<p>A single categorical Z variable is allowed.  One or more categorical variables can be considered as <b>X</b> variables (common variables).  The same <b>X</b> variables in <code>tab.x</code> must be available in <code>tab.xz</code>.  Moreover, it is assumed that the joint distribution of the <b>X</b> variables computed from <code>tab.xz</code> is equal to <code>tab.x</code>; a warning is produced if this is not true.
</p>
</td>
</tr>
</table>
<table>
<tr style="vertical-align: top;">
<td><code>deal.sparse</code></td>
<td>

<p>Text, how to estimate the cell relative frequencies when dealing with too sparse tables. When <code>deal.sparse="discard"</code> (default) no estimation is performed if <code>tab.xy</code> or <code>tab.xz</code> is too sparse. When <code>deal.sparse="relfreq"</code> the standard estimator (cell count divided by the sample size) is considered. 
Note that here sparseness is measured by number of cells with respect to the sample size; sparse table are those where the number of cells exceeds  the sample size (see Details).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nA</code></td>
<td>

<p>Integer, sample size of file A used to estimate <code>tab.xy</code>. If  <code>NULL</code>, it is obtained as sum of frequencies in<code>tab.xy</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nB</code></td>
<td>

<p>Integer, sample size of file B used to estimate <code>tab.xz</code>. If  <code>NULL</code>, it is obtained as sum of frequencies in<code>tab.xz</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Additional arguments that may be required when deriving an estimate of uncertainty by calling <code>Frechet.bounds.cat</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function permits to compute the Frechet bounds for the frequencies in the contingency table of Y vs. Z, starting from the conditional distributions P(Y|<b>X</b>) and P(Z|<b>X</b>) (for details see <br><code>Frechet.bounds.cat</code>), by considering all the possible subsets of the <b>X</b> variables.  In this manner it is possible to identify the subset of the <b>X</b> variables, with highest association with both Y and Z, that permits to reduce the uncertainty concerning the distribution of Y vs. Z. 
</p>



<p>The uncertainty is measured by the average of the widths of the bounds for the cells in the table Y vs. Z:
</p>
<p style="text-align: center;"><code class="reqn"> \bar{d} = \frac{1}{J \times K} \sum_{j,k} ( p^{(up)}_{Y=j,Z=k} - p^{(low)}_{Y=j,Z=k} )</code>
</p>

<p>For details see <code>Frechet.bounds.cat</code>.
</p>
<p>Provided that uncertainty, measured in terms of <code class="reqn">\bar{d}</code>, tends to reduce when conditioning on a higher number of <b>X</b> variables. Two penalties are introduced to account for the additional number of cells to be estimated when adding a X variable. The first penalty, introduced in D'Orazio et al. (2017), is:
</p>
<p style="text-align: center;"><code class="reqn">g_1=log\left( 1 + \frac{H_{D_m}}{H_{D_Q}} \right) </code>
</p>

<p>Where <code class="reqn">H_{D_m}</code> is the number of cell in the table obtained by crossing the given subset of <b>X</b> variables and the <code class="reqn">H_{D_Q}</code> is the number of cell in the table achieved by crossing all the available <b>X</b> variables. 
A second penalty takes into account the number of cells to estimate with respect to the sample size (D'Orazio et al., 2019). It is obtained as:
</p>
<p style="text-align: center;"><code class="reqn">g_2 = max \left[ \frac{1}{n_A - H_{D_m} \times J}, \frac{1}{n_B - H_{D_m} \times K}  \right]</code>
</p>

<p>with <code class="reqn">n_A &gt; H_{D_m} \times J</code>  and  <code class="reqn">n_B &gt; H_{D_m} \times K</code>. In practice, it is considered the number of cells to estimate compared to the sample size. This criterion is considered to measure sparseness too. In particular, for the purposes of this function, tables are NOT considered sparse when: 
</p>
<p style="text-align: center;"><code class="reqn">min\left[ \frac{n_A}{H_{D_m} \times J}, \frac{n_B}{H_{D_m} \times K} \right] &gt; 1 </code>
</p>

<p>This rule is applied when deciding how to proceed with estimation in case of sparse table (argument <code>deal.sparse</code>). 
Note that sparseness can be measured in different manners. The outputs include also the empty cells in each table (due to statistical zeros or structural zeros) and the Cohen's effect size with respect to the case of uniform distribution of frequencies across cells (the value 1/no.of.cells in every cell):
</p>
<p style="text-align: center;"><code class="reqn">\omega_{eq} = \sqrt{H \sum_{h=1}^{H} (\hat{p}_h - 1/H)^2 } </code>
</p>

<p>values of <code class="reqn">\omega_{eq}</code> jointly with  <code class="reqn">n/H \leq 1</code> usually indicate severe sparseness. 
</p>


<h3>Value</h3>

<p>A list with the estimated bounds for the cells in the table of Y vs. Z for each possible subset of the <b>X</b> variables.  The final component in the list, <code>sum.unc</code>, is a data.frame that summarizes the main results. In particular, it reports the number of <b>X</b> variables (<code>"x.vars"</code>), the number of cells in each of the input tables and the cells with frequency equal to 0 (columns ending with <code>freq0</code> ). Moreover, it reported the value (<code>"av.n"</code>) of the rule used to decide whether we are dealing with a sparse case (see Details) and the Cohen's effect size measured for the table crossing the considered combination of the X variables. 
Finally, it is provided the average width of the uncertainty intervals (<code>"av.width"</code>), the penalty terms g1 and g2 (<code>"penalty1"</code> and <code>"penalty2"</code> respectively), and the penalized average widths (<code>"av.width.pen1"</code> and <code>"av.width.pen2"</code>, where av.width.pen1=av.width+pen1 and av.width.pen2=av.width+pen2).
</p>




<h3>Author(s)</h3>

<p>Marcello D'Orazio <a href="mailto:mdo.statmatch@gmail.com">mdo.statmatch@gmail.com</a> 
</p>


<h3>References</h3>


<p>D'Orazio, M., Di Zio, M. and Scanu, M. (2006). <em>Statistical Matching: Theory and Practice.</em> Wiley, Chichester.
</p>
<p>D'Orazio, M., Di Zio, M. and Scanu, M. (2017). “The use of uncertainty to choose matching variables in statistical matching”. <em>International Journal of Approximate Reasoning </em>, 90, pp. 433-440.
</p>
<p>D'Orazio, M., Di Zio, M. and Scanu, M. (2019). “Auxiliary variable selection in a a statistical matching problem”. In Zhang, L.-C. and Chambers, R. L. (eds.) <em>Analysis of Integrated Data</em>, Chapman &amp; Hall/CRC (Forthcoming).
</p>


<h3>See Also</h3>

 
<p><code>Frechet.bounds.cat</code>, <code>harmonize.x</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(quine, package="MASS") #loads quine from MASS
str(quine)
quine$c.Days &lt;- cut(quine$Days, c(-1, seq(0,50,10),100))
table(quine$c.Days)


# split quine in two subsets
suppressWarnings(RNGversion("3.5.0"))
set.seed(4567)
lab.A &lt;- sample(nrow(quine), 70, replace=TRUE)
quine.A &lt;- quine[lab.A, 1:4]
quine.B &lt;- quine[-lab.A, c(1:3,6)]

# compute the tables required by Fbwidths.by.x()
freq.xA &lt;- xtabs(~Eth+Sex+Age, data=quine.A)
freq.xB &lt;- xtabs(~Eth+Sex+Age, data=quine.B)

freq.xy &lt;- xtabs(~Eth+Sex+Age+Lrn, data=quine.A)
freq.xz &lt;- xtabs(~Eth+Sex+Age+c.Days, data=quine.B)

# apply Fbwidths.by.x()
bounds.yz &lt;- Fbwidths.by.x(tab.x=freq.xA+freq.xB, tab.xy=freq.xy,
        tab.xz=freq.xz)

bounds.yz$sum.unc


</code></pre>


</div>