<div class="container">

<table style="width: 100%;"><tr>
<td>reliability-deprecated</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Composite Reliability using SEM</h2>

<h3>Description</h3>

<p>Calculate composite reliability from estimated factor-model parameters
</p>


<h3>Usage</h3>

<pre><code class="language-R">reliability(object, what = c("alpha", "omega", "omega2", "omega3", "ave"),
            return.total = FALSE, dropSingle = TRUE, omit.factors = character(0),
            omit.indicators = character(0), omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A <code>lavaan</code> or
<code>lavaan.mi</code> object, expected to contain only
exogenous common factors (i.e., a CFA model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>what</code></td>
<td>
<p><code>character</code> vector naming any reliability indices to
calculate. All are returned by default. When indicators are ordinal,
both traditional <code>"alpha"</code> and Zumbo et al.'s (2007) so-called
"ordinal alpha" (<code>"alpha.ord"</code>) are returned, though the latter is
arguably of dubious value (Chalmers, 2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.total</code></td>
<td>
<p><code>logical</code> indicating whether to return a final
column containing the reliability of a composite of all indicators (not
listed in <code>omit.indicators</code>) of factors not listed in
<code>omit.factors</code>.  Ignored in 1-factor models, and should only be set
<code>TRUE</code> if all factors represent scale dimensions that could be
meaningfully collapsed to a single composite (scale sum or scale mean).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dropSingle</code></td>
<td>
<p><code>logical</code> indicating whether to exclude factors
defined by a single indicator from the returned results. If <code>TRUE</code>
(default), single indicators will still be included in the <code>total</code>
column when <code>return.total = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.factors</code></td>
<td>
<p><code>character</code> vector naming any common factors
modeled in <code>object</code> whose composite reliability is not of
interest. For example, higher-order or method factors. Note that
<code>reliabilityL2()</code> should be used to calculate composite
reliability of a higher-order factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.indicators</code></td>
<td>
<p><code>character</code> vector naming any observed variables
that should be ignored when calculating composite reliability. This can
be useful, for example, to estimate reliability when an indicator is
removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any "improper solutions" such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The coefficient alpha (Cronbach, 1951) can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \alpha = \frac{k}{k - 1}\left[ 1 - \frac{\sum^{k}_{i = 1}
\sigma_{ii}}{\sum^{k}_{i = 1} \sigma_{ii} + 2\sum_{i &lt; j} \sigma_{ij}}
\right],</code>
</p>

<p>where <code class="reqn">k</code> is the number of items in a factor, <code class="reqn">\sigma_{ii}</code> is the
item <em>i</em> observed variances, <code class="reqn">\sigma_{ij}</code> is the observed
covariance of items <em>i</em> and <em>j</em>.
</p>
<p>Several coefficients for factor-analysis reliability have been termed
"omega", which Cho (2021) argues is a misleading misnomer and argues for
using <code class="reqn">\rho</code> to represent them all, differentiated by descriptive
subscripts.  In our package, we number <code class="reqn">\omega</code> based on commonly
applied calculations.  Bentler (1968) first introduced factor-analysis
reliability for a unidimensional factor model with congeneric indicators.
However, assuming there are no cross-loadings in a multidimensional CFA,
this reliability coefficient can be calculated for each factor in the model.
</p>
<p style="text-align: center;"><code class="reqn"> \omega_1 =\frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right) + \sum^{k}_{i = 1} \theta_{ii} + 2\sum_{i &lt; j}
\theta_{ij} }, </code>
</p>

<p>where <code class="reqn">\lambda_i</code> is the factor loading of item <em>i</em>, <code class="reqn">\psi</code> is
the factor variance, <code class="reqn">\theta_{ii}</code> is the variance of measurement errors
of item <em>i</em>, and <code class="reqn">\theta_{ij}</code> is the covariance of measurement
errors from item <em>i</em> and <em>j</em>. McDonald (1999) later referred to
this <em>and other reliability coefficients</em> as "omega", which is a source
of confusion when reporting coefficients (Cho, 2021).
</p>
<p>The additional coefficients generalize the first formula by accounting for
multidimenisionality (possibly with cross-loadings) and correlated errors.
By setting <code>return.total=TRUE</code>, one can estimate reliability for a
single composite calculated using all indicators in the multidimensional
CFA (Bentler, 1972, 2009).  <code>"omega2"</code> is calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \omega_2 = \frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\hat{\Sigma}</code> is the model-implied covariance matrix, and
<code class="reqn">\bold{1}</code> is the <code class="reqn">k</code>-dimensional vector of 1. The first and the
second coefficients omega will have the same value per factor in models with
simple structure, but they differ when there are (e.g.) cross-loadings
or method factors. The first coefficient omega can be viewed as the
reliability controlling for the other factors (like <code class="reqn">\eta^2_{partial}</code> in
ANOVA). The second coefficient omega can be viewed as the unconditional
reliability (like <code class="reqn">\eta^2</code> in ANOVA).
</p>
<p>The <code>"omega3"</code> coefficient (McDonald, 1999), sometimes referred to as
hierarchical omega, can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \omega_3 =\frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \Sigma \bold{1}}, </code>
</p>

<p>where <code class="reqn">\Sigma</code> is the observed covariance matrix. If the model fits the
data well, <code class="reqn">\omega_3</code> will be similar to <code class="reqn">\omega_2</code>. Note that if
there is a directional effect in the model, all coefficients are calcualted
from total factor variances: <code>lavInspect(object, "cov.lv")</code>.
</p>
<p>In conclusion, <code class="reqn">\omega_1</code>, <code class="reqn">\omega_2</code>, and <code class="reqn">\omega_3</code> are
different in the denominator. The denominator of the first formula assumes
that a model is congeneric factor model where measurement errors are not
correlated. The second formula accounts for correlated measurement errors.
However, these two formulas assume that the model-implied covariance matrix
explains item relationships perfectly. The residuals are subject to sampling
error. The third formula use observed covariance matrix instead of
model-implied covariance matrix to calculate the observed total variance.
This formula is the most conservative method in calculating coefficient
omega.
</p>
<p>The average variance extracted (AVE) can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> AVE = \frac{\bold{1}^\prime
\textrm{diag}\left(\Lambda\Psi\Lambda^\prime\right)\bold{1}}{\bold{1}^\prime
\textrm{diag}\left(\hat{\Sigma}\right) \bold{1}}, </code>
</p>

<p>Note that this formula is modified from Fornell &amp; Larcker (1981) in the case
that factor variances are not 1. The proposed formula from Fornell &amp; Larcker
(1981) assumes that the factor variances are 1. Note that AVE will not be
provided for factors consisting of items with dual loadings. AVE is the
property of items but not the property of factors. AVE is calculated with
polychoric correlations when ordinal indicators are used.
</p>
<p>Coefficient alpha is by definition applied by treating indicators as numeric
(see Chalmers, 2018), which is consistent with the <code>alpha</code> function in
the <code>psych</code> package. When indicators are ordinal, <code>reliability</code>
additionally applies the standard alpha calculation to the polychoric
correlation matrix to return Zumbo et al.'s (2007) "ordinal alpha".
</p>
<p>Coefficient omega for categorical items is calculated using Green and Yang's
(2009, formula 21) approach. Three types of coefficient omega indicate
different methods to calculate item total variances. The original formula
from Green and Yang is equivalent to <code class="reqn">\omega_3</code> in this function.
Green and Yang did not propose a method for
calculating reliability with a mixture of categorical and continuous
indicators, and we are currently unaware of an appropriate method.
Therefore, when <code>reliability</code> detects both categorical and continuous
indicators of a factor, an error is returned. If the categorical indicators
load on a different factor(s) than continuous indicators, then reliability
will still be calculated separately for those factors, but
<code>return.total</code> must be <code>FALSE</code> (unless <code>omit.factors</code> is used
to isolate factors with indicators of the same type).
</p>


<h3>Value</h3>

<p>Reliability values (coefficient alpha, coefficients omega, average
variance extracted) of each factor in each group. If there are multiple
factors, a <code>total</code> column can optionally be included.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Bentler, P. M. (1972). A lower-bound method for the dimension-free
measurement of internal consistency. <em>Social Science Research, 1</em>(4),
343–357. <a href="https://doi.org/10.1016/0049-089X%2872%2990082-8">doi:10.1016/0049-089X(72)90082-8</a>
</p>
<p>Bentler, P. M. (2009). Alpha, dimension-free, and model-based internal
consistency reliability. <em>Psychometrika, 74</em>(1), 137–143.
<a href="https://doi.org/10.1007/s11336-008-9100-1">doi:10.1007/s11336-008-9100-1</a>
</p>
<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of
ordinal alpha. <em>Educational and Psychological Measurement, 78</em>(6),
1056–1071. <a href="https://doi.org/10.1177/0013164417727036">doi:10.1177/0013164417727036</a>
</p>
<p>Cho, E. (2021) Neither Cronbach’s alpha nor McDonald’s omega: A commentary
on Sijtsma and Pfadt. *Psychometrika, 86*(4), 877–886.
<a href="https://doi.org/10.1007/s11336-021-09801-1">doi:10.1007/s11336-021-09801-1</a>
</p>
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of
tests. <em>Psychometrika, 16</em>(3), 297–334. <a href="https://doi.org/10.1007/BF02310555">doi:10.1007/BF02310555</a>
</p>
<p>Fornell, C., &amp; Larcker, D. F. (1981). Evaluating structural equation models
with unobservable variables and measurement errors. <em>Journal of
Marketing Research, 18</em>(1), 39–50. <a href="https://doi.org/10.2307/3151312">doi:10.2307/3151312</a>
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using
structural equation modeling: An alternative to coefficient alpha.
<em>Psychometrika, 74</em>(1), 155–167. <a href="https://doi.org/10.1007/s11336-008-9099-3">doi:10.1007/s11336-008-9099-3</a>
</p>
<p>McDonald, R. P. (1999). <em>Test theory: A unified treatment</em>. Mahwah, NJ:
Erlbaum.
</p>
<p>Raykov, T. (2001). Estimation of congeneric scale reliability using
covariance structure analysis with nonlinear constraints <em>British
Journal of Mathematical and Statistical Psychology, 54</em>(2), 315–323.
<a href="https://doi.org/10.1348/000711001159582">doi:10.1348/000711001159582</a>
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of
coefficients alpha and theta for Likert rating scales.
<em>Journal of Modern Applied Statistical Methods, 6</em>(1), 21–29.
<a href="https://doi.org/10.22237/jmasm/1177992180">doi:10.22237/jmasm/1177992180</a>
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens’
scales of measurement do not help make it: A response to Chalmers.
<em>Educational and Psychological Measurement, 79</em>(6), 1184–1197.
<a href="https://doi.org/10.1177/0013164419844305">doi:10.1177/0013164419844305</a>
</p>


<h3>See Also</h3>

<p><code>semTools-deprecated</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(HolzingerSwineford1939)
HS9 &lt;- HolzingerSwineford1939[ , c("x7","x8","x9")]
HSbinary &lt;- as.data.frame( lapply(HS9, cut, 2, labels=FALSE) )
names(HSbinary) &lt;- c("y7","y8","y9")
HS &lt;- cbind(HolzingerSwineford1939, HSbinary)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ y7 + y8 + y9 '

fit &lt;- cfa(HS.model, data = HS, ordered = c("y7","y8","y9"), std.lv = TRUE)

## works for factors with exclusively continuous OR categorical indicators
reliability(fit)

## reliability for ALL indicators only available when they are
## all continuous or all categorical
reliability(fit, omit.factors = "speed", return.total = TRUE)


## loop over visual indicators to calculate alpha if one indicator is removed
for (i in paste0("x", 1:3)) {
  cat("Drop x", i, ":\n")
  print(reliability(fit, omit.factors = c("textual","speed"),
                    omit.indicators = i, what = "alpha"))
}


## works for multigroup models and for multilevel models (and both)
data(Demo.twolevel)
## assign clusters to arbitrary groups
Demo.twolevel$g &lt;- ifelse(Demo.twolevel$cluster %% 2L, "type1", "type2")
model2 &lt;- ' group: type1
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3

group: type2
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3
'
fit2 &lt;- sem(model2, data = Demo.twolevel, cluster = "cluster", group = "g")
reliability(fit2, what = c("alpha","omega3"))

</code></pre>


</div>