<div class="container">

<table style="width: 100%;"><tr>
<td>pairwise_comparison_one_group</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Do Pairwise Comparison for one Set of Forecasts</h2>

<h3>Description</h3>

<p>This function does the pairwise comparison for one set of forecasts, but
multiple models involved. It gets called from <code>pairwise_comparison()</code>.
<code>pairwise_comparison()</code> splits the data into arbitrary subgroups specified
by the user (e.g. if pairwise comparison should be done separately for
different forecast targets) and then the actual pairwise comparison for that
subgroup is managed from <code>pairwise_comparison_one_group()</code>. In order to
actually do the comparison between two models over a subset of common
forecasts it calls <code>compare_two_models()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pairwise_comparison_one_group(scores, metric, baseline, by, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>scores</code></td>
<td>
<p>A data.table of scores as produced by <code>score()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>A character vector of length one with the metric to do the
comparison on. The default is "auto", meaning that either "interval_score",
"crps", or "brier_score" will be selected where available.
See <code>available_metrics()</code> for available metrics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p>character vector of length one that denotes the baseline
model against which to compare other models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>by</code></td>
<td>
<p>character vector with names of columns present in the input
data.frame. <code>by</code> determines how pairwise comparisons will be computed.
You will get a relative skill score for every grouping level determined in
<code>by</code>. If, for example, <code>by = c("model", "location")</code>. Then you will get a
separate relative skill score for every model in every location. Internally,
the data.frame will be split according <code>by</code> (but removing "model" before
splitting) and the pairwise comparisons will be computed separately for the
split data.frames.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments for the comparison between two models. See
<code>compare_two_models()</code> for more information.</p>
</td>
</tr>
</table>
</div>