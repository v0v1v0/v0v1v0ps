<div class="container">

<table style="width: 100%;"><tr>
<td>ple_train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Patient-level Estimates: Train Model</h2>

<h3>Description</h3>

<p>Wrapper function to train a patient-level estimate (ple) model. Used directly in PRISM
and can be used to directly fit a ple model by name.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ple_train(
  Y,
  A,
  X,
  Xtest = NULL,
  family = "gaussian",
  propensity = FALSE,
  ple = "ranger",
  meta = ifelse(family == "survival", "T-learner", "X-learner"),
  hyper = NULL,
  tau = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>The outcome variable. Must be numeric or survival (ex; Surv(time,cens) )</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>Treatment variable. (Default supports binary treatment, either numeric or 
factor). "ple_train" accomodates &gt;2 along with binary treatments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Covariate space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtest</code></td>
<td>
<p>Test set. Default is NULL (no test predictions). Variable types should match X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Outcome type. Options include "gaussion" (default), "binomial", and "survival".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>propensity</code></td>
<td>
<p>Propensity score estimation, P(A=a|X). Default=FALSE which 
use the marginal estimates, P(A=a) (applicable for RCT data). If TRUE, will 
use the "ple" base learner to estimate P(A=a|X).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ple</code></td>
<td>
<p>Base-learner used to estimate patient-level equantities, such as the 
conditional average treatment effect (CATE), E(Y|A=1,X)-E(Y|A=0, X) = CATE(X). 
Default is random based based through "ranger". "None" uses no ple. See below for 
details on estimating the treatment contrasts.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>Using the ple model as a base learner, meta-learners can be used for 
estimating patient-level treatment differences. Options include "T-learner" (treatment
specific models), "S-learner" (single model), and "X-learner". For family="gaussian" &amp;
"binomial", the default is "X-learner", which uses a two-stage regression 
approach (See Kunzel et al 2019). For "survival", the default is "T-learner". "X-learner" 
is currently not supported for survival outcomes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyper</code></td>
<td>
<p>Hyper-parameters for the ple model (must be list). Default is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>Maximum follow-up time for RMST based estimates (family="survival"). 
Default=NULL, which takes min(max(time[a])), for a=1,..,A.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Any additional parameters, not currently passed through.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>ple_train uses base-learners along with a meta-learner to obtain patient-level 
estimates under different treatment exposures (see Kunzel et al).  For family="gaussian" 
or "binomial", output estimates of <code class="reqn">\mu(a,x)=E(Y|x,a)</code> and treatment differences 
(average treatment effect or risk difference). For survival, either logHR based estimates
or RMST based estimates can be obtained. Current base-learner ("ple") options include:
</p>
<p>1. <strong>linear</strong>: Uses either linear regression (family="gaussian"), 
logistic regression (family="binomial"), or cox regression (family="survival"). 
No hyper-parameters.
</p>
<p>2. <strong>ranger</strong>: Uses random forest ("ranger" R package). The default hyper-parameters are: 
hyper = list(mtry=NULL, min.node.pct=0.10)
</p>
<p>where mtry is number of randomly selected variables (default=NULL; sqrt(dim(X)))
and min.node.pct is the minimum node size as a function of the total data size 
(ex: min.node.pct=10% requires at least 10
</p>
<p>3. <strong>glmnet</strong>: Uses elastic net ("glmnet" R package). The default hyper-parameters are: 
hyper = list(lambda="lambda.min")
</p>
<p>where lambda controls the penalty parameter for predictions. lambda="lambda.1se"
will likely result in a less complex model. 
</p>
<p>4. <strong>bart</strong>:  Uses bayesian additive regression trees (Chipman et al 2010; 
BART R package). Default hyper-parameters are:
</p>
<p>hyper = list(sparse=FALSE)
</p>
<p>where sparse controls whether to perform variable selection based on a sparse 
Dirichlet prior rather than simply uniform.
</p>


<h3>Value</h3>

<p>Trained ple models and patient-level estimates for train/test sets. 
</p>

<ul>
<li>
<p> mod - trained model(s)
</p>
</li>
<li>
<p> mu_train - Patient-level estimates (training set)
</p>
</li>
<li>
<p> mu_test - Patient-level estimates (test set)
</p>
</li>
</ul>
<h3>References</h3>

<p>Wright, M. N. &amp; Ziegler, A. (2017). ranger: A fast implementation of 
random forests for high dimensional data in C++ and R. J Stat Softw 77:1-17. 
doi: <a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a>
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008) Regularization Paths for
Generalized Linear Models via Coordinate Descent,
<a href="https://web.stanford.edu/~hastie/Papers/glmnet.pdf">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a> Journal of Statistical 
Software, Vol. 33(1), 1-22 Feb 2010 Vol. 33(1), 1-22 Feb 2010.
</p>
<p>Chipman, H., George, E., and McCulloch R. (2010) Bayesian Additive 
Regression Trees. The Annals of Applied Statistics, 4,1, 266-298
</p>
<p>Kunzel S, Sekhon JS, Bickel PJ, Yu B. Meta-learners for Estimating
Hetergeneous Treatment Effects using Machine Learning. 2019.
</p>


<h3>See Also</h3>

<p><code>PRISM</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(StratifiedMedicine)
## Continuous ##
dat_ctns = generate_subgrp_data(family="gaussian")
Y = dat_ctns$Y
X = dat_ctns$X
A = dat_ctns$A


# X-Learner (With ranger based learners)
mod1 = ple_train(Y=Y, A=A, X=X, Xtest=X, ple="ranger", method="X-learner")
summary(mod1$mu_train)

# T-Learner (Treatment specific)
mod2 = ple_train(Y=Y, A=A, X=X, Xtest=X, ple="ranger", method="T-learner")
summary(mod2$mu_train)


mod3 = ple_train(Y=Y, A=A, X=X, Xtest=X, ple="bart", method="X-learner")
summary(mod3$mu_train)



</code></pre>


</div>