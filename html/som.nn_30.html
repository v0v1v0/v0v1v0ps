<div class="container">

<table style="width: 100%;"><tr>
<td>som.nn.multitrain</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multi-step hexagonal som training</h2>

<h3>Description</h3>

<p>A self-organising map with hexagonal tolology is trained
in several steps and
a model of Type SOMnn created for prediction of unknown samples.
In contrast to a "normal" som, class-labels for all samples of
the training set are required to build the topological model after SOM training.
</p>


<h3>Usage</h3>

<pre><code class="language-R">som.nn.multitrain(
  x,
  class.col = 1,
  kernel = "internal",
  xdim = 7,
  ydim = 5,
  toroidal = FALSE,
  len = c(0),
  alpha = c(0.2),
  radius = c(0),
  focus = 1,
  norm = TRUE,
  dist.fun = dist.fun.inverse,
  max.dist = 1.1,
  name = "som.nn job"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
One column is needed as class labels. The column with class
lables is selected by the argument <code>class.col</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class.col</code></td>
<td>
<p>single string or number. If class is a string, it is considered to be the
name of the column with class labels.
If class is a number, the respective column will be used as class labels
(after beeing coerced to character).
Default is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>kernel for som training. One of the predefined kernels
<code>"bubble"</code>: train with the R-implementation or
<code>"gaussian"</code>: train with the R-implementation of the Gaussian kernel or
<code>"SOM"</code>: train with <code>SOM</code> (<code>class::SOM</code>) or
<code>"kohonen"</code>: train with <code>som</code> (<code>kohonen::som</code>) or
<code>"som"</code>: train with <code>som</code> (<code>som::som</code>).
If a function is specified (as closure, not as character)
the specified custom function is used for training.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xdim</code></td>
<td>
<p>dimension in x-direction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ydim</code></td>
<td>
<p>dimension in y-direction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>toroidal</code></td>
<td>
<p><code>logical</code>; if TRUE an endless som is trained as on the
surface of a torus. default: FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>len</code></td>
<td>
<p><code>vector</code> of numberis of steps to be trained (steps - not epochs!).
the length of len defines the number of training rounds tobe performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>initial training rate; the learning rate is decreased linearly to 0.0 for the laset training step.
Default: 0.02.
If length(<code>alpha</code>) &gt; 1, the length must be tha same as for <code>len</code>
and defines different alphas for each training round.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>radius</code></td>
<td>
<p>inital radius for SOM training.
If Gaussian distance function is used, radius corresponds to sigma.
The distance is decreased linearly to 1.0 for the last training step.
If <code>radius = 0</code> (default), the diameter of the SOM is used as initial
radius.
If length(<code>radius</code>) &gt; 1, the length must be tha same as for <code>len</code>
and defines different radii for each training round.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>focus</code></td>
<td>
<p>Enhancement factor for focussing of training of "dirty" samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>norm</code></td>
<td>
<p>logical; if TRUE, input data is normalised by <code>scale(x, TRUE, TRUE)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist.fun</code></td>
<td>
<p>parameter for k-NN prediction: Function used to calculate
distance-dependent weights. Any distance function must accept the two parameters
<code>x</code> (distance) and <code>sigma</code> (maximum distance to give a weight &gt; 0.0).
Default is <code>dist.fun.inverse</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.dist</code></td>
<td>
<p>parameter for k-NN prediction: Parameter <code>sigma</code> for dist.fun.
Default is 2.1. In order to avoid rounding issues, it is recommended not to
use exact integers as limit, but values like 1.1 to make sure, that all
neurons within distance 1 are included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>optional name for the model. Name will be stored as slot <code>model@name</code> in the
trained model.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Besides of the predefined kernels
<code>"bubble", "gaussian", "SOM", "kohonen" or "som"</code>,
any specified custom kernel function can be used for som training. The function must match the
signature <code>kernel(data, grid, rlen, alpha, radius, init, toroidal)</code>, with
arguments:
</p>

<ul>
<li> <p><code>data:</code> <code>numeric</code> matrix of training data; one sample per row
</p>
</li>
<li> <p><code>classes:</code> optional <code>charater</code> vector of classes for training data
</p>
</li>
<li> <p><code>grid:</code> somgrid, generated with <code>somgrid</code>
</p>
</li>
<li> <p><code>rlen:</code> number of training steps
</p>
</li>
<li> <p><code>alpha:</code> training rate
</p>
</li>
<li> <p><code>radius:</code> training radius
</p>
</li>
<li> <p><code>init:</code> <code>numeric</code> matrix of initial codebook vectors; one code per row
</p>
</li>
<li> <p><code>toroidal:</code> <code>logical</code>; TRUE, if the topology of grid is toroidal
</p>
</li>
</ul>
<p>The returned value must be a list with at minimum one element
</p>

<ul><li> <p><code>codes:</code> <code>numeric</code> matrix of result codebook vectors; one code per row
</p>
</li></ul>
<p>If <code>focus &gt; 1</code> enhancement of dirty samples is activated:
Training samples, mapped to neuron with &gt;1 classes, are preferred in the next training step.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the trained model
</pre></div>


<h3>Examples</h3>

<pre><code class="language-R">## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>


</div>