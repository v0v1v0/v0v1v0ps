<div class="container">

<table style="width: 100%;"><tr>
<td>sbrl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
fit the scalable bayesian rule lists model
</h2>

<h3>Description</h3>

<p>Fit the scalable bayesian rule lists model with given data and parameters. It generates a model that is a probabilistic classifier that optimizes the posterior of a Bayesian hierarchical model over pre-mined association rules.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sbrl(tdata, iters=30000, pos_sign="1", 
 neg_sign="0", rule_minlen=1, rule_maxlen=1, 
 minsupport_pos=0.10, minsupport_neg=0.10, 
 lambda=10.0, eta=1.0, alpha=c(1,1), nchain=10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tdata</code></td>
<td>
<p>a dataframe, with a "label" column specifying the correct labels for each observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iters</code></td>
<td>
<p>the number of iterations for each MCMC chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_sign</code></td>
<td>
<p>the sign for the positive labels in the "label" column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neg_sign</code></td>
<td>
<p>the sign for the negative labels in the "label" column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rule_minlen</code></td>
<td>
<p>the minimum number of cardinality for rules to be mined from the dataframe.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rule_maxlen</code></td>
<td>
<p>the maximum number of cardinality for rules to be mined from the dataframe.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minsupport_pos</code></td>
<td>
<p>a number between 0 and 1, for the minimum percentage support for the positive observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minsupport_neg</code></td>
<td>
<p>a number between 0 and 1, for the minimum percentage support for the negative observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>a hyperparameter for the expected length of the rule list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eta</code></td>
<td>
<p>a hyperparameter for the expected cardinality of the rules in the optimal rule list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>a prior pseudo-count for the positive and negative classes. fixed at 1's</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nchain</code></td>
<td>
<p>an integer for the number of the chains that MCMC will be running.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Return a list of :
</p>
<table>
<tr style="vertical-align: top;">
<td><code>rs</code></td>
<td>
<p>a ruleset which contains the rule indices and their positive probabilities for the best rule list by training sbrl with the given data and parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rulenames</code></td>
<td>
<p>a list of all the rule names mined with <code>arules</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>featurenames</code></td>
<td>
<p>a list of all the feature names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mat_feature_rule</code></td>
<td>
<p>a binary matrix representing which features are included in which rules.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Hongyu Yang, Morris Chen, Cynthia Rudin, Margo Seltzer
</p>


<h3>References</h3>

<p>Hongyu Yang, Cynthia Rudin, Margo Seltzer (2017)
<em>Scalable Bayesian Rule Lists.</em>
Proceedings of the 34th International Conference on Machine Learning, PMLR 70:3921-3930, 2017.
</p>
<p>Benjamin Letham, Cynthia Rudin, Tyler McCormick and David Madigan (2015)
<em>Building Interpretable Classifiers with Rules using Bayesian Analysis.</em>
Annals of Applied Statistics, 2015.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Let us use the titactoe dataset
data(tictactoe)
for (name in names(tictactoe)) {tictactoe[name] &lt;- as.factor(tictactoe[,name])}

# Train on two-thirds of the data
b = round(2*nrow(tictactoe)/3, digit=0)
data_train &lt;- tictactoe[1:b, ]
# Test on the remaining one third of the data
data_test &lt;- tictactoe[(b+1):nrow(tictactoe), ]
# data_train, data_test are dataframes with factor columns
# The class column is "label"

# Run the sbrl algorithm on the training set
  sbrl_model &lt;- sbrl(data_train, iters=20000, pos_sign="1",
   neg_sign="0", rule_minlen=1, rule_maxlen=3, 
   minsupport_pos=0.10, minsupport_neg=0.10, 
   lambda=10.0, eta=1.0, nchain=25)
  print(sbrl_model)

# Make predictions on the test set
  yhat &lt;- predict(sbrl_model, data_test)
# yhat will be a list of predicted negative and positive probabilities for the test data. 

#clean up
rm(list = ls())
gc()
</code></pre>


</div>