<div class="container">

<table style="width: 100%;"><tr>
<td>nb_grpreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Group-regularized Negative Binomial Regression</h2>

<h3>Description</h3>

<p>This function implements group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. In negative binomial regression, we assume that <code class="reqn">y_i \sim NB(\alpha, \mu_i)</code>, where
</p>
<p style="text-align: center;"><code class="reqn">f(y_i | \alpha, \mu_i ) = \frac{\Gamma(y_i+\alpha)}{y_i! \Gamma(\alpha)} (\frac{\mu_i}{\mu_i+\alpha})^{y_i}(\frac{\alpha}{\mu_i +\alpha})^{\alpha}, y_i = 0, 1, 2, ...</code>
</p>

<p>Then <code class="reqn">E(y_i) = \mu_i</code>, and we relate <code class="reqn">\mu_i</code> to a set of <code class="reqn">p</code> covariates <code class="reqn">x_i</code> through the log link,
</p>
<p style="text-align: center;"><code class="reqn">\log(\mu_i) = \beta_0 + x_i^T \beta, i=1,..., n</code>
</p>

<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function can estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. Our implementation for regularized negative binomial regression is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than sample size.
</p>
<p>In addition, this function has the option of returning the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in the grid <code>lambda</code>. The GIC can be used for model selection and serves as a useful alternative to cross-validation. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">nb_grpreg(Y, X, groups, X_test, nb_size=1, penalty=c("gLASSO","gSCAD","gMCP"),
          group_weights, taper, n_lambda=100, lambda, 
          max_iter=10000, tol=1e-4, return_GIC=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly nonnegative integer responses for training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X_test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X_test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb_size=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement gamma regression with the SSGL penalty, use the <code>SSGL</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_GIC</code></td>
<td>
<p>Boolean variable for whether or not to return the GIC. Default is <code>return_GIC=TRUE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of "1" indicates that the group was classified as nonzero, and an entry of "0" indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y_pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X_test</code> (or training data <code>X</code> if no argument was specified for <code>X_test</code>). The <code class="reqn">k</code>th column in <code>Y_pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>GIC</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of GIC values. The <code class="reqn">k</code>th entry of <code>GIC</code> corresponds to the <code class="reqn">k</code>th entry in our <code>lambda</code> grid. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes <code>GIC</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). "Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors." <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). "Tuning parameter selection in high dimensional penalized likelihood." <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552.
</p>
<p>Wang, H. and Leng, C. (2007). "Unified LASSO estimation by least squares approximation." <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). "Model selection and estimation in regression with grouped variables." <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate data
set.seed(1234)
X = matrix(runif(100*15), nrow=100)
n = dim(X)[1]
groups = c("A","A","A","A","B","B","B","B","C","C","D","D","E","E","E")
groups = as.factor(groups)
beta_true = c(-1.5,1.5,-1.5,1.5,0,0,0,0,0,0,2,-2,0,0,0)

## Generate count responses from negative binomial regression
eta = crossprod(t(X), beta_true)
Y = rnbinom(n,size=1, mu=exp(eta))

## Generate test data
n_test = 50
X_test = matrix(runif(n_test*15), nrow=n_test)
  
## Fit negative binomial regression models with the group MCP penalty
nb_mod = nb_grpreg(Y, X, groups, X_test, penalty="gMCP")
  
## Tuning parameters used to fit models 
nb_mod$lambda
  
# Predicted n_test-dimensional vectors mu=E(Y_test) based on test data, X_test. 
# The kth column of 'Y_pred' corresponds to the kth entry in 'lambda.'
nb_mod$Y_pred
  
# Classifications of the 8 groups. The kth column of 'classifications'
# corresponds to the kth entry in lambda.
nb_mod$classifications

## Plot lambda vs. GIC
plot(nb_mod$lambda, nb_mod$GIC, type='l')

## Model selection with the lambda that minimizes GIC
nb_mod$lambda_min
nb_mod$min_index 
nb_mod$classifications[, nb_mod$min_index]
nb_mod$beta[, nb_mod$min_index]
</code></pre>


</div>