<div class="container">

<table style="width: 100%;"><tr>
<td>gom.em</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Discrete (Rasch) Grade of Membership Model
</h2>

<h3>Description</h3>

<p>This function estimates the grade of membership model (Erosheva, Fienberg
&amp; Joutard, 2007; also called mixed membership model) by the EM algorithm
assuming a discrete membership score distribution. The function is restricted
to dichotomous item responses.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gom.em(dat, K=NULL, problevels=NULL, weights=NULL, model="GOM", theta0.k=seq(-5,5,len=15),
    xsi0.k=exp(seq(-6, 3, len=15)), max.increment=0.3, numdiff.parm=1e-4,
    maxdevchange=1e-6, globconv=1e-4, maxiter=1000, msteps=4, mstepconv=0.001,
    theta_adjust=FALSE, lambda.inits=NULL, lambda.index=NULL, pi.k.inits=NULL,
    newton_raphson=TRUE, optimizer="nlminb", progress=TRUE)

## S3 method for class 'gom'
summary(object, file=NULL, ...)

## S3 method for class 'gom'
anova(object,...)

## S3 method for class 'gom'
logLik(object,...)

## S3 method for class 'gom'
IRT.irfprob(object,...)

## S3 method for class 'gom'
IRT.likelihood(object,...)

## S3 method for class 'gom'
IRT.posterior(object,...)

## S3 method for class 'gom'
IRT.modelfit(object,...)

## S3 method for class 'IRT.modelfit.gom'
summary(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>

<p>Data frame with dichotomous responses
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>

<p>Number of classes (only applies for <code>model="GOM"</code>)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>problevels</code></td>
<td>

<p>Vector containing probability levels for membership functions
(only applies for <code>model="GOM"</code>). If a specific space of probability
levels should be estimated, then a matrix can be supplied (see Example 1,
Model 2a).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Optional vector of sampling weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>The type of grade of membership model. The default <code>"GOM"</code>
is the nonparametric grade of membership model. A parametric multivariate normal
representation can be requested by <code>"GOMnormal"</code>.
The probabilities and membership
functions specifications described in Details are called via <code>"GOMRasch"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta0.k</code></td>
<td>

<p>Vector of <code class="reqn">\tilde{\theta}_k</code> grid (applies only for <code>model="GOMRasch"</code>)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xsi0.k</code></td>
<td>

<p>Vector of <code class="reqn">\xi_p</code> grid (applies only for <code>model="GOMRasch"</code>)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.increment</code></td>
<td>

<p>Maximum increment
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numdiff.parm</code></td>
<td>

<p>Numerical differentiation parameter
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxdevchange</code></td>
<td>

<p>Convergence criterion for change in relative deviance
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>globconv</code></td>
<td>

<p>Global convergence criterion for parameter change
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>

<p>Maximum number of iterations
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>msteps</code></td>
<td>

<p>Number of iterations within a M step
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mstepconv</code></td>
<td>

<p>Convergence criterion within a M step
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta_adjust</code></td>
<td>
<p>Logical indicating whether multivariate normal distribution
should be adaptively chosen during the EM algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.inits</code></td>
<td>
<p>Initial values for item parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.index</code></td>
<td>
<p>Optional integer matrix with integers indicating
equality constraints among <code class="reqn">\lambda</code> item parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi.k.inits</code></td>
<td>
<p>Initial values for distribution parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newton_raphson</code></td>
<td>
<p>Logical indicating whether Newton-Raphson should be
used for final iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimizer</code></td>
<td>
<p>Type of optimizer. Can be <code>"optim"</code> or <code>"nlminb"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>

<p>Display iteration progress? Default is <code>TRUE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>Object of class <code>gom</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>Optional file name for summary output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Further arguments to be passed
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The item response model of the grade of membership model
(Erosheva, Fienberg &amp; Junker, 2002;
Erosheva, Fienberg &amp; Joutard, 2007) with <code class="reqn">K</code> classes
for dichotomous correct responses <code class="reqn">X_{pi}</code>
of person <code class="reqn">p</code> on item <code class="reqn">i</code> is as follows (<code>model="GOM"</code>)
</p>
<p style="text-align: center;"><code class="reqn">
    P(X_{pi}=1 | g_{p1}, \ldots, g_{pK} )=\sum_k \lambda_{ik} g_{pk}
\quad, \quad \sum_{k=1}^K g_{pk}=1
\quad, \quad 0 \leq g_{pk} \leq 1
                </code>
</p>

<p>In most applications (e.g. Erosheva et al., 2007), the grade of
membership function <code class="reqn">\{g_{pk}\}</code> is assumed to follow a Dirichlet
distribution. In our <code>gom.em</code> implementation
the membership function is assumed to be discretely represented
by a grid <code class="reqn">u=(u_1, \ldots, u_L)</code> with entries between 0 and 1
(e.g. <code>seq(0,1,length=5)</code> with <code class="reqn">L=5</code>).
The values <code class="reqn">g_{pk}</code> of the membership function can then
only take values in <code class="reqn">\{ u_1, \ldots, u_L \}</code> with the restriction
<code class="reqn">\sum_k g_{pk} \sum_l \bold{1}(g_{pk}=u_l )=1</code>.
The grid <code class="reqn">u</code> is specified by using the argument <code>problevels</code>.
</p>
<p>The Rasch grade of membership model (<code>model="GOMRasch"</code>) poses constraints
on probabilities <code class="reqn">\lambda_{ik}</code> and membership functions <code class="reqn">g_{pk}</code>.
The membership
function of person <code class="reqn">p</code> is parameterized by a location parameter <code class="reqn">\theta_p</code>
and a variability parameter <code class="reqn">\xi_p</code>. Each class <code class="reqn">k</code> is represented by
a location parameter <code class="reqn">\tilde{\theta}_k</code>. The membership function is defined as
</p>
<p style="text-align: center;"><code class="reqn"> g_{pk} \propto
\exp \left[ - \frac{ (\theta_p - \tilde{\theta}_k)^2 }{2 \xi_p^2 } \right]
</code>
</p>

<p>The person parameter <code class="reqn">\theta_p</code> indicates the usual 'ability', while
<code class="reqn">\xi_p</code> describes the individual tendency to change between classes
<code class="reqn">1,\ldots,K</code> and their corresponding locations
<code class="reqn">\tilde{\theta}_1, \ldots,\tilde{\theta}_K</code>.
The extremal class probabilities <code class="reqn">\lambda_{ik}</code> follow the Rasch model
</p>
<p style="text-align: center;"><code class="reqn"> \lambda_{ik}=invlogit( \tilde{\theta}_k - b_i  )=
\frac{ \exp( \tilde{\theta}_k - b_i ) }{ 1 + \exp( \tilde{\theta}_k - b_i ) }</code>
</p>

<p>Putting these assumptions together leads to the model equation
</p>
<p style="text-align: center;"><code class="reqn">
    P(X_{pi}=1 | g_{p1}, \ldots, g_{pK} )=
    P(X_{pi}=1 | \theta_p, \xi_p  )=
        \sum_k \frac{ \exp( \tilde{\theta}_k - b_i ) }{ 1 + \exp(\tilde{\theta}_k - b_i ) }
        \cdot \exp \left[ - \frac{ (\theta_p - \tilde{\theta}_k)^2 }{2 \xi_p^2 } \right]
                </code>
</p>

<p>In the extreme case of a very small <code class="reqn">\xi_p=\varepsilon &gt; 0</code> and
<code class="reqn">\theta_p=\theta_0</code>, the Rasch model is obtained
</p>
<p style="text-align: center;"><code class="reqn">
    P(X_{pi}=1 | \theta_p, \xi_p  )=
    P(X_{pi}=1 | \theta_0, \varepsilon  )=
        \frac{ \exp( \theta_0 - b_i ) }{ 1 + \exp( \theta_0 - b_i ) }
                </code>
</p>

<p>See Erosheva et al. (2002), Erosheva (2005, 2006) or Galyart (2015)
for a comparison of grade of membership models with latent trait models
and latent class models.
</p>
<p>The grade of membership model is also published under the name
Bernoulli aspect model, see Bingham, Kaban and Fortelius (2009).
</p>


<h3>Value</h3>

<p>A list with following entries:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>deviance</code></td>
<td>
<p>Deviance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ic</code></td>
<td>
<p>Information criteria</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>item</code></td>
<td>
<p>Data frame with item parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>person</code></td>
<td>
<p>Data frame with person parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EAP.rel</code></td>
<td>
<p>EAP reliability (only applies for <code>model="GOMRasch"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MAP</code></td>
<td>
<p>Maximum aposteriori estimate of the membership function
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>EAP</code></td>
<td>
<p>EAP estimate for individual membership scores</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classdesc</code></td>
<td>
<p>Descriptives for class membership</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Estimated response probabilities <code class="reqn">\lambda_{ik}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se.lambda</code></td>
<td>
<p>Standard error for estimated response probabilities
<code class="reqn">\lambda_{ik}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>Mean of the distribution of <code class="reqn">(\theta_p, \xi_p)</code>
(only applies for <code>model="GOMRasch"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sigma</code></td>
<td>
<p>Covariance matrix of <code class="reqn">(\theta_p, \xi_p)</code>
(only applies for <code>model="GOMRasch"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>Estimated item difficulties (only applies for <code>model="GOMRasch"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se.b</code></td>
<td>
<p>Standard error of estimated difficulties
(only applies for <code>model="GOMRasch"</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f.yi.qk</code></td>
<td>
<p>Individual likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f.qk.yi</code></td>
<td>
<p>Individual posterior</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probs</code></td>
<td>
<p>Array with response probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.ik</code></td>
<td>
<p>Expected counts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>Number of iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>I</code></td>
<td>
<p>Number of items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Number of classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>TP</code></td>
<td>
<p>Number of discrete integration points for <code class="reqn">(g_{p1},...,g_{pK})</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta.k</code></td>
<td>
<p>Used grid of membership functions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further values</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Bingham, E., Kaban, A., &amp; Fortelius, M. (2009).
The aspect Bernoulli model: multiple causes of presences and absences.
<em>Pattern Analysis and Applications, 12</em>(1), 55-78.
</p>
<p>Erosheva, E. A. (2005). Comparing latent structures of the grade of membership,
Rasch, and latent class models. <em>Psychometrika, 70</em>, 619-628.
</p>
<p>Erosheva, E. A. (2006). <em>Latent class representation of the grade of membership
model</em>. Seattle: University of Washington.
</p>
<p>Erosheva, E. A., Fienberg, S. E., &amp; Junker, B. W. (2002).
Alternative statistical models and representations for large sparse
multi-dimensional contingency tables.
<em>Annales-Faculte Des Sciences Toulouse Mathematiques, 11</em>,
485-505.
</p>
<p>Erosheva, E. A., Fienberg, S. E., &amp; Joutard, C. (2007).
Describing disability through individual-level mixture models
for multivariate binary data. <em>Annals of Applied Statistics,
1</em>, 502-537.
</p>
<p>Galyardt, A. (2015).
Interpreting mixed membership models: Implications of Erosheva's representation
theorem. In E. M. Airoldi, D. Blei, E. A. Erosheva, &amp; S. E. Fienberg (Eds.).
<em>Handbook of Mixed Membership Models</em> (pp. 39-65). Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p>For joint maximum likelihood estimation of the grade of membership model
see <code>gom.jml</code>.
</p>
<p>See also the <span class="pkg">mixedMem</span> package for estimating mixed membership
models by a variational EM algorithm.
</p>
<p>The C code of Erosheva et al. (2007) can be downloaded from
<em>http://projecteuclid.org/euclid.aoas/1196438029#supplemental</em>.
</p>
<p>Code from Manrique-Vallier can be downloaded from
<em>http://pages.iu.edu/~dmanriqu/software.html</em>.
</p>
<p>See <em>http://users.ics.aalto.fi/ella/publications/aspect_bernoulli.m</em>
for a Matlab implementation of the algorithm in Bingham, Kaban and
Fortelius (2009).
</p>


<h3>Examples</h3>

<pre><code class="language-R">#############################################################################
# EXAMPLE 1: PISA data mathematics
#############################################################################

data(data.pisaMath)
dat &lt;- data.pisaMath$data
dat &lt;- dat[, grep("M", colnames(dat)) ]

#***
# Model 1: Discrete GOM with 3 classes and 5 probability levels
problevels &lt;- seq( 0, 1, len=5 )
mod1 &lt;- sirt::gom.em( dat, K=3, problevels, model="GOM")
summary(mod1)

## Not run: 
#-- some plots

#* multivariate scatterplot
car::scatterplotMatrix(mod1$EAP, regLine=FALSE, smooth=FALSE, pch=16, cex=.4)
#* ternary plot
vcd::ternaryplot(mod1$EAP, pch=16, col=1, cex=.3)

#***
# Model 1a: Multivariate normal distribution
problevels &lt;- seq( 0, 1, len=5 )
mod1a &lt;- sirt::gom.em( dat, K=3, theta0.k=seq(-15,15,len=21), model="GOMnormal" )
summary(mod1a)

#***
# Model 2: Discrete GOM with 4 classes and 5 probability levels
problevels &lt;- seq( 0, 1, len=5 )
mod2 &lt;- sirt::gom.em( dat, K=4, problevels,  model="GOM"  )
summary(mod2)

# model comparison
smod1 &lt;- IRT.modelfit(mod1)
smod2 &lt;- IRT.modelfit(mod2)
IRT.compareModels(smod1,smod2)

#***
# Model 2a: Estimate discrete GOM with 4 classes and restricted space of probability levels
#  the 2nd, 4th and 6th class correspond to "intermediate stages"
problevels &lt;- scan()
 1  0  0  0
.5 .5  0  0
 0  1  0  0
 0 .5 .5  0
 0  0  1  0
 0  0 .5 .5
 0  0  0  1

problevels &lt;- matrix( problevels, ncol=4, byrow=TRUE)
mod2a &lt;- sirt::gom.em( dat, K=4, problevels,  model="GOM" )
# probability distribution for latent classes
cbind( mod2a$theta.k, mod2a$pi.k )
  ##        [,1] [,2] [,3] [,4]       [,5]
  ##   [1,]  1.0  0.0  0.0  0.0 0.17214630
  ##   [2,]  0.5  0.5  0.0  0.0 0.04965676
  ##   [3,]  0.0  1.0  0.0  0.0 0.09336660
  ##   [4,]  0.0  0.5  0.5  0.0 0.06555719
  ##   [5,]  0.0  0.0  1.0  0.0 0.27523678
  ##   [6,]  0.0  0.0  0.5  0.5 0.08458620
  ##   [7,]  0.0  0.0  0.0  1.0 0.25945016

## End(Not run)

#***
# Model 3: Rasch GOM
mod3 &lt;- sirt::gom.em( dat, model="GOMRasch", maxiter=20 )
summary(mod3)

#***
# Model 4: 'Ordinary' Rasch model
mod4 &lt;- sirt::rasch.mml2( dat )
summary(mod4)

## Not run: 
#############################################################################
# EXAMPLE 2: Grade of membership model with 2 classes
#############################################################################

#********* DATASET 1 *************
# define an ordinary 2 latent class model
set.seed(8765)
I &lt;- 10
prob.class1 &lt;- stats::runif( I, 0, .35 )
prob.class2 &lt;- stats::runif( I, .70, .95 )
probs &lt;- cbind( prob.class1, prob.class2 )

# define classes
N &lt;- 1000
latent.class &lt;- c( rep( 1, 1/4*N ), rep( 2,3/4*N ) )

# simulate item responses
dat &lt;- matrix( NA, nrow=N, ncol=I )
for (ii in 1:I){
    dat[,ii] &lt;- probs[ ii, latent.class ]
    dat[,ii] &lt;- 1 * ( stats::runif(N) &lt; dat[,ii] )
}
colnames(dat) &lt;- paste0( "I", 1:I)

# Model 1: estimate latent class model
mod1 &lt;- sirt::gom.em(dat, K=2, problevels=c(0,1), model="GOM" )
summary(mod1)
# Model 2: estimate GOM
mod2 &lt;- sirt::gom.em(dat, K=2, problevels=seq(0,1,0.5), model="GOM" )
summary(mod2)
# estimated distribution
cbind( mod2$theta.k, mod2$pi.k )
  ##       [,1] [,2]        [,3]
  ##  [1,]  1.0  0.0 0.243925644
  ##  [2,]  0.5  0.5 0.006534278
  ##  [3,]  0.0  1.0 0.749540078

#********* DATASET 2 *************
# define a 2-class model with graded membership
set.seed(8765)
I &lt;- 10
prob.class1 &lt;- stats::runif( I, 0, .35 )
prob.class2 &lt;- stats::runif( I, .70, .95 )
prob.class3 &lt;- .5*prob.class1+.5*prob.class2  # probabilities for 'fuzzy class'
probs &lt;- cbind( prob.class1, prob.class2, prob.class3)
# define classes
N &lt;- 1000
latent.class &lt;- c( rep(1,round(1/3*N)),rep(2,round(1/2*N)),rep(3,round(1/6*N)))
# simulate item responses
dat &lt;- matrix( NA, nrow=N, ncol=I )
for (ii in 1:I){
    dat[,ii] &lt;- probs[ ii, latent.class ]
    dat[,ii] &lt;- 1 * ( stats::runif(N) &lt; dat[,ii] )
        }
colnames(dat) &lt;- paste0( "I", 1:I)

#** Model 1: estimate latent class model
mod1 &lt;- sirt::gom.em(dat, K=2, problevels=c(0,1), model="GOM" )
summary(mod1)

#** Model 2: estimate GOM
mod2 &lt;- sirt::gom.em(dat, K=2, problevels=seq(0,1,0.5), model="GOM" )
summary(mod2)
# inspect distribution
cbind( mod2$theta.k, mod2$pi.k )
  ##       [,1] [,2]      [,3]
  ##  [1,]  1.0  0.0 0.3335666
  ##  [2,]  0.5  0.5 0.1810114
  ##  [3,]  0.0  1.0 0.4854220

#***
# Model2m: estimate discrete GOM in mirt
# define latent classes
Theta &lt;- scan( nlines=1)
   1 0   .5 .5    0 1
Theta &lt;- matrix( Theta, nrow=3, ncol=2,byrow=TRUE)
# define mirt model
I &lt;- ncol(dat)
#*** create customized item response function for mirt model
name &lt;- 'gom'
par &lt;- c("a1"=-1, "a2"=1 )
est &lt;- c(TRUE, TRUE)
P.gom &lt;- function(par,Theta,ncat){
    # GOM for two extremal classes
    pext1 &lt;- stats::plogis(par[1])
    pext2 &lt;- stats::plogis(par[2])
    P1 &lt;- Theta[,1]*pext1 + Theta[,2]*pext2
    cbind(1-P1, P1)
}
# create item response function
icc_gom &lt;- mirt::createItem(name, par=par, est=est, P=P.gom)
#** define prior for latent class analysis
lca_prior &lt;- function(Theta,Etable){
  # number of latent Theta classes
  TP &lt;- nrow(Theta)
  # prior in initial iteration
  if ( is.null(Etable) ){ prior &lt;- rep( 1/TP, TP ) }
  # process Etable (this is correct for datasets without missing data)
  if ( ! is.null(Etable) ){
    # sum over correct and incorrect expected responses
    prior &lt;- ( rowSums(Etable[, seq(1,2*I,2)]) + rowSums(Etable[,seq(2,2*I,2)]) )/I
                 }
  prior &lt;- prior / sum(prior)
  return(prior)
}
#*** estimate discrete GOM in mirt package
mod2m &lt;- mirt::mirt(dat, 1, rep( "icc_gom",I), customItems=list("icc_gom"=icc_gom),
           technical=list( customTheta=Theta, customPriorFun=lca_prior)  )
# correct number of estimated parameters
mod2m@nest &lt;- as.integer(sum(mod.pars$est) + nrow(Theta)-1 )
# extract log-likelihood and compute AIC and BIC
mod2m@logLik
( AIC &lt;- -2*mod2m@logLik+2*mod2m@nest )
( BIC &lt;- -2*mod2m@logLik+log(mod2m@Data$N)*mod2m@nest )
# extract coefficients
( cmod2m &lt;- sirt::mirt.wrapper.coef(mod2m) )
# compare estimated distributions
round( cbind( "sirt"=mod2$pi.k, "mirt"=mod2m@Prior[[1]] ), 5 )
  ##           sirt    mirt
  ##   [1,] 0.33357 0.33627
  ##   [2,] 0.18101 0.17789
  ##   [3,] 0.48542 0.48584
# compare estimated item parameters
dfr &lt;- data.frame( "sirt"=mod2$item[,4:5] )
dfr$mirt &lt;- apply(cmod2m$coef[, c("a1", "a2") ], 2, stats::plogis )
round(dfr,4)
  ##      sirt.lam.Cl1 sirt.lam.Cl2 mirt.a1 mirt.a2
  ##   1        0.1157       0.8935  0.1177  0.8934
  ##   2        0.0790       0.8360  0.0804  0.8360
  ##   3        0.0743       0.8165  0.0760  0.8164
  ##   4        0.0398       0.8093  0.0414  0.8094
  ##   5        0.1273       0.7244  0.1289  0.7243
  ##   [...]

#############################################################################
# EXAMPLE 3: Lung cancer dataset; using sampling weights
#############################################################################

data(data.si08, package="sirt")
dat &lt;- data.si08

#- Latent class model with 3 classes
problevels &lt;- c(0,1)
mod1 &lt;- sirt::gom.em( dat[,1:5], weights=dat$wgt, K=3, problevels=problevels )
summary(mod1)

#- Grade of membership model with discrete distribution
problevels &lt;- seq(0,1,length=5)
mod2 &lt;- sirt::gom.em( dat[,1:5], weights=dat$wgt, K=3, problevels=problevels )
summary(mod2)

#- Grade of membership model with multivariate normal distribution
mod3 &lt;- sirt::gom.em( dat[,1:5], weights=dat$wgt, K=3, theta0.k=10*seq(-1,1,len=11),
            model="GOMnormal", optimizer="nlminb" )
summary(mod3)

## End(Not run)
</code></pre>


</div>