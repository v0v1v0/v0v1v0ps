<div class="container">

<table style="width: 100%;"><tr>
<td>criterion</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Criterion for a Loss/Merit Function for Data Given a Permutation</h2>

<h3>Description</h3>

<p>Compute the value for different loss functions <code class="reqn">L</code> and merit function
<code class="reqn">M</code> for data given a permutation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)

## S3 method for class 'array'
criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)

## S3 method for class 'dist'
criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)

## S3 method for class 'matrix'
criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)

## S3 method for class 'data.frame'
criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)

## S3 method for class 'table'
criterion(x, order = NULL, method = NULL, force_loss = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object of class dist or a matrix (currently no functions
are implemented for array).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>
<p>an object of class ser_permutation suitable for
<code>x</code>.  If <code>NULL</code>, the identity permutation is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character vector with the names of the criteria to be
employed (see <code>list_criterion_methods()</code>), or <code>NULL</code> (default) in which case all available criteria are
used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>force_loss</code></td>
<td>
<p>logical; should merit function be converted into loss
functions by multiplying with -1?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional parameters passed on to the criterion method.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><strong>Criteria for distance matrices (dist)</strong>
</p>
<p>For a symmetric dissimilarity matrix <code class="reqn">D</code> with elements <code class="reqn">d(i,j)</code>
where <code class="reqn">i, j = 1 \ldots n</code>, the aim is generally to place low distance
values close to the diagonal. The following criteria to judge the quality of
a certain permutation of the objects in a dissimilarity matrix are currently
implemented (for a more detailed description and an experimental comparison
see Hahsler (2017)):
</p>

<ul>
<li> <p><strong>Gradient measures:</strong> <code>"Gradient_raw"</code>, <code>"Gradient_weighted"</code> (Hubert et al, 2001)
</p>
<p>A symmetric dissimilarity matrix where the values in
all rows and columns only increase when moving away from the main diagonal
is called a perfect <em>anti-Robinson matrix</em> (Robinson 1951). A suitable
merit measure which quantifies the divergence of a matrix from the
anti-Robinson form is
</p>
<p style="text-align: center;"><code class="reqn"> M(D) = \sum_{i=1}^n \sum_{i&lt;k&lt;j} f(d_{ij}, d_{ik}) + \sum_{i&lt;k&lt;j}
    f(d_{ij}, d_{kj})</code>
</p>
<p> where <code class="reqn">f(.,.)</code> is a function which defines how a
violation or satisfaction of a gradient condition for an object triple
(<code class="reqn">O_i, O_k, O_j</code>) is counted.
</p>
<p>Hubert et al (2001) suggest two functions. The first function is given by:
</p>
<p style="text-align: center;"><code class="reqn">f(z,y) = sign(y-z) = +1 \ \text{if}\ z &lt; y;\ 0\ \text{if}\ z = y; \ \text{and}\ -1 \ \text{if}\ z &gt; y.</code>
</p>

<p>It results in raw number of triples satisfying the gradient constraints
minus triples which violate the constraints.
</p>
<p>The second function is defined as: </p>
<p style="text-align: center;"><code class="reqn">f(z,y) = |y-z| sign(y-z) = y-z</code>
</p>
<p> It
weights the each satisfaction or violation by the difference by its
magnitude given by the absolute difference between the values.
</p>
</li>
<li> <p><strong>Anti-Robinson events:</strong> <code>"AR_events"</code>, <code>"AR_deviations"</code> (Chen, 2002)
</p>
<p><code>"AR_events"</code> counts the number of violations of the anti-Robinson form.
</p>
<p style="text-align: center;"><code class="reqn"> L(D) = \sum_{i=1}^n \sum_{i&lt;k&lt;j} f(d_{ik}, d_{ij}) + \sum_{i&lt;k&lt;j} f(d_{kj}, d_{ij})</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn"> f(z, y) = I(z, y) = 1 \ \text{if}\  z &lt; y\ \text{and}\ 0 \ \text{otherwise,}</code>
</p>

<p>where <code class="reqn">I(.)</code> is an indicator function returning 1 only for violations.
Chen (2002) presented a formulation for an equivalent loss function and
called the violations <em>anti-Robinson events.</em>
</p>
<p><code>"AR_deviations"</code>: Chen (2002) also introduced a
weighted versions of the loss function by using
</p>
<p style="text-align: center;"><code class="reqn"> f(z, y) = |y-z|I(z, y) </code>
</p>
<p> which weights each violation by
the deviation.
</p>
</li>
<li> <p><strong>Relative generalized Anti-Robinson events:</strong> <code>"RGAR"</code>  (Tien et al, 2008)
</p>
<p>Counts Anti-Robinson events in a variable band (window specified
by <code>w</code> defaults to the maximum of <code class="reqn">n-1</code>) around the main diagonal
and normalizes by the maximum of possible events.
</p>
<p style="text-align: center;"><code class="reqn"> L(D) = 1/m \sum_{i=1}^n \sum_{(i-w)\le j&lt;k&lt;i} I(d_{ij} &lt; d_{ik}) +
    \sum_{i&lt;j&lt;k\le(i+w))} I(d_{ij} &gt; d_{ik}) </code>
</p>

<p>where <code class="reqn">m=(2/3-n)w + nw^2 - 2/3 w^3</code>, the maximal number of possible
anti-Robinson events in the window.  The window size <code class="reqn">w</code> represents the
number of neighboring objects (number of entries from the diagonal of the
distance matrix) are considered. The window size is <code class="reqn">2 \le w &lt; n</code>, where
smaller values result in focusing on the local structure while larger values
look at the global structure.
</p>
<p><code>...</code> parameters are:
</p>

<ul>
<li> <p><code>w</code> window size. Default is to use a <code>pct</code> of 100% of <code class="reqn">n</code>.
</p>
</li>
<li> <p><code>pct</code> and alternative specification of w as a percentage of <code class="reqn">n</code> in <code class="reqn">(0, 100]</code>.
</p>
</li>
<li> <p><code>relative</code> logical; can be set to <code>FALSE</code> to get the GAR, i.e., the absolute number of AR
events in the window.
</p>
</li>
</ul>
</li>
<li> <p><strong>Banded anti-Robinson form criterion:</strong> <code>"BAR"</code>  (Earle and Hurley, 2015)
</p>
<p>Simplified measure for closeness to the anti-Robinson form in a band of size
<code class="reqn">b</code> with <code class="reqn">1 &lt;= b &lt; n</code> around the diagonal.
</p>
<p style="text-align: center;"><code class="reqn"> L(D) = \sum_{|i-j|&lt;=b} (b+1-|i-j|) d_{ij} </code>
</p>

<p>For <code class="reqn">b = 1</code> the measure reduces to the Hamiltonian path length.  For
<code class="reqn">b = n-1</code> the measure is equivalent to ARc defined (Earle and Hurley,
2015). Note that ARc is equivalent to the Linear Seriation criterion (scaled
by 1/2).
</p>
<p><code>...</code> parameter is: <code>b</code> band size defaults to a band of 20% of <code class="reqn">n</code>.
</p>
</li>
<li> <p><strong>Hamiltonian path length:</strong> <code>"Path_length"</code>  (Caraux and Pinloche, 2005)
</p>
<p>The order of the objects in a dissimilarity matrix corresponds to a path
through a graph where each node represents an object and is visited exactly
once, i.e., a Hamilton path. The length of the path is defined as the sum of
the edge weights, i.e., dissimilarities.
</p>
<p style="text-align: center;"><code class="reqn">L(D) = \sum_{i=1}^{n-1} d_{i,i+1}</code>
</p>

<p>The length of the Hamiltonian path is equal to the value of the minimal span
loss function (as used by Chen 2002).  Both notions are related to the
<em>traveling salesperson problem (TSP).</em>
</p>
<p>If <code>order</code> is not unique or there are non-finite distance values
<code>NA</code> is returned.
</p>
</li>
<li> <p><strong>Lazy path length:</strong> <code>"Lazy_path_length"</code> (Earl and Hurley, 2015)
</p>
<p>A weighted version of the Hamiltonian path criterion. This loss function
postpones larger distances to later in the order (i.e., a lazy traveling
sales person).
</p>
<p style="text-align: center;"><code class="reqn">L(D) = \sum_{i=1}^{n-1} (n-i) d_{i,i+1}</code>
</p>

<p>Earl and Hurley (2015) proposed this criterion for reordering in
visualizations to concentrate on closer objects first.
</p>
</li>
<li> <p><strong>Inertia criterion:</strong> <code>"Inertia"</code>  (Caraux and Pinloche, 2005)
</p>
<p>Measures the moment of the inertia of dissimilarity values around the
diagonal as
</p>
<p style="text-align: center;"><code class="reqn">M(D) = \sum_{i=1}^n \sum_{j=1}^n d(i,j)|i-j|^2</code>
</p>

<p><code class="reqn">|i-j|</code> is used as a measure for the distance to the diagonal and
<code class="reqn">d(i,j)</code> gives the weight. This criterion gives higher weight to values
farther away from the diagonal. It increases with quality.
</p>
</li>
<li> <p><strong>Least squares criterion:</strong> <code>"Least_squares"</code> (Caraux and Pinloche, 2005)
</p>
<p>The sum of squared differences between distances and the rank differences:
</p>
<p style="text-align: center;"><code class="reqn">L(D) = \sum_{i=1}^n
  \sum_{j=1}^n (d(i,j) - |i-j|)^2,</code>
</p>
<p> where <code class="reqn">d(i,j)</code> is an element of the
dissimilarity matrix <code class="reqn">D</code> and <code class="reqn">|i-j|</code> is the rank difference between
the objects.
</p>
<p>Note that if Euclidean distance is used to calculate <code class="reqn">D</code> from a data
matrix <code class="reqn">X</code>, the order of the elements in <code class="reqn">X</code> by projecting them on
the first principal component of <code class="reqn">X</code> minimizes this criterion.  The
least squares criterion is related to <em>unidimensional scaling.</em>
</p>
</li>
<li> <p><strong>Linear Seriation Criterion:</strong> <code>"LS"</code>  (Hubert and Schultz, 1976)
</p>
<p>Weights the distances with the absolute rank differences.
</p>
<p style="text-align: center;"><code class="reqn">L(D) \sum_{i,j=1}^n d(i,j) (-|i-j|)</code>
</p>

</li>
<li> <p><strong>2-Sum Criterion:</strong> <code>"2SUM"</code>  (Barnard, Pothen and Simon, 1993)
</p>
<p>The 2-Sum loss criterion multiplies the similarity between objects with the
squared rank differences.
</p>
<p style="text-align: center;"><code class="reqn">L(D) \sum_{i,j=1}^n 1/(1+d(i,j)) (i-j)^2,</code>
</p>

<p>where <code class="reqn">s(i,j) = 1/(1+d(i,j))</code> represents the similarity between objects
<code class="reqn">i</code> and <code class="reqn">j</code>.
</p>
</li>
<li> <p><strong>Absolute Spearman Correlation</strong> <code>"Rho"</code>
</p>
<p>The absolute value of the Spearman rank correlation
between the original distances and the rank differences in the order.
</p>
</li>
<li> <p><strong>Matrix measures:</strong> <code>"ME"</code>, <code>"Moore_stress"</code>, <code>"Neumann_stress"</code>
</p>
<p>These criteria are defined on general matrices (see
below for definitions).  The dissimilarity matrix is first converted into a
similarity matrix using <code class="reqn">S = 1/(1+D)</code>. If a different transformation is
required, then perform the transformation first and supply a matrix instead
of a dist object.
</p>
</li>
</ul>
<p><strong>Criteria for matrices (matrix)</strong>
</p>
<p>For a general matrix <code class="reqn">X = x_{ij}</code>, <code class="reqn">i = 1 \ldots n</code> and
<code class="reqn">j = 1 \ldots m</code>, currently the following loss/merit functions are implemented:
</p>

<ul>
<li> <p><strong>Measure of Effectiveness:</strong> <code>"ME"</code>  (McCormick, 1972).
</p>
<p>The measure of effectiveness (ME) for matrix <code class="reqn">X</code>, is defined as
</p>
<p style="text-align: center;"><code class="reqn">M(X) = 1/2 \sum_{i=1}^{n} \sum_{j=1}^{m}
    x_{i,j}(x_{i,j-1}+x_{i,j+1}+x_{i-1,j}+x_{i+1,j})</code>
</p>

<p>with, by convention
</p>
<p style="text-align: center;"><code class="reqn">x_{0,j}=x_{m+1,j}=x_{i,0}=x_{i,n+1}=0.</code>
</p>

<p>ME is a merit measure, i.e. a higher ME indicates a better arrangement.
Maximizing ME is the objective of the bond energy algorithm (BEA). ME is not
defined for matrices with negative values. <code>NA</code> is returned in this
case.
</p>
</li>
<li> <p><strong>Weighted correlation coefficient:</strong> <code>"Cor_R"</code>  (Deutsch and Martin, 1971)
</p>
<p>Developed as the Measure of Effectiveness for the Moment
Ordering Algorithm.
R is a merit measure normalized so that its value always lies in
<code class="reqn">[-1,1]</code>.  For the special case of a square matrix <code class="reqn">R=1</code> corresponds
to only the main diagonal being filled, <code class="reqn">R=0</code> to a random distribution
of value throughout the array, and <code class="reqn">R=-1</code> to the opposite diagonal only
being filled.
</p>
</li>
<li> <p><strong>Matrix Stress:</strong> <code>"Moore_stress"</code>, <code>"Neumann_stress"</code>  (Niermann, 2005)
</p>
<p>Stress measures the conciseness of the presentation of a matrix/table and
can be seen as a purity function which compares the values in a matrix/table
with its neighbors. The stress measure used here is computed as the sum of
squared distances of each matrix entry from its adjacent entries.
</p>
<p style="text-align: center;"><code class="reqn"> L(X) = \sum_{i=1}^n \sum_{j=1}^m \sigma_{ij} </code>
</p>

<p>The following types of neighborhoods are available:
</p>

<ul>
<li>
<p> Moore: comprises the eight adjacent entries.
</p>
<p style="text-align: center;"><code class="reqn">
     \sigma_{ij} = \sum_{k=\max(1,i-1)}^{\min(n,i+1)}
     \sum_{l=\max(1,j-1)}^{\min(m,j+1)} (x_{ij} - x_{kl})^2 </code>
</p>

</li>
<li>
<p> Neumann: comprises the four adjacent entries.  </p>
<p style="text-align: center;"><code class="reqn"> \sigma_{ij} =
     \sum_{k=\max(1,i-1)}^{\min(n,i+1)} (x_{ij} - x_{kj})^2 +
     \sum_{l=\max(1,j-1)}^{\min(m,j+1)} (x_{ij} - x_{il})^2 </code>
</p>

</li>
</ul>
<p>The major difference between the Moore and the Neumann neighborhood is that
for the later the contribution of row and column permutations to stress are
independent and thus can be optimized independently.
</p>
</li>
</ul>
<h3>Value</h3>

<p>A named vector of real values.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>References</h3>

<p>Barnard, S.T., A. Pothen, and H. D. Simon (1993): A Spectral
Algorithm for Envelope Reduction of Sparse Matrices. <em>In Proceedings of
the 1993 ACM/IEEE Conference on Supercomputing,</em> 493–502. Supercomputing
'93. New York, NY, USA: ACM.
</p>
<p>Caraux, G. and S. Pinloche (2005): Permutmatrix: A Graphical Environment to
Arrange Gene Expression Profiles in Optimal Linear Order,
<em>Bioinformatics,</em> <strong>21</strong>(7), 1280–1281.
</p>
<p>Chen, C.-H. (2002): Generalized association plots: Information visualization
via iteratively generated correlation matrices, <em>Statistica Sinica,</em>
<strong>12</strong>(1), 7–29.
</p>
<p>Deutsch, S.B. and J.J. Martin (1971): An ordering algorithm for analysis of
data arrays. <em>Operational Research,</em> <strong>19</strong>(6), 1350–1362.
<a href="https://doi.org/10.1287/opre.19.6.1350">doi:10.1287/opre.19.6.1350</a>
</p>
<p>Earle, D. and C.B. Hurley (2015): Advances in Dendrogram Seriation for
Application to Visualization. <em>Journal of Computational and Graphical
Statistics,</em> <strong>24</strong>(1), 1–25.
<a href="https://doi.org/10.1080/10618600.2013.874295">doi:10.1080/10618600.2013.874295</a>
</p>
<p>Hahsler, M. (2017): An experimental comparison of seriation methods for
one-mode two-way data. <em>European Journal of Operational Research,</em>
<strong>257</strong>, 133–143.
<a href="https://doi.org/10.1016/j.ejor.2016.08.066">doi:10.1016/j.ejor.2016.08.066</a>
</p>
<p>Hubert, L. and J. Schultz (1976): Quadratic Assignment as a General Data
Analysis Strategy. <em>British Journal of Mathematical and Statistical
Psychology,</em> <strong>29</strong>(2). Blackwell Publishing Ltd. 190–241.
<a href="https://doi.org/10.1111/j.2044-8317.1976.tb00714.x">doi:10.1111/j.2044-8317.1976.tb00714.x</a>
</p>
<p>Hubert, L., P. Arabie, and J. Meulman (2001): <em>Combinatorial Data
Analysis: Optimization by Dynamic Programming.</em> Society for Industrial
Mathematics.
<a href="https://doi.org/10.1137/1.9780898718553">doi:10.1137/1.9780898718553</a>
</p>
<p>Niermann, S. (2005): Optimizing the Ordering of Tables With Evolutionary
Computation, <em>The American Statistician,</em> <strong>59</strong>(1), 41–46.
<a href="https://doi.org/10.1198/000313005X22770">doi:10.1198/000313005X22770</a>
</p>
<p>McCormick, W.T., P.J. Schweitzer and T.W. White (1972): Problem
decomposition and data reorganization by a clustering technique,
<em>Operations Research,</em> <strong>20</strong>(5), 993-1009.
<a href="https://doi.org/10.1287/opre.20.5.993">doi:10.1287/opre.20.5.993</a>
</p>
<p>Robinson, W.S. (1951): A method for chronologically ordering archaeological
deposits, <em>American Antiquity,</em> <strong>16</strong>, 293–301.
<a href="https://doi.org/10.2307/276978">doi:10.2307/276978</a>
</p>
<p>Tien, Y-J., Yun-Shien Lee, Han-Ming Wu and Chun-Houh Chen (2008): Methods
for simultaneously identifying coherent local clusters with smooth global
patterns in gene expression profiles, <em>BMC Bioinformatics,</em>
<strong>9</strong>(155), 1–16.
<a href="https://doi.org/10.1186/1471-2105-9-155">doi:10.1186/1471-2105-9-155</a>
</p>


<h3>See Also</h3>

<p>Other criterion: 
<code>registry_for_criterion_methods</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## create random data and calculate distances
m &lt;- matrix(runif(20),ncol=2)
d &lt;- dist(m)

## get an order for rows (optimal for the least squares criterion)
o &lt;- seriate(d, method = "MDS")
o

## compare the values for all available criteria
rbind(
    unordered = criterion(d),
    ordered = criterion(d, o)
)

## compare RGAR by window size (from local to global)
w &lt;- 2:(nrow(m)-1)
RGAR &lt;- sapply(w, FUN = function (w)
  criterion(d, o, method="RGAR", w = w))
plot(w, RGAR, type = "b", ylim = c(0,1),
  xlab = "Windows size (w)", main = "RGAR by window size")
</code></pre>


</div>