<div class="container">

<table style="width: 100%;"><tr>
<td>USMLeastSquaresClassifierSSLR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>General Interface for USMLeastSquaresClassifier (Updated Second Moment Least Squares Classifier) model</h2>

<h3>Description</h3>

<p>model from RSSL package
This methods uses the closed form solution of the supervised least squares problem,
except that the second moment matrix (X'X) is exchanged with a second moment matrix that
is estimated based on all data. See for instance <cite>Shaffer1991</cite>, where in this
implementation we use all data to estimate E(X'X), instead of just the labeled data.
This method seems to work best when the data is first centered <code>x_center=TRUE</code>
and the outputs are scaled using <code>y_scale=TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">USMLeastSquaresClassifierSSLR(
  lambda = 0,
  intercept = TRUE,
  x_center = FALSE,
  scale = FALSE,
  y_scale = FALSE,
  ...,
  use_Xu_for_scaling = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>numeric; L2 regularization parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical; Whether an intercept should be included</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_center</code></td>
<td>
<p>logical;  Should the features be centered?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical; Should the features be normalized? (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y_scale</code></td>
<td>
<p>logical; whether the target vector should be centered</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Not used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_Xu_for_scaling</code></td>
<td>
<p>logical; whether the unlabeled objects should be used to determine the mean and scaling for the normalization</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Shaffer, J.P., 1991. The Gauss-Markov Theorem and Random Regressors. The American Statistician, 45(4), pp.269-273.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(tidyverse)
library(tidymodels)
library(caret)
library(SSLR)

data(breast)

set.seed(1)
train.index &lt;- createDataPartition(breast$Class, p = .7, list = FALSE)
train &lt;- breast[ train.index,]
test  &lt;- breast[-train.index,]

cls &lt;- which(colnames(breast) == "Class")

#% LABELED
labeled.index &lt;- createDataPartition(breast$Class, p = .2, list = FALSE)
train[-labeled.index,cls] &lt;- NA


m &lt;- USMLeastSquaresClassifierSSLR() %&gt;% fit(Class ~ ., data = train)

#Accesing model from RSSL
model &lt;- m$model

#Accuracy
predict(m,test) %&gt;%
  bind_cols(test) %&gt;%
  metrics(truth = "Class", estimate = .pred_class)

</code></pre>


</div>