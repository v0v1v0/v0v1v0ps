<div class="container">

<table style="width: 100%;"><tr>
<td>sentencepiece_download_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Download a Sentencepiece model</h2>

<h3>Description</h3>

<p>Download pretrained models built on Wikipedia
made available at <a href="https://bpemb.h-its.org">https://bpemb.h-its.org</a> through <a href="https://github.com/bheinzerling/bpemb">https://github.com/bheinzerling/bpemb</a>. 
These models contain Byte Pair Encoded models trained with sentencepiece as well
as Glove embeddings of these Byte Pair subwords. Models for 275 languages are available.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sentencepiece_download_model(
  language,
  vocab_size,
  dim,
  model_dir = system.file(package = "sentencepiece", "models")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>language</code></td>
<td>
<p>a character string with the language name. This can be either a plain language or a wikipedia shorthand. <br>
Possible values can be found by looking at the examples or typing sentencepiece:::.bpemb$languages <br>
If you provide multi it downloads the multilingual model available at <a href="https://bpemb.h-its.org/multi/">https://bpemb.h-its.org/multi/</a></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab_size</code></td>
<td>
<p>integer indicating the number of tokens in the final vocabulary. Defaults to 5000. Possible values depend on the language. To inspect possible values, type sentencepiece:::.bpemb$vocab_sizes and look to your language of your choice.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>dimension of the embedding. Either 25, 50, 100, 200 or 300.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_dir</code></td>
<td>
<p>path to the location where the model will be downloaded to. Defaults to <code>system.file(package = "sentencepiece", "models")</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list with elements 
</p>

<ul>
<li>
<p>language: the provided language
</p>
</li>
<li>
<p>wikicode: the wikipedia code of the provided language
</p>
</li>
<li>
<p>file_model: the path to the downloaded Sentencepiece model
</p>
</li>
<li>
<p>url: the url where the Sentencepiece model was fetched from
</p>
</li>
<li>
<p>download_failed: logical, indicating if the download failed
</p>
</li>
<li>
<p>download_message: a character string with possible download failure information
</p>
</li>
<li>
<p>glove: a list with elements file_model, url, download_failed and download_message indicating the path to the Glove embeddings in txt format. Only present if the dim argument is provided in the function. Otherwise the embeddings will not be downloaded
</p>
</li>
<li>
<p>glove.bin: a list with elements file_model, url, download_failed and download_message indicating the path to the Glove embeddings in bin format. Only present if the dim argument is provided in the function. Otherwise the embeddings will not be downloaded
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>sentencepiece_load_model</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">path &lt;- getwd()



##
## Download only the tokeniser model
##
dl &lt;- sentencepiece_download_model("Russian", vocab_size = 50000, model_dir = path)
dl &lt;- sentencepiece_download_model("English", vocab_size = 100000, model_dir = path)
dl &lt;- sentencepiece_download_model("French", vocab_size = 25000, model_dir = path)
dl &lt;- sentencepiece_download_model("multi", vocab_size = 320000, model_dir = path)
dl &lt;- sentencepiece_download_model("Vlaams", vocab_size = 1000, model_dir = path)
dl &lt;- sentencepiece_download_model("Dutch", vocab_size = 25000, model_dir = path)
dl &lt;- sentencepiece_download_model("nl", vocab_size = 25000, model_dir = path)
str(dl)
model     &lt;- sentencepiece_load_model(dl$file_model)

##
## Download the tokeniser model + Glove embeddings of Byte Pairs
##
dl &lt;- sentencepiece_download_model("nl", vocab_size = 1000, dim = 50, model_dir = path)
str(dl)
model     &lt;- sentencepiece_load_model(dl$file_model)
embedding &lt;- read_word2vec(dl$glove$file_model)



dl &lt;- sentencepiece_download_model("nl", vocab_size = 1000, dim = 25,
                                   model_dir = tempdir())
str(dl)


</code></pre>


</div>