<div class="container">

<table style="width: 100%;"><tr>
<td>BPEembedder</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Build a BPEembed model containing a Sentencepiece and Word2vec model</h2>

<h3>Description</h3>

<p>Build a sentencepiece model on text and build a matching word2vec model on the sentencepiece vocabulary
</p>


<h3>Usage</h3>

<pre><code class="language-R">BPEembedder(
  x,
  tokenizer = c("bpe", "char", "unigram", "word"),
  args = list(vocab_size = 8000, coverage = 0.9999),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a data.frame with columns doc_id and text</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokenizer</code></td>
<td>
<p>character string with the type of sentencepiece tokenizer. Either 'bpe', 'char', 'unigram' or 'word' for Byte Pair Encoding, Character level encoding,
Unigram encoding or pretokenised word encoding. Defaults to 'bpe' (Byte Pair Encoding). Passed on to <code>sentencepiece</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args</code></td>
<td>
<p>a list of arguments passed on to <code>sentencepiece</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed on to <code>word2vec</code> for training a word2vec model</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>an object of class BPEembed which is a list with elements 
</p>

<ul>
<li>
<p>model: a sentencepiece model as loaded with <code>sentencepiece_load_model</code>
</p>
</li>
<li>
<p>embedding: a matrix with embeddings as loaded with <code>read.wordvectors</code>
</p>
</li>
<li>
<p>dim: the dimension of the embedding
</p>
</li>
<li>
<p>n: the number of elements in the vocabulary
</p>
</li>
<li>
<p>file_sentencepiece: the sentencepiece model file
</p>
</li>
<li>
<p>file_word2vec: the word2vec embedding file
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>sentencepiece</code>, <code>word2vec</code>, <code>predict.BPEembed</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(tokenizers.bpe)
data(belgium_parliament, package = "tokenizers.bpe")
x     &lt;- subset(belgium_parliament, language %in% "dutch")
model &lt;- BPEembedder(x, tokenizer = "bpe", args = list(vocab_size = 1000),
                     type = "cbow", dim = 20, iter = 10) 
model

txt    &lt;- c("De eigendomsoverdracht aan de deelstaten is ingewikkeld.")
values &lt;- predict(model, txt, type = "encode")  
</code></pre>


</div>