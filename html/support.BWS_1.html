<div class="container">

<table style="width: 100%;"><tr>
<td>support.BWS-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Tools for Case 1 best-worst scaling
</h2>

<h3>Description</h3>

<p>The package provides three basic functions that support an implementation of object case (Case 1) best-worst scaling: one for converting a two-level orthogonal main-effect design/balanced incomplete block design into questions; one for creating a data set suitable for analysis; and one for calculating count-based scores.
</p>


<h3>Details</h3>

<p>Object case (or Case 1) best-worst scaling (BWS), or maximum difference scaling (MaxDiff) (Finn and Louviere 1992) is a stated preference method. After listing the items (objects) evaluated by respondents, a number of different subsets of the items are constructed from the list using the design of experiments. Each of the subsets is presented as a choice set to respondents, who are then asked to select the best (or most important) item and the worst (or least important) item in the choice set. This question is repeated until all the subsets are evaluated.
</p>
<p>There are two methods to construct choice sets for object case BWS: one uses a two-level orthogonal main-effect design (OMED) (Finn and Louviere, 1992) and the other uses a balanced incomplete block design (BIBD) (Auger et al., 2007). The first method uses a two-level OMED with <code class="reqn">T</code> columns, where <code class="reqn">T</code> is the total number of items evaluated: each column corresponds to an item and each row corresponds to a question. There are two values in the two-level OMEDs (e.g., 1 and 2): one value is interpreted as an item being “absent” from the corresponding column and the other as being “present.” In this way, we can decide which items are assigned to each question: for example, if a row in a two-level OMED contains a value of 2 (which means “present” here ) in the 1st, 5th, and 8th columns, and a value of 1 in the other columns, these three items are presented in a question corresponding to the row.
</p>
<p>The second method uses a BIBD, which is a category of designs in which a subset of treatments is assigned to each block. The features of a BIBD are expressed by “number of treatments (items),” “size of a block (number of items per question),” “number of blocks (questions),” “number of replications of each treatment (item),” and “frequency that each pair of treatments (items) appears in the same block (question).” Each row corresponds to a question; the number of columns is equal to the number of items per question; and the level values correspond to item identification numbers. For example, assume that there are seven items, ITEM1, ITEM2, ..., and ITEM7, and a BIBD with seven rows, four columns, and seven level values (1, 2, ..., 7). Under these assumptions, if a row in the BIBD contains values of 1, 4, 6, and 7,  a set containing ITEM1, ITEM4, ITEM6, and ITEM7 is presented in a question corresponding to the row.
</p>
<p>There are two approaches to analyzing responses to object case BWS questions: a counting approach and a modeling approach. The counting approach calculates several types of scores on the basis of the number of times (the frequency or count) item <code class="reqn">i</code> is selected as the best (<code class="reqn">B_{in}</code>) and the worst (<code class="reqn">W_{in}</code>) among all the questions for respondent <code class="reqn">n</code>. These scores are roughly divided into two categories: disaggregated (individual-level) scores and aggregated (total-level) scores (Finn and Louviere, 1992; Lee et al., 2007; Cohen, 2009; Mueller and Rungie, 2009).
</p>
<p>The first category includes a disaggregated BW score and its standardized score:
</p>
<p style="text-align: center;"><code class="reqn">
BW_{in} = B_{in} - W_{in},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
std.BW_{in} = \frac{BW_{in}}{r},
</code>
</p>

<p>where <code class="reqn">r</code> is the frequency with which item <code class="reqn">i</code> appears across all questions.
</p>
<p>The frequency with which item <code class="reqn">i</code> is selected as the best across all questions for <code class="reqn">N</code> respondents is defined as <code class="reqn">B_{i}</code>. Similarly, the frequency with which item <code class="reqn">i</code> is selected as the worst is defined as <code class="reqn">W_{i}</code> (i.e., <code class="reqn">B_{i} = \sum_{n=1}^{N} B_{in}</code>, <code class="reqn">W_{i} = \sum_{n=1}^{N} W_{in}</code>). The second category includes the aggregated versions of <code class="reqn">BW_{in}</code> and <code class="reqn">std.BW_{in}</code>, as well as the square root of the ratio of <code class="reqn">B_{i}</code> to <code class="reqn">W_{i}</code> and its standardized score:
</p>
<p style="text-align: center;"><code class="reqn">
BW_{i} = B_{i} - W_{i},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
std.BW_{i} = \frac{BW_{i}}{Nr},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
sqrt.BW_{i} = \sqrt{\frac{B_{i}}{W_{i}}},
</code>
</p>

<p style="text-align: center;"><code class="reqn">
std.sqrt.BW_{i} = \frac{sqrt.BW_{i}}{max.sqrt.BW_{i}},
</code>
</p>

<p>where <code class="reqn">max.sqrt.BW_{i}</code> is the maximum value of <code class="reqn">sqrt.BW_{i}</code>. 
</p>
<p>The modeling approach uses discrete choice models to analyze responses. In the package, this approach is based on the understanding of respondents' behavior in the following situation (Finn and Louviere, 1992; Auger et al., 2007). Suppose that <code class="reqn">m</code> items exist in a choice set (a question). The number of possible pairs in which item <code class="reqn">i</code> is selected as the best and item <code class="reqn">j</code> is selected as the worst (<code class="reqn">i \neq j</code>) from <code class="reqn">m</code> items is <code class="reqn">m \times (m - 1)</code>. Respondents are assumed to have a utility (<code class="reqn">v</code>) for each item. Further, they are assumed to select item <code class="reqn">i</code> as the best and item <code class="reqn">j</code> as the worst because the difference in utility between <code class="reqn">i</code> and <code class="reqn">j</code> represents the greatest utility difference (the maxdiff model). Under these assumptions, the probability of selecting item <code class="reqn">i</code> as the best and item <code class="reqn">j</code> as the worst is expressed as a conditional logit model:
</p>
<p style="text-align: center;"><code class="reqn">
Pr(i, j) = \frac{\exp(v_{i} - v_{j})}{\sum_{k=1}^{m}\sum_{l=1, k \neq l}^{m}\exp(v_{k} - v_{l})}.
</code>
</p>

<p>A share of preference for item <code class="reqn">i</code> (<code class="reqn">SP_{i}</code>) based on the conditional logit model choice rule is as follows (Cohen, 2003; Cohen and Neira, 2004; Lusk and Briggeman, 2009):
</p>
<p style="text-align: center;"><code class="reqn">
SP_{i} = \frac{\exp(v_{i})}{\sum_{t=1}^{T}\exp(v_{t})}.
</code>
</p>

<p>Version 0.2-0 and later versions of the package are also available for the marginal and marginal sequential models (Hensher et al., 2015, Appendix 6B) in the modeling approach.
</p>


<h3>Acknowledgments</h3>

<p>This work was supported by JSPS KAKENHI Grant Numbers JP25450341, JP16K07886, and JP20K06251.
</p>


<h3>Author(s)</h3>

<p>Hideo Aizaki
</p>


<h3>References</h3>

<p>Aizaki H, Fogarty J (2023)
R packages and tutorial for case 1 best-worst scaling.
<em>Journal of Choice Modelling</em>, <b>46</b>, 100394.
</p>
<p>Aizaki H, Nakatani T, Sato K (2014) 
<em>Stated Preference Methods Using R</em>. 
CRC Press. 
</p>
<p>Auger P, Devinney TM, Louviere JJ (2007) 
Using best-worst scaling methodology to investigate consumer ethical beliefs across countries. 
<em>Journal of Business Ethics</em>, <b>70</b>, 299–326. 
</p>
<p>Cohen E (2009) 
Applying best-worst scaling to wine marketing. 
<em>International Journal of Wine Business Research</em>, <b>21</b>(1), 8–23. 
</p>
<p>Cohen SH (2003) 
Maximum difference scaling: 
Improved measures of importance and preference for segmentation. 
<em>Sawtooth Software Research Paper Series</em>, 1–17. 
<a href="https://sawtoothsoftware.com/resources/technical-papers/maximum-difference-scaling-improved-measures-of-importance-and-preference-for--segmentation">https://sawtoothsoftware.com/resources/technical-papers/maximum-difference-scaling-improved-measures-of-importance-and-preference-for–segmentation</a>.
</p>
<p>Cohen S, Neira L (2004) 
Measuring preference for product benefits across countries: 
Overcoming scale usage bias with maximum difference scaling. 
<em>Excellence in International Research</em>, 1–22.
</p>
<p>Finn A, Louviere JJ (1992) 
Determining the appropriate response to evidence of public concern: 
The case of food safety. 
<em>Journal of Public Policy &amp; Marketing</em>, <b>11</b>(2), 12–25. 
</p>
<p>Hensher DA, Rose JM, Greene WH (2015) 
<em>Applied Choice Analysis</em>. 2nd edition. Cambridge University Press. 
</p>
<p>Hess S, Palma D (2019a) Apollo: 
a flexible, powerful and customisable freeware package for choice model estimation and application. 
<em>Journal of Choice Modelling</em>, <b>32</b>, 100170. 
</p>
<p>Hess S, Palma D (2019b) 
Apollo version 0.0.9, user manual, 
<a href="http://www.apollochoicemodelling.com/">http://www.apollochoicemodelling.com/</a>.
</p>
<p>Lee JA, Soutar GN, Louviere J (2007) 
Measuring values using best-worst scaling: The LOV example. 
<em>Psychology &amp; Marketing</em>, <b>24</b>(12), 1043–1058. 
</p>
<p>Lusk JL, Briggeman BC (2009) 
Food values. 
<em>American Journal of Agricultural Economics</em>, <b>91</b>(1), 184–196. 
</p>
<p>Louviere JJ, Flynn TN, Marley AAJ (2015) 
<em>Best-Worst Scaling: Theory, Methods and Applications</em>. 
Cambridge University Press. 
</p>
<p>Mueller S, Rungie C (2009) 
Is there more information in best-worst choice data?: 
Using the attitude heterogeneity structure to identify consumer segments. 
<em>International Journal of Wine Business Research</em>, <b>21</b>(1), 24–40. 
</p>


</div>