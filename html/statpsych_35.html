<div class="container">

<table style="width: 100%;"><tr>
<td>ci.kappa</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Confidence interval for two kappa reliability coefficients</h2>

<h3>Description</h3>

<p>Computes confidence intervals for the intraclass kappa coefficient and
Cohen's kappa coefficient with two dichotomous ratings.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ci.kappa(alpha, f00, f01, f10, f11)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>alpha level for 1-alpha confidence</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f00</code></td>
<td>
<p>number of objects rated y = 0 and x = 0</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f01</code></td>
<td>
<p>number of objects rated y = 0 and x = 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f10</code></td>
<td>
<p>number of objects rated y = 1 and x = 0</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f11</code></td>
<td>
<p>number of objects rated y = 1 and x = 1</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a 2-row matrix. The results in row 1 are for the intraclass
kappa. The results in row 2 are for Cohen's kappa. The columns are:
</p>

<ul>
<li>
<p> Estimate - estimate of interrater reliability
</p>
</li>
<li>
<p> SE - standard error
</p>
</li>
<li>
<p> LL - lower limit of the confidence interval
</p>
</li>
<li>
<p> UL - upper limit of the confidence interval
</p>
</li>
</ul>
<h3>References</h3>

<p>Fleiss JL, Paik MC (2003).
<em>Statistical Methods for Rates and Proportions</em>, 3rd edition.
Wiley.
</p>


<h3>Examples</h3>

<pre><code class="language-R">ci.kappa(.05, 31, 12, 4, 58)

# Should return:
#               Estimate         SE        LL        UL
# IC kappa:    0.6736597 0.07479965 0.5270551 0.8202643
# Cohen kappa: 0.6756757 0.07344761 0.5317210 0.8196303


</code></pre>


</div>