<div class="container">

<table style="width: 100%;"><tr>
<td>scrapeR_in_batches</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Batch Web Page Content Scraper
</h2>

<h3>Description</h3>

<p>The <code>scrapeR_in_batches</code> function processes a dataframe in batches, scraping web content from URLs in a specified column and writing the scraped content to a column in df.
</p>


<h3>Usage</h3>

<pre><code class="language-R">scrapeR_in_batches(df, url_column, extract_contacts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>

<p>A dataframe containing the URLs to be scraped.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>url_column</code></td>
<td>

<p>The name of the column in <code>df</code> that contains the URLs.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extract_contacts</code></td>
<td>

<p>A function that searches scraped content for emails and phone numbers, defaults to FALSE.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function divides the input dataframe into batches of a fixed size (default: 100). For each batch, it extracts the combined text content from the web pages of the URLs in the specified column. The results are appended to the df. The function also includes a throttling mechanism to pause between batch processing, reducing the load on the server being scraped.
</p>


<h3>Value</h3>

<p>The values are returned to content column and optionally to an email and phone_number column if extract_contacts is TRUE.
</p>


<h3>Note</h3>

<p>Ensure that the <span class="pkg">httr</span>, <span class="pkg">rvest</span>, and <span class="pkg">stringr</span> packages are installed and loaded. Also, handle large datasets and output files with care to avoid memory issues.
</p>


<h3>Author(s)</h3>

<p>Mathieu Dubeau Ph.D
</p>


<h3>References</h3>

<p>Refer to <a href="https://www.rdocumentation.org/packages/rvest">rvest package documentation</a> and <a href="https://www.rdocumentation.org/packages/httr">httr package documentation</a> for underlying web scraping methods.
</p>


<h3>See Also</h3>

<p><code>GET</code>, <code>read_html</code>, <code>html_nodes</code>, <code>html_text</code>, <code>write.table</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
  mock_scrapeR &lt;- function(url) {
    return(paste("Scraped content from", url))
  }

  df &lt;- data.frame(url = c("http://site1.com", "http://site2.com"), stringsAsFactors = FALSE)

  ## Not run: 
    scrapeR_in_batches(df, url_column = "url", extract_contacts = FALSE)
  
## End(Not run)
</code></pre>


</div>