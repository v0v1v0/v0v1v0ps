<div class="container">

<table style="width: 100%;"><tr>
<td>bootEff</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bootstrap Effects</h2>

<h3>Description</h3>

<p>Bootstrap model effects (standardised coefficients) and optional
SEM correlated errors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bootEff(
  mod,
  R,
  seed = NULL,
  type = c("nonparametric", "parametric", "semiparametric"),
  ran.eff = NULL,
  cor.err = NULL,
  catch.err = TRUE,
  parallel = c("snow", "multicore", "no"),
  ncpus = NULL,
  cl = NULL,
  bM.arg = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.
Alternatively, a <code>"psem"</code> object from
<a href="https://rdrr.io/cran/piecewiseSEM/man/psem.html"><code>piecewiseSEM::psem()</code></a>.
If model lists are unnamed, response variable names will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>Number of bootstrap resamples to generate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Seed for the random number generator. If not provided, a random
five-digit integer is used (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of bootstrapping to perform. Can be <code>"nonparametric"</code>
(default), <code>"parametric"</code>, or <code>"semiparametric"</code> (the last two currently
only for mixed models, via <code>lme4::bootMer()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ran.eff</code></td>
<td>
<p>For nonparametric bootstrapping of mixed models, the name of
the (highest-level) random effect to resample (see Details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cor.err</code></td>
<td>
<p>Optional, names of SEM correlated errors to be bootstrapped
(ignored if <code>mod</code> is a <code>"psem"</code> object). Should be of the form: <code>c("var1 ~~ var2", "var3 ~~ var4", ...)</code> (spaces optional), using model/response
variable names.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>catch.err</code></td>
<td>
<p>Logical, should errors generated during model fitting or
estimation be caught and <code>NA</code> returned for estimates? If <code>FALSE</code>, any such
errors will cause the function to exit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>The type of parallel processing to use. Can be one of
<code>"snow"</code>, <code>"multicore"</code>, or <code>"no"</code> (for none).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncpus</code></td>
<td>
<p>Number of system cores to use for parallel processing. If <code>NULL</code>
(default), all available cores are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>Optional cluster to use if <code>parallel = "snow"</code>. If <code>NULL</code>
(default), a local cluster is created using the specified number of cores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bM.arg</code></td>
<td>
<p>A named list of any additional arguments to <code>lme4::bootMer()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments to <code>stdEff()</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>bootEff()</code> uses <code>boot::boot()</code> (primarily) to bootstrap
standardised effects from a fitted model or list of models (calculated
using <code>stdEff()</code>). Bootstrapping is typically nonparametric, i.e. model
effects are calculated from data where the rows have been randomly sampled
with replacement. 10,000 such resamples should provide accurate coverage
for confidence intervals in most situations, with fewer sufficing in some
cases. To ensure that data is resampled in the same way across individual
bootstrap operations within the same run (e.g. models in a list), the same
seed is set per operation, with the value saved as an attribute to the
matrix of bootstrapped values (for reproducibility). The seed can either be
user-supplied or a randomly-generated five-digit number (default), and is
always re-initialised on exit (i.e. <code>set.seed(NULL)</code>).
</p>
<p>Where <code>weights</code> are specified, bootstrapped effects will be a weighted
average across the set of candidate models for each response variable,
calculated after each model is first refit to the resampled dataset
(specifying <code>weights = "equal"</code> will use a simple average instead – see
<code>avgEst()</code>). If no weights are specified and <code>mod</code> is a nested list of
models, the function will throw an error, as it will be expecting weights
for a presumed model averaging scenario. If instead the user wishes to
bootstrap each individual model, they should recursively apply the function
using <code>rMapply()</code> (remember to set a seed).
</p>
<p>Where names of response variables with correlated errors are specified to
<code>cor.err</code>, the function will also return bootstrapped Pearson correlated
errors (weighted residuals) for those models. If <code>weights</code> are supplied and
<code>mod</code> is a nested list, residuals will first be averaged across candidate
models. If any two models (or candidate sets) with correlated errors were
fit to different subsets of data observations, both models/sets are first
refit to data containing only the observations in common.
</p>
<p>For nonparametric bootstrapping of mixed models, resampling should occur at
the group-level, as individual observations are not independent. The name
of the random effect to resample must be supplied to <code>ran.eff</code>. For nested
random effects, this should be the highest-level group (Davison &amp; Hinkley,
1997; Ren et al., 2010). This form of resampling will result in datasets of
different sizes if observations are unbalanced across groups; however this
should not generally be an issue, as the number of independent units
(groups), and hence the 'degrees of freedom', remains
<a href="https://stats.stackexchange.com/questions/46965/bootstrapping-unbalanced-clustered-data-non-parametric-bootstrap">unchanged</a>.
</p>
<p>For mixed models with <a href="https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified">non-nested random effects</a>,
nonparametric resampling will not be appropriate. In these cases,
parametric or semiparametric bootstrapping can be performed instead via
<code>lme4::bootMer()</code> (with additional arguments passed to that function as
necessary). NOTE: As <code>lme4::bootMer()</code> takes only a fitted model as its
first argument (i.e. no lists), any model averaging is calculated
'post-hoc' using the estimates in boot objects for each candidate model,
rather than during the bootstrapping process itself (i.e. the default
procedure via <code>boot::boot()</code>). Results are then returned in a new boot
object for each response variable or correlated error estimate.
</p>
<p>If supplied a list containing both mixed and non-mixed models, <code>bootEff()</code>
with nonparametric bootstrapping will still work and will treat all models
as mixed models for resampling (with a warning). This is likely a
relatively rare scenario, but may occur where the user decides that
non-mixed models perform similarly and/or cause less fitting issues than
their mixed counterparts for at least some response variables (e.g. where
random effect variance estimates are at or near zero). The data will be
resampled on the supplied random effect for all models. If nonparametric
bootstrapping is not used in this scenario however, an error will occur, as
<code>lme4::bootMer()</code> will only accept mixed models.
</p>
<p>Parallel processing is used by default via the parallel package and
option <code>parallel = "snow"</code> (and is generally recommended), but users can
specify the type of parallel processing to use, or none. If <code>"snow"</code>, a
cluster of workers is created using <code>makeCluster()</code>, and the user can
specify the number of system cores to incorporate in the cluster (defaults
to all available). <code>bootEff()</code> then exports all required objects and
functions to this cluster using <code>clusterExport()</code>, after performing a
(rough) match of all objects and functions in the current global
environment to those referenced in the model call(s). Users should load any
required external packages prior to calling the function.
</p>


<h3>Value</h3>

<p>An object of class <code>"boot"</code> containing the bootstrapped effects, or a
(named) list/nested list of such objects.
</p>


<h3>Note</h3>

<p>Bootstrapping mixed (or indeed any other) models may take a very long
time when the number of replicates, observations, parameters, and/or models
is high. To decrease processing time, it may be worth trying different
optimisers and/or other options to generate faster estimates (always check
results).
</p>


<h3>References</h3>

<p>Burnham, K. P., &amp; Anderson, D. R. (2002). <em>Model Selection and
Multimodel Inference: A Practical Information-Theoretic Approach</em> (2nd
ed.). Springer-Verlag. <a href="https://link.springer.com/book/10.1007/b97636">https://link.springer.com/book/10.1007/b97636</a>
</p>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap Methods and their
Application</em>. Cambridge University Press.
</p>
<p>Ren, S., Lai, H., Tong, W., Aminzadeh, M., Hou, X., &amp; Lai, S. (2010).
Nonparametric bootstrapping for hierarchical data. <em>Journal of Applied
Statistics</em>, <em>37</em>(9), 1487–1498. <a href="https://doi.org/10/dvfzcn">doi:10/dvfzcn</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Bootstrap Shipley SEM (test – 1 rep)
# (set 'site' as group for resampling – highest-level random effect)
bootEff(shipley.sem, R = 1, ran.eff = "site", parallel = "no")

# Check estimates (use saved boot object – 1000 reps)
lapply(shipley.sem.boot, "[[", 1)  # original
lapply(shipley.sem.boot, function(i) head(i$t))  # bootstrapped
</code></pre>


</div>