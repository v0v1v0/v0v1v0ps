<div class="container">

<table style="width: 100%;"><tr>
<td>sdf_schema_json</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Work with the schema</h2>

<h3>Description</h3>

<p>These functions support flexible schema inspection both algorithmically and in human-friendly ways.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sdf_schema_json(
  x,
  parse_json = TRUE,
  simplify = FALSE,
  append_complex_type = TRUE
)

sdf_schema_viewer(
  x,
  simplify = TRUE,
  append_complex_type = TRUE,
  use_react = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An <code>R</code> object wrapping, or containing, a Spark DataFrame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parse_json</code></td>
<td>
<p>Logical. If <code>TRUE</code> then the JSON return value will be parsed into an R list.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simplify</code></td>
<td>
<p>Logical. If <code>TRUE</code> then the schema will be folded into itself such that
<code>{"name" : "field1", "type" : {"type" : "array", "elementType" : "string", "containsNull" : true},
 "nullable" : true, "metadata" : { } }</code> will be rendered simply <code>{"field1 (array)" : "[string]"}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>append_complex_type</code></td>
<td>
<p>Logical. This only matters if <code>parse_json=TRUE</code> and <code>simplify=TRUE</code>. 
In that case indicators will be included in the return value for array and struct types.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_react</code></td>
<td>
<p>Logical. If <code>TRUE</code> schemas will be rendered using reactjson.
Otherwise they will be rendered using jsonedit (the default). Using react works better
in some contexts (e.g. bookdown-rendered HTML) and has a different look &amp; feel. It does however carry
an extra dependency on the <code>reactR</code> package suggested by <code>listviewer</code>.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>sdf_schema</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(testthat)
library(jsonlite)
library(sparklyr)
library(sparklyr.nested)
sample_json &lt;- paste0(
  '{"aircraft_id":["string"],"phase_sequence":["string"],"phases (array)":{"start_point (struct)":',
  '{"segment_phase":["string"],"agl":["double"],"elevation":["double"],"time":["long"],',
  '"latitude":["double"],"longitude":["double"],"altitude":["double"],"course":["double"],',
  '"speed":["double"],"source_point_keys (array)":["[string]"],"primary_key":["string"]},',
  '"end_point (struct)":{"segment_phase":["string"],"agl":["double"],"elevation":["double"],',
  '"time":["long"],"latitude":["double"],"longitude":["double"],"altitude":["double"],',
  '"course":["double"],"speed":["double"],"source_point_keys (array)":["[string]"],',
  '"primary_key":["string"]},"phase":["string"],"primary_key":["string"]},"primary_key":["string"]}'
)

with_mock(
  # I am mocking functions so that the example works without a real spark connection
  spark_read_parquet = function(x, ...){return("this is a spark dataframe")},
  sdf_schema_json = function(x, ...){return(fromJSON(sample_json))},
  spark_connect = function(...){return("this is a spark connection")},
  
  # the meat of the example is here
  sc &lt;- spark_connect(),
  spark_data &lt;- spark_read_parquet(sc, path="path/to/data/*.parquet", name="some_name"),
  sdf_schema_viewer(spark_data)
)

## End(Not run)
</code></pre>


</div>