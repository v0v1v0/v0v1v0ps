<div class="container">

<table style="width: 100%;"><tr>
<td>sisal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Sequential Input Selection Algorithm (<abbr><span class="acronym">SISAL</span></abbr>)
</h2>

<h3>Description</h3>

<p>Identifies relevant inputs using a backward selection type algorithm
with optional branching.  Choices are made by assessing linear models
estimated with ordinary least squares or ridge regression in a
cross-validation setting.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sisal(X, y, Mtimes = 100, kfold = 10, hbranches = 1,
      max.width = hbranches^2, q = 0.165, standardize = TRUE,
      pruning.criterion = c("round robin", "random nodes",
                            "random edges", "greedy"),
      pruning.keep.best = TRUE, pruning.reverse = FALSE,
      verbose = 1, use.ridge = FALSE,
      max.warn = getOption("nwarnings"), sp = -1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p> a <code>numeric</code> <code>matrix</code> where each column is a
predictor (independent variable) and each row is an observation
(data point) </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> a <code>numeric</code> vector containing a sample of the response
(dependent) variable, in the same order as the rows of
<code><var>X</var></code> </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Mtimes</code></td>
<td>
<p> the number of times the cross-validation is repeated,
i.e. the number of predictions made for each data point.  An
integral value (<code>numeric</code> or <code>integer</code>).  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kfold</code></td>
<td>
<p> the number of approximately equally sized parts used for
partitioning the data on each cross-validation round.  An integral
value (<code>numeric</code> or <code>integer</code>).  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hbranches</code></td>
<td>
<p> the number of branches to take when removing a
variable from the model.  In Tikka and Hollmén
(2008), the algorithm always removes the “weakest” variable
(<code><var>hbranches</var></code> equals <code>1</code>, also the default here).  By
using a value larger than <code>1</code>, the algorithm creates branches
in the search graph by removing each of the <code><var>hbranches</var></code>
“weakest” variables, one at a time.  The number of branches
created is naturally limited by the number of variables remaining in
the model at that point.  See also <code><var>max.width</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.width</code></td>
<td>
<p> the maximum number of nodes with a given number of
variables allowed in the search graph.  The same limit is used for
all search levels.  An integral value (<code>numeric</code> or
<code>integer</code>).  See <code><var>pruning.criterion</var></code> and
<code><var>pruning.keep.best</var></code>.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p> a <code>numeric</code> value between <code>0</code> and <code>0.5</code>
(endpoints excluded) defining the quantiles
<code>1-<var>q</var></code> and <code><var>q</var></code>.  The difference of these sample
quantiles is used as the width of the sampling distribution (a
measure of uncertainty) of each coefficient in a linear model.  The
default value <code>0.165</code> is the same as used by Tikka and
Hollmén (2008).  In case of a normally distributed
parameter, the width is approximately twice the standard deviation
(one standard deviation on both sides of the mean). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p> a <code>logical</code> flag.  If <code>TRUE</code>,
standardizes the data to zero mean and unit variance.  If
<code>FALSE</code>, uses original data.  This affects the scale of the
results.  If <code><var>use.ridge</var></code> is <code>TRUE</code>, this should be
set to <code>TRUE</code> or the search graph and the sets of selected
variables could be affected. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pruning.criterion</code></td>
<td>
<p> a <code>character</code> string.  Options are
<code>"round robin"</code>, <code>"random nodes"</code>, <code>"random edges"</code>
and <code>"greedy"</code>.  Abbreviations are allowed.  This affects how
the search tree is pruned if the number of nodes to explore is about
to exceed <code><var>max.width</var></code>.  One of the following methods is
used to select <code><var>max.width</var></code> nodes for the next level of
search.
</p>
<p>If <code>"round robin"</code>, the nodes of the current level
(<code><var>i</var></code> variables) take turns selecting nodes for the next
level (<code><var>i</var>-1</code> variables).  The turns are taken in order of
increasing validation error.  Each parent node chooses children
according to the order described in ‘Details’. If a duplicate
choice would be made, the turn is skipped.
</p>
<p>If <code>"random nodes"</code>, random nodes are selected with uniform
probability.
</p>
<p>If <code>"random edges"</code>, random nodes are selected, with the
probability of a node directly proportional to the number of edges
leading to it.
</p>
<p>If <code>"greedy"</code>, a method similar to <code>"round robin"</code> is
used, but with the (virtual) looping order of parents and children
swapped.  Whereas the outer loop in <code>"round robin"</code> operates
over children and the inner loop over parents, the outer loop in
<code>"greedy"</code> operates over parents and the inner loop over
children.  That is, a <code>"greedy"</code> parent node selects all its
children before passing on the turn to the next parent.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pruning.keep.best</code></td>
<td>
<p> a <code>logical</code> flag.  If <code>TRUE</code>, the
nodes that would also be present in the <code><var>hbranches</var> = 1</code>
case are immune to pruning.  If <code>FALSE</code>, the result may
underperform the original Tikka and Hollmén (2008)
solution in terms of (the lowest) validation error as function of
the number of inputs.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pruning.reverse</code></td>
<td>
<p> a <code>logical</code> flag.  If <code>TRUE</code>, all
the methods described in <code><var>pruning.criterion</var></code> except
<code>"random nodes"</code> use reverse orders or inverse probabilities.
The default is <code>FALSE</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p> a <code>numeric</code> or <code>integer</code> verbosity level
from <code>0</code> (no output) to <code>5</code> (all possible diagnostics).  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.ridge</code></td>
<td>
<p> a <code>logical</code> flag.  If <code>TRUE</code>, the function
uses ridge regression with automatic selection of the regularization
(smoothing) parameter.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.warn</code></td>
<td>
<p> a <code>numeric</code> value giving the maximum number of
warnings to store in the returned object.  If more warnings are
given, their total number is still recorded in the object. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sp</code></td>
<td>
<p> a <code>numeric</code> value passed to <code>magic</code> if
<code><var>use.ridge</var></code> is <code>TRUE</code>.  Initial value of the
regularization parameter.  If negative (the default), initialization
is automatic.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> additional arguments passed to <code>magic</code> if
<code><var>use.ridge</var></code> is <code>TRUE</code>.  It is an error to supply
arguments named <code>"S"</code> or <code>"off"</code>.  </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>When choosing which variable to drop from the model, the importance of
a variable is measured by looking at two variables derived from the
sampling distribution of its coefficient in the linear models of the
repeated cross-validation runs: </p>
 <ol>
<li>
<p> absolute value of
the median and </p>
</li>
<li>
<p> width of the distribution (see <code><var>q</var></code>).
</p>
</li>
</ol>
<p> The importance of an input variable is the ratio of the median to
the width: <code><var>hbranches</var></code> variables with the smallest ratios
are dropped, one variable in each branch.  See <code><var>max.width</var></code>
and <code><var>pruning.criterion</var></code>.
</p>
<p>The main results of the function are described here.  More details are
available in ‘Value’.
</p>
<p>The function returns two sets of inputs variables: </p>

<dl>
<dt>L.v</dt>
<dd>
<p> set corresponding to the smallest validation error. </p>
</dd>
<dt>L.f</dt>
<dd>
<p> smallest set where validation error is close to the
smallest error.  The margin is the standard deviation of the training
error measured in the node of the smallest validation error. </p>
</dd> </dl>
<p>The mean of mean squared errors in the <b>tr</b>aining and
<b>v</b>alidation sets are also returned (<code><var>E.tr</var></code>,
<code><var>E.v</var></code>).  For the training set, the standard deviation of
<abbr><span class="acronym">MSE</span></abbr>s (<code><var>s.tr</var></code>) is also returned.  The length of
these vectors is the number of variables in <code><var>X</var></code>.  The
<var>i</var>:th element in each of the vectors corresponds to the best
model with <var>i</var> input variables, where goodness is measured by the
mean <abbr><span class="acronym">MSE</span></abbr> in the validation set.
</p>
<p>Linear models fitted to the whole data set are also returned.  Both
ordinary least square regression (<code><var>lm.L.f</var></code>,
<code><var>lm.L.v</var></code>, <code><var>lm.full</var></code>) and ridge regression models
(<code><var>magic.L.f</var></code>, <code><var>magic.L.v</var></code>,
<code><var>magic.full</var></code>) are computed, irrespective of the
<code><var>use.ridge</var></code> setting.  Both fitting methods are used for the
<code><var>L.f</var></code> set of variables, the <code><var>L.v</var></code> set and the
full set (all variables).
</p>


<h3>Value</h3>

<p> A <code>list</code> with <code>class</code> <code>"sisal"</code>.  The items are:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>L.f</code></td>
<td>
<p> a <code>numeric</code> vector containing indices to columns of
<code><var>X</var></code>.  See ‘Details’. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L.v</code></td>
<td>
<p> a <code>numeric</code> index vector like <code><var>L.f</var></code>.  See
‘Details’. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>E.tr</code></td>
<td>
<p> a <code>numeric</code> vector of length <code><var>d</var> + 1</code>.
See ‘Details’. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s.tr</code></td>
<td>
<p> a <code>numeric</code> vector of length <code><var>d</var> + 1</code>.
See ‘Details’. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>E.v</code></td>
<td>
<p> a <code>numeric</code> vector of length <code><var>d</var> + 1</code>.  See
‘Details’. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L.f.nobranch</code></td>
<td>
<p> a <code>numeric</code> vector or <code>NULL</code>.  Like
<code><var>L.f</var></code> but for the “no branching” solution.
<code>NULL</code> if branching is not used or if some elements of
<code><var>branching.useful</var></code> are missing. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L.v.nobranch</code></td>
<td>
<p> like <code><var>L.f.nobranch</var></code> but related to
<code><var>L.v</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>E.tr.nobranch</code></td>
<td>
<p> a <code>numeric</code> vector or <code>NULL</code>.  Like
<code><var>E.tr</var></code> but for the “no branching” solution.
<code>NULL</code> when <code><var>branching.useful</var></code> is <code>NULL</code>.  An
element is missing when the corresponding element of
<code><var>branching.useful</var></code> is missing. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s.tr.nobranch</code></td>
<td>
<p> like <code><var>E.tr.nobranch</var></code> but related to
<code><var>s.tr</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>E.v.nobranch</code></td>
<td>
<p> like <code><var>E.tr.nobranch</var></code> but related to
<code><var>E.v</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.evaluated</code></td>
<td>
<p> a <code>numeric</code> vector of length <code><var>d</var> +
    1</code>.  The number of nodes evaluated for each model size, indexed by
the number of variables used plus one. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>edges</code></td>
<td>
<p> a <code>list</code> of directed edges between nodes in the
search graph.  There is an edge from node <var>A</var> to node <var>B</var> if
and only if <var>B</var> was a candidate for a new node to be evaluated,
resulting from removing one variable in <var>A</var>.  The <var>i</var>:th
element of the list contains edges directed away from the node
represented by the <var>i</var>:th element of <code><var>vertices</var></code>.
Each element is a list with one element, <code>"edges"</code>, which is a
<code>numeric</code> vector of indices to <code><var>vertices</var></code>, pointing
to the nodes towards which the edges are directed.  There are no
edges directed away from pruned nodes or nodes representing a single
variable. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vertices</code></td>
<td>
<p> a <code>character</code> vector the same size as
<code><var>edges</var></code>.  Contains the names of the nodes in the search
graph.  Each name contains the indices of the variables included in
the set in question, separated by dots. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vertices.logical</code></td>
<td>
<p> a <code>logical</code> <code>matrix</code> containing an
alternative representation of <code><var>vertices</var></code>.  Number of rows
is the length of <code><var>vertices</var></code> and number of columns is
<code><var>d</var></code>.  The <var>i</var>:th column indicates whether the
<var>i</var>:th input variable is present in a given node.  The row index
and the index to <code><var>vertices</var></code> are equivalent. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vertex.data</code></td>
<td>
<p>A <code>data.frame</code> with information about each
node in the search graph (missing information means pruned node).
The rows correspond to items in <code><var>vertices</var></code>. The columns
are:
</p>

<dl>
<dt>E.tr</dt>
<dd>
<p> mean of <abbr><span class="acronym">MSE</span></abbr>s, training. </p>
</dd>
<dt>s.tr</dt>
<dd>
<p> standard deviation (<code><var>n</var>-1</code>) of
<abbr><span class="acronym">MSE</span></abbr>s, training. </p>
</dd>
<dt>E.v</dt>
<dd>
<p> mean of <abbr><span class="acronym">MSE</span></abbr>s, validation. </p>
</dd>
<dt>E.v.level.rank</dt>
<dd>
<p> rank of the node among all the evaluated
(non-pruned) nodes with the same number of variables, in terms
of validation error. Smallest error is rank 1. </p>
</dd>
<dt>n.rank.deficient</dt>
<dd>
<p> number of rank deficient linear models.
This problem arises when the number of input variables is large
compared to the number of observations and
<code><var>use.ridge</var></code> is <code>FALSE</code>. </p>
</dd>
<dt>n.NA.models</dt>
<dd>
<p> number of models that could not be estimated
due to lack of any samples </p>
</dd>
<dt>n.inputs</dt>
<dd>
<p> number of input variables used in the model
represented by the node. </p>
</dd>
<dt>min.branches</dt>
<dd>
<p> the smallest branching factor large enough
for producing the node.  This is a number <code><var>k</var></code> between
<code>1</code> and <code><var>hbranches</var></code>.  The value for the root
node (all input variables) is <code>1</code>.  The value for other
nodes is the minimum of the set of values suggested by its
parents. The value suggested by an individual parent is the
<code><var>min.branches</var></code> value of the parent itself or the
ranking of the child in terms of increasing importance of the
removed variable (see ‘Details’), whichever is larger.
For example, when <code><var>pruning.keep.best</var></code> is <code>TRUE</code>,
the <code><var>hbranches</var> = 1</code> search path can be followed by
looking for nodes where <code><var>min.branches</var></code> is <code>1</code>. </p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.names</code></td>
<td>
<p> names of the variables (column names of
<code><var>X</var></code>). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p> number of observations in the (<code><var>X</var></code>,
<code><var>y</var></code>) data. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p> number of variables (columns) in <code><var>X</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.missing</code></td>
<td>
<p> number of samples where either <code><var>y</var></code> or all
variables of <code><var>X</var></code> are missing. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.clean</code></td>
<td>
<p> number of complete samples in the data set
<code><var>X</var></code>, <code><var>y</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lm.L.f</code></td>
<td>
 <p><code>lm</code> model fitted to <code><var>L.f</var></code>
variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lm.L.v</code></td>
<td>
 <p><code>lm</code> model fitted to <code><var>L.v</var></code>
variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lm.full</code></td>
<td>
 <p><code>lm</code> model fitted to all variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>magic.L.f</code></td>
<td>
 <p><code>magic</code> model fitted to <code><var>L.f</var></code>
variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>magic.L.v</code></td>
<td>
 <p><code>magic</code> model fitted to <code><var>L.v</var></code>
variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>magic.full</code></td>
<td>
 <p><code>magic</code> model fitted to all
variables. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean.y</code></td>
<td>
<p> mean of <code><var>y</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd.y</code></td>
<td>
<p> standard deviation (denominator <code><var>n</var> - 1</code>) of
<code><var>y</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zeroRange.y</code></td>
<td>
<p> a <code>logical</code> value indicating whether all
non-missing elements of <code><var>y</var></code> are equal, with some numeric
tolerance. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean.X</code></td>
<td>
<p> column means of <code><var>X</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd.X</code></td>
<td>
<p> standard deviation (denominator <code><var>n</var> - 1</code>) of
each column in <code><var>X</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zeroRange.X</code></td>
<td>
<p> a <code>logical</code> vector.  Like
<code><var>zeroRange.y</var></code> but for each column of <code><var>X</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constant.X</code></td>
<td>
<p> a <code>logical</code> vector where the i:th value
indicates whether the i:th column of <code><var>X</var></code> has a (nearly)
constant, non-zero value (<code>NA</code> values allowed). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>params</code></td>
<td>
<p> a named <code>list</code> containing the values used for most
of the parameter-like formal arguments of the
function, and also anything in <code>...</code>.  The names are the
names of the parameters. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise.points</code></td>
<td>
<p> a <code>numeric</code> square <code>matrix</code> with
<code><var>d</var></code> rows and columns.  The count in row <var>i</var>, column
<var>j</var> indicates the number of times that variable <var>i</var> was
better than variable <var>j</var>.  See ‘Details’ in
<code>plotSelected.sisal</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise.wins</code></td>
<td>
<p> a <code>logical</code> square <code>matrix</code> with
<code><var>d</var></code> rows and columns.  A <code>TRUE</code> value in row
<var>i</var>, column <var>j</var> indicates that <var>i</var> is more important
than variable <var>j</var>. Derived from <code><var>pairwise.points</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise.preferences</code></td>
<td>
<p> a <code>numeric</code> vector with
<code><var>d</var></code> elements.  Number of wins minus number of losses
(when another variable wins) per variable.  Derived from
<code><var>pairwise.wins</var></code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise.rank</code></td>
<td>
<p> an <code>integer</code> vector of ranks according to
Copeland's pairwise aggregation method.  Element number <var>i</var> is
the rank of variable (column) number <var>i</var> in <code><var>X</var></code>.
Derived from <code><var>pairwise.preferences</var></code>.  See
‘Details’ in <code>plotSelected.sisal</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path.length</code></td>
<td>
<p> a <code>numeric</code> vector of path lengths.  Consider
a path starting from the full model and continuing through
incrementally smaller models, each with the smallest validation
error among the nodes with that number of variables.  However, the
path is broken at each point where the model with one less variable
cannot be constructed by removing one variable from the bigger model
(is not nested).  The vector contains the lengths of the pieces.
Its length is the number of breaks plus one. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nested.path</code></td>
<td>
<p> a <code>numeric</code> vector containing the indices
(column numbers) of the input variables in their removal order on
the “nested path”.  The first element is the index of the
variable that was removed first.  The remaining variable is the last
element.  If the path does not exist, this is <code>NULL</code>.  See
‘Details’ in <code>plotSelected.sisal</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nested.rank</code></td>
<td>
<p> an <code>integer</code> vector of ranks determined by
<code><var>nested.path</var></code>.  Element number <var>i</var> is the rank of
variable (column) number <var>i</var> in <code><var>X</var></code>.  <code>NULL</code> if
<code><var>nested.path</var></code> is <code>NULL</code>.  See ‘Details’ in
<code>plotSelected.sisal</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>branching.useful</code></td>
<td>
<p> If branching is enabled
(<code><var>hbranches</var> &gt; 1</code>), this is a <code>logical</code> vector of
length <code><var>d</var></code>.  If the <var>i</var>:th element is <code>TRUE</code>,
branching improved the best model with <var>i</var> variables in terms of
validation error.  The result is <code>NA</code> if a comparison is not
possible (may happen if <code><var>pruning.keep.best</var></code> is
<code>FALSE</code>).  If branching is not used, this is <code>NULL</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warnings</code></td>
<td>
<p> warnings stored.  A <code>list</code> of objects that
evaluate to a <code>character</code> string. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.warn</code></td>
<td>
<p> number of warnings produced.  May be higher than number
of warnings stored. </p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Mikko Korpela </p>


<h3>References</h3>

<p>Tikka, J. and Hollmén, J. (2008) Sequential input
selection algorithm for long-term prediction of time series.
<em>Neurocomputing</em>, 71(13–15):2604–2615.
</p>


<h3>See Also</h3>

<p>See <code>magic</code> for information about the algorithm used for
estimating the regularization parameter and the corresponding linear
model when <code><var>use.magic</var></code> is <code>TRUE</code>.
</p>
<p>See <code>summary.sisal</code> for how to extract information from
the returned object.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(stats)
set.seed(123)
X &lt;- cbind(sine=sin((1:100)/5),
           linear=seq(from=-1, to=1, length.out=100),
           matrix(rnorm(800), 100, 8,
                  dimnames=list(NULL, paste("random", 1:8, sep="."))))
y &lt;- drop(X %*% c(3, 10, 1, rep(0, 7)) + rnorm(100))
foo &lt;- sisal(X, y, Mtimes=10, kfold=5)
print(foo)           # selected inputs "L.v" are same as
summary(foo$lm.full) # significant coefficients of full model
</code></pre>


</div>