<div class="container">

<table style="width: 100%;"><tr>
<td>wschisq</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Weighted sums of non-central chi squared random variables</h2>

<h3>Description</h3>

<p>Approximated density, distribution, and quantile functions for
weighted sums of non-central chi squared random variables:
</p>
<p style="text-align: center;"><code class="reqn">Q_K = \sum_{i = 1}^K w_i \chi^2_{d_i}(\lambda_i),</code>
</p>

<p>where <code class="reqn">w_1, \ldots, w_n</code> are positive weights, <code class="reqn">d_1, \ldots, d_n</code>
are positive degrees of freedom, and <code class="reqn">\lambda_1, \ldots, \lambda_n</code>
are non-negative non-centrality parameters. Also, simulation of <code class="reqn">Q_K</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">d_wschisq(x, weights, dfs, ncps = 0, method = c("I", "SW", "HBE")[1],
  exact_chisq = TRUE, imhof_epsabs = 1e-06, imhof_epsrel = 1e-06,
  imhof_limit = 10000, grad_method = "simple",
  grad_method.args = list(eps = 1e-07))

p_wschisq(x, weights, dfs, ncps = 0, method = c("I", "SW", "HBE", "MC")[1],
  exact_chisq = TRUE, imhof_epsabs = 1e-06, imhof_epsrel = 1e-06,
  imhof_limit = 10000, M = 10000, MC_sample = NULL)

q_wschisq(u, weights, dfs, ncps = 0, method = c("I", "SW", "HBE", "MC")[1],
  exact_chisq = TRUE, imhof_epsabs = 1e-06, imhof_epsrel = 1e-06,
  imhof_limit = 10000, nlm_gradtol = 1e-06, nlm_iterlim = 1000,
  M = 10000, MC_sample = NULL)

r_wschisq(n, weights, dfs, ncps = 0)

cutoff_wschisq(thre = 1e-04, weights, dfs, ncps = 0, log = FALSE,
  x_tail = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of quantiles.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>vector with the positive weights of the sum. Must have the
same length as <code>dfs</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dfs</code></td>
<td>
<p>vector with the positive degrees of freedom of the chi squared
random variables. Must have the same length as <code>weights</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncps</code></td>
<td>
<p>non-centrality parameters. Either <code>0</code> (default) or a
vector with the same length as <code>weights</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>method for approximating the density, distribution, or
quantile function. Must be <code>"I"</code> (Imhof), <code>"SW"</code>
(Satterthwaite–Welch), <code>"HBE"</code> (Hall–Buckley–Eagleson), or
<code>"MC"</code> (Monte Carlo; only for distribution or quantile functions).
Defaults to <code>"I"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exact_chisq</code></td>
<td>
<p>if <code>weights</code> and <code>dfs</code> have length one, shall
the <code>Chisquare</code> functions be called? Otherwise, the
approximations are computed for this exact case. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imhof_epsabs, imhof_epsrel, imhof_limit</code></td>
<td>
<p>precision parameters passed to
<code>imhof</code>'s <code>epsabs</code>, <code>epsrel</code>, and
<code>limit</code>, respectively. They default to <code>1e-6</code>, <code>1e-6</code>,
and <code>1e4</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grad_method, grad_method.args</code></td>
<td>
<p>numerical differentiation parameters
passed to <code>grad</code>'s <code>method</code> and
<code>method.args</code>, respectively. They default to <code>"simple"</code>,
and <code>list(eps = 1e-7)</code> (better precision than <code>imhof_epsabs</code> to
avoid numerical artifacts).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>number of Monte Carlo samples for approximating the distribution if
<code>method = "MC"</code>. Defaults to <code>1e4</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MC_sample</code></td>
<td>
<p>if provided, it is employed when <code>method = "MC"</code>. If
not, it is computed internally.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>u</code></td>
<td>
<p>vector of probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlm_gradtol, nlm_iterlim</code></td>
<td>
<p>convergence control parameters passed to
<code>nlm</code>'s <code>gradtol</code> and <code>iterlim</code>, respectively.
They default to <code>1e-6</code> and <code>1e3</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>sample size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thre</code></td>
<td>
<p>vector with the error thresholds of the tail probability and
mean/variance explained by the first terms of the series. Defaults to
<code>1e-4</code>. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>are <code>weights</code> and <code>dfs</code> given in log-scale? Defaults to
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_tail</code></td>
<td>
<p>scalar evaluation point for determining the upper tail
probability. If <code>NULL</code>, set to the <code>0.90</code> quantile of the whole
series, computed by the <code>"HBE"</code> approximation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Four methods are implemented for approximating the distribution of a
weighted sum of chi squared random variables:
</p>

<ul>
<li> <p><code>"I"</code>: Imhof's approximation (Imhof, 1961) for the evaluation
of the distribution function. If this method is selected, the function
is simply a wrapper to <code>imhof</code> from the
<code>CompQuadForm</code> package (Duchesne and Lafaye De Micheaux, 2010).
</p>
</li>
<li> <p><code>"SW"</code>: Satterthwaite–Welch (Satterthwaite, 1946; Welch, 1938)
approximation, consisting in matching the first <em>two</em> moments of
<code class="reqn">Q_K</code> with a gamma distribution.
</p>
</li>
<li> <p><code>"HBE"</code>: Hall–Buckley–Eagleson (Hall, 1983; Buckley and
Eagleson, 1988) approximation, consisting in matching the first
<em>three</em> moments of <code class="reqn">Q_K</code> with a gamma distribution.
</p>
</li>
<li> <p><code>"MC"</code>: Monte Carlo approximation using the empirical
cumulative distribution function with <code>M</code> simulated samples.
</p>
</li>
</ul>
<p>The Imhof method is exact up to the prescribed numerical accuracy. It is
also the most time-consuming method. The density and quantile functions
for this approximation are obtained by numerical differentiation and
inversion, respectively, of the approximated distribution.
</p>
<p>For the methods based on gamma matching, the <code>GammaDist</code>
density, distribution, and quantile functions are invoked. The
Hall–Buckley–Eagleson approximation tends to overperform the
Satterthwaite–Welch approximation.
</p>
<p>The Monte Carlo method is relatively inaccurate and slow, but serves as an
unbiased reference of the true distribution function. The inversion of the
empirical cumulative distribution is done by <code>quantile</code>.
</p>
<p>An empirical comparison of these and other approximation methods is
given in Bodenham and Adams (2016).
</p>
<p><code>cutoff_wschisq</code> removes <code>NA</code>s/<code>NaN</code>s in <code>weights</code> or
<code>dfs</code> with a message. The threshold <code>thre</code> ensures that the
tail probability of the truncated and whole series differ less than
<code>thre</code> at <code>x_tail</code>, or that <code>thre</code> is the proportion of the
mean/variance of the whole series that is <em>not</em> retained. The (upper)
tail probabilities for evaluating truncation are computed using the
Hall–Buckley–Eagleson approximation at <code>x_tail</code>.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>d_wschisq</code>: density function evaluated at <code>x</code>, a vector.
</p>
</li>
<li> <p><code>p_wschisq</code>: distribution function evaluated at <code>x</code>,
a vector.
</p>
</li>
<li> <p><code>q_wschisq</code>: quantile function evaluated at <code>u</code>, a vector.
</p>
</li>
<li> <p><code>r_wschisq</code>: a vector of size <code>n</code> containing a random
sample.
</p>
</li>
<li> <p><code>cutoff_wschisq</code>: a data frame with the indexes up to which the
truncated series explains the tail probability with absolute error
<code>thre</code>, or the proportion of the mean/variance of the whole series
that is <em>not</em> explained by the truncated series.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Eduardo García-Portugués and Paula Navarro-Esteban.
</p>


<h3>References</h3>

<p>Bodenham, D. A. and Adams, N. M. (2016). A comparison of efficient
approximations for a weighted sum of chi-squared random variables.
<em>Statistics and Computing</em>, 26(4):917–928.
<a href="https://doi.org/10.1007/s11222-015-9583-4">doi:10.1007/s11222-015-9583-4</a>
</p>
<p>Buckley, M. J. and Eagleson, G. K. (1988). An approximation to the
distribution of quadratic forms in normal random variables.
<em>Australian Journal of Statistics</em>, 30(1):150–159.
<a href="https://doi.org/10.1111/j.1467-842X.1988.tb00471.x">doi:10.1111/j.1467-842X.1988.tb00471.x</a>
</p>
<p>Duchesne, P. and Lafaye De Micheaux, P. (2010) Computing the distribution
of quadratic forms: Further comparisons between the Liu–Tang–Zhang
approximation and exact methods. <em>Computational Statistics and Data
Analysis</em>, 54(4):858–862. <a href="https://doi.org/10.1016/j.csda.2009.11.025">doi:10.1016/j.csda.2009.11.025</a>
</p>
<p>Hall, P. (1983). Chi squared approximations to the distribution of a sum
of independent random variables. <em>Annals of Probability</em>,
11(4):1028–1036. <a href="https://doi.org/10.1214/aop/1176993451">doi:10.1214/aop/1176993451</a>
</p>
<p>Imhof, J. P. (1961). Computing the distribution of quadratic forms in normal
variables. <em>Biometrika</em>, 48(3/4):419–426.
<a href="https://doi.org/10.2307/2332763">doi:10.2307/2332763</a>
</p>
<p>Satterthwaite, F. E. (1946). An approximate distribution of estimates of
variance components. <em>Biometrics Bulletin</em>, 2(6):110–114.
<a href="https://doi.org/10.2307/3002019">doi:10.2307/3002019</a>
</p>
<p>Welch, B. L. (1938). The significance of the difference between two means
when the population variances are unequal. <em>Biometrika</em>,
29(3/4):350–362. <a href="https://doi.org/10.2307/2332010">doi:10.2307/2332010</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Plotting functions for the examples
add_approx_dens &lt;- function(x, dfs, weights, ncps) {

  lines(x, d_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "SW", exact_chisq = FALSE), col = 3)
  lines(x, d_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "HBE", exact_chisq = FALSE), col = 4)
  lines(x, d_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "I", exact_chisq = TRUE), col = 2)
  legend("topright", legend = c("True", "SW", "HBE", "I"), lwd = 2,
         col = c(1, 3:4, 2))

}
add_approx_distr &lt;- function(x, dfs, weights, ncps, ...) {

  lines(x, p_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "SW", exact_chisq = FALSE), col = 3)
  lines(x, p_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "HBE", exact_chisq = FALSE), col = 4)
  lines(x, p_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "MC", exact_chisq = FALSE), col = 5,
                     type = "s")
  lines(x, p_wschisq(x, weights = weights, dfs = dfs, ncps = ncps,
                     method = "I", exact_chisq = TRUE), col = 2)
  legend("bottomright", legend = c("True", "SW", "HBE", "MC", "I"), lwd = 2,
         col = c(1, 3:5, 2))

}
add_approx_quant &lt;- function(u, dfs, weights, ncps, ...) {

  lines(u, q_wschisq(u, weights = weights, dfs = dfs, ncps = ncps,
                     method = "SW", exact_chisq = FALSE), col = 3)
  lines(u, q_wschisq(u, weights = weights, dfs = dfs, ncps = ncps,
                     method = "HBE", exact_chisq = FALSE), col = 4)
  lines(u, q_wschisq(u, weights = weights, dfs = dfs, ncps = ncps,
                     method = "MC", exact_chisq = FALSE), col = 5,
                     type = "s")
  lines(u, q_wschisq(u, weights = weights, dfs = dfs, ncps = ncps,
                     method = "I", exact_chisq = TRUE), col = 2)
  legend("topleft", legend = c("True", "SW", "HBE", "MC", "I"), lwd = 2,
         col = c(1, 3:5, 2))

}

# Validation plots for density, distribution, and quantile functions
u &lt;- seq(0.01, 0.99, l = 100)
old_par &lt;- par(mfrow = c(1, 3))

# Case 1: 1 * ChiSq_3(0) + 1 * ChiSq_3(0) = ChiSq_6(0)
weights &lt;- c(1, 1)
dfs &lt;- c(3, 3)
ncps &lt;- 0
x &lt;- seq(-1, 30, l = 100)
main &lt;- expression(1 * chi[3]^2 * (0) + 1 * chi[3]^2 * (0))
plot(x, dchisq(x, df = 6), type = "l", main = main, ylab = "Density")
add_approx_dens(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(x, pchisq(x, df = 6), type = "l", main = main, ylab = "Distribution")
add_approx_distr(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(u, qchisq(u, df = 6), type = "l", main = main, ylab = "Quantile")
add_approx_quant(u = u, weights = weights, dfs = dfs, ncps = ncps)

# Case 2: 2 * ChiSq_3(1) + 1 * ChiSq_6(0.5) + 0.5 * ChiSq_12(0.25)
weights &lt;- c(2, 1, 0.5)
dfs &lt;- c(3, 6, 12)
ncps &lt;- c(1, 0.5, 0.25)
x &lt;- seq(0, 70, l = 100)
main &lt;- expression(2 * chi[3]^2 * (1)+ 1 * chi[6]^2 * (0.5) +
                   0.5 * chi[12]^2 * (0.25))
samp &lt;- r_wschisq(n = 1e4, weights = weights, dfs = dfs, ncps = ncps)
hist(samp, breaks = 50, freq = FALSE, main = main, ylab = "Density",
     xlim = range(x), xlab = "x"); box()
add_approx_dens(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(x, ecdf(samp)(x), main = main, ylab = "Distribution", type = "s")
add_approx_distr(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(u, quantile(samp, probs = u), type = "s", main = main,
     ylab = "Quantile")
add_approx_quant(u = u, weights = weights, dfs = dfs, ncps = ncps)

# Case 3: \sum_{k = 1}^K k^(-3) * ChiSq_{5k}(1 / k^2)
K &lt;- 1e2
weights&lt;- 1 / (1:K)^3
dfs &lt;- 5 * 1:K
ncps &lt;- 1 / (1:K)^2
x &lt;- seq(0, 25, l = 100)
main &lt;- substitute(sum(k^(-3) * chi[5 * k]^2 * (1 / k^2), k == 1, K),
                   list(K = K))
samp &lt;- r_wschisq(n = 1e4, weights = weights, dfs = dfs, ncps = ncps)
hist(samp, breaks = 50, freq = FALSE, main = main, ylab = "Density",
     xlim = range(x), xlab = "x"); box()
add_approx_dens(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(x, ecdf(samp)(x), main = main, ylab = "Distribution", type = "s")
add_approx_distr(x = x, weights = weights, dfs = dfs, ncps = ncps)
plot(u, quantile(samp, probs = u), type = "s", main = main,
     ylab = "Quantile")
add_approx_quant(u = u, weights = weights, dfs = dfs, ncps = ncps)
par(old_par)

# Cutoffs for infinite series of the last example
K &lt;- 1e7
log_weights&lt;- -3 * log(1:K)
log_dfs &lt;- log(5) + log(1:K)
(cutoff &lt;- cutoff_wschisq(thre = 10^(-(1:4)), weights = log_weights,
                          dfs = log_dfs, log = TRUE))

# Approximation
x &lt;- seq(0, 25, l = 100)
l &lt;- length(cutoff$mean)
main &lt;- expression(sum(k^(-3) * chi[5 * k]^2, k == 1, K))
col &lt;- viridisLite::viridis(l)
plot(x, d_wschisq(x, weights = exp(log_weights[1:cutoff$mean[l]]),
                  dfs = exp(log_dfs[1:cutoff$mean[l]])), type = "l",
     ylab = "Density", col = col[l], lwd = 3)
for(i in rev(seq_along(cutoff$mean)[-l])) {
  lines(x, d_wschisq(x, weights = exp(log_weights[1:cutoff$mean[i]]),
                     dfs = exp(log_dfs[1:cutoff$mean[i]])), col = col[i])
}
legend("topright", legend = paste0(rownames(cutoff), " (", cutoff$mean, ")"),
       lwd = 2, col = col)

</code></pre>


</div>