<div class="container">

<table style="width: 100%;"><tr>
<td>fitmaxstab</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fits a max-stable process to data</h2>

<h3>Description</h3>

<p>This function fits max-stable processes to data using
pairwise likelihood. Two max-stable characterisations are available:
the Smith and Schlather representations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fitmaxstab(data,  coord, cov.mod, loc.form, scale.form,
shape.form, marg.cov = NULL, temp.cov = NULL, temp.form.loc = NULL,
temp.form.scale = NULL, temp.form.shape = NULL, iso = FALSE, ...,
fit.marge = FALSE, warn = TRUE, method = "Nelder", start, control =
list(), weights = NULL, corr = FALSE, check.grad
= FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A matrix representing the data. Each column corresponds to
one location.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coord</code></td>
<td>
<p>A matrix that gives the coordinates of each
location. Each row corresponds to one location.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov.mod</code></td>
<td>
<p>A character string corresponding to the covariance
model in the max-stable representation. Must be one of "gauss" for
the Smith's model; "whitmat", "cauchy", "powexp", "bessel" or
"caugen" for the Whittle-Matern, the Cauchy, the Powered Exponential, the
Bessel and the Generalized Cauchy correlation families with the
Schlather's model; "brown" for Brown-Resnick processes. The
geometric Gaussian and Extremal-t models with a Whittle-Matern
correlation function can be fitted by passing respectively
"gwhitmat" or "twhitmat". Other correlation function families are
considered in a similar way.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loc.form, scale.form, shape.form</code></td>
<td>
<p>R formulas defining the
spatial linear model for the GEV parameters. May be missing. See
section Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>marg.cov</code></td>
<td>
<p>Matrix with named columns giving additional covariates
for the GEV parameters. If <code>NULL</code>, no extra covariates are
used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>temp.cov</code></td>
<td>
<p>Matrix with names columns giving additional *temporal*
covariates for the GEV parameters. If <code>NULL</code>, no temporal trend
are assume for the GEV parameters — see section Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>temp.form.loc, temp.form.scale, temp.form.shape</code></td>
<td>
<p>R formulas
defining the temporal trends for the GEV parameters. May be
missing. See section Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iso</code></td>
<td>
<p>Logical. If <code>TRUE</code> an isotropic model is fitted to
data. Otherwise (default), anisotropy is allowed. Currently, this is
only implemented for the Smith's model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Several arguments to be passed to the
<code>optim</code>, <code>nlm</code> or <code>nlminb</code>
functions. See section details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit.marge</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the GEV parameters
are estimated pointwise or using the formulas given by
<code>loc.form</code>, <code>scale.form</code> and <code>shape.form</code>. If
<code>FALSE</code>, observations are supposed to be unit Frechet
distributed. Note that when formulas are given, <code>fit.marge</code> is
automatically set to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), users are warned if
the log-likelihood is infinite at starting values and/or problems
arised while computing the standard errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The method used for the numerical optimisation
procedure. Must be one of <code>BFGS</code>, <code>Nelder-Mead</code>,
<code>CG</code>, <code>L-BFGS-B</code>, <code>SANN</code>, <code>nlm</code> or
<code>nlminb</code>. See <code>optim</code> for details. Please note that
passing <code>nlm</code> or <code>nlminb</code> will use the <code>nlm</code>
or <code>nlminb</code> functions instead of <code>optim</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>A named list giving the initial values for the
parameters over which the pairwise likelihood is to be minimized. If
<code>start</code> is omitted the routine attempts to find good starting
values - but might fail.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>A list giving the control parameters to be passed to
the <code>optim</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>A numeric vector specifying the weights in the pairwise
likelihood - and so has length the number of pairs. If <code>NULL</code>
(default), no weighting scheme is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corr</code></td>
<td>
<p>Logical. If <code>TRUE</code> (non default), the asymptotic
correlation matrix is computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check.grad</code></td>
<td>
<p>Logical. If <code>TRUE</code> (non default), the analytic
gradient of the pairwise likelihood will be compared to the
numerical one. Such a checking might be usefull for ill-conditionned
situation diagnosis.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>As spatial data often deal with a large number of locations, it is
impossible to write analytically the joint distribution. Consequently,
the fitting procedure substitutes the "full likelihood" for the
pairwise likelihood.
</p>
<p>Let define <code class="reqn">L_{i,j}(x_{i,j}, \theta)</code> the
likelihood for site <code class="reqn">i</code> and <code class="reqn">j</code>, where <code class="reqn">i = 1,
  \dots, N-1</code>, <code class="reqn">j = i+1, \dots, N</code>, <code class="reqn">N</code> is the number of site within the region and
<code class="reqn">x_{i,j}</code> are the joint observations for site <code class="reqn">i</code>
and <code class="reqn">j</code>. Then the pairwise likelihood
<code class="reqn">PL(\theta)</code> is defined by:
</p>
<p style="text-align: center;"><code class="reqn">\ell_P = \log PL(\theta) = \sum_{i = 1}^{N-1} \sum_{j=i+1}^{N} \log
  L_{i,j} (x_{i,j}, \theta)</code>
</p>

<p>As pairwise likelihood is an approximation of the “full likelihood”,
standard errors cannot be computed directly by the inverse of the
Fisher information matrix. Instead, a sandwich estimate must be used
to account for model mispecification e.g.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\theta} \sim N(\theta, H^{-1} J H^{-1})</code>
</p>

<p>where <code class="reqn">H</code> is the Fisher information matrix (computed from the
misspecified model) and <code class="reqn">J</code> is the variance of the score
function.
</p>














<p>There are two different kind of covariates : "spatial" and
"temporal".
</p>
<p>A "spatial" covariate may have different values accross station but
does not depend on time. For example the coordinates of the stations
are obviously "spatial". These "spatial" covariates should be used
with the <code>marg.cov</code> and <code>loc.form, scale.form, shape.form</code>.
</p>
<p>A "temporal" covariates may have different values accross time but
does not depend on space. For example the years where the annual
maxima were recorded is "temporal". These "temporal" covariates should
be used with the <code>temp.cov</code> and <code>temp.form.loc,
    temp.form.scale, temp.form.shape</code>.
</p>
<p>As a consequence note that <code>marg.cov</code> must have K rows (K being
the number of sites) while <code>temp.cov</code> must have n rows (n being
the number of observations).
</p>


<h3>Value</h3>

<p>This function returns a object of class <code>maxstab</code>. Such objects
are list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>A vector containing the estimated parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>std.err</code></td>
<td>
<p>A vector containing the standard errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixed</code></td>
<td>
<p>A vector containing the parameters of the model that
have been held fixed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param</code></td>
<td>
<p>A vector containing all parameters (optimised and fixed).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deviance</code></td>
<td>
<p>The (pairwise) deviance at the maximum pairwise
likelihood estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corr</code></td>
<td>
<p>The correlation matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convergence, counts, message</code></td>
<td>
<p>Components taken from the
list returned by <code>optim</code> - for the <code>mle</code> method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>The data analysed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The max-stable characterisation used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit.marge</code></td>
<td>
<p>A logical that specifies if the GEV margins were
estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov.fun</code></td>
<td>
<p>The estimated covariance function - for the Schlather
model only.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extCoeff</code></td>
<td>
<p>The estimated extremal coefficient function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov.mod</code></td>
<td>
<p>The covariance model for the spatial structure.</p>
</td>
</tr>
</table>
<h3>Warning</h3>

<p>When using reponse surfaces to model spatially the GEV parameters, the
likelihood is pretty rough so that the general purpose optimization
routines may fail. It is your responsability to check if the
numerical optimization succeeded or not. I tried, as best as I can, to
provide warning messages if the optimizers failed but in some cases,
no warning will appear!
</p>


<h3>Author(s)</h3>

<p>Mathieu Ribatet</p>


<h3>References</h3>

<p>Cox, D. R. and Reid, N. (2004) A note on pseudo-likelihood constructed
from marginal densities. <em>Biometrika</em> <b>91</b>, 729–737.
</p>
<p>Demarta, S. and McNeil, A. (2005) The t copula and Related Copulas
<em>International Statistical Review</em> <b>73</b>, 111-129.
</p>
<p>Gholam–Rezaee, M. (2009) Spatial extreme value: A composite
likelihood. PhD Thesis. Ecole Polytechnique Federale de Lausanne.
</p>
<p>Kabluchko, Z., Schlather, M. and de Haan, L. (2009) Stationary
max-stable fields associated to negative definite functions
<em>Annals of Probability</em> <b>37</b>:5, 2042–2065.
</p>
<p>Padoan, S. A. (2008) Computational Methods for Complex Problems in
Extreme Value Theory. PhD Thesis. University of Padova.
</p>
<p>Padoan, S. A., Ribatet, M. and Sisson, S. A. (2010) Likelihood-based
inference for max-stable processes. <em>Journal of the American
Statistical Association (Theory and Methods)</em> <b>105</b>:489,
263-277.
</p>
<p>Schlather, M. (2002) Models for Stationary Max-Stable Random
Fields. <em>Extremes</em> <b>5</b>:1, 33–44.
</p>
<p>Smith, R. L. (1990) Max-stable processes and spatial
extremes. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
##Define the coordinate of each location
n.site &lt;- 30
locations &lt;- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) &lt;- c("lon", "lat")

##Simulate a max-stable process - with unit Frechet margins
data &lt;- rmaxstab(40, locations, cov.mod = "whitmat", nugget = 0, range = 3,
smooth = 0.5)

##Now define the spatial model for the GEV parameters
param.loc &lt;- -10 + 2 * locations[,2]
param.scale &lt;- 5 + 2 * locations[,1] + locations[,2]^2
param.shape &lt;- rep(0.2, n.site)

##Transform the unit Frechet margins to GEV
for (i in 1:n.site)
  data[,i] &lt;- frech2gev(data[,i], param.loc[i], param.scale[i],
param.shape[i])

##Define a model for the GEV margins to be fitted
##shape ~ 1 stands for the GEV shape parameter is constant
##over the region
loc.form &lt;- loc ~ lat
scale.form &lt;- scale ~ lon + I(lat^2)
shape.form &lt;- shape ~ 1

##Fit a max-stable process using the Schlather's model
fitmaxstab(data, locations, "whitmat", loc.form, scale.form,
           shape.form)

## Model without any spatial structure for the GEV parameters
## Be careful this could be *REALLY* time consuming
fitmaxstab(data, locations, "whitmat")

##  Fixing the smooth parameter of the Whittle-Matern family
##  to 0.5 - e.g. considering exponential family. We suppose the data
##  are unit Frechet here.
fitmaxstab(data, locations, "whitmat", smooth = 0.5, fit.marge = FALSE)

##  Fitting a penalized smoothing splines for the margins with the
##     Smith's model
data &lt;- rmaxstab(40, locations, cov.mod = "gauss", cov11 = 100, cov12 =
                 25, cov22 = 220)

##     And transform it to ordinary GEV margins with a non-linear
##     function
fun &lt;- function(x)
  2 * sin(pi * x / 4) + 10
fun2 &lt;- function(x)
  (fun(x) - 7 ) / 15

param.loc &lt;- fun(locations[,2])
param.scale &lt;- fun(locations[,2])
param.shape &lt;- fun2(locations[,1])

##Transformation from unit Frechet to common GEV margins
for (i in 1:n.site)
  data[,i] &lt;- frech2gev(data[,i], param.loc[i], param.scale[i],
param.shape[i])

##Defining the knots, penalty, degree for the splines
n.knots &lt;- 5
knots &lt;- quantile(locations[,2], prob = 1:n.knots/(n.knots+1))
knots2 &lt;- quantile(locations[,1], prob = 1:n.knots/(n.knots+1))

##Be careful the choice of the penalty (i.e. the smoothing parameter)
##may strongly affect the result Here we use p-splines for each GEV
##parameter - so it's really CPU demanding but one can use 1 p-spline
##and 2 linear models.
##A simple linear model will be clearly faster...
loc.form &lt;- y ~ rb(lat, knots = knots, degree = 3, penalty = .5)
scale.form &lt;- y ~ rb(lat, knots = knots, degree = 3, penalty = .5)
shape.form &lt;- y ~ rb(lon, knots = knots2, degree = 3, penalty = .5)

fitted &lt;- fitmaxstab(data, locations, "gauss", loc.form, scale.form, shape.form,
                     control = list(ndeps = rep(1e-6, 24), trace = 10),
                     method = "BFGS")
fitted
op &lt;- par(mfrow=c(1,3))
plot(locations[,2], param.loc, col = 2, ylim = c(7, 14),
     ylab = "location parameter", xlab = "latitude")
plot(fun, from = 0, to = 10, add = TRUE, col = 2)
points(locations[,2], predict(fitted)[,"loc"], col = "blue", pch = 5)
new.data &lt;- cbind(lon = seq(0, 10, length = 100), lat = seq(0, 10, length = 100))
lines(new.data[,1], predict(fitted, new.data)[,"loc"], col = "blue")
legend("topleft", c("true values", "predict. values", "true curve", "predict. curve"),
       col = c("red", "blue", "red", "blue"), pch = c(1, 5, NA, NA), inset = 0.05,
       lty = c(0, 0, 1, 1), ncol = 2)

plot(locations[,2], param.scale, col = 2, ylim = c(7, 14),
     ylab = "scale parameter", xlab = "latitude")
plot(fun, from = 0, to = 10, add = TRUE, col = 2)
points(locations[,2], predict(fitted)[,"scale"], col = "blue", pch = 5)
lines(new.data[,1], predict(fitted, new.data)[,"scale"], col = "blue")
legend("topleft", c("true values", "predict. values", "true curve", "predict. curve"),
       col = c("red", "blue", "red", "blue"), pch = c(1, 5, NA, NA), inset = 0.05,
       lty = c(0, 0, 1, 1), ncol = 2)

plot(locations[,1], param.shape, col = 2,
     ylab = "shape parameter", xlab = "longitude")
plot(fun2, from = 0, to = 10, add = TRUE, col = 2)
points(locations[,1], predict(fitted)[,"shape"], col = "blue", pch = 5)
lines(new.data[,1], predict(fitted, new.data)[,"shape"], col = "blue")
legend("topleft", c("true values", "predict. values", "true curve", "predict. curve"),
       col = c("red", "blue", "red", "blue"), pch = c(1, 5, NA, NA), inset = 0.05,
       lty = c(0, 0, 1, 1), ncol = 2)
par(op)

## End(Not run)
</code></pre>


</div>