<div class="container">

<table style="width: 100%;"><tr>
<td>fit_sgo_cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit an SGO model using k-fold cross-validation.</h2>

<h3>Description</h3>

<p>Function to fit a pathwise solution of sparse-group SLOPE (SGO) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fit_sgo_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  nfolds = 10,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  v_weights = NULL,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li>
<p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between OSCAR and gOSCAR. Must be between 0 and 1. Recommended value is 0.95.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Fits SGO models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>all_models</code></td>
<td>
<p>A list of all the models fitted along the path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"sgs"</code> object type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>


<h3>See Also</h3>

<p><code>fit_sgo()</code>
</p>
<p>Other model-selection: 
<code>as_sgs()</code>,
<code>fit_goscar_cv()</code>,
<code>fit_gslope_cv()</code>,
<code>fit_sgs_cv()</code>,
<code>scaled_sgs()</code>
</p>
<p>Other SGS-methods: 
<code>as_sgs()</code>,
<code>coef.sgs()</code>,
<code>fit_sgo()</code>,
<code>fit_sgs()</code>,
<code>fit_sgs_cv()</code>,
<code>plot.sgs()</code>,
<code>predict.sgs()</code>,
<code>print.sgs()</code>,
<code>scaled_sgs()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGO with cross-validation
cv_model = fit_sgo_cv(X = data$X, y = data$y, groups=groups, type = "linear", 
path_length = 5, nfolds=5, alpha = 0.95, min_frac = 0.05, 
standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>


</div>