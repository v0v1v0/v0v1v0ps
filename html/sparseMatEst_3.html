<div class="container">

<table style="width: 100%;"><tr>
<td>sparseCov</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sparse covariance matrix estimator with error control</h2>

<h3>Description</h3>

<p>Given a data matrix, <code>sparseCov</code> estimates the covariance
matrix for the data under the assumption that the true covariance
matrix is sparse, i.e. that most of the off-diagonal entries are
equal to zero.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sparseCov(dat, alf = 0.5, iter = 10, pnrm = Inf, THRSH = "hard")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>nxk data matrix, n observations, k dimensions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alf</code></td>
<td>
<p>false positive rate in [0,1], Default is 0.5</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>number of iterates, Default is 10</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pnrm</code></td>
<td>
<p>norm to use, Default = Inf</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>THRSH</code></td>
<td>
<p>Type of thresholding used;
Takes values: hard, soft, adpt, scad.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The algorithm begins with the empirical covariance estimator as
computed by <code>cov</code>.  It then iteratively computes covariance
estimators with false positive rates of <code>alf</code>, <code>alf</code>^2,
and so on until <code>iter</code> estimators have been constructed.
</p>
<p>The norm chosen determines the topology on the space of matrices.
<code>pnorm</code> defaults to <code>Inf</code> being the operator norm
or maximal eigenvalue.  This is theoretically justified to work
in the references.
Other norms could be considered, but their performance is not
a strong.
</p>
<p>Four thresholding methods are implemented.  <code>THRSH</code> defaults
to hard thresholding where small matrix entries are set to zero
while large entries are not affected.  The soft and adpt thresholds
shrink all entries towards zero.  The scad threshold interpolates
between hard and soft thresholding.  More details can be found
in the references.
</p>


<h3>Value</h3>

<p>a list of arrays containing <code>iter+1</code> sparse
covariance matrices corresponding to false positive rates of
<code>1</code>, <code>alf</code>,
<code>alf</code>^2,..., <code>alf</code>^<code>iter</code>.  Each list
corresponds to one type of thresholding chosen by <code>THRSH</code>.
</p>


<h3>Author(s)</h3>

<p>Adam B Kashlak <a href="mailto:kashlak@ualberta.ca">kashlak@ualberta.ca</a>
</p>


<h3>References</h3>

<p>Kashlak, Adam B., and Linglong Kong.
"A concentration inequality based methodology
for sparse covariance estimation." arXiv
preprint arXiv:1705.02679 (2017).
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Generate four sparse covariance matrix estimators
# with false positive rates of 0.5, 0.25, 0.125,
# and 0.0625
n = 30
k = 50
dat = matrix(rnorm(n*k),n,k)
out = sparseCov( dat, alf=0.5, iter=4, THRSH=c("hard","soft") )
  par(mfcol=c(2,2))
  lab = c(1,0.5,0.5^2,0.5^3,0.5^4);
  for( i in 2:5 )
    image( out$hard[,,i]!=0, main=lab[i] )
  for( i in 2:5 )
    image( log(abs(out$hard[,,i] - out$soft[,,i])), main=lab[i] )
</code></pre>


</div>