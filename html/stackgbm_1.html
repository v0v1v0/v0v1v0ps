<div class="container">

<table style="width: 100%;"><tr>
<td>stackgbm-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>stackgbm: Stacked Gradient Boosting Machines</h2>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style="float: right" alt="logo" width="120"></p>
<p>A minimalist implementation of model stacking by Wolpert (1992) <a href="https://doi.org/10.1016/S0893-6080%2805%2980023-1">doi:10.1016/S0893-6080(05)80023-1</a> for boosted tree models. A classic, two-layer stacking model is implemented, where the first layer generates features using gradient boosting trees, and the second layer employs a logistic regression model that uses these features as inputs. Utilities for training the base models and parameters tuning are provided, allowing users to experiment with different ensemble configurations easily. It aims to provide a simple and efficient way to combine multiple gradient boosting models to improve predictive model performance and robustness.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nan Xiao <a href="mailto:me@nanx.me">me@nanx.me</a> (<a href="https://orcid.org/0000-0002-0250-5673">ORCID</a>) [copyright holder]
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://nanx.me/stackgbm/">https://nanx.me/stackgbm/</a>
</p>
</li>
<li> <p><a href="https://github.com/nanxstats/stackgbm">https://github.com/nanxstats/stackgbm</a>
</p>
</li>
<li>
<p> Report bugs at <a href="https://github.com/nanxstats/stackgbm/issues">https://github.com/nanxstats/stackgbm/issues</a>
</p>
</li>
</ul>
</div>