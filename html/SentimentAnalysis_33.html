<div class="container">

<table style="width: 100%;"><tr>
<td>generateDictionary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generates dictionary of decisive terms</h2>

<h3>Description</h3>

<p>Routine applies method for dictionary generation (LASSO, ridge regularization, elastic net, 
ordinary least squares, generalized linear model or spike-and-slab regression) to 
the document-term matrix in order to extract decisive terms that 
have a statistically significant impact on the response variable.
</p>


<h3>Usage</h3>

<pre><code class="language-R">generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'Corpus'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'character'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'data.frame'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'TermDocumentMatrix'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)

## S3 method for class 'DocumentTermMatrix'
generateDictionary(
  x,
  response,
  language = "english",
  modelType = "lasso",
  filterTerms = NULL,
  control = list(),
  minWordLength = 3,
  sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A vector of characters, a <code>data.frame</code>, an object of type 
<code>Corpus</code>, <code>TermDocumentMatrix</code> or
<code>DocumentTermMatrix</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>Response variable including the given gold standard.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>language</code></td>
<td>
<p>Language used for preprocessing operations (default: 
English).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelType</code></td>
<td>
<p>A string denoting the estimation method. Allowed values are <code>lasso</code>, <code>ridge</code>, 
<code>enet</code>, <code>lm</code> or <code>glm</code> or <code>spikeslab</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>filterTerms</code></td>
<td>
<p>Optional vector of strings (default: <code>NULL</code>) to filter terms that are used
for dictionary generation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>(optional) A list of parameters defining the model used for dictionary generation.
</p>
<p>If <code>modelType=lasso</code> is selected, individual parameters are as follows:
</p>

<ul>
<li>
<p>"s" Value of the parameter lambda at which the LASSO is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li>
<p>"family" Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code>glmnet</code> for further details.
</p>
</li>
<li>
<p>"grouped" Determines whether grouped LASSO is used (with default <code>FALSE</code>).
</p>
</li>
</ul>
<p>If <code>modelType=ridge</code> is selected, individual parameters are as follows:
</p>

<ul>
<li>
<p>"s" Value of the parameter lambda at which the ridge is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li>
<p>"family" Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code>glmnet</code> for further details.
</p>
</li>
<li>
<p>"grouped" Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li>
</ul>
<p>If <code>modelType=enet</code> is selected, individual parameters are as follows:
</p>

<ul>
<li>
<p>"alpha" Abstraction parameter for switching between LASSO (with <code>alpha=1</code>) and
ridge regression (<code>alpha=0</code>). Default is <code>alpha=0.5</code>. Recommended option is to 
test different values between 0 and 1.
</p>
</li>
<li>
<p>"s" Value of the parameter lambda at which the elastic net is evaluated. Default
is <code>s="lambda.1se"</code> which takes the calculated minimum value for <code class="reqn">\lambda</code> 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
<code>lambda="lambda.min"</code>.
</p>
</li>
<li>
<p>"family" Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code>glmnet</code> for further details.
</p>
</li>
<li>
<p>"grouped" Determines whether grouped function is used (with default <code>FALSE</code>).
</p>
</li>
</ul>
<p>If <code>modelType=lm</code> is selected, no parameters are passed on. 
</p>
<p>If <code>modelType=glm</code> is selected, individual parameters are as follows:
</p>

<ul><li>
<p>"family" Distribution for response variable. Default is <code>family="gaussian"</code>.
For non-negative counts, use <code>family="poisson"</code>. For binary variables
<code>family="binomial"</code>. See <code>glm</code> for further details.
</p>
</li></ul>
<p>If <code>modelType=spikeslab</code> is selected, individual parameters are as follows:
</p>

<ul>
<li>
<p>"n.iter1" Number of burn-in Gibbs sampled values (i.e., discarded values). Default is 500.
</p>
</li>
<li>
<p>"n.iter2" Number of Gibbs sampled values, following burn-in. Default is 500.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minWordLength</code></td>
<td>
<p>Removes words given a specific minimum length (default: 3). This 
preprocessing is applied when the input is a character vector or a corpus and the
document-term matrix is generated inside the routine.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparsity</code></td>
<td>
<p>A numeric for removing sparse terms in the document-term matrix. The
argument <code>sparsity</code> specifies the maximal allowed sparsity. Default is 
<code>sparsity=0.9</code>, however, this is only applied when the document-term matrix
is calculated inside the routine.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weighting</code></td>
<td>
<p>Weights a document-term matrix by e.g. term frequency - inverse
document frequency (default). Other variants can be used from 
<code>DocumentTermMatrix</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional parameters passed to function for e.g. 
preprocessing or <code>glmnet</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Result is a matrix which sentiment values for each document across
all defined rules
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0209323">doi:10.1371/journal.pone.0209323</a>
</p>


<h3>References</h3>

<p>Pr\"ollochs and Feuerriegel (2018). Statistical inferences for 
Polarity Identification in Natural Language, PloS One 13(12).
</p>


<h3>See Also</h3>

<p><code>analyzeSentiment</code>, <code>predict.SentimentDictionaryWeighted</code>, 
<code>plot.SentimentDictionaryWeighted</code> and <code>compareToResponse</code> for
advanced evaluations
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Create a vector of strings
documents &lt;- c("This is a good thing!",
               "This is a very good thing!",
               "This is okay.",
               "This is a bad thing.",
               "This is a very bad thing.")
response &lt;- c(1, 0.5, 0, -0.5, -1)

# Generate dictionary with LASSO regularization
dictionary &lt;- generateDictionary(documents, response)

# Show dictionary
dictionary
summary(dictionary)
plot(dictionary)

# Compute in-sample performance
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)
plotSentimentResponse(sentiment, response)

# Generate new dictionary with spike-and-slab regression instead of LASSO regularization
library(spikeslab)
dictionary &lt;- generateDictionary(documents, response, modelType="spikeslab")

# Generate new dictionary with tf weighting instead of tf-idf

library(tm)
dictionary &lt;- generateDictionary(documents, response, weighting=weightTf)
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)

# Use instead lambda.min from the LASSO estimation
dictionary &lt;- generateDictionary(documents, response, control=list(s="lambda.min"))
sentiment &lt;- predict(dictionary, documents)
compareToResponse(sentiment, response)

# Use instead OLS as estimation method
dictionary &lt;- generateDictionary(documents, response, modelType="lm")
sentiment &lt;- predict(dictionary, documents)
sentiment

dictionary &lt;- generateDictionary(documents, response, modelType="lm", 
                                 filterTerms = c("good", "bad"))
sentiment &lt;- predict(dictionary, documents)
sentiment

dictionary &lt;- generateDictionary(documents, response, modelType="lm", 
                                 filterTerms = extractWords(loadDictionaryGI()))
sentiment &lt;- predict(dictionary, documents)
sentiment

# Generate dictionary without LASSO intercept
dictionary &lt;- generateDictionary(documents, response, intercept=FALSE)
dictionary$intercept
 
## Not run: 
imdb &lt;- loadImdb()

# Generate Dictionary
dictionary_imdb &lt;- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson")
summary(dictionary_imdb)

compareDictionaries(dictionary_imdb,
                    loadDictionaryGI())
                    
# Show estimated coefficients with Kernel Density Estimation (KDE)
plot(dictionary_imdb)
plot(dictionary_imdb) + xlim(c(-0.1, 0.1))

# Compute in-sample performance
pred_sentiment &lt;- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)

# Test a different sparsity parameter
dictionary_imdb &lt;- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson", sparsity=0.99)
summary(dictionary_imdb)
pred_sentiment &lt;- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)

## End(Not run)
</code></pre>


</div>