<div class="container">

<table style="width: 100%;"><tr>
<td>synthesisr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>synthesisr: Import, assemble, and deduplicate bibiliographic datasets</h2>

<h3>Description</h3>

<p>Systematic review searches include multiple databases
that export results in a variety of formats with overlap in
coverage between databases. To streamline the process of importing,
assembling, and deduplicating results, synthesisr recognizes
bibliographic files exported from databases commonly used for
systematic reviews and merges results into a standardized format.
</p>


<h3>Import &amp; Export</h3>

<p>The key task performed by <code>synthesisr</code> is flexible import and presentation of bibliographic data. This is typically achieved by <code>read_refs</code>, which can import multiple files at once and link them together into a single <code>data.frame</code>. Conversely, export is via <code>write_refs</code>. Users that require more detailed control can use the following functions:
</p>

<ul>
<li> <p><code>detect_</code> Detect file attributes
</p>
</li>
<li> <p><code>parse_</code> Parse a vector containing bibliographic data
</p>
</li>
<li> <p><code>clean_</code> Cleaning functions for author and column names
</p>
</li>
<li> <p><code>code_lookup</code> A dataset of potential ris tags
</p>
</li>
</ul>
<h3>Data formatting</h3>


<ul>
<li> <p><code>bibliography-class</code> Methods for class 'bibliography'
</p>
</li>
<li> <p><code>merge_columns</code> rbind two data.frames with different numbers of columns
</p>
</li>
<li> <p><code>format_citation</code> Return a clean citation from a bibliography or data.frame
</p>
</li>
<li> <p><code>add_line_breaks</code> Set a maximum character width for strings
</p>
</li>
</ul>
<h3>Deduplication</h3>

<p>When importing from multiple databases, it is likely that there will be duplicates in the resulting dataset. The easiest way to deal with this problem in <code>synthesisr</code> is using the <code>deduplicate</code> command; but this can be risky, particularly if there are no DOIs in the dataset. To get finer control of the deduplication process, consider using the sub-functions:
</p>

<ul>
<li> <p><code>find_duplicates</code> Locate potentially duplicated references
</p>
</li>
<li> <p><code>extract_unique_references</code> Return a data.frame with only 'unique' references
</p>
</li>
<li> <p><code>review_duplicates</code> Manually review potential duplicates
</p>
</li>
<li> <p><code>override_duplicates</code> Manually override identified duplicates
</p>
</li>
<li> <p><code>fuzz_</code> Fuzzy string matching c/o 'fuzzywuzzy'
</p>
</li>
<li> <p><code>string_</code> Fuzzy string matching c/o <code>stringdist</code>
</p>
</li>
</ul>
</div>