<div class="container">

<table style="width: 100%;"><tr>
<td>GSS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Golden Section Search for Minimising Univariate Function over a Closed
Interval</h2>

<h3>Description</h3>

<p>Golden Section Search (GSS) is a useful algorithm for minimising a
continuous univariate function <code class="reqn">f(x)</code> over an interval
<code class="reqn">\left[a,b\right]</code> in instances where the first derivative
<code class="reqn">f'(x)</code> is not easily obtainable, such as with loss functions
that need to be minimised under cross-validation to tune a
hyperparameter in a machine learning model. The method is described
by Fox (2021).
</p>


<h3>Usage</h3>

<pre><code class="language-R">GSS(f, a, b, tol = 1e-08, maxitgss = 100L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>A function of one variable that returns a numeric value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>A numeric of length 1 representing the lower endpoint of the
search interval</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>A numeric of length 1 representing the upper endpoint of the
search interval; must be greater than <code>a</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>A numeric of length 1 representing the tolerance used to
determine when the search interval has been narrowed sufficiently
for convergence</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxitgss</code></td>
<td>
<p>An integer of length 1 representing the maximum number
of iterations to use in the search</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to pass to <code>f</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function is modelled after a MATLAB function written by
 (). The method assumes that
there is one local minimum in this interval. The solution produced is
also an interval, the width of which can be made arbitrarily small by
setting a tolerance value. Since the desired solution is a single
point, the midpoint of the final interval can be taken as the best
approximation to the solution.
</p>
<p>The premise of the method is to shorten the interval
<code class="reqn">\left[a,b\right]</code> by comparing the values of the function at two
test points, <code class="reqn">x_1 &lt; x_2</code>, where <code class="reqn">x_1 = a + r(b-a)</code> and
<code class="reqn">x_2 = b - r(b-a)</code>, and <code class="reqn">r=(\sqrt{5}-1)/2\approx 0.618</code> is the
reciprocal of the golden ratio. One compares <code class="reqn">f(x_1)</code> to <code class="reqn">f(x_2)</code>
and updates the search interval <code class="reqn">\left[a,b\right]</code> as follows:
</p>

<ul>
<li>
<p> If <code class="reqn">f(x_1)&lt;f(x_2)</code>, the solution cannot lie in
<code class="reqn">\left[x_2,b\right]</code>;
thus, update the search interval to
</p>
<p style="text-align: center;"><code class="reqn">\left[a_\mathrm{new},b_\mathrm{new}\right]=\left[a,x_2\right]</code>
</p>

</li>
<li>
<p> If <code class="reqn">f(x_1)&gt;f(x_2)</code>, the solution cannot lie in
<code class="reqn">\left[a,x_1\right]</code>;
thus, update the search interval to
</p>
<p style="text-align: center;"><code class="reqn">\left[a_\mathrm{new},b_\mathrm{new}\right]=\left[x_1,b\right]</code>
</p>

</li>
</ul>
<p>One then chooses two new test points by replacing <code class="reqn">a</code> and <code class="reqn">b</code> with
<code class="reqn">a_\mathrm{new}</code> and <code class="reqn">b_\mathrm{new}</code> and recalculating <code class="reqn">x_1</code>
and <code class="reqn">x_2</code> based on these new endpoints. One continues iterating in
this fashion until <code class="reqn">b-a&lt; \tau</code>, where <code class="reqn">\tau</code> is the desired
tolerance.
</p>


<h3>Value</h3>

<p>A list object containing the following:
</p>

<ul>
<li> <p><code>argmin</code>, the argument of <code>f</code> that minimises <code>f</code>
</p>
</li>
<li> <p><code>funmin</code>, the minimum value of <code>f</code> achieved at <code>argmin</code>
</p>
</li>
<li> <p><code>converged</code>, a logical indicating whether the convergence tolerance
was satisfied
</p>
</li>
<li> <p><code>iterations</code>, an integer indicating the number of search iterations
used
</p>
</li>
</ul>
<h3>References</h3>

<p>(????).
<em>Golden Section Method Algorithm, author=Katarzyna Zarnowiec, organization=MATLAB Central File Exchange, url=https://www.mathworks.com/matlabcentral/fileexchange/25919-golden-section-method-algorithm, urldate=2022-10-19, year=2022, </em>.<br><br> Fox WP (2021).
<em>Nonlinear Optimization: Models and Applications</em>, 1st edition.
Chapman and Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code>goldsect</code> is similar to this function, but does
not allow the user to pass additional arguments to <code>f</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">f &lt;- function(x) (x - 1) ^ 2
GSS(f, a = 0, b = 2)

</code></pre>


</div>