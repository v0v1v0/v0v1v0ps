<div class="container">

<table style="width: 100%;"><tr>
<td>LOGISTIC_REGRESSION</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Logistic regression</h2>

<h3>Description</h3>

<p>Logistic regression analyses with SPSS- and SAS-like output. The output includes 
model summaries, classification tables, omnibus tests of model coefficients, 
the model coefficients, likelihood ratio tests for the predictors, overdispersion 
tests, model effect sizes, the correlation matrix for the model coefficients,
collinearity statistics, and casewise regression diagnostics.</p>


<h3>Usage</h3>

<pre><code class="language-R">LOGISTIC_REGRESSION(data, DV, forced = NULL, hierarchical = NULL,
                    ref_category = NULL,
                    family = 'binomial',
                    plot_type = 'residuals',
                    verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>A dataframe where the rows are cases and the columns are the variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DV</code></td>
<td>

<p>The name of the dependent variable. 
<br> Example: DV = 'outcomeVar'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>forced</code></td>
<td>

<p>(optional) A vector of the names of the predictor variables for a forced/simultaneous  
entry regression. The variables can be numeric or factors. 
<br> Example: forced = c('VarA', 'VarB', 'VarC')</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hierarchical</code></td>
<td>

<p>(optional) A list with the names of the predictor variables for each step of a 
hierarchical regression. The variables can be numeric or factors.
<br> Example: hierarchical = list(step1=c('VarA', 'VarB'), step2=c('VarC', 'VarD'))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ref_category</code></td>
<td>

<p>(optional) The reference category for DV. 
<br> Example: ref_category = 'alive'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>

<p>(optional) The name of the error distribution to be used in the model. The options are:
</p>

<ul>
<li>
<p>"binomial" (the default), or
</p>
</li>
<li>
<p>"quasibinomial", which should be used when there is overdispersion.
</p>
</li>
</ul>
<p>Example: family = 'quasibinomial'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot_type</code></td>
<td>

<p>(optional) The kind of plots, if any. The options are:
</p>

<ul>
<li>
<p>'residuals' (the default),
</p>
</li>
<li>
<p>'diagnostics', for regression diagnostics, and
</p>
</li>
<li>
<p>'none', for no plots.
</p>
</li>
</ul>
<p>Example: plot_type = 'diagnostics'</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>(optional) Should detailed results be displayed in console? <br> The options are: 
TRUE (default) or FALSE. If TRUE, plots of residuals are also produced.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function uses the glm function from the stats package and
supplements the output with additional statistics and in formats that resembles
SPSS and SAS output. The predictor variables can be numeric or factors.
</p>
<p>Predicted values for this model, for selected levels of the predictor variables,
can be produced and plotted using the PLOT_MODEL funtion in this package.
</p>
<p>Good sources for interpreting logistic regression residuals and diagnostics plots:
</p>

<ul>
<li>
<p><a href="https://rpubs.com/benhorvath/glm_diagnostics">rpubs.com/benhorvath</a>
</p>
</li>
<li>
<p><a href="https://library.virginia.edu/data/articles/understanding-deviance-residuals">library.virginia.edu</a>
</p>
</li>
<li>
<p><a href="https://online.stat.psu.edu/stat462/node/207/">online.stat.psu.edu</a>
</p>
</li>
</ul>
<h3>Value</h3>

<p>An object of class "LOGISTIC_REGRESSION". The object is a list containing the
following possible components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>modelMAIN</code></td>
<td>
<p>All of the glm function output for the regression model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelMAINsum</code></td>
<td>
<p>All of the summary.glm function output for the regression model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modeldata</code></td>
<td>
<p>All of the predictor and outcome raw data that were used in the model,
along with regression diagnostic statistics for each case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>collin_diags</code></td>
<td>
<p>Collinearity diagnostic coefficients for models without interaction terms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cormat</code></td>
<td>
<p>The correlation matrix for the model coefficients.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Brian P. O'Connor</p>


<h3>References</h3>

<p>Dunn, P. K., &amp; Smyth, G. K. (2018). <em>Generalized linear models 
with examples in R.</em> Springer.
<br><br> Field, A., Miles, J., &amp; Field, Z. (2012). 
<em>Discovering statistics using R.</em> Los Angeles, CA: Sage.
<br><br> Hair, J. F., Black, W. C., Babin, B. J., &amp; Anderson, R. E. (2014). 
<em>Multivariate data analysis,</em> (8th ed.).
Lawrence Erlbaum Associates.
<br><br> Hosmer, D. W., Lemeshow, S., &amp; Sturdivant, R. X. (2013) 
<em>Applied logistic regression.</em> (3rd ed.). John Wiley &amp; Sons.
<br><br> Orme, J. G., &amp; Combs-Orme, T. (2009). <em>Multiple regression with discrete 
dependent variables.</em> Oxford University Press.
<br><br> Pituch, K. A., &amp; Stevens, J. P. (2016). 
<em>Applied multivariate statistics for the social sciences: Analyses with 
SAS and IBM's SPSS,</em> (6th ed.). Routledge.
<br><br> Rindskopf, D. (2023). Generalized linear models. In H. Cooper, M. N. 
Coutanche, L. M. McMullen, A. T. Panter, D. Rindskopf, &amp; K. J. Sher (Eds.), 
<em>APA handbook of research methods in psychology: Data analysis and 
research publication, </em> (2nd ed., pp. 201-218). American Psychological Association.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># forced (simultaneous) entry
LOGISTIC_REGRESSION(data = data_Meyers_2013, DV='graduated', 
                    forced=c('sex','family_encouragement'),
                    plot_type = 'diagnostics')
	
# hierarchical entry, and using family = "quasibinomial"
LOGISTIC_REGRESSION(data = data_Kremelburg_2011, DV='OCCTRAIN',
                    hierarchical=list( step1=c('AGE'), step2=c('EDUC','REALRINC')),
                    family = "quasibinomial") 

</code></pre>


</div>