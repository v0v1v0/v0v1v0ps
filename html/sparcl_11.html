<div class="container">

<table style="width: 100%;"><tr>
<td>KMeansSparseCluster.permute</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Choose tuning parameter for sparse k-means clustering</h2>

<h3>Description</h3>

<p>The tuning parameter controls the L1 bound on w, the feature weights. A
permutation approach is used to select the tuning parameter.
</p>


<h3>Usage</h3>

<pre><code class="language-R">KMeansSparseCluster.permute(x, K=NULL, nperms = 25, wbounds = NULL,
silent = FALSE, nvals = 10, centers=NULL)
## S3 method for class 'KMeansSparseCluster.permute'
print(x,...)
## S3 method for class 'KMeansSparseCluster.permute'
plot(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The nxp data matrix, n is the number of observations and p
the number of features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>The number of clusters desired - that is, the "K" in K-means
clustering. Must specify K or centers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nperms</code></td>
<td>
<p>Number of permutations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wbounds</code></td>
<td>
<p>The range of tuning parameters to consider. This is the
L1 bound on w, the feature weights. If NULL, then a range of values
will be chosen automatically. Should be greater than 1 if non-null.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>Print out progress?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nvals</code></td>
<td>
<p>If wbounds is NULL, then the number of candidate tuning
parameter values to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>centers</code></td>
<td>
<p>Optional argument. If you want to run the k-means
algorithm starting from a particular set of clusters, then you
can enter the Kxp matrix of cluster centers here. Default use
case involves taking centers=NULL and instead specifying K.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> not used. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Sparse k-means clustering seeks a p-vector of weights w (one per feature) and a set of
clusters  C1,...,CK that optimize
$maximize_C1,...,CK,w sum_j w_j BCSS_j$ subject to $||w||_2 &lt;= 1,
||w||_1 &lt;= s, w_j &gt;= 0$,
where $BCSS_j$ is the between cluster sum of squares for feature
j, and s is a value for the L1 bound on w. Let O(s) denote the
objective function with tuning parameter s: i.e. $O(s)=sum_j w_j
BCSS_j$.
</p>
<p>We permute the data as follows: within each feature, we permute the
observations. Using the permuted data, we can run sparse K-means with
tuning parameter s, yielding the objective function O*(s). If we do
this repeatedly we can get a number of O*(s) values.
</p>
<p>Then, the Gap statistic is given by $Gap(s)=log(O(s))-mean(log(O*(s)))$. The
optimal s is that which results in the highest Gap statistic. Or, we
can choose the smallest s such that its Gap statistic is within
$sd(log(O*(s)))$ of the largest Gap statistic.
</p>


<h3>Value</h3>

 
<table>
<tr style="vertical-align: top;">
<td><code>gaps</code></td>
<td>
<p>The gap statistics obtained (one for each of the tuning
parameters tried). If O(s) is the objective function evaluated at
the tuning parameter s, and O*(s) is the same quantity but for the
permuted data, then Gap(s)=log(O(s))-mean(log(O*(s))).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sdgaps</code></td>
<td>
<p>The standard deviation of log(O*(s)), for each value of the
tuning parameter s.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nnonzerows</code></td>
<td>
<p>The number of features with non-zero weights, for
each value of the tuning parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wbounds</code></td>
<td>
<p>The tuning parameters considered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bestw</code></td>
<td>
<p>The value of the tuning parameter corresponding to the
highest gap statistic.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Daniela M. Witten and Robert Tibshirani</p>


<h3>References</h3>

<p>Witten and Tibshirani (2009) A framework for feature
selection in clustering.</p>


<h3>See Also</h3>

<p>KMeansSparseCluster, HierarchicalSparseCluster, HierarchicalSparseCluster.permute</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate data
set.seed(11)
x &lt;- matrix(rnorm(50*70),ncol=70)
x[1:25,1:10] &lt;- x[1:25,1:10]+1.5
x &lt;- scale(x, TRUE, TRUE)
# choose tuning parameter
km.perm &lt;-
KMeansSparseCluster.permute(x,K=2,wbounds=seq(2,5,len=8),nperms=3)
print(km.perm)
plot(km.perm)
# run sparse k-means
km.out &lt;- KMeansSparseCluster(x,K=2,wbounds=km.perm$bestw)
print(km.out)
plot(km.out)
# run sparse k-means for a range of tuning parameter values
km.out &lt;- KMeansSparseCluster(x,K=2,wbounds=2:7)
print(km.out)
plot(km.out)
# Repeat, but this time start with a particular choice of cluster
# centers.
# This will do 4-means clustering starting with this particular choice
# of cluster centers.
km.perm.out &lt;- KMeansSparseCluster.permute(x,wbounds=2:6, centers=x[1:4,],nperms=3)
print(km.out)
plot(km.out)
</code></pre>


</div>