<div class="container">

<table style="width: 100%;"><tr>
<td>cv_nb_grpreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation for Group-Regularized Negative Binomial Regression</h2>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. The cross-validation error (CVE) and cross-validation standard error (CVSE) are computed using the deviance for negative binomial regression.
</p>
<p>For a description of group-regularized negative binomial regression, see the description for the <code>nb_grpreg</code> function. Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>
<p>Note that the <code>nb_grpreg</code> function also returns the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in <code>lambda</code>, and the GIC can also be used for model selection instead of cross-validation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv_nb_grpreg(Y, X, groups, nb_size=1, penalty=c("gLASSO","gSCAD","gMCP"),
            n_folds=10, group_weights, taper, n_lambda=100, lambda, 
            max_iter=10000, tol=1e-4) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly nonnegative integer responses for training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb_size=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement cross-validation for gamma regression with the SSGL penalty, use the <code>cv_SSGL</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_folds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>n_folds=10</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). "Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors." <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). "Tuning parameter selection in high dimensional penalized likelihood." <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552. 
</p>
<p>Wang, H. and Leng, C. (2007). "Unified LASSO estimation by least squares approximation." <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). "Model selection and estimation in regression with grouped variables." <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate data
set.seed(1234)
X = matrix(runif(100*14), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,2,3,3,4,5,5,6,6)
beta_true = c(-1,1,1,0,0,0,0,-1,1,0,0,0,-1.5,1.5)

## Generate count responses from negative binomial regression
eta = crossprod(t(X), beta_true)
Y = rnbinom(n, size=1, mu=exp(eta))

## 10-fold cross-validation for group-regularized negative binomial
## regression with the group MCP penalty
nb_cv = cv_nb_grpreg(Y, X, groups, penalty="gMCP")

## Plot cross-validation curve
plot(nb_cv$lambda, nb_cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
nb_cv$lambda_min 
## index of lambda_min in lambda
nb_cv$min_index
</code></pre>


</div>