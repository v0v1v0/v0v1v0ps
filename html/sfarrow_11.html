<div class="container">

<table style="width: 100%;"><tr>
<td>write_sf_dataset</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Write <code>sf</code> object to an Arrow multi-file dataset</h2>

<h3>Description</h3>

<p>Write <code>sf</code> object to an Arrow multi-file dataset
</p>


<h3>Usage</h3>

<pre><code class="language-R">write_sf_dataset(
  obj,
  path,
  format = "parquet",
  partitioning = dplyr::group_vars(obj),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p>object of class <code>sf</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path</code></td>
<td>
<p>string path referencing a directory for the output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>format</code></td>
<td>
<p>output file format ("parquet" or "feather")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partitioning</code></td>
<td>
<p>character vector of columns in <code>obj</code> for grouping or
the <code>dplyr::group_vars</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments and options passed to
<code>arrow::write_dataset</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Translate an <code>sf</code> spatial object to <code>data.frame</code> with WKB
geometry columns and then write to an <code>arrow</code> dataset with
partitioning. Allows for <code>dplyr</code> grouped datasets (using
<code>group_by</code>) and uses those variables to define
partitions.
</p>


<h3>Value</h3>

<p><code>obj</code> invisibly
</p>


<h3>See Also</h3>

<p><code>write_dataset</code>, <code>st_read_parquet</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># read spatial object
nc &lt;- sf::st_read(system.file("shape/nc.shp", package="sf"), quiet = TRUE)

# create random grouping
nc$group &lt;- sample(1:3, nrow(nc), replace = TRUE)

# use dplyr to group the dataset. %&gt;% also allowed
nc_g &lt;- dplyr::group_by(nc, group)

# write out to parquet datasets
tf &lt;- tempfile()  # create temporary location
on.exit(unlink(tf))
# partitioning determined by dplyr 'group_vars'
write_sf_dataset(nc_g, path = tf)

list.files(tf, recursive = TRUE)

# open parquet files from dataset
ds &lt;- arrow::open_dataset(tf)

# create a query. %&gt;% also allowed
q &lt;- dplyr::filter(ds, group == 1)

# read the dataset (piping syntax also works)
nc_d &lt;- read_sf_dataset(dataset = q)

nc_d
plot(sf::st_geometry(nc_d))

</code></pre>


</div>