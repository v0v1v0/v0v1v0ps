<div class="container">

<table style="width: 100%;"><tr>
<td>transform_forecasts</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Transform forecasts and observed values</h2>

<h3>Description</h3>

<p>Function to transform forecasts and true values before scoring.
</p>


<h3>Usage</h3>

<pre><code class="language-R">transform_forecasts(data, fun = log_shift, append = TRUE, label = "log", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data.frame or data.table with the predictions and observations.
For scoring using <code>score()</code>, the following columns need to be present:
</p>

<ul>
<li> <p><code>true_value</code> - the true observed values
</p>
</li>
<li> <p><code>prediction</code> - predictions or predictive samples for one
true value. (You only don't need to provide a prediction column if
you want to score quantile forecasts in a wide range format.)</p>
</li>
</ul>
<p>For scoring integer and continuous forecasts a <code>sample</code> column is needed:
</p>

<ul><li> <p><code>sample</code> - an index to identify the predictive samples in the
prediction column generated by one model for one true value. Only
necessary for continuous and integer forecasts, not for
binary predictions.</p>
</li></ul>
<p>For scoring predictions in a quantile-format forecast you should provide
a column called <code>quantile</code>:
</p>

<ul><li> <p><code>quantile</code>: quantile to which the prediction corresponds
</p>
</li></ul>
<p>In addition a <code>model</code> column is suggested and if not present this will be
flagged and added to the input data with all forecasts assigned as an
"unspecified model").
</p>
<p>You can check the format of your data using <code>check_forecasts()</code> and there
are examples for each format (example_quantile, example_continuous,
example_integer, and example_binary).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fun</code></td>
<td>
<p>A function used to transform both true values and predictions.
The default function is <code>log_shift()</code>, a custom function that is essentially
the same as <code>log()</code>, but has an additional arguments (<code>offset</code>)
that allows you add an offset before applying the logarithm. This is often
helpful as the natural log transformation is not defined at zero. A common,
and pragmatic solution, is to add a small offset to the data before applying
the log transformation. In our work we have often used an offset of 1 but
the precise value will depend on your application.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>append</code></td>
<td>
<p>Logical, defaults to <code>TRUE</code>. Whether or not to append a
transformed version of the data to the currently existing data (<code>TRUE</code>). If
selected, the data gets transformed and appended to the existing data frame,
making it possible to use the outcome directly in <code>score()</code>. An additional
column, 'scale', gets created that denotes which rows or untransformed
('scale' has the value "natural") and which have been transformed ('scale'
has the value passed to the argument <code>label</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>
<p>A string for the newly created 'scale' column to denote the
newly transformed values. Only relevant if <code>append = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional parameters to pass to the function you supplied. For
the default option of <code>log_shift()</code> this could be the <code>offset</code> argument.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>There are a few reasons, depending on the circumstances, for
why this might be desirable (check out the linked reference for more info).
In epidemiology, for example, it may be useful to log-transform incidence
counts before evaluating forecasts using scores such as the weighted interval
score (WIS) or the continuous ranked probability score (CRPS).
Log-transforming forecasts and observations changes the interpretation of
the score from a measure of absolute distance between forecast and
observation to a score that evaluates a forecast of the exponential growth
rate. Another motivation can be to apply a variance-stabilising
transformation or to standardise incidence counts by population.
</p>
<p>Note that if you want to apply a transformation, it is important to transform
the forecasts and observations and then apply the score. Applying a
transformation after the score risks losing propriety of the proper scoring
rule.
</p>


<h3>Value</h3>

<p>A <code>data.table</code> with either a transformed version of the data, or one
with both the untransformed and the transformed data. includes the original
data as well as a transformation of the original data. There will be one
additional column, ‘scale’, present which will be set to "natural" for the
untransformed forecasts.
</p>


<h3>Author(s)</h3>

<p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a>
</p>


<h3>References</h3>

<p>Transformation of forecasts for evaluating predictive
performance in an epidemiological context
Nikos I. Bosse, Sam Abbott, Anne Cori, Edwin van Leeuwen, Johannes Bracher,
Sebastian Funk
medRxiv 2023.01.23.23284722
<a href="https://doi.org/10.1101/2023.01.23.23284722">doi:10.1101/2023.01.23.23284722</a>
<a href="https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1">https://www.medrxiv.org/content/10.1101/2023.01.23.23284722v1</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(magrittr) # pipe operator

# transform forecasts using the natural logarithm
# negative values need to be handled (here by replacing them with 0)
example_quantile %&gt;%
  .[, true_value := ifelse(true_value &lt; 0, 0, true_value)] %&gt;%
# Here we use the default function log_shift() which is essentially the same
# as log(), but has an additional arguments (offset) that allows you add an
# offset before applying the logarithm.
  transform_forecasts(append = FALSE) %&gt;%
  head()

# alternatively, integrating the truncation in the transformation function:
example_quantile %&gt;%
 transform_forecasts(
   fun = function(x) {log_shift(pmax(0, x))}, append = FALSE
 ) %&gt;%
 head()

# specifying an offset for the log transformation removes the
# warning caused by zeros in the data
example_quantile %&gt;%
  .[, true_value := ifelse(true_value &lt; 0, 0, true_value)] %&gt;%
  transform_forecasts(offset = 1, append = FALSE) %&gt;%
  head()

# adding square root transformed forecasts to the original ones
example_quantile %&gt;%
  .[, true_value := ifelse(true_value &lt; 0, 0, true_value)] %&gt;%
  transform_forecasts(fun = sqrt, label = "sqrt") %&gt;%
  score() %&gt;%
  summarise_scores(by = c("model", "scale"))

# adding multiple transformations
example_quantile %&gt;%
  .[, true_value := ifelse(true_value &lt; 0, 0, true_value)] %&gt;%
  transform_forecasts(fun = log_shift, offset = 1) %&gt;%
  transform_forecasts(fun = sqrt, label = "sqrt") %&gt;%
  head()
</code></pre>


</div>