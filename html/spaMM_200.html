<div class="container">

<table style="width: 100%;"><tr>
<td>hatvalues.HLfit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Leverage extractor for HLfit objects
</h2>

<h3>Description</h3>

<p>This gets “leverages” or “hat values” from an object. However, there is hidden complexity in what this may mean, so care must be used in selecting proper arguments for a given use (see Details). To get the full hat matrix, see <code>get_matrix(., which="hat_matrix")</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'HLfit'
hatvalues(model, type = "projection", which = "resid", force=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>An object of class <code>HLfit</code>, as returned by the fitting functions in <code>spaMM</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Character: <code>"projection"</code>, <code>"std"</code>, or more cryptic values not documented here. See Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which</code></td>
<td>
<p>Character: <code>"resid"</code> for the traditional leverages of the observations, <code>"ranef"</code> for random-effect leverages, or <code>"both"</code> for both.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>force</code></td>
<td>
<p>Boolean: to force recomputation of the leverages even if they are available in the object, for checking purposes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For consistency with the generic.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Leverages may have distinct meaning depending on context. The textbook version for linear models is that leverages <code class="reqn">(q_i)</code> are the diagonal elements of a projection matrix (“hat matrix”), and that they may be used to standardize (“studentize”) residuals as follows. If the residual variance <code class="reqn">\phi</code> is known, then the variance of each fitted residual <code class="reqn">\hat{e}_i</code> is <code class="reqn">\phi(1-q_i)</code>. Standardized residuals, all with variance 1, are then <code class="reqn">\hat{e}_i/</code><code class="reqn">\sqrt{}</code><code class="reqn">(\phi(1-q_i))</code>. This standardization of variance no longer holds exactly with estimated <code class="reqn">\phi</code>, but if one uses here an unbiased (REML) estimator of <code class="reqn">\phi</code>, the studentized residuals may still practically have a unit expected variance. 
</p>
<p>When a simple linear model is fitted by ML, the variance of the fitted residuals is less than <code class="reqn">\phi</code>, but <code class="reqn">\hat{\phi}</code> is downward biased so that residuals standardized only by <code class="reqn">\sqrt{}</code><code class="reqn">(\phi)</code>, without any leverage correction, more closely have expected unit variance than if corrected by the previous leverages. The ML and REML computations can be seen as both using “standardizing” leverages, defined so that they are zero in the ML case and are equal to the “projection” leverages (the above ones, derived from a projection matrix) in the REML case.
</p>
<p>These “standardizing” leverages can themselves been seen as special cases of those that appear in expressions for derivatives, with respect to the dispersion parameters, of the log-determinant of the information matrices considered in the Laplace approximation for marginal or restricted likelihood (Lee et al. 2006). This provides a basis to generalize the concept of standardizing leverages for ML and REML in mixed-effect models. In particular, in an ML fit, one considers leverages <code class="reqn">(q*_i)</code> that are no longer the diagonal elements of the projection matrix for the mixed model [and, as hinted above, for a simple linear model the ML <code class="reqn">(q*_i)</code> are zero]. The generalized standardizing leverages may include corrections for non-Gaussian response, for non-Gaussian random effects, and for taking into account the variation of the GLM weights in the logdet(info.mat) derivatives. Which corrections are included depend on the precise method used to fit the model (e.g., EQL vs PQL vs REML). Standardizing leverages are also defined for the random effects.
</p>
<p>These distinctions suggest breaking the usual synonymy between “leverages” or “hat values”: the term “hat values” better stands for the diagonal elements of a projection matrix, while “leverages” better stands for the standardizing values.   
<code>hatvalues(.,type="std")</code> returns the standardizing leverages. By contrast, <code>hatvalues(.,type="projection")</code> will always return hat values from the fitted projection matrix. Note that these values typically differ between ML and REML fit because the fitted projection matrix differs between them.
</p>


<h3>Value</h3>

<p>A list with separate components <code>resid</code> (leverages of the observations) and <code>ranef</code> if <code>which="both"</code>, and a vector otherwise.
</p>


<h3>References</h3>

<p>Lee, Y., Nelder, J. A. and Pawitan, Y. (2006) Generalized linear models with random effects: unified analysis via
h-likelihood. Chapman &amp; Hall: London.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (spaMM.getOption("example_maxtime")&gt;0.8) {
data("Orthodont",package = "nlme")
rnge &lt;- (107:108)

# all different:
#
hatvalues(rlfit &lt;- fitme(distance ~ age+(age|Subject), 
                         data = Orthodont, method="REML"))[rnge]
hatvalues(mlfit &lt;- fitme(distance ~ age+(age|Subject), 
                         data = Orthodont))[rnge] 
hatvalues(mlfit,type="std")[rnge]
}
</code></pre>


</div>