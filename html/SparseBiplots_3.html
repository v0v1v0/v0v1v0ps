<div class="container">

<table style="width: 100%;"><tr>
<td>LASSO_HJBiplot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>LASSO HJ Biplot</h2>

<h3>Description</h3>

<p>This function performs the representation of the SPARSE HJ Biplot applying the LASSO regularization, on the original data matrix, implementing the norm L1.
</p>


<h3>Usage</h3>

<pre><code class="language-R">LASSO_HJBiplot(X, Lambda, Transform.Data = 'scale', Operator = 'Hard-Thresholding')
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>array_like; <br>
A data frame which provides the data to be analyzed. All the variables must be numeric.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Lambda</code></td>
<td>
<p>float; <br>
Tuning parameter for the LASSO penalty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Transform.Data</code></td>
<td>
<p>character; <br>
A value indicating whether the columns of X (variables) should be centered or scaled. Options are: "center" that removes the columns means and "scale" that removes the columns means and divide by its standard deviation. Default is "scale".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Operator</code></td>
<td>
<p>character; <br>
The operator used to solve the norm L1. Allowed values are "Soft-Thresholding" and "Hard-Thresholding".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Algorithm that performs a procedure of contraction and selection of variables. LASSO imposes a penalty that causes the charges of some components to be reduced to zero. By producing zero loadings for some components and not zero for others, the Lasso technique performs selection of variables. As the value of the penalty approaches one, the loadings approach zero.
</p>


<h3>Value</h3>

<p><code>LASSO_HJBiplot</code> returns a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>loadings</code></td>
<td>
<p>  array_like; <br>
penalized loadings, the loadings of the sparse principal components.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_ceros</code></td>
<td>
<p>  array_like; <br>
number of loadings equal to cero in each component.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coord_ind</code></td>
<td>
<p>  array_like; <br>
matrix with the coordinates of individuals.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coord_var</code></td>
<td>
<p>  array_like; <br>
matrix with the coordinates of variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eigenvalues</code></td>
<td>
<p>  array_like; <br>
vector with the eigenvalues penalized.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>explvar</code></td>
<td>
<p>  array_like; <br>
an vector containing the proportion of variance explained by the first 1, 2,.,k sparse principal components obtained.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Mitzi Cubilla-Montilla, Carlos Torres-Cubilla, Ana Belen Nieto Librero and Purificacion Galindo Villardon
</p>


<h3>References</h3>


<ul>
<li>
<p> Galindo, M. P. (1986). Una alternativa de representacion simultanea: HJ-Biplot. Questiio, 10(1), 13-23.
</p>
</li>
<li>
<p> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267-288.
</p>
</li>
<li>
<p> Tibshirani, R. (2011). Regression shrinkage and selection via the lasso: a retrospective. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(3), 273-282.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>Plot_Biplot</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"> LASSO_HJBiplot(mtcars, Lambda = 0.2, Operator = 'Hard-Thresholding')

</code></pre>


</div>