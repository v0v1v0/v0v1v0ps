<div class="container">

<table style="width: 100%;"><tr>
<td>SFGAM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Sparse Frequentist Generalized Additive Models</h2>

<h3>Description</h3>

<p>This function implements sparse frequentist generalized additive models (GAMs) with the group LASSO, group SCAD, and group MCP penalties. Let <code class="reqn">y_i</code> denote the <code class="reqn">i</code>th response and <code class="reqn">x_i</code> denote a <code class="reqn">p</code>-dimensional vector of covariates. GAMs are of the form,
</p>
<p style="text-align: center;"><code class="reqn">g(E(y_i)) = \beta_0 + \sum_{j=1}^{p} f_j (x_{ij}), i = 1, ..., n,</code>
</p>

<p>where <code class="reqn">g</code> is a monotone increasing link function. The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression. The univariate functions are estimated using linear combinations of B-spline basis functions. Under group regularization of the basis coefficients, some of the univariate functions <code class="reqn">f_j(x_j)</code> will be estimated as <code class="reqn">\hat{f}_j(x_j) = 0</code>, depending on the size of the regularization parameter <code class="reqn">\lambda</code>. 
</p>
<p>For implementation of sparse <em>Bayesian</em> GAMs with the SSGL penalty, use the <code>SBGAM</code> function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SFGAM(y, X, X.test, df=6, 
      family=c("gaussian","binomial", "poisson", "negativebinomial","gamma"),
      nb.size=1, gamma.shape=1, penalty=c("gLASSO","gMCP","gSCAD"), taper, 
      nlambda=100, lambda, max.iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>number of B-spline basis functions to use in each basis expansion. Default is <code>df=6</code>, but the user may specify degrees of freedom as any integer greater than or equal to 3.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>group regularization method to use on the groups of basis coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement sparse GAMs with the SSGL penalty, use the <code>SBGAM</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f.pred</code></td>
<td>
<p>List of <code class="reqn">L</code> <code class="reqn">n_{test} \times p</code> matrices, where the <code class="reqn">k</code>th matrix in the list corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>. The <code class="reqn">j</code>th column in each matrix in <code>f.pred</code> is the estimate of the <code class="reqn">j</code>th function evaluated on the test data in <code>X.test</code> for the <code class="reqn">j</code>th covariate (or training data <code>X</code> if <code>X.test</code> was not specified). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for <code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifications</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of classifications. An entry of "1" indicates that the corresponding function was classified as nonzero, and an entry of "0" indicates that the function was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p><code class="reqn">dp \times L</code> matrix of estimated basis coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loss</code></td>
<td>
<p>vector of either the residual sum of squares (<code>"gaussian"</code>) or the negative log-likelihood (<code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, <code>"gamma"</code>) of the fitted model. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). "Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors." <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). "Unified LASSO estimation by least squares approximation." <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped variables. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>: 49-67.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate data
set.seed(12345)
X = matrix(runif(100*20), nrow=100)
n = dim(X)[1]
y = 5*sin(2*pi*X[,1])-5*cos(2*pi*X[,2]) + rnorm(n)

## Test data with 50 observations
X.test = matrix(runif(50*20), nrow=50)

## K-fold cross-validation with group MCP penalty
cv.mod = cv.SFGAM(y, X, family="gaussian", penalty="gMCP")
## Plot CVE curve
plot(cv.mod$lambda, cv.mod$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes cross-validation error
lambda.opt = cv.mod$lambda.min

## Fit a single model with lambda.opt
SFGAM.mod = SFGAM(y, X, X.test, penalty="gMCP", lambda=lambda.opt)

## Classifications
SFGAM.mod$classifications
## Predicted function evaluations on test data
f.pred = SFGAM.mod$f.pred  

## Plot estimated first function
x1 = X.test[,1]
f1.hat = f.pred[,1]

## Plot x_1 against f_1(x_1)
plot(x1[order(x1)], f1.hat[order(x1)], xlab=expression(x[1]), 
     ylab=expression(f[1](x[1])))
</code></pre>


</div>