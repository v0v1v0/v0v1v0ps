<div class="container">

<table style="width: 100%;"><tr>
<td>RFTrainer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Random Forest Trainer</h2>

<h3>Description</h3>

<p>Trains a random forest model.
</p>


<h3>Details</h3>

<p>Trains a Random Forest model. A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting.
This implementation uses ranger R package which provides faster model training.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>n_estimators</code></dt>
<dd>
<p>the number of trees in the forest, default= 100</p>
</dd>
<dt><code>max_features</code></dt>
<dd>
<p>the number of features to consider when looking for the best split.
Possible values are <code>auto(default)</code> takes sqrt(num_of_features),
<code>sqrt</code> same as auto,
<code>log</code> takes log(num_of_features),
<code>none</code> takes all features</p>
</dd>
<dt><code>max_depth</code></dt>
<dd>
<p>the maximum depth of each tree</p>
</dd>
<dt><code>min_node_size</code></dt>
<dd>
<p>the minumum number of samples required to split an internal node</p>
</dd>
<dt><code>criterion</code></dt>
<dd>
<p>the function to measure the quality of split. For classification, <code>gini</code> is used which
is a measure of gini index. For regression, the <code>variance</code> of responses is used.</p>
</dd>
<dt><code>classification</code></dt>
<dd>
<p>whether to train for classification (1) or regression (0)</p>
</dd>
<dt><code>verbose</code></dt>
<dd>
<p>show computation status and estimated runtime</p>
</dd>
<dt><code>seed</code></dt>
<dd>
<p>seed value</p>
</dd>
<dt><code>class_weights</code></dt>
<dd>
<p>weights associated with the classes for sampling of training observation</p>
</dd>
<dt><code>always_split</code></dt>
<dd>
<p>vector of feature names to be always used for splitting</p>
</dd>
<dt><code>importance</code></dt>
<dd>
<p>Variable importance mode, one of 'none', 'impurity', 'impurity_corrected', 'permutation'. The 'impurity' measure is the Gini index for classification, the variance of the responses for regression. Defaults to "impurity"</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-RFTrainer-new"><code>RFTrainer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-RFTrainer-fit"><code>RFTrainer$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-RFTrainer-predict"><code>RFTrainer$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-RFTrainer-get_importance"><code>RFTrainer$get_importance()</code></a>
</p>
</li>
<li> <p><a href="#method-RFTrainer-clone"><code>RFTrainer$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-RFTrainer-new"></a>



<h4>Method <code>new()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>RFTrainer$new(
  n_estimators,
  max_depth,
  max_features,
  min_node_size,
  classification,
  class_weights,
  always_split,
  verbose,
  save_model,
  seed,
  importance
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>n_estimators</code></dt>
<dd>
<p>integer, the number of trees in the forest, default= 100</p>
</dd>
<dt><code>max_depth</code></dt>
<dd>
<p>integer, the maximum depth of each tree</p>
</dd>
<dt><code>max_features</code></dt>
<dd>
<p>integer, the number of features to consider when looking for the best split.
Possible values are <code>auto(default)</code> takes sqrt(num_of_features),
<code>sqrt</code> same as auto,
<code>log</code> takes log(num_of_features),
<code>none</code> takes all features</p>
</dd>
<dt><code>min_node_size</code></dt>
<dd>
<p>integer, the minumum number of samples required to split an internal node</p>
</dd>
<dt><code>classification</code></dt>
<dd>
<p>integer, whether to train for classification (1) or regression (0)</p>
</dd>
<dt><code>class_weights</code></dt>
<dd>
<p>weights associated with the classes for sampling of training observation</p>
</dd>
<dt><code>always_split</code></dt>
<dd>
<p>vector of feature names to be always used for splitting</p>
</dd>
<dt><code>verbose</code></dt>
<dd>
<p>logical, show computation status and estimated runtime</p>
</dd>
<dt><code>save_model</code></dt>
<dd>
<p>logical, whether to save model</p>
</dd>
<dt><code>seed</code></dt>
<dd>
<p>integer, seed value</p>
</dd>
<dt><code>importance</code></dt>
<dd>
<p>Variable importance mode, one of 'none', 'impurity', 'impurity_corrected', 'permutation'. The 'impurity' measure is the Gini index for classification, the variance of the responses for regression. Defaults to "impurity"</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Create a new 'RFTrainer' object.
</p>



<h5>Returns</h5>

<p>A 'RFTrainer' object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
</pre>
</div>


<hr>
<a id="method-RFTrainer-fit"></a>



<h4>Method <code>fit()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>RFTrainer$fit(X, y)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>X</code></dt>
<dd>
<p>data.frame containing train features</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>character, name of the target variable</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Trains the random forest model
</p>



<h5>Returns</h5>

<p>NULL, trains and saves the model in memory
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')
</pre>
</div>


<hr>
<a id="method-RFTrainer-predict"></a>



<h4>Method <code>predict()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>RFTrainer$predict(df)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>df</code></dt>
<dd>
<p>data.frame containing test features</p>
</dd>
</dl>
</div>



<h5>Details</h5>

<p>Return predictions from random forest model
</p>



<h5>Returns</h5>

<p>a vector containing predictions
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')
predictions &lt;- bst$predict(iris)
</pre>
</div>


<hr>
<a id="method-RFTrainer-get_importance"></a>



<h4>Method <code>get_importance()</code>
</h4>



<h5>Usage</h5>

<div class="r"><pre>RFTrainer$get_importance()</pre></div>



<h5>Details</h5>

<p>Returns feature importance from the model
</p>



<h5>Returns</h5>

<p>a data frame containing feature predictions
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>data("iris")
bst &lt;- RFTrainer$new(n_estimators=50,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')
predictions &lt;- bst$predict(iris)
bst$get_importance()
</pre>
</div>


<hr>
<a id="method-RFTrainer-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>RFTrainer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R">
## ------------------------------------------------
## Method `RFTrainer$new`
## ------------------------------------------------

data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)

## ------------------------------------------------
## Method `RFTrainer$fit`
## ------------------------------------------------

data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')

## ------------------------------------------------
## Method `RFTrainer$predict`
## ------------------------------------------------

data("iris")
bst &lt;- RFTrainer$new(n_estimators=10,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')
predictions &lt;- bst$predict(iris)

## ------------------------------------------------
## Method `RFTrainer$get_importance`
## ------------------------------------------------

data("iris")
bst &lt;- RFTrainer$new(n_estimators=50,
                     max_depth=4,
                     classification=1,
                     seed=42,
                     verbose=TRUE)
bst$fit(iris, 'Species')
predictions &lt;- bst$predict(iris)
bst$get_importance()
</code></pre>


</div>