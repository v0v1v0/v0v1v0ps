<div class="container">

<table style="width: 100%;"><tr>
<td>sfalcmcross</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Latent class stochastic frontier using cross-sectional data</h2>

<h3>Description</h3>

<p><code>sfalcmcross</code> is a symbolic formula based function for the
estimation of the latent class stochastic frontier model (LCM) in the case
of cross-sectional or pooled cross-sectional data. The model is estimated
using maximum likelihood (ML). See Orea and Kumbhakar (2004), Parmeter and
Kumbhakar (2014, p282).
</p>
<p>Only the half-normal distribution is possible for the one-sided error term.
Eleven optimization algorithms are available.
</p>
<p>The function also accounts for heteroscedasticity in both one-sided and
two-sided error terms, as in Reifschneider and Stevenson (1991), Caudill and
Ford (1993), Caudill <em>et al.</em> (1995) and Hadri (1999).
</p>
<p>The model can estimate up to five classes.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sfalcmcross(
  formula,
  uhet,
  vhet,
  thet,
  logDepVar = TRUE,
  data,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  udist = "hnormal",
  start = NULL,
  whichStart = 2L,
  initAlg = "nm",
  initIter = 100,
  lcmClasses = 2,
  method = "bfgs",
  hessianType = 1,
  itermax = 2000L,
  printInfo = FALSE,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

## S3 method for class 'sfalcmcross'
print(x, ...)

## S3 method for class 'sfalcmcross'
bread(x, ...)

## S3 method for class 'sfalcmcross'
estfun(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A symbolic description of the model to be estimated based on
the generic function <code>formula</code> (see section ‘Details’).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>uhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
one-sided error variance (see section ‘Details’).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
two-sided error variance (see section ‘Details’).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thet</code></td>
<td>
<p>A one-part formula to account for technological heterogeneity in
the construction of the classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logDepVar</code></td>
<td>
<p>Logical. Informs whether the dependent variable is logged
(<code>TRUE</code>) or not (<code>FALSE</code>). Default = <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>The data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>An optional vector specifying a subset of observations to be
used in the optimization process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>An optional vector of weights to be used for weighted
log-likelihood. Should be <code>NULL</code> or numeric vector with positive values.
When <code>NULL</code>, a numeric vector of 1 is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wscale</code></td>
<td>
<p>Logical. When <code>weights</code> is not <code>NULL</code>, a scaling
transformation is used such that the <code>weights</code> sums to the sample
size. Default <code>TRUE</code>. When <code>FALSE</code> no scaling is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>If <code>S = 1</code> (default), a production (profit) frontier is
estimated: <code class="reqn">\epsilon_i = v_i-u_i</code>. If <code>S = -1</code>, a cost frontier is
estimated: <code class="reqn">\epsilon_i = v_i+u_i</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>udist</code></td>
<td>
<p>Character string. Distribution specification for the one-sided
error term. Only the half normal distribution <code>'hnormal'</code> (Aigner
<em>et al.</em>, 1977, Meeusen and Vandenbroeck, 1977) is currently
implemented.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>whichStart</code></td>
<td>
<p>Integer. If <code>'whichStart = 1'</code>, the starting values
are obtained from the method of moments. When <code>'whichStart = 2'</code>
(Default), the model is initialized by solving the homoscedastic pooled
cross section SFA model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initAlg</code></td>
<td>
<p>Character string specifying the algorithm used for
initialization and obtain the starting values (when <code>'whichStart = 2'</code>).
Only <span class="pkg">maxLik</span> package algorithms are available:
</p>
 <ul>
<li> <p><code>'bfgs'</code>, for Broyden-Fletcher-Goldfarb-Shanno
(see <code>maxBFGS</code>)
</p>
</li>
<li> <p><code>'bhhh'</code>, for Berndt-Hall-Hall-Hausman
(see <code>maxBHHH</code>)
</p>
</li>
<li> <p><code>'nr'</code>, for Newton-Raphson (see <code>maxNR</code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead - Default -
(see <code>maxNM</code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code>maxCG</code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code>maxSANN</code>)
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initIter</code></td>
<td>
<p>Maximum number of iterations for initialization algorithm.
Default <code>100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lcmClasses</code></td>
<td>
<p>Number of classes to be estimated (default = <code>2</code>). A
maximum of five classes can be estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Optimization algorithm used for the estimation.  Default =
<code>'bfgs'</code>. 11 algorithms are available: </p>
 <ul>
<li> <p><code>'bfgs'</code>,
for Broyden-Fletcher-Goldfarb-Shanno (see
<code>maxBFGS</code>) </p>
</li>
<li> <p><code>'bhhh'</code>, for
Berndt-Hall-Hall-Hausman (see <code>maxBHHH</code>) </p>
</li>
<li>
<p><code>'nr'</code>, for Newton-Raphson (see <code>maxNR</code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead (see <code>maxNM</code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code>maxCG</code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code>maxSANN</code>)
</p>
</li>
<li> <p><code>'ucminf'</code>, for a quasi-Newton type optimization with BFGS updating of
the inverse Hessian and soft line search with a trust region type monitoring
of the input to the line search algorithm
(see <code>ucminf</code>)
</p>
</li>
<li> <p><code>'mla'</code>, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see <code>mla</code>)
</p>
</li>
<li> <p><code>'sr1'</code>, for Symmetric Rank 1 (see
<code>trust.optim</code>) </p>
</li>
<li> <p><code>'sparse'</code>,
for trust regions and sparse Hessian
(see <code>trust.optim</code>) </p>
</li>
<li>
<p><code>'nlminb'</code>, for optimization using PORT routines (see
<code>nlminb</code>)</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessianType</code></td>
<td>
<p>Integer. If <code>1</code> (default), analytic Hessian is
returned. If <code>2</code>, bhhh Hessian is estimated (<code class="reqn">g'g</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>itermax</code></td>
<td>
<p>Maximum number of iterations allowed for optimization.
Default = <code>2000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printInfo</code></td>
<td>
<p>Logical. Print information during optimization. Default =
<code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Numeric. Convergence tolerance. Default = <code>1e-12</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradtol</code></td>
<td>
<p>Numeric. Convergence tolerance for gradient. Default =
<code>1e-06</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stepmax</code></td>
<td>
<p>Numeric. Step max for <code>ucminf</code> algorithm. Default =
<code>0.1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>qac</code></td>
<td>
<p>Character. Quadratic Approximation Correction for <code>'bhhh'</code>
and <code>'nr'</code> algorithms. If <code>'qac = stephalving'</code>, the step length
is decreased but the direction is kept. If <code>'qac = marquardt'</code>
(default), the step length is decreased while also moving closer to the pure
gradient direction. See <code>maxBHHH</code> and
<code>maxNR</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an object of class sfalcmcross (returned by the function
<code>sfalcmcross</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments of frontier are passed to sfalcmcross;
additional arguments of the print, bread, estfun, nobs methods are currently
ignored.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>LCM is an estimation of a finite mixture of production functions:
</p>
<p style="text-align: center;"><code class="reqn">y_i = \alpha_j + \mathbf{x_i^{\prime}} 
\bm{\beta_j} + v_{i|j} - Su_{i|j}</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_{i|j} = v_{i|j} - Su_{i|j}</code>
</p>

<p>where <code class="reqn">i</code> is the observation, <code class="reqn">j</code> is the class, <code class="reqn">y</code> is the
output (cost, revenue, profit), <code class="reqn">x</code> is the vector of main explanatory
variables (inputs and other control variables), <code class="reqn">u</code> is the one-sided
error term with variance <code class="reqn">\sigma_{u}^2</code>, and <code class="reqn">v</code> is the two-sided
error term with variance <code class="reqn">\sigma_{v}^2</code>.
</p>
<p><code>S = 1</code> in the case of production (profit) frontier function and
<code>S = -1</code> in the case of cost frontier function.
</p>
<p>The contribution of observation <code class="reqn">i</code> to the likelihood conditional on
class <code class="reqn">j</code> is defined as:
</p>
<p style="text-align: center;"><code class="reqn">P(i|j) = \frac{2}{\sqrt{\sigma_{u|j}^2 + 
\sigma_{v|j}^2}}\phi\left(\frac{S\epsilon_{i|j}}{\sqrt{
\sigma_{u|j}^2 +\sigma_{v|j}^2}}\right)\Phi\left(\frac{
\mu_{i*|j}}{\sigma_{*|j}}\right)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\mu_{i*|j}=\frac{- S\epsilon_{i|j}
\sigma_{u|j}^2}{\sigma_{u|j}^2 + \sigma_{v|j}^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sigma_*^2 = \frac{\sigma_{u|j}^2 
\sigma_{v|j}^2}{\sigma_{u|j}^2 + \sigma_{v|j}^2}</code>
</p>

<p>The prior probability of using a particular technology can depend on some
covariates (namely the variables separating the observations into classes)
using a logit specification:
</p>
<p style="text-align: center;"><code class="reqn">\pi(i,j) = \frac{\exp{(\bm{\theta}_j'\mathbf{Z}_{hi})}}{
\sum_{m=1}^{J}\exp{(\bm{\theta}_m'\mathbf{Z}_{hi})}}</code>
</p>

<p>with <code class="reqn">\mathbf{Z}_h</code> the covariates, <code class="reqn">\bm{\theta}</code> the coefficients estimated for
the covariates, and <code class="reqn">\exp(\bm{\theta}_J'\mathbf{Z}_h)=1</code>.
</p>
<p>The unconditional likelihood of observation <code class="reqn">i</code> is simply the average
over the <code class="reqn">J</code> classes:
</p>
<p style="text-align: center;"><code class="reqn">P(i) = \sum_{m=1}^{J}\pi(i,m)P(i|m)</code>
</p>

<p>The number of classes to retain can be based on information criterion (see
for instance <code>ic</code>).
</p>
<p>Class assignment is based on the largest posterior probability. This
probability is obtained using Bayes' rule, as follows for class <code class="reqn">j</code>:
</p>
<p style="text-align: center;"><code class="reqn">w\left(j|i\right)=\frac{P\left(i|j\right)
\pi\left(i,j\right)}{\sum_{m=1}^JP\left(i|m\right)
\pi\left(i, m\right)}</code>
</p>

<p>To accommodate heteroscedasticity in the variance parameters of the error
terms, a single part (right) formula can also be specified. To impose the
positivity on these parameters, the variances are modelled respectively as:
<code class="reqn">\sigma^2_{u|j} = \exp{(\bm{\delta}_j'\mathbf{Z}_u)}</code> and <code class="reqn">\sigma^2_{v|j} =
\exp{(\bm{\phi}_j'\mathbf{Z}_v)}</code>, where <code class="reqn">Z_u</code> and <code class="reqn">Z_v</code> are the
heteroscedasticity variables (inefficiency drivers in the case of <code class="reqn">\mathbf{Z}_u</code>)
and <code class="reqn">\bm{\delta}</code> and <code class="reqn">\bm{\phi}</code> the coefficients. <code>'sfalcmcross'</code> only
supports the half-normal distribution for the one-sided error term.
</p>
<p><code>sfalcmcross</code> allows for the maximization of weighted log-likelihood.
When option <code>weights</code> is specified and <code>wscale = TRUE</code>, the weights
are scaled as:
</p>
<p style="text-align: center;"><code class="reqn">new_{weights} = sample_{size} \times 
\frac{old_{weights}}{\sum(old_{weights})}</code>
</p>

<p>For complex problems, non-gradient methods (e.g. <code>nm</code> or
<code>sann</code>) can be used to warm start the optimization and zoom in the
neighborhood of the solution. Then a gradient-based methods is recommended
in the second step. In the case of <code>sann</code>, we recommend to significantly
increase the iteration limit (e.g. <code>itermax = 20000</code>). The Conjugate
Gradient (<code>cg</code>) can also be used in the first stage.
</p>
<p>A set of extractor functions for fitted model objects is available for
objects of class <code>'sfalcmcross'</code> including methods to the generic functions
<code>print</code>,
<code>summary</code>,
<code>coef</code>,
<code>fitted</code>,
<code>logLik</code>,
<code>residuals</code>,
<code>vcov</code>,
<code>efficiencies</code>,
<code>ic</code>,
<code>marginal</code>,
<code>estfun</code> and
<code>bread</code> (from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> package),
<code>lmtest::coeftest()</code> (from the <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package).
</p>


<h3>Value</h3>

<p><code>sfalcmcross</code> returns a list of class <code>'sfalcmcross'</code>
containing the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>Multi parts formula describing the estimated model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>The argument <code>'S'</code>. See the section ‘Arguments’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>typeSfa</code></td>
<td>
<p>Character string. 'Latent Class Production/Profit Frontier, e
= v - u' when <code>S = 1</code> and 'Latent Class Cost Frontier, e = v + u' when
<code>S = -1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nobs</code></td>
<td>
<p>Number of observations used for optimization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nXvar</code></td>
<td>
<p>Number of main explanatory variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nZHvar</code></td>
<td>
<p>Number of variables in the logit specification of the finite
mixture model (i.e. number of covariates).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logDepVar</code></td>
<td>
<p>The argument <code>'logDepVar'</code>. See the section
‘Arguments’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nuZUvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
one-sided error term.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nvZVvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
two-sided error term.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nParm</code></td>
<td>
<p>Total number of parameters estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>udist</code></td>
<td>
<p>The argument <code>'udist'</code>. See the section
‘Arguments’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>startVal</code></td>
<td>
<p>Numeric vector. Starting value for ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataTable</code></td>
<td>
<p>A data frame (tibble format) containing information on data
used for optimization along with residuals and fitted values of the OLS and
ML estimations, and the individual observation log-likelihood. When
<code>weights</code> is specified an additional variable is also provided in
<code>dataTable</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initHalf</code></td>
<td>
<p>When <code>start = NULL</code> and <code>whichStart == 2L</code>.
Initial ML estimation with half normal distribution for the one-sided error
term. Model to construct the starting values for
the latent class estimation. Object of class <code>'maxLik'</code> and
<code>'maxim'</code> returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>isWeights</code></td>
<td>
<p>Logical. If <code>TRUE</code> weighted log-likelihood is
maximized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optType</code></td>
<td>
<p>The optimization algorithm used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nIter</code></td>
<td>
<p>Number of iterations of the ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optStatus</code></td>
<td>
<p>An optimization algorithm termination message.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>startLoglik</code></td>
<td>
<p>Log-likelihood at the starting values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nClasses</code></td>
<td>
<p>The number of classes estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mlLoglik</code></td>
<td>
<p>Log-likelihood value of the ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mlParam</code></td>
<td>
<p>Numeric vector. Parameters obtained from ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mlParamMatrix</code></td>
<td>
<p>Double. Matrix of ML parameters by class.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradient</code></td>
<td>
<p>Numeric vector. Each variable gradient of the ML
estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradL_OBS</code></td>
<td>
<p>Matrix. Each variable individual observation gradient of
the ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gradientNorm</code></td>
<td>
<p>Numeric. Gradient norm of the ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>invHessian</code></td>
<td>
<p>The covariance matrix of the parameters obtained from the
ML estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessianType</code></td>
<td>
<p>The argument <code>'hessianType'</code>. See the section
‘Arguments’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mlDate</code></td>
<td>
<p>Date and time of the estimated model.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>In the case of panel data, <code>sfalcmcross</code> estimates a pooled
cross-section where the probability of belonging to a class a priori is not
permanent (not fixed over time).
</p>


<h3>References</h3>

<p>Aigner, D., Lovell, C. A. K., and P. Schmidt. 1977. Formulation
and estimation of stochastic frontier production function models.
<em>Journal of Econometrics</em>, <b>6</b>(1), 21–37.
</p>
<p>Caudill, S. B., and J. M. Ford. 1993. Biases in frontier estimation due to
heteroscedasticity. <em>Economics Letters</em>, <b>41</b>(1), 17–20.
</p>
<p>Caudill, S. B., Ford, J. M., and D. M. Gropper. 1995. Frontier estimation
and firm-specific inefficiency measures in the presence of
heteroscedasticity. <em>Journal of Business &amp; Economic Statistics</em>,
<b>13</b>(1), 105–111.
</p>
<p>Hadri, K. 1999. Estimation of a doubly heteroscedastic stochastic frontier
cost function. <em>Journal of Business &amp; Economic Statistics</em>,
<b>17</b>(3), 359–363.
</p>
<p>Meeusen, W., and J. Vandenbroeck. 1977. Efficiency estimation from
Cobb-Douglas production functions with composed error. <em>International
Economic Review</em>, <b>18</b>(2), 435–445.
</p>
<p>Orea, L., and S.C. Kumbhakar. 2004. Efficiency measurement using a latent
class stochastic frontier model. <em>Empirical Economics</em>, <b>29</b>,
169–183.
</p>
<p>Parmeter, C.F., and S.C. Kumbhakar. 2014. Efficiency analysis: A primer on
recent advances. <em>Foundations and Trends in Econometrics</em>, <b>7</b>,
191–385.
</p>
<p>Reifschneider, D., and R. Stevenson. 1991. Systematic departures from the
frontier: A framework for the analysis of firm inefficiency.
<em>International Economic Review</em>, <b>32</b>(3), 715–723.
</p>


<h3>See Also</h3>

<p><code>print</code> for printing <code>sfalcmcross</code>
object.
</p>
<p><code>summary</code> for creating and printing
summary results.
</p>
<p><code>coef</code> for extracting coefficients of the
estimation.
</p>
<p><code>efficiencies</code> for computing
(in-)efficiency estimates.
</p>
<p><code>fitted</code> for extracting the fitted frontier
values.
</p>
<p><code>ic</code> for extracting information criteria.
</p>
<p><code>logLik</code> for extracting log-likelihood
value(s) of the estimation.
</p>
<p><code>marginal</code> for computing marginal effects of
inefficiency drivers.
</p>
<p><code>residuals</code> for extracting residuals of the
estimation.
</p>
<p><code>vcov</code> for computing the variance-covariance
matrix of the coefficients.
</p>
<p><code>bread</code> for bread for sandwich estimator.
</p>
<p><code>estfun</code> for gradient extraction for each
observation.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
# Intercept and initStat used as separating variables
cb_2c_h1 &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, thet = ~initStat, 
data = worldprod)
summary(cb_2c_h1)

# summary of the initial ML model
summary(cb_2c_h1$InitHalf)

# Only the intercept is used as the separating variable
# and only variable initStat is used as inefficiency driver
cb_2c_h3 &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, uhet = ~initStat, 
data = worldprod)
summary(cb_2c_h3)

</code></pre>


</div>