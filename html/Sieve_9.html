<div class="container">

<table style="width: 100%;"><tr>
<td>sieve_predict</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predict the outcome of interest for new samples</h2>

<h3>Description</h3>

<p>Use the fitted sieve regression model from sieve_solver. It also returns the testing mean-squared errors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sieve_predict(model, testX, testY = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a list. Use the fitted model from sieve_solver.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testX</code></td>
<td>
<p>a data frame. Dimension equals to test sample size x feature diemnsion. Should be of a similar format as the training feature provided to sieve_preprocess.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>testY</code></td>
<td>
<p>a vector. The outcome of testing samples (if known). Default is NULL. For regression problems, the algorithm also returns the testing mean-squared errors.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list. 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>predictY</code></td>
<td>
<p>a matrix. Dimension is test sample size (# of rows) x number of penalty hyperparameter lambda (# of columns). 
For regression problem, that is, when family = "gaussian", each entry is the estimated conditional mean (or predictor of outcome Y). For classification problems (family = "binomial"), each entry is the predicted probability of having Y = 1 (which class is defined as "class 1" depends on the training data labeling). </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MSE</code></td>
<td>
<p>For regression problem, when testY is provided, the algorithm also calculates the mean-sqaured errors using testing data. Each entry of <code>MSE</code> correponds to one value of penalization hyperparameter <code>lambda</code></p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">xdim &lt;- 1 #1 dimensional feature
#generate 1000 training samples
TrainData &lt;- GenSamples(s.size = 1000, xdim = xdim)
#use 50 cosine basis functions
type &lt;- 'cosine'
basisN &lt;- 50 
sieve.model &lt;- sieve_preprocess(X = TrainData[,2:(xdim+1)], 
                                basisN = basisN, type = type)
sieve.fit&lt;- sieve_solver(model = sieve.model, Y = TrainData$Y)
#generate 1000 testing samples
TestData &lt;- GenSamples(s.size = 1000, xdim = xdim)
sieve.prediction &lt;- sieve_predict(model = sieve.fit, 
                                  testX = TestData[,2:(xdim+1)], 
                                  testY = TestData$Y)
###if the outcome is binary, 
###need to solve a nonparametric logistic regression problem
xdim &lt;- 1
TrainData &lt;- GenSamples(s.size = 1e3, xdim = xdim, y.type = 'binary', frho = 'nonlinear_binary')
sieve.model &lt;- sieve_preprocess(X = TrainData[,2:(xdim+1)], 
                                basisN = basisN, type = type)
sieve.fit&lt;- sieve_solver(model = sieve.model, Y = TrainData$Y,
                         family = 'binomial')
                         
###the predicted value is conditional probability (of taking class 1).
TrainData &lt;- GenSamples(s.size = 1e3, xdim = xdim, y.type = 'binary', frho = 'nonlinear_binary')
sieve.prediction &lt;- sieve_predict(model = sieve.fit, 
                                  testX = TestData[,2:(xdim+1)])
</code></pre>


</div>