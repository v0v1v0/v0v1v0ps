<div class="container">

<table style="width: 100%;"><tr>
<td>myknn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
K Nearest Neighbor Classifier
</h2>

<h3>Description</h3>

<p>Implement the K nearest neighbor classification algorithm to predict the label of a new input using a training data set.
</p>


<h3>Usage</h3>

<pre><code class="language-R">myknn(train, test, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>

<p>Matrix of training data sets. An n by (d+1) matrix, where n is the sample size and d is the dimension. The last column is the class label.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>

<p>Vector of a test point. It also admits a matrix input with each row representing a new test point.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>

<p>Number of nearest neighbors considered.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The tuning parameter K can be tuned via cross-validation, see cv.tune function for the tuning procedure.
</p>


<h3>Value</h3>

<p>It returns the predicted class label of the new test point. If input is a matrix, it returns a vector which contains the predicted class labels of all the new test points.  
</p>


<h3>Author(s)</h3>

<p>Wei Sun, Xingye Qiao, and Guang Cheng 
</p>


<h3>References</h3>

<p>Fix, E. and Hodges, J. L., Jr. (1951). Discriminatory Analysis, Nonparametric Discrimination: Consistency Properties. Randolph Field, Texas, Project 21-49-004, Report No.4.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
	# Training data
	set.seed(1)
	n = 100
	d = 10
	DATA = mydata(n, d)

	# Testing data
	set.seed(2015)
	ntest = 100  
	TEST = mydata(ntest, d)
	TEST.x = TEST[,1:d]
	
	# K nearest neighbor classifier
	myknn(DATA, TEST.x, K = 5)

</code></pre>


</div>