<div class="container">

<table style="width: 100%;"><tr>
<td>sparseBC.choosekr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Do tuning parameter K and R selection for sparse biclustering via cross-validation.
</h2>

<h3>Description</h3>

<p>Perform cross-validation to select K (number of row clusters) and R (number of column clusters) for sparse biclustering.  We assume that lambda is known.   
</p>


<h3>Usage</h3>

<pre><code class="language-R">sparseBC.choosekr(x, k, r, lambda, percent = 0.1, trace=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Data matrix; samples are rows and columns are features.  Cannot contain missing values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>A range of values of K to be considered.  Values considered must be an increasing sequence.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>

<p>A range of values of R to be considered.  Values considered must be an increasing sequence.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>Non-negative regularization parameter for lasso.  lambda=0 means no regularization.    
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>percent</code></td>
<td>

<p>Percentage of elements of x to be left out for cross-validation.  1 must be divisible by the specified percentage.  The default value is 0.1.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>

<p>Print out progress as iterations are performed.  Default is FALSE.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function performs cross-validation as described in Algorithm (2) in Tan and Witten (2014) 'Sparse biclustering of transposable data'.  Briefly, it works as follows: (1) some percent of the elements of x is removed at random from the data matrix - call those elements missing elements, (2) the missing elements are imputed using the mean of the other elements of the matrix, (3) sparse biclustering is performed with various values of K and R and the mean matrix is estimated, (4) calculate the sum of squared error of the missing values between x and the estimated mean matrix.  This procedure is repeated 1/percent times.  Finally, we select K and R based on the criterion described in Algorithm (2) in Tan and Witten (2014).  A similar procedure is used in Witten et al (2009) 'A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis'.     
</p>
<p>Note that sparseBC is run with center=TRUE in this function.  
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>estimated_kr</code></td>
<td>
<p>The chosen values of K and R based on cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>results.mean</code></td>
<td>
<p>Mean squared error for all values of K and R considered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>results.se</code></td>
<td>
<p>Standard error of the sum of squared error for all values of K and R considered.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Kean Ming Tan and Daniela Witten
</p>


<h3>References</h3>

<p>KM Tan and D Witten (2014) Sparse biclustering of transposable data.  <em>Journal of Computational and Graphical Statistics</em> 23(4):985-1008.
</p>
<p>D Witten, R Tibshirani, and T Hastie (2009) A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis, <em>Biostatistics</em> 10(3), 515â€“534.
</p>


<h3>See Also</h3>

<p><code>sparseBC</code>
<code>sparseBC.BIC</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
########### Create data matrix with K=2 R=4 row and column clusters 
#k &lt;- 2
#r &lt;- 4
#n &lt;- 200
#p &lt;- 200
#  mus&lt;-runif(k*r,-3,3)
#  mus&lt;-matrix(c(mus),nrow=k,ncol=r,byrow=FALSE)
#  truthCs&lt;-sample(1:k,n,rep=TRUE)
#  truthDs&lt;-sample(1:r,p,rep=TRUE)
#  x&lt;-matrix(rnorm(n*p,mean=0,sd=2),nrow=n,ncol=p)
#  for(i in 1:max(truthCs)){
#     for(j in 1:max(truthDs)){ 
#         x[truthCs==i, truthDs==j] &lt;- x[truthCs==i, truthDs==j] + mus[i,j]
#    }
#  }
#  x&lt;-x-mean(x)

# Example is commented out for short run-time	
############ Perform sparseBC.choosekr to choose the number of row and column clusters
#sparseBC.choosekr(x,1:5,1:5,0,0.2)$estimated_kr

</code></pre>


</div>