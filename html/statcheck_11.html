<div class="container">

<table style="width: 100%;"><tr>
<td>statcheck</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Extract statistics and recompute p-values</h2>

<h3>Description</h3>

<p><code>statcheck</code> extracts Null Hypothesis Significance (NHST) results from 
strings and returns the extracted values, reported p-values and recomputed 
p-values.
</p>


<h3>Usage</h3>

<pre><code class="language-R">statcheck(
  texts,
  stat = c("t", "F", "cor", "chisq", "Z", "Q"),
  OneTailedTests = FALSE,
  alpha = 0.05,
  pEqualAlphaSig = TRUE,
  pZeroError = TRUE,
  OneTailedTxt = FALSE,
  AllPValues = FALSE,
  messages = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>texts</code></td>
<td>
<p>A vector of strings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stat</code></td>
<td>
<p>Specify which test types you want to extract. "t" to extract 
t-values, "F" to extract F-values, "cor" to extract correlations, "chisq"to 
extract <code class="reqn">\chi2</code> values, "Z" to extract Z-values, and "Q" to extract 
Q-values. Using <code>c()</code> you can specify multiple tests. Defaults to all
tests.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OneTailedTests</code></td>
<td>
<p>Logical. Do you want to assume that all reported tests 
are one-tailed (TRUE) or two-tailed (FALSE, default)?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Assumed level of significance in the scanned texts. Defaults to 
.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pEqualAlphaSig</code></td>
<td>
<p>Logical. If TRUE, statcheck counts p &lt;= alpha as
significant (default), if FALSE, statcheck counts p &lt; alpha as significant.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pZeroError</code></td>
<td>
<p>Logical. If TRUE, statcheck counts p = .000 as an error 
(because a p-value is never exactly zero, and should be reported as &lt; .001), 
if FALSE, statcheck does not count p = .000 automatically as an error.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OneTailedTxt</code></td>
<td>
<p>Logical. If TRUE, statcheck searches the text for 
"one-sided", "one-tailed", and "directional" to identify the possible use of 
one-sided tests. If one or more of these strings is found in the text AND the 
result would have been correct if it was a one-sided test, the result is 
assumed to be indeed one-sided and is counted as correct.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AllPValues</code></td>
<td>
<p>Logical. If TRUE, the output will consist of a dataframe 
with all detected p values, also the ones that were not part of the full 
results in APA format.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>messages</code></td>
<td>
<p>Logical. If TRUE, statcheck will print a progress bar while 
it's extracting statistics from text.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>statcheck</code> roughly works in three steps.
</p>
<p><strong>1. Scan text for statistical results</strong>
</p>
<p><code>statcheck</code> uses regular expressions to recognizes statistical results 
from t-tests, F-tests, <code class="reqn">\chi2</code>-tests, Z-tests, Q-tests, and correlations. 
statcheck can only recognize these results if the results are reported 
exactly according to the APA guidelines:
</p>

<ul>
<li> <p><em>t</em>(df) = value, <em>p</em> = value
</p>
</li>
<li> <p><em>F</em>(df1, df2) = value, <em>p</em> = value
</p>
</li>
<li> <p><em>r</em>(df) = value, p = value
</p>
</li>
<li> <p><em><code class="reqn">\chi2</code></em> (df, N = value) = value, <em>p</em> = value 
(N is optional)
</p>
</li>
<li> <p><em>Z</em> = value, <em>p</em> = value
</p>
</li>
<li> <p><em>Q</em>(df) = value, <em>p</em> = value (statcheck can distinguish
between Q, Qw / Q-within, and Qb / Q-between)
</p>
</li>
</ul>
<p><code>statcheck</code> takes into account that test statistics and p values may be 
exactly (=) or inexactly (&lt; or &gt;) reported. Different spacing has also been 
taken into account.
</p>
<p><strong>2. Recompute p-value</strong>
</p>
<p><code>statcheck</code> uses the reported test statistic and degrees of freedom to
recompute the p-value. By default, the recomputed p-value is two-sided
</p>
<p><strong>3. Compare reported and recomputed p-value</strong>
</p>
<p>This comparison takes into account how the results were reported, e.g., 
p &lt; .05 is treated differently than p = .05. Incongruent p values are marked 
as an <code>error</code>. If the reported result is significant and the recomputed 
result is not, or vice versa, the result is marked as a 
<code>decision_error</code>.
</p>
<p>Correct rounding is taken into account. For instance, a reported t-value of 
2.35 could correspond to an actual value of 2.345 to 2.354 with a range of 
p-values that can slightly deviate from the recomputed p-value. 
<code>statcheck</code> will not count cases like this as errors.
</p>
<p>Note that when <code>statcheck</code> flags an <code>error</code> or 
<code>decision_error</code>, it implicitly assumes that the p-value is the 
inconsistent value, but it could just as well be the case that the test 
statistic or degrees of freedom contain a reporting error. <code>statcheck</code>
merely detects wether a set of numbers is consistent with each other.
</p>


<h3>Value</h3>

<p>A data frame containing for each extracted statistic:
</p>

<dl>
<dt>source</dt>
<dd>
<p>Name of the file of which the statistic is extracted</p>
</dd>
<dt>test_type</dt>
<dd>
<p>Character indicating the statistic that is extracted</p>
</dd>
<dt>df1</dt>
<dd>
<p>First degree of freedom (if applicable)</p>
</dd>
<dt>df2</dt>
<dd>
<p>Second degree of freedom</p>
</dd>
<dt>test_comp</dt>
<dd>
<p>Reported comparison of the test statistic, when 
importing from pdf this will often not be converted properly</p>
</dd>
<dt>test_value</dt>
<dd>
<p>Reported value of the statistic</p>
</dd>
<dt>p_comp</dt>
<dd>
<p>Reported comparison, when importing from pdf this might not 
be converted properly</p>
</dd>
<dt>reported_p</dt>
<dd>
<p>The reported p-value, or NA if the reported value was 
n.s.</p>
</dd>
<dt>computed_p</dt>
<dd>
<p>The recomputed p-value</p>
</dd>
<dt>raw</dt>
<dd>
<p>Raw string of the statistical reference that is extracted</p>
</dd>
<dt>error</dt>
<dd>
<p>The computed p value is not congruent with the reported 
p-value</p>
</dd>
<dt>decision_error</dt>
<dd>
<p>The reported result is significant whereas the 
recomputed result is not, or vice versa.</p>
</dd>
<dt>one_tailed_in_txt</dt>
<dd>
<p>Logical. Does the text contain the string 
"sided", "tailed", and/or "directional"?</p>
</dd>
<dt>apa_factor</dt>
<dd>
<p>What proportion of all detected p-values was part of a 
fully APA reported result?</p>
</dd>
</dl>
<h3>See Also</h3>

<p>For more details, see the 
<a href="https://rpubs.com/michelenuijten/statcheckmanual">online manual</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">txt &lt;- "blablabla the effect was very significant (t(100)=1, p &lt; 0.001)"
statcheck(txt)

</code></pre>


</div>