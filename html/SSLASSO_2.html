<div class="container">

<table style="width: 100%;"><tr>
<td>SSLASSO</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The Spike-and-Slab LASSO</h2>

<h3>Description</h3>

<p>Spike-and-Slab LASSO is a spike-and-slab refinement of the LASSO procedure, using a mixture of Laplace priors indexed by  <code>lambda0</code> (spike) and <code>lambda1</code> (slab). 
</p>
<p>The <code>SSLASSO</code> procedure fits coefficients paths for Spike-and-Slab LASSO-penalized
linear regression models over a grid of values for the regularization
parameter <code>lambda0</code>. The code has been adapted from the <code>ncvreg</code> package (Breheny and Huang, 2011). </p>


<h3>Usage</h3>

<pre><code class="language-R">SSLASSO(X, y, penalty = c("adaptive", "separable"), variance = c("fixed", "unknown"), 
lambda1, lambda0, nlambda = 100, theta = 0.5, sigma, a = 1, b,  
eps = 0.001, max.iter = 500,  counter = 10, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>The design matrix (n x p), without an intercept.  <code>SSLASSO</code>
standardizes the data by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector of continuous responses (n x 1). The responses will be centered by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>The penalty to be applied to the model.  Either "separable"
(with a fixed <code>theta</code>) or "adaptive" (with a random <code>theta</code>, where <code>theta ~ B(a,p)</code>). The default is <code>"adaptive"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variance</code></td>
<td>
<p>Whether the error variance is also estimated. Either "fixed" (with a fixed <code>sigma</code>) or "unknown" (with a random <code>sigma</code>, where <code>p(sigma) ~ 1/sigma</code>). The default is <code>"fixed"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda1</code></td>
<td>
<p>Slab variance parameter. Needs to be less than <code>lambda0</code>. The default is <code>lambda0 = 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda0</code></td>
<td>
<p>Spike penalty parameters (L x 1). Either a numeric value for a single run (L=1) or a sequence of increasing values for dynamic posterior exploration. The default is <code>lambda0 = seq(1, nrow(X), length.out = 100)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of <code>lambda0</code> values. Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>Prior mixing proportion. For "separable" penalty, this value is fixed. For "adaptive" penalty, this value is used as a starting value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Error variance. For "fixed" variance, this value is fixed. For "unknown" variance, this value is used as a starting value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>a = 1</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>Hyperparameter of the beta prior <code>B(a,b)</code> for the adaptive penalty (default <code>b = ncol(X)</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Convergence criterion: converged when difference in regression coefficients is less than <code>eps</code> (default <code>eps = 0.001</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>Maximum number of iterations.  Default is 500.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>counter</code></td>
<td>
<p>Applicable only for the adaptive penalty. Determines how often the parameter <code>theta</code> is updated throughout the cycles of coordinate ascent. Default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warn</code></td>
<td>
<p>TRUE if warnings should be printed; FALSE by default</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter
<code>lambda0</code> is fitted using a coordinate descent algorithm. The algorithm uses 
screening rules for discarding irrelevant predictors along the lines of Breheny (2011).
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"SSLASSO"</code> containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients (p x L).  The number of rows is
equal to the number of coefficients <code>p</code>, and the number of columns is
equal to <code>L</code> (the length of <code>lambda0</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>A vector of length <code>L</code> containing the intercept for each value of <code>lambda0</code>. The intercept is <code>intercept = mean(y) - crossprod(XX, beta)</code>, where <code>XX</code> is the centered design matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>A vector of length <code>L</code> containing the number
of iterations until convergence at each value of <code>lambda0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda0</code></td>
<td>
<p>The sequence of regularization parameter values in the
path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>Same as above.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thetas</code></td>
<td>
<p>A vector of length <code>L</code> containing the hyper-parameter values <code>theta</code> (the same as <code>theta</code> for "separable" penalty).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmas</code></td>
<td>
<p>A vector of length <code>L</code> containing the values <code>sigma</code> (the same as the initial <code>sigma</code> for "known" variance).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>select</code></td>
<td>
<p>A (p x L) binary matrix indicating which variables were selected along the solution path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A single model chosen after the stabilization of the regularization path.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Veronika Rockova &lt;Veronika.Rockova@chicagobooth.edu&gt;, Gemma Moran &lt;gmoran@wharton.upenn.edu&gt;</p>


<h3>References</h3>

<p>Rockova, V. and George, E.I. (2018) The Spike-and-Slab LASSO. Journal of the American Statistical Association.
</p>
<p>Moran, G., Rockova, V. and George, E.I. (2018) On variance estimation for Bayesian variable selection. &lt;https://arxiv.org/abs/1801.03019&gt;</p>


<h3>See Also</h3>

<p><code>plot.SSLASSO</code></p>


<h3>Examples</h3>

<pre><code class="language-R">## Linear regression, where p &gt; n

library(SSLASSO)

p &lt;- 1000
n &lt;- 100

X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)
beta &lt;- c(1, 2, 3, rep(0, p-3))
y = X[,1] * beta[1] + X[,2] * beta[2] + X[,3] * beta[3] + rnorm(n)

# Oracle SSLASSO with known variance

result1 &lt;- SSLASSO(X, y, penalty = "separable", theta = 3/p)
plot(result1)

# Adaptive SSLASSO with known variance

result2 &lt;- SSLASSO(X, y)
plot(result2)

# Adaptive SSLASSO with unknown variance

result3 &lt;- SSLASSO(X, y, variance = "unknown")
plot(result3)

</code></pre>


</div>