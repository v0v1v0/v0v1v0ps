<div class="container">

<table style="width: 100%;"><tr>
<td>compute_policy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>compute_policy</h2>

<h3>Description</h3>

<p>Derive the corresponding policy function from the alpha vectors
</p>


<h3>Usage</h3>

<pre><code class="language-R">compute_policy(
  alpha,
  transition,
  observation,
  reward,
  state_prior = rep(1, dim(observation)[[1]])/dim(observation)[[1]],
  a_0 = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>the matrix of alpha vectors returned by <code>sarsop</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transition</code></td>
<td>
<p>Transition matrix, dimension n_s x n_s x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observation</code></td>
<td>
<p>Observation matrix, dimension n_s x n_z x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reward</code></td>
<td>
<p>reward matrix, dimension n_s x n_a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>state_prior</code></td>
<td>
<p>initial belief state, optional, defaults to uniform
over states</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a_0</code></td>
<td>
<p>previous action. Belief in state depends not only on observation, but on prior belief of the state and subsequent action that had been taken.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a data frame providing the optimal policy (choice of action) and corresponding value of the action for each possible belief state
</p>


<h3>Examples</h3>

<pre><code class="language-R">
m &lt;- fisheries_matrices()
 ## Takes &gt; 5s
if(assert_has_appl()){
alpha &lt;- sarsop(m$transition, m$observation, m$reward, 0.95, precision = 10)
compute_policy(alpha, m$transition, m$observation, m$reward)
}


</code></pre>


</div>