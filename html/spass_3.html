<div class="container">

<table style="width: 100%;"><tr>
<td>bssr.nb.gf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Blinded Sample Size Reestimation for Longitudinal Count Data with marginal Negative Binomial Distribution and underlying Gamma Frailty with Autoregressive Correlation Structure of Order One</h2>

<h3>Description</h3>

<p><code>bssr.nb.gf</code> fits blinded observations and recalculates the sample size required for sustaining power at desired alternative when testing for
trend parameters in a Gamma frailty models. See 'Details' for more information.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bssr.nb.gf(
  data,
  alpha = 0.025,
  power = 0.8,
  delta,
  h0 = 0,
  tp,
  k,
  trend = c("constant", "exponential", "custom"),
  approx = 20
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a matrix or data frame containing count data which is to be fitted. Columns correspond to time points, rows to observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>level (type I error) to which the hypothesis is tested.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power</code></td>
<td>
<p>power (1 - type II error) to which an alternative should be proven.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>the relevant effect size, which is assumed to be true, see 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h0</code></td>
<td>
<p>the value against which h is tested, see 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tp</code></td>
<td>
<p>number of observed time points. (see <code>rnbinom.gf</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>sample size allocation factor between groups: see 'Details'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trend</code></td>
<td>
<p>the trend which assumed to underlying in the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approx</code></td>
<td>
<p>numer of iterations in numerical calculation of the sandwich estimator, see 'Details'.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function recalculates a sample size for testing in constant and exponential trends.
</p>
<p>Under a constant trend, the means in control and experiment group are equal to <code class="reqn">\lambda_1</code> and  <code class="reqn">\lambda_1 + \lambda_2</code>, respectively.
The treatment effect <code>delta</code> is therefore equal to <code class="reqn">\lambda_2</code>.
</p>
<p>Under an exponential trend, the means in control and experiment group are equal to <code class="reqn">exp(\lambda_1+t \cdot \lambda_2)</code> and  <code class="reqn">\lambda_1 + t\cdot \lambda_2 + t\cdot \lambda_3</code>, respectively.
The treatment effect <code>delta</code> is therefore equal to <code class="reqn">\lambda_3</code>.
</p>
<p><code>bssr.nb.gf</code> returns the required sample size for the control and treatment group required to prove an existing
alternative <code>delta</code> with a specified power <code>power</code> when testing the null hypothesis <code class="reqn">H_0: \delta \ge h_0</code> at level <code>alpha</code>.
Nuisance parameters are estimated through the blinded observations <code>data</code>, thus not further required.
For sample sizes <code class="reqn">n_C</code> and <code class="reqn">n_T</code> of the control and treatment group, respectively, the argument <code>k</code> is the desired
sample size allocation factor at the end of the study, i.e. <code class="reqn">k = n_T/n_C</code>.
</p>


<h3>Value</h3>

<p><code>bssr.nb.gf</code> returns the required sample size within the control group and treatment group.
</p>


<h3>Source</h3>

<p><code>bssr.nb.gf</code> uses code contributed by Thomas Asendorf.
</p>


<h3>See Also</h3>

<p><code>rnbinom.gf</code> for information on the Gamma Frailty model, <code>n.nb.gf</code> for calculating
initial sample size required when performing inference, <code>fit.nb.gf</code> for calculating
initial parameters required when performing sample size estimation.
</p>


<h3>Examples</h3>

<pre><code class="language-R">##The example is commented as it may take longer than 10 seconds to run.
##Please uncomment prior to execution.

##Example for constant rates
#set.seed(12)
#h&lt;-function(lambda.eta){
#   lambda.eta[2]
#}
#hgrad&lt;-function(lambda.eta){
#   c(0, 1, 0)
#}

##Calculate initial sample size
#estimate&lt;-n.nb.gf(lambda=c(0,-0.3), size=1, rho=0.5, tp=6, k=1, h=h, hgrad=hgrad,
#   h0=0, trend="constant", approx=20)

##Generate and permutate data with different nuisance parameters
#random&lt;-get.groups(n=round(estimate$n/2), size=c(0.8, 0.8), lambda=c(0.5, -0.3),
#   rho=c(0.4, 0.4), tp=6, trend="constant")
#random&lt;-random[sample(1:nrow(random), nrow(random)), ]

##Recalculate sample size with data
#reestimate&lt;-bssr.nb.gf(data=random, alpha=0.025, power=0.8, delta=-0.3, h0=0,
#   tp=6, k=1, trend="constant", approx = 20)

#summary(reestimate)

</code></pre>


</div>