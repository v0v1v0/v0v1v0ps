<div class="container">

<table style="width: 100%;"><tr>
<td>scgwr_p</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parallel implementation of scalable geographically weighted regression</h2>

<h3>Description</h3>

<p>Parallel implementation of scalable geographically weighted regression for large samples
</p>


<h3>Usage</h3>

<pre><code class="language-R">scgwr_p( coords, y, x = NULL, knn = 100, kernel = "gau",
       p = 4, approach = "CV", nsamp = NULL, cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>coords</code></td>
<td>
<p>Matrix of spatial point coordinates (N x 2)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector of explained variables (N x 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Matrix of explanatory variables (N x K). Default is NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knn</code></td>
<td>
<p>Number of nearest-neighbors being geographically weighted. Default is 100. Larger knn is better for larger samples (see Murakami er al., 2019)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>Kernel to model spatial heterogeneity. Gaussian kernel ("gau") and exponential kernel ("exp") are available</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Degree of the polynomial to approximate the kernel function. Default is 4</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approach</code></td>
<td>
<p>If "CV", leave-one-out cross-validation is used for the model calibration. If "AICc", the corrected Akaike Information Criterion is minimized for the calibation. Default is "CV"</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsamp</code></td>
<td>
<p>Number of samples used to approximate the cross-validation. The samples are randomly selected. If the value is large enough (e.g., 10,000), error due to the sampling is quite small owing to the central limit theorem. The value must be smaller than the sample size. Default is NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>
<p>Number of cores used for the parallel computation. If cl = NULL, which is the default, the number of available cores is detected and used</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>Matrix of estimated coefficients (N x K)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bse</code></td>
<td>
<p>Matrix of the standard errors for the coefficients (N x k)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t</code></td>
<td>
<p>Matrix of the t-values for the coefficients (N x K)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Matrix of the p-values for the coefficients (N x K)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>Estimated model parameters includeing a scale parameter and a shrinkage parameter if penalty = TRUE (see Murakami et al., 2018)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>e</code></td>
<td>
<p>Error statistics. It includes sum of squared errors (SSE), residual standard error (resid_SE), R-squared (R2), adjusted R2 (adjR2), log-likelihood (logLik), corrected Akaike information criterion (AICc), and the cross-validation (CV) score measured by root mean squared error (RMSE) (CV_score(RMSE))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector of predicted values (N x 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>resid</code></td>
<td>
<p>Vector of residuals (N x 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>other</code></td>
<td>
<p>Other objects internally used</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Murakami, D., Tsutsumida, N., Yoshida, T., Nakaya, T., and Lu, B. (2019) Scalable GWR: A linear-time algorithm for large-scale geographically weighted regression with polynomial kernels. &lt;arXiv:1905.00266&gt;.
</p>


<h3>See Also</h3>

<p><code>scgwr</code>, <code>predict0</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># require(spData);require(sp)
# data(house)
# dat   &lt;- data.frame(coordinates(house), house@data[,c("price","age","rooms","beds","syear")])
# coords&lt;- dat[ ,c("long","lat")]
# y	    &lt;- log(dat[,"price"])
# x     &lt;- dat[,c("age","rooms","beds","syear")]

# Parallel estimation
# res1  &lt;- scgwr_p( coords = coords, y = y, x = x )
# res1

# Parallel estimation + Approximate cross-validation using 10000 samples
# res2  &lt;- scgwr_p( coords = coords, y = y, x = x, nsamp = 10000 )
# res2
</code></pre>


</div>