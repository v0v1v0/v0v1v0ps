<div class="container">

<table style="width: 100%;"><tr>
<td>squarem</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Squared Extrapolation Methods for Accelerating Slowly-Convergent 
Fixed-Point Iterations</h2>

<h3>Description</h3>

<p>Globally-convergent, partially monotone, acceleration schemes for 
accelerating the convergence of *any* smooth, monotone, slowly-converging
contraction mapping. It can be used to accelerate the convergence of a wide 
variety of iterations including the expectation-maximization (EM) algorithms 
and its variants, majorization-minimization (MM) algorithm, power method for 
dominant eigenvalue-eigenvector, Google's page-rank algorithm, and 
multi-dimensional scaling.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  squarem(par, fixptfn, objfn, ... , control=list())
  </code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>A vector of parameters denoting the initial guess for the 
fixed-point.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixptfn</code></td>
<td>
<p>A vector function, $F$ that denotes the fixed-point 
mapping.  This function is the most essential input in the package.  
It should accept a parameter vector as input and should return a 
parameter vector of same length. This function defines the fixed-point 
iteration: <code class="reqn">x_{k+1} = F(x_k)</code>.  
In the case of EM algorithm, <code class="reqn">F</code> defines a single E and M step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objfn</code></td>
<td>
<p>This is a scalar function, <code class="reqn">L</code>, that denotes 
a ”merit” function which attains its local maximum or minimum at the fixed          -point of <code class="reqn">F</code>. Also see the control parameter <code>minimize</code> which              determines whether the objective function is minimized or maximized. The               objective function should accept a parameter vector as input and should return a       scalar value.  In the EM algorithm, the merit function <code class="reqn">L</code> is the either        log-likelihood or its negative. In someproblems, a natural merit function may not       exist, in which case the algorithm works with only <code>fixptfn</code>. The merit           function function <code>objfn</code> does not have to be specified, even when a natural       merit function is available, especially when its computation is expensive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>A list of control parameters specifing any changes to 
default values of algorithm control parameters.  Full names of control list            elements must be specified, otherwise, user-specifications are ignored.  
See *Details*.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed to <code>fixptfn</code> and  <code>objfn</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>squarem</code> is a general-purpose algorithm for accelerating 
the convergence of <em>any</em> slowly-convergent (smooth) fixed-point iteration.  Full names of 
</p>
<p>Default values of <code>control</code> are:
<code>K=1</code>,
<code>method=3</code>, 
<code>minimize=TRUE</code>,
<code>square=TRUE</code>, 
<code>step.min0=1</code>, 
<code>step.max0=1</code>, 
<code>mstep=4</code>, 
<code>objfn.inc=1</code>, 
<code>kr=1</code>, 
<code>tol=1e-07</code>, 
<code>maxiter=1500</code>, 
<code>trace=FALSE</code>,
<code>intermed=FALSE</code>.
</p>

<dl>
<dt><code>K</code></dt>
<dd>
<p>An integer denoting the order of the SQUAREM scheme.
Default is 1, which is a first-order scheme developed in Varadhan and 
Roland (2008). Our experience is that first-order schemes are adequate 
for most problems. <code>K=2,3</code> may provide greater speed in some 
problems, although they are less reliable than the first-order schemes.</p>
</dd>
<dt><code>method</code></dt>
<dd>
<p>Either an integer or a character variable that denotes the 
particular SQUAREM scheme to be used.  When <code>K=1</code>, method should be 
an integer, either 1, 2, or 3.  These correspond to the 3 schemes 
discussed in Varadhan and Roland (2008).  Default is <code>method=3</code>.  
When K &gt; 1, method should be a character string, either <code>''RRE''</code> 
or <code>''MPE''</code>.  These correspond to the reduced-rank extrapolation 
or squared minimal=polynomial extrapolation (See Roland, Varadhan, and 
Frangakis (2007)).  Default is ”RRE”.</p>
</dd>
<dt><code>minimize</code></dt>
<dd>
<p>A logical variable.  By default it is set to <code>TRUE</code> for minimization of the objective function. If the objective function is to be maximized, which is commonly the case for likelihood estimation, it should be changed to <code>FALSE</code>.</p>
</dd>
<dt><code>square</code></dt>
<dd>
<p>A logical variable indicating whether or not a squared 
extrapolation scheme should be used.  Our experience is that the 
squared extrapolation schemes are faster and more stable than the 
unsquared schemes. Hence, we have set the default as TRUE.</p>
</dd>  
<dt><code>step.min0</code></dt>
<dd>
<p>A scalar denoting the minimum steplength taken by a
SQUAREM algorithm.  Default is 1.  For contractive fixed-point 
iterations (e.g. EM and MM), this defualt works well.  In problems 
where an eigenvalue of the Jacobian of $F$ is outside of the 
interval <code class="reqn">(0,1)</code>, <code>step.min0</code> should be less than 1 
or even negative in some cases.</p>
</dd>
<dt><code>step.max0</code></dt>
<dd>
<p>A positive-valued scalar denoting the initial value 
of the maximum steplength taken by a SQUAREM algorithm.  
Default is 1.  When the steplength computed by SQUAREM exceeds  
<code>step.max0</code>, the steplength is set equal to step.max0, but 
then step.max0 is increased by a factor of mstep.</p>
</dd>
<dt><code>mstep</code></dt>
<dd>
<p>A scalar greater than 1.  When the steplength computed 
by SQUAREM exceeds  <code>step.max0</code>, the steplength is set equal 
to  <code>step.max0</code>, but  <code>step.max0</code> is increased by a factor 
of  <code>mstep</code>. Default is 4.</p>
</dd>
<dt><code>objfn.inc</code></dt>
<dd>
<p>A non-negative scalar that dictates the degree of 
non-montonicity.  Default is 1.  Set  <code>objfn.inc = 0</code> to 
obtain monotone convergence. Setting  <code>objfn.inc = Inf</code> gives a 
non-monotone scheme.  In-between values result in partially-monotone 
convergence.</p>
</dd>
<dt><code>kr</code></dt>
<dd>
<p>A non-negative scalar that dictates the degree of 
non-montonicity.  Default is 1.  Set  <code>kr = 0</code> to obtain 
monotone convergence. Setting  <code>kr = Inf</code> gives a non-monotone 
scheme.  In-between values result in partially-monotone convergence.  This parameter is only used when  <code>objfn</code> is not specified by user.</p>
</dd>
<dt><code>tol</code></dt>
<dd>
<p>A small, positive scalar that determines when iterations 
should be terminated.  Iteration is terminated when 
<code class="reqn">||x_k - F(x_k)|| \leq tol</code>.  
Default is <code>1.e-07</code>.</p>
</dd>
<dt><code>maxiter</code></dt>
<dd>
<p>An integer denoting the maximum limit on the number 
of evaluations of  <code>fixptfn</code>, <code class="reqn">F</code>.  Default is 1500.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p>A logical variable denoting whether some of the intermediate 
results of iterations should be displayed to the user.  
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>intermed</code></dt>
<dd>
<p>A logical variable denoting whether the intermediate 
results of iterat ions should be returned. If set to <code>TRUE</code>, the function 
will return a matrix where each row corresponds to parameters at each iteration, 
along with the corresponding log-likelihood value.  When the codeobjfn is not specified it will return the fixed-point residual instead of the objective function values. 
Default is <code>FALSE</code>.</p>
</dd>
</dl>
<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>Parameter, <code class="reqn">x*</code> that are the fixed-point of <code class="reqn">F</code> 
such that <code class="reqn">x* = F(x*)</code>, if convergence is successful.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value.objfn</code></td>
<td>
<p>The value of the objective function $L$ at termination.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fpevals</code></td>
<td>
<p>Number of times the fixed-point function <code>fixptfn</code> was evaluated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objfevals</code></td>
<td>
<p>Number of times the objective function <code>objfn</code> was evaluated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> 
indicates successful convergence, whereas <code>1</code> denotes failure to 
converge.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.intermed</code></td>
<td>
<p>A matrix where each row corresponds to parameters at each iteration, 
along with the corresponding log-likelihood value. This object is returned only when 
the control parameter <code>intermed</code> is set to <code>TRUE</code>.  It is not returned when 
<code>objfn</code> is not specified.</p>
</td>
</tr>
</table>
<h3>References</h3>

 
<p>R Varadhan and C Roland (2008), Simple and globally convergent numerical 
schemes for accelerating the convergence of any EM algorithm, 
<em>Scandinavian Journal of Statistics</em>, 35:335-353.
</p>
<p>C Roland, R Varadhan, and CE Frangakis (2007), Squared polynomial 
extrapolation methods with cycling: an application to the positron emission 
tomography problem, <em>Numerical Algorithms</em>, 44:159-172.
</p>
<p>Y Du and R Varadhan (2020), SQUAREM: An R package for off-the-shelf acceleration 
of EM, MM, and other EM-like monotone algorithms, <em>Journal of Statistical Software</em>,
92(7): 1-41.  &lt;doi:10.18637/jss.v092.i07&gt;
</p>


<h3>See Also</h3>

<p><code>fpiter</code> 
</p>


<h3>Examples</h3>

<pre><code class="language-R">###########################################################################
# Also see the vignette by typing:
#  vignette("SQUAREM", all=FALSE)
#
# Example 1:  EM algorithm for Poisson mixture estimation 

poissmix.em &lt;- function(p,y) {
# The fixed point mapping giving a single E and M step of the EM algorithm
# 
pnew &lt;- rep(NA,3)
i &lt;- 0:(length(y)-1)
zi &lt;- p[1]*exp(-p[2])*p[2]^i / (p[1]*exp(-p[2])*p[2]^i + (1 - p[1])*exp(-p[3])*p[3]^i)
pnew[1] &lt;- sum(y*zi)/sum(y)
pnew[2] &lt;- sum(y*i*zi)/sum(y*zi)
pnew[3] &lt;- sum(y*i*(1-zi))/sum(y*(1-zi))
p &lt;- pnew
return(pnew)
}

poissmix.loglik &lt;- function(p,y) {
# Objective function whose local minimum is a fixed point 
# negative log-likelihood of binary poisson mixture
i &lt;- 0:(length(y)-1)
loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
		(1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
return ( -sum(loglik) )
}

# Real data from Hasselblad (JASA 1969)
poissmix.dat &lt;- data.frame(death=0:9, freq=c(162,267,271,185,111,61,27,8,3,1))
y &lt;- poissmix.dat$freq
tol &lt;- 1.e-08

# Use a preset seed so the example is reproducable. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=54321))

p0 &lt;- c(runif(1),runif(2,0,4))  # random starting value

# Basic EM algorithm
pf1 &lt;- fpiter(p=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, control=list(tol=tol))

# First-order SQUAREM algorithm with SqS3 method
pf2 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list(tol=tol))

# First-order SQUAREM algorithm with SqS2 method
pf3 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list(method=2, tol=tol))

# First-order SQUAREM algorithm with SqS3 method; non-monotone 
# Note: the objective function is not evaluated when objfn.inc = Inf 
pf4 &lt;- squarem(par=p0,y=y, fixptfn=poissmix.em,
               control=list(tol=tol, objfn.inc=Inf))

# First-order SQUAREM algorithm with SqS3 method; 
#  objective function is not specified
pf5 &lt;- squarem(par=p0,y=y, fixptfn=poissmix.em, control=list(tol=tol, kr=0.1))

# Second-order (K=2) SQUAREM algorithm with SqRRE 
pf6 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list (K=2, tol=tol))

# Second-order SQUAREM algorithm with SqRRE; objective function is not specified
pf7 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, control=list(K=2, tol=tol))

# Comparison of converged parameter estimates
par.mat &lt;- rbind(pf1$par, pf2$par, pf3$par, pf4$par, pf5$par, pf6$par, pf7$par)
par.mat

# Compare objective function values 
# (note: `NA's indicate that \code{objfn} was not specified)
c(pf1$value, pf2$value, pf3$value, pf4$value, 
  pf5$value, pf6$value, pf7$value)

# Compare number of fixed-point evaluations
c(pf1$fpeval, pf2$fpeval, pf3$fpeval, pf4$fpeval, 
  pf5$fpeval, pf6$fpeval, pf7$fpeval)

# Compare mumber of objective function evaluations 
# (note: `0' indicate that \code{objfn} was not specified)
c(pf1$objfeval, pf2$objfeval, pf3$objfeval, pf4$objfeval, 
  pf5$objfeval, pf6$objfeval, pf7$objfeval)

###############################################################
# Example 2: Same as above (i.e. Poisson mixture)
# but now showing how to "maximize" the log-likelihood

poissmix.loglik.max &lt;- function(p,y) {
# Objective function which is to be *maximized* 
# Log-likelihood of binary poisson mixture
i &lt;- 0:(length(y)-1)
loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
		(1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
return ( sum(loglik) )
}

# Maximizing the log-likelihood
# Note:  the control parameter `minimize' is set to FALSE
#
pf.max &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik.max, 
               control=list(tol=tol, minimize=FALSE))
pf.max

##############################################################################
# Example 3:  Accelerating the convergence of power method iteration 
#  for finding the dominant eigenvector of a matrix 

power.method &lt;- function(x, A) {
# Defines one iteration of the power method
# x = starting guess for dominant eigenvector
# A = a square matrix
ax &lt;- as.numeric(A %*% x)
f &lt;- ax / sqrt(as.numeric(crossprod(ax)))
f
}

# Finding the dominant eigenvector of the Bodewig matrix
b &lt;- c(2, 1, 3, 4, 1,  -3,   1,   5,  3,   1,   6,  -2,  4,   5,  -2,  -1)
bodewig.mat &lt;- matrix(b,4,4)
eigen(bodewig.mat)

p0 &lt;- rnorm(4)

# Standard power method iteration
ans1 &lt;- fpiter(p0, fixptfn=power.method, A=bodewig.mat)
# re-scaling the eigenvector so that it has unit length
ans1$par &lt;- ans1$par / sqrt(sum(ans1$par^2))  
ans1

# First-order SQUAREM with default settings 
ans2 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(K=1))
ans2$par &lt;- ans2$par / sqrt(sum(ans2$par^2))
ans2

# First-order SQUAREM with a smaller step.min0
# Convergence is dramatically faster now!
ans3 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(step.min0 = 0.5))
ans3$par &lt;- ans3$par / sqrt(sum(ans3$par^2))
ans3

# Second-order SQUAREM
ans4 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(K=2, method="rre"))
ans4$par &lt;- ans4$par / sqrt(sum(ans4$par^2))
ans4
</code></pre>


</div>