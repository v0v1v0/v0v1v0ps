<div class="container">

<table style="width: 100%;"><tr>
<td>svyby_repwts</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compare survey statistics calculated separately from different sets of replicate weights</h2>

<h3>Description</h3>

<p>A modified version of the <code>svyby()</code> function from the <code>survey</code> package.
Whereas <code>svyby()</code> calculates statistics separately for each subset formed by a specified grouping variable,
<code>svyby_repwts()</code> calculates statistics separately for each replicate design, in addition to any additional user-specified grouping variables.
</p>


<h3>Usage</h3>

<pre><code class="language-R">svyby_repwts(
  rep_designs,
  formula,
  by,
  FUN,
  ...,
  deff = FALSE,
  keep.var = TRUE,
  keep.names = TRUE,
  verbose = FALSE,
  vartype = c("se", "ci", "ci", "cv", "cvpct", "var"),
  drop.empty.groups = TRUE,
  return.replicates = FALSE,
  na.rm.by = FALSE,
  na.rm.all = FALSE,
  multicore = getOption("survey.multicore")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>rep_designs</code></td>
<td>
<p>The replicate-weights survey designs to be compared. Supplied either as:
</p>

<ul>
<li>
<p> A named list of replicate-weights survey design objects, for example <code>list('nr' = nr_adjusted_design, 'ue' = ue_adjusted_design)</code>.
</p>
</li>
<li>
<p> A 'stacked' replicate-weights survey design object created by <code>stack_replicate_designs()</code>.
</p>
</li>
</ul>
<p>The designs must all have the same number of columns of replicate weights, of the same type (bootstrap, JKn, etc.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A formula specifying the variables to pass to <code>FUN</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>by</code></td>
<td>
<p>A formula specifying factors that define subsets</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>FUN</code></td>
<td>
<p>A function taking a formula and survey design object as its first two arguments.
Usually a function from the <code>survey</code> package, such as <code>svytotal</code> or <code>svymean</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other arguments to <code>FUN</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deff</code></td>
<td>
<p>A value of <code>TRUE</code> or <code>FALSE</code>, indicating whether design effects should be estimated if possible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.var</code></td>
<td>
<p>A value of <code>TRUE</code> or <code>FALSE</code>. If <code>FUN</code> returns a <code>svystat</code> object, indicates whether to extract standard errors from it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.names</code></td>
<td>
<p>Define row names based on the subsets</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>If <code>TRUE</code>, print a label for each subset as it is processed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vartype</code></td>
<td>
<p>Report variability as one or more of standard error, confidence interval, coefficient of variation,  percent coefficient of variation, or variance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop.empty.groups</code></td>
<td>
<p>If <code>FALSE</code>, report <code>NA</code> for empty groups, if <code>TRUE</code> drop them from the output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.replicates</code></td>
<td>
<p>If <code>TRUE</code>, return all the replicates as the "replicates" attribute of the result.
This can be useful if you want to produce custom summaries of the estimates from each replicate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm.by</code></td>
<td>
<p>If true, omit groups defined by <code>NA</code> values of the <code>by</code> variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm.all</code></td>
<td>
<p>If true, check for groups with no non-missing observations for variables defined by <code>formula</code> and treat these groups as empty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multicore</code></td>
<td>
<p>Use <code>multicore</code> package to distribute subsets over multiple processors?</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class <code>"svyby"</code>: a data frame showing the grouping factors and results of <code>FUN</code> for each combination of the grouping factors.
The first grouping factor always consists of indicators for which replicate design was used for an estimate.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
suppressPackageStartupMessages(library(survey))
data(api)

dclus1 &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1$variables$response_status &lt;- sample(x = c("Respondent", "Nonrespondent",
                                                 "Ineligible", "Unknown eligibility"),
                                           size = nrow(dclus1),
                                           replace = TRUE)
orig_rep_design &lt;- as.svrepdesign(dclus1)

# Adjust weights for cases with unknown eligibility
ue_adjusted_design &lt;- redistribute_weights(
    design = orig_rep_design,
    reduce_if = response_status %in% c("Unknown eligibility"),
    increase_if = !response_status %in% c("Unknown eligibility"),
    by = c("stype")
)

# Adjust weights for nonresponse
nr_adjusted_design &lt;- redistribute_weights(
    design = ue_adjusted_design,
    reduce_if = response_status %in% c("Nonrespondent"),
    increase_if = response_status == "Respondent",
    by = c("stype")
)

# Compare estimates from the three sets of replicate weights

  list_of_designs &lt;- list('original' = orig_rep_design,
                          'unknown eligibility adjusted' = ue_adjusted_design,
                          'nonresponse adjusted' = nr_adjusted_design)

  ##_ First compare overall means for two variables
  means_by_design &lt;- svyby_repwts(formula = ~ api00 + api99,
                                  FUN = svymean,
                                  rep_design = list_of_designs)

  print(means_by_design)

  ##_ Next compare domain means for two variables
  domain_means_by_design &lt;- svyby_repwts(formula = ~ api00 + api99,
                                         by = ~ stype,
                                         FUN = svymean,
                                         rep_design = list_of_designs)

  print(domain_means_by_design)

# Calculate confidence interval for difference between estimates

ests_by_design &lt;- svyby_repwts(rep_designs = list('NR-adjusted' = nr_adjusted_design,
                                                  'Original' = orig_rep_design),
                               FUN = svymean, formula = ~ api00 + api99)

differences_in_estimates &lt;- svycontrast(stat = ests_by_design, contrasts = list(
  'Mean of api00: NR-adjusted vs. Original' = c(1,-1,0,0),
  'Mean of api99: NR-adjusted vs. Original' = c(0,0,1,-1)
))

print(differences_in_estimates)

confint(differences_in_estimates, level = 0.95)

## End(Not run)
</code></pre>


</div>