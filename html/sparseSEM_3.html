<div class="container">

<table style="width: 100%;"><tr>
<td>elasticNetSEM</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
The Elastic Net penalized SEM with Network GPT Framework
</h2>

<h3>Description</h3>

<p>Fit the elastic-net penalized structureal Equation Models (SEM) with input data (X, Y): Y = BY + fX + e.
</p>
<p>For users new to this package, elasticNetSEM provides the simplified entry point: 
Missing matrix can be all 0 (none or uknown), so as B matrix (unknow connections in the network), 
thus only Y and X are mandatory.
</p>
<p>Underlying the function, the program obtains the optimal hyperparameter (alpha, lambda) from 
k-fold cross validation (CV) with fixed k= 5.  Specifically, for each alpha from 0.95 to 0.05 at
a step of -0.05, the function perform 5 fold CV for lambda_max to lambda_min in 20 step 
to determine the optimal (alpha, lambda) for the data. 
</p>
<p>Generally, the software program performs the following Network GPT Framework to arrive at final network structure: <br>
Step 1. Generating a Complete Graph:
</p>
<p>- SEM-ridge regression (L2 penalty) with k-fold CV: this step find the optimal ridge hyperparameter rho; <br></p>
<p>- fit SEM ridge regression model (L2 penalty) with rho from Step 1, obtain the initial status (non-sparse)
of network structure (B_ridge); <br></p>
<p>Step 2. Elastic net penalized SEM regression with k-fold CV: this step finds the optimal hyperparameter (alpha, lambda); <br></p>
<p>Step 3. Fit elastic net SEM model with (alpha, lambda) from Step 2; This step applies a block cooridnate ascent algorithm, and the complete graph from Step-1 is used as the intial step;  <br></p>
<p>Step 4. Calculate results for PD, FDR, provide the function output.
</p>
<p>For large scale network inference, a standalone C/C++ software with openMPI for 
parallel computation is also available upon request.
</p>


<h3>Usage</h3>

<pre><code class="language-R">elasticNetSEM(Y, X, Missing, B, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>The observed node response data with dimension of M (nodes) by N (samples). Y is normalized inside the function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>The network node attribute matrix with dimension of M by N. Theoretically, X can be L by N matrix, with L being the total
node attributes. In current implementation, each node only allows one and only one attribute. <br>
If you have more than one attributes for some nodes,  please consider selecting the top one by either
correlation or principal component methods.  <br>
If for some nodes there is no attribute available, fill in the rows with all zeros.  See the yeast data 'yeast.rda' for example. <br>
X is normalized inside the function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Missing</code></td>
<td>

<p>Optional M by N matrix corresponding to elements of Y. 0 denotes not missing, and 1 denotes missing.
If a node i in sample j has the label missing (Missing[i,j] = 1), then Y[i,j] is set to 0.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>

<p>Optional input. For a network with M nodes, B is the M by M adjacency matrix.
If data is simulated/with known true network topology (i.e., known adjacency matrix), the Power
of detection (PD) and False Discovery Rate (FDR) is computed in the output parameter 'statistics'.
</p>
<p>If the true network topology is unknown, B is optional, and the PD/FDR in output parameter
'statistics' should be ignored.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>describe the information output from -1 - 10, larger number means more output
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>the function perform CV and parameter inference, calculate power and FDR
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Bout</code></td>
<td>

<p>the computed weights for the network topology. B[i,j] = 0 means there is no edge between node i and j;
B[i,j]!=0 denotes an (undirected) edge between note i and j with B[i,j] being the weight of the edge.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fout</code></td>
<td>

<p>f is 1 by M array keeping the weight for X (in SEM: Y = BY + FX + e). Theoretically, F can be M by L matrix,
with M being the number of nodes, and L being the total node attributes. However, in current implementation,
each node only allows one and only one attribute.
If you have more than one attributes for some nodes, please consider selecting the top one by either
correlation or principal component methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stat</code></td>
<td>

<p>statistics is 1x6 array keeping record of: <br>
1. correct positive <br>
2. total positive   <br>
3. false positive   <br>
4. positive detected  <br>
5. Power of detection (PD) = correct positive/total positive  <br>
6. False Discovery Rate (FDR) = false positive/positive detected
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyperparameters</code></td>
<td>
<p> Model hyperparameters obtained from cross validation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runTime</code></td>
<td>
<p>computational time</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Difference in three functions:<br>
1) elasticNetSEM: Default alpha = 0.95: -0.05: 0.05; default 20 lambdas <br>
2) elasticNetSEMcv: user supplied alphas (one or more), lambdas; compute the optimal parameters and network parameters <br>
3) elasticNetSEMpoint: user supplied one alpha and one lambda, compute the network parameters 
</p>


<h3>Author(s)</h3>

<p>Anhui Huang; Dept of Electrical and Computer Engineering, Univ of Miami, Coral Gables, FL</p>


<h3>References</h3>

<p>1. Cai, X., Bazerque, J.A., and Giannakis, G.B. (2013). Inference of Gene Regulatory Networks with Sparse Structural Equation Models Exploiting Genetic Perturbations. PLoS Comput Biol 9, e1003068. <br>
2. Huang, A. (2014). "Sparse model learning for inferring genotype and phenotype associations." Ph.D Dissertation Chapter 7. University of Miami(1186). <br></p>


<h3>Examples</h3>

<pre><code class="language-R">	library(sparseSEM)
	data(B);
	data(Y);
	data(X);
	data(Missing);
	#Example
	
	  OUT &lt;- elasticNetSEM(Y, X, Missing, B, verbose = 1); 
  

</code></pre>


</div>