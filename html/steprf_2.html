<div class="container">

<table style="width: 100%;"><tr>
<td>RFcv2</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross validation, n-fold for random forest (RF)</h2>

<h3>Description</h3>

<p>This function is a cross validation function
for random forest. It is for functions 'steprf', 'steprfAVI', ect.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RFcv2(
  trainx,
  trainy,
  cv.fold = 10,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predacc</code></td>
<td>
<p>"VEcv" for vecv for numerical data, or "ccr" (i.e., correct
classification rate) or "kappa" for categorical data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with the following component:
vecv for numerical data: ; or
ccr (correct classification rate) for categorical data: .
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(spm)
data(hard)
data(petrel)

rfcv1 &lt;- RFcv2(petrel[, c(1,2, 6:9)], petrel[, 5], predacc = "VEcv")
rfcv1

rfcv2 &lt;- RFcv2(hard[, -c(1, 17)], hard[, 17], predacc = "ccr")
rfcv2

rfcv3 &lt;- RFcv2(hard[, -c(1, 17)], hard[, 17], predacc = "kappa")
rfcv3

n &lt;- 10 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv2(petrel[, c(1,2,6:9)], petrel[, 5], predacc = "VEcv")
VEcv [i] &lt;- rfcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RF", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 10 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv2(hard[, c(4:6)], hard[, 17], predacc = "ccr")
measures &lt;- rbind(measures, rfcv1)
}
plot(measures ~ c(1:n), xlab = "Iteration for RF", ylab = "Correct
classification Rate  (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)


</code></pre>


</div>