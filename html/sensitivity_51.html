<div class="container">

<table style="width: 100%;"><tr>
<td>johnson</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Johnson indices</h2>

<h3>Description</h3>

<p><code>johnson</code> computes the Johnson indices for correlated input relative importance by 
<code class="reqn">R^2</code> decomposition for linear and logistic regression models. These 
indices allocates  a share of <code class="reqn">R^2</code> to each input based on the relative 
weight allocation (RWA) system, in the case of dependent or correlated inputs.
</p>


<h3>Usage</h3>

<pre><code class="language-R">johnson(X, y, rank = FALSE, logistic = FALSE, nboot = 0, conf = 0.95)
## S3 method for class 'johnson'
print(x, ...)
## S3 method for class 'johnson'
plot(x, ylim = c(0,1), ...)
## S3 method for class 'johnson'
ggplot(data,  mapping = aes(), ylim = c(0, 1), ..., environment
                 = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a data frame (or object coercible by <code>as.data.frame</code>)
containing the design of experiments (model input variables).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector containing the responses corresponding to the design
of experiments (model output variables).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rank</code></td>
<td>
<p>logical. If <code>TRUE</code>, the analysis is done on the
ranks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logistic</code></td>
<td>
<p>logical. If <code>TRUE</code>, the analysis is done via a
logistic regression (binomial GLM).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nboot</code></td>
<td>
<p>the number of bootstrap replicates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>
<p>the confidence level of the bootstrap confidence intervals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the object returned by <code>johnson</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>the object returned by <code>johnson</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylim</code></td>
<td>
<p>the y-coordinate limits of the plot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mapping</code></td>
<td>
<p>Default list of aesthetic mappings to use for plot. If not specified, 
must be supplied in each layer added to the plot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>environment</code></td>
<td>
<p>[Deprecated] Used prior to tidy evaluation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments to be passed to methods, such as graphical
parameters (see <code>par</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Logistic regression model (<code>logistic = TRUE</code>) and rank-based indices
(<code>rank = TRUE</code>) are incompatible.
</p>


<h3>Value</h3>

<p><code>johnson</code> returns a list of class <code>"johnson"</code>, containing the following
components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>johnson</code></td>
<td>
<p>a data frame containing the estimations of the johnson
indices, bias and confidence intervals.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Bertrand Iooss and Laura Clouvel
</p>


<h3>References</h3>

<p>L. Clouvel, B. Iooss, V. Chabridon, M. Il Idrissi and F. Robin, 2024,
<em>An overview of variance-based importance measures in the linear regression context: 
comparative analyses and numerical tests</em>, Preprint.
<a href="https://hal.science/hal-04102053">https://hal.science/hal-04102053</a>
</p>
<p>B. Iooss, V. Chabridon and V. Thouvenot, <em>Variance-based importance 
measures for machine learning model interpretability</em>, Congres lambda-mu23,
Saclay, France, 10-13 octobre 2022
<a href="https://hal.science/hal-03741384">https://hal.science/hal-03741384</a>
</p>
<p>J.W. Johnson, 2000, <em>A heuristic method for estimating the relative 
weight of predictor variables in multiple regression</em>, Multivariate 
Behavioral Research, 35:1-19.
</p>
<p>J.W. Johnson and J.M. LeBreton, 2004, <em>History and use of relative 
importance indices in organizational research</em>, Organizational 
Research Methods, 7:238-257.
</p>


<h3>See Also</h3>

<p><code>src</code>, <code>lmg</code>, <code>pmvd</code>, <code>johnsonshap</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
##################################
# Same example than the one in src()

# a 100-sample with X1 ~ U(0.5, 1.5)
#                   X2 ~ U(1.5, 4.5)
#                   X3 ~ U(4.5, 13.5)

library(boot)
n &lt;- 100
X &lt;- data.frame(X1 = runif(n, 0.5, 1.5),
                X2 = runif(n, 1.5, 4.5),
                X3 = runif(n, 4.5, 13.5))

# linear model : Y = X1 + X2 + X3

y &lt;- with(X, X1 + X2 + X3)

# sensitivity analysis

x &lt;- johnson(X, y, nboot = 100)
print(x)
plot(x)

library(ggplot2)
ggplot(x)


#################################
# Same examples than the ones in lmg()

library(boot)
library(mvtnorm)

set.seed(1234)
n &lt;- 1000
beta&lt;-c(1,-1,0.5)
sigma&lt;-matrix(c(1,0,0,
                0,1,-0.8,
                0,-0.8,1),
              nrow=3,
              ncol=3)

##########
# Gaussian correlated inputs

X &lt;-rmvnorm(n, rep(0,3), sigma)
colnames(X)&lt;-c("X1","X2", "X3")

#########
# Linear Model

y &lt;- X%*%beta + rnorm(n,0,2)

# Without Bootstrap confidence intervals
x&lt;-johnson(X, y)
print(x)
plot(x)

# With Boostrap confidence intervals
x&lt;-johnson(X, y, nboot=100, conf=0.95)
print(x)
plot(x)

# Rank-based analysis
x&lt;-johnson(X, y, rank=TRUE, nboot=100, conf=0.95)
print(x)
plot(x)

#######
# Logistic Regression
y&lt;-as.numeric(X%*%beta + rnorm(n)&gt;0)
x&lt;-johnson(X,y, logistic = TRUE)
plot(x)
print(x)

#################################
# Test on a modified Linkletter fct with: 
# - multivariate normal inputs (all multicollinear)
# - in dimension 50 (there are 42 dummy inputs)
# - large-size sample (1e4)

library(mvtnorm)

n &lt;- 1e4
d &lt;- 50
sigma &lt;- matrix(0.5,ncol=d,nrow=d)
diag(sigma) &lt;- 1
X &lt;- rmvnorm(n, rep(0,d), sigma)

y &lt;- linkletter.fun(X)
joh &lt;- johnson(X,y)
sum(joh$johnson) # gives the R2
plot(joh)
</code></pre>


</div>