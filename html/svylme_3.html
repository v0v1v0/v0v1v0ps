<div class="container">

<table style="width: 100%;"><tr>
<td>svy2lme</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Linear mixed models by pairwise likelihood
</h2>

<h3>Description</h3>

<p>Fits linear mixed models to survey data by maximimising the profile pairwise composite
likelihood. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">svy2lme(formula, design, sterr=TRUE,  return.devfun=FALSE,
method=c("general","nested"), all.pairs=FALSE, subtract.margins=FALSE)
## S3 method for class 'svy2lme'
coef(object,...,random=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>

<p>Model formula as in the <code>lme4</code> package</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>design</code></td>
<td>

<p>A survey design object produced by <code>survey::svydesign</code>. The
pairwise weights will be computed from this design, which must have
separate probabilities or weights for each stage of sampling.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sterr</code></td>
<td>

<p>Estimate standard errors for fixed effects? Set to <code>FALSE</code> for
greater speed when using resampling to get standard errors. Also,
a PPS-without-replacement survey design can't get sandwich standard errors
(because fourth-order sampling probabilities would be needed) 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.devfun</code></td>
<td>
<p>If <code>TRUE</code>, return the deviance function as a
component of the object. This will increase the memory use
substantially, but allows for bootstrapping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>"nested"</code> requires the model clusters to have a
single grouping variable that is the same as the primary sampling
unit. It's faster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all.pairs</code></td>
<td>
<p>Only with <code>method="general"</code>, use all pairs
rather than just correlated pairs?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subtract.margins</code></td>
<td>
<p>If <code>TRUE</code> and <code>all.pairs=TRUE</code>,
compute with all pairs by the faster algorithm involving subtraction
from the marginal likelihood</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p><code>svy2lme</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>for method compatibility</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random</code></td>
<td>
<p>if <code>TRUE</code>, the variance components rather than
the fixed effects</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The population pairwise likelihood would be the sum of the
loglikelihoods for a pair of observations, taken over all pairs of
observations from the same cluster.  This is estimated by taking a
weighted sum over pairs in the sample, with the weights being the
reciprocals of pairwise sampling probabilities. The advantage over
standard weighted pseudolikelihoods is that there is no
large-cluster assumption needed and no rescaling of weights. The
disadvantage is some loss of efficiency and simpler point
estimation.
</p>
<p>With <code>method="nested"</code> we have the method of Yi et al
(2016). Using <code>method="general"</code> relaxes the conditions on the
design and model. 
</p>
<p>The code uses <code>lme4::lmer</code> to parse the formula and produce
starting values, profiles out the fixed effects and residual
variance, and then uses <code>minqa::bobyqa</code> to maximise the
resulting profile deviance.
</p>
<p>As with <code>lme4::lmer</code>, the default is to estimate the
correlations of the random effects, since there is typically  no
reason to assume these are zero. You can force two random effects to
be independent by entering them in separate terms, eg
<code>(1|g)+(-1+x|g)</code> in the model formula asks for a random intercept
and a random slope with no random intercept, which will be uncorrelated.
</p>
<p>The internal parametrisation of the variance components uses the
Cholesky decomposition of the relative variance matrix (the variance
matrix divided by the residual variance), as in
<code>lme4::lmer</code>. The component <code>object$s2</code> contains the
estimated residual variance and the component <code>object$opt$par</code>
contains the elements of the Cholesky factor in column-major order,
omitting any elements that are forced to be zero by requiring
indepedent random effects. 
</p>
<p>Standard errors of the fixed effects are currently estimated using a
"with replacement" approximation, valid when the sampling fraction
is small and superpopulation (model, process) inference is
intended. Tthe influence functions are added up within
cluster, centered within strata, the residuals added up within strata, and then
the crossproduct is taken within each stratum. The stratum variance
is scaled by <code>ni/(ni-1)</code> where <code>ni</code> is the number of PSUs
in the stratum, and then added up across strata. When the sampling
and model structure are the same, this is the estimator of Yi et al,
but it also allows for there to be sampling stages before the stages
that are modelled, and for the model and sampling structures to be
different.
</p>
<p>The <code>return.devfun=TRUE</code> option is useful if you want to
examine objects that aren't returned as part of the output. For
example, <code>get("ij", environment(object$devfun))</code> is the set of
pairs used in computation. 
</p>


<h3>Value</h3>

<p><code>svy2lme</code> returns an object with <code>print</code>, <code>coef</code>, and
<code>vcov</code> methods.
</p>
<p>The <code>coef</code> method with <code>random=TRUE</code> returns a two-element
list: the first element is the estimated residual variance, the second
is the matrix of estimated variances and covariances of the random effects.
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley
</p>


<h3>References</h3>

<p>J.N.K. Rao, Fran√ßois Verret and Mike A. Hidiroglou "A weighted composite likelihood approach to inference for two-level models from survey data" Survey Methodology, December 2013  Vol. 39, No. 2, pp. 263-282
</p>
<p>Grace Y. Yi , J. N. K. Rao and Haocheng Li "A WEIGHTED COMPOSITE LIKELIHOOD APPROACH FOR ANALYSIS OF SURVEY DATA UNDER TWO-LEVEL MODELS" Statistica Sinica 
Vol. 26, No. 2 (April 2016), pp. 569-587
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(api, package="survey")

# one-stage cluster sample
dclus1&lt;-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
# two-stage cluster sample
dclus2&lt;-svydesign(id=~dnum+snum, fpc=~fpc1+fpc2, data=apiclus2)

svy2lme(api00~(1|dnum)+ell+mobility+api99, design=dclus1)
svy2lme(api00~(1|dnum)+ell+mobility+api99, design=dclus2)
svy2lme(api00~(1|dnum)+ell+mobility+api99, design=dclus2,method="nested")

lme4::lmer(api00~(1|dnum)+ell+mobility+api99, data=apipop)

## Simulated

set.seed(2000-2-29)

df&lt;-data.frame(x=rnorm(1000*20),g=rep(1:1000,each=20), t=rep(1:20,1000), id=1:20000)
df$u&lt;-with(df, rnorm(1000)[g])

df$y&lt;-with(df, x+u+rnorm(1000,s=2))

## oversample extreme `u` to bias random-intercept variance
pg&lt;-exp(abs(df$u/2)-2.2)[df$t==1]

in1&lt;-rbinom(1000,1,pg)==1
in2&lt;-rep(1:5, length(in1))

sdf&lt;-subset(df, (g %in% (1:1000)[in1]) &amp; (t %in% in2))

p1&lt;-rep(pg[in1],each=5)
N2&lt;-rep(20,nrow(sdf))

## Population values
lme4::lmer(y~x+(1|g), data=df)

## Naive estimator: higher intercept variance
lme4::lmer(y~x+(1|g), data=sdf)

##pairwise estimator
sdf$w1&lt;-1/p1
sdf$w2&lt;-20/5

design&lt;-survey::svydesign(id=~g+id, data=sdf, weights=~w1+w2)
pair&lt;-svy2lme(y~x+(1|g),design=design,method="nested")
pair

pair_g&lt;-svy2lme(y~x+(1|g),design=design,method="general")
pair_g

all.equal(coef(pair), coef(pair_g))
all.equal(SE(pair), SE(pair_g))


</code></pre>


</div>