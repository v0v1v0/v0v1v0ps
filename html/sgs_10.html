<div class="container">

<table style="width: 100%;"><tr>
<td>fit_gslope_cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit a gSLOPE model using k-fold cross-validation.</h2>

<h3>Description</h3>

<p>Function to fit a pathwise solution of group SLOPE (gSLOPE) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fit_gslope_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  nfolds = 10,
  gFDR = 0.1,
  pen_method = 1,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li>
<p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the penalties. Must be between 0 and 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Brzyski et al. (2019)):
</p>

<ul>
<li> <p><code>"1"</code> uses the gMean gSLOPE sequence.
</p>
</li>
<li> <p><code>"2"</code> uses the gMax gSLOPE sequence.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the penalties from <code>pen_method</code> if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code>. To void this behaviour, set <code class="reqn">\lambda = 1</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Fits gSLOPE models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all_models</code></td>
<td>
<p>Fitting information for all models fit on the path, which is a <code>"gslope"</code> object type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"gslope"</code> object type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Brzyski, D., Gossmann, A., Su, W., Bodgan, M. (2019). <em>Group SLOPE â€“ Adaptive Selection of Groups of Predictors</em>, <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269">https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p><code>fit_gslope()</code>
</p>
<p>Other gSLOPE-methods: 
<code>coef.sgs()</code>,
<code>fit_goscar()</code>,
<code>fit_goscar_cv()</code>,
<code>fit_gslope()</code>,
<code>plot.sgs()</code>,
<code>predict.sgs()</code>,
<code>print.sgs()</code>
</p>
<p>Other model-selection: 
<code>as_sgs()</code>,
<code>fit_goscar_cv()</code>,
<code>fit_sgo_cv()</code>,
<code>fit_sgs_cv()</code>,
<code>scaled_sgs()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run gSLOPE with cross-validation
cv_model = fit_gslope_cv(X = data$X, y = data$y, groups=groups, type = "linear", path_length = 5, 
nfolds=5, gFDR = 0.1, min_frac = 0.05, standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>


</div>